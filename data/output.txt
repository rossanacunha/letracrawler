Diabetes mellitus, ou simplesmente diabetes, é um grupo de doenças metabólicas em que se verificam níveis elevados de glicose no sangue durante um longo intervalo de tempo
Os sintomas da elevada quantidade de glicose incluem necessidade frequente de urinar e aumento da sede e da fome
Quando não é tratada, a diabetes pode causar várias complicações
Entre as complicações agudas estão a cetoacidose, coma hiperosmolar hiperglicémico ou morte
Entre as complicações a longo prazo estão doenças cardiovasculares, acidentes vasculares cerebrais, doença renal crónica, úlceras no pé e retinopatia diabética.
A diabetes é o resultado quer de produção de quantidade insuficiente de insulina pelo pâncreas, quer pelas células do corpo que não respondem apropriadamente à insulina que é produzida
Existem três tipos principais de diabetes:
Tanto a prevenção como o tratamento da diabetes consistem em manter uma dieta saudável, praticar regularmente exercício físico, manter um peso normal e abster-se de fumar
Em pessoas com a doença, é importante controlar a pressão arterial e manter a higiene dos pés
A diabetes do tipo 1 deve ser tratada com injeções regulares de insulina
A diabetes do tipo 2 pode ser tratada com medicamentos com ou sem insulina
Tanto a insulina como alguns medicamentos por via oral podem causar baixos níveis de glicose no sangue
Em pessoas obesas com diabetes do tipo 2, a cirurgia de redução do estômago pode ser uma medida eficaz
A diabetes gestacional geralmente resolve-se por si própria após o nascimento do bebé
No entanto, se não for tratada durante a gravidez pode ser a causa de várias complicações para a mãe e para o bebé.
Estima-se que em 2015 cerca de 415 milhões de pessoas em todo o mundo tivessem diabetes
Cerca de 90% dos casos eram diabetes do tipo 2, Isso representa 8,3% da população adulta, afetando em igual proporção mulheres e homens
Em 2014, a tendência sugeria que a prevalência continuaria a aumentar
A diabetes aumenta pelo menos duas vezes o risco de morte prematura
Entre 2012 e 2015, a diabetes foi a causa de entre 1,5 e 5 milhões de mortes anuais
Estima-se que em 2014 o custo económico global da doença tenha sido de 612 mil milhões de dólares.


O termo "diabetes", geralmente, se refere a diabetes mellitus, mas existem muitas outras condições, mais raras, também denominadas como "diabetes"
A diabetes insípida (insípida significa "sem gosto" em Latim), é uma doença rara, na qual há menor alteração na glicose do organismo porém com sintomas semelhantes ao diabetes mellitus
Esta diabetes pode ser causada por danos aos rins ou à glândula pituitária.
No caso da diabetes mellitus tipo 1, esta aparece quando o sistema imunitário do doente ataca as células beta do pâncreas
A causa desta confusão ainda não foi definida, apesar de parecer estar associada a casos de constipações e outras doenças
O tipo de alimentação, o estilo de vida etc
não têm qualquer influência no aparecimento deste tipo de diabetes.
Normalmente, se inicia na infância ou adolescência, e se caracteriza por um déficit de insulina, devido à destruição das células beta do pâncreas por processos autoimunes ou idiopáticos
Só cerca de 1 em 20 pessoas diabéticas tem diabetes tipo 1, a qual se apresenta mais frequentemente entre jovens e crianças
Este tipo de diabetes se conhecia como diabetes mellitus insulino-dependente ou diabetes infantil
Nela, o corpo produz pouca ou nenhuma insulina
As pessoas que padecem dela devem receber injeções diárias de insulina
A quantidade de injeções diárias é variável em função do tratamento escolhido pelo endocrinologista e também em função da quantidade de insulina produzida pelo pâncreas
A insulina sintética pode ser de ação lenta ou rápida: a de ação lenta é ministrada ao acordar e ao dormir (alguns tipos de insulina de ação lenta, porém, são ministradas apenas uma vez por dia) ; a de ação rápida é indicada logo antes de grandes refeições
Para controlar este tipo de diabetes é necessário o equilíbrio de três fatores: a insulina, a alimentação e o exercício.
Sobre a alimentação é preciso ter vários fatores em conta
Apesar de ser necessário algum rigor na alimentação, há de lembrar que este tipo de diabetes atinge essencialmente jovens, e esses jovens estão muitas vezes em crescimento e têm vidas ativas
Assim, o plano alimentar deve ser concebido com isso em vista, uma vez que muitas vezes se faz uma dieta demasiado limitada para a idade e atividade do doente
Para o dia a dia, é desaconselhável a ingestão de carboidratos de ação rápida (sumos, bolos, cremes) e incentivado os de ação lenta (pão, bolachas, arroz, massa...) de modo a evitar picos de glicemia.
Resultados contraditórios têm sido relatados sobre os benefícios da atividade física no controle metabólico desses pacientes
Ainda controverso também é o tipo de exercício (aeróbica ou treinamento resistido), alimentação antes do exercício e dose de insulina mais benéfico neste grupo
A prática de exercícios pode agravar a cetose e hipoglicemia porém diminuem os riscos de problemas cardíacos e melhoram o controle glicêmico e o perfil lipídico especialmente em jovens.(Mais informações sobre exercícios e diabetes tipo 1) Nas grandes cidades existem academias especializadas em pacientes com problemas de saúde e que podem ajudar na escolha e monitoração correta da prática dos exercícios para diabéticos.
Antigamente chamada de "diabetes não insulinodependente" ou "diabetes tardio", tem mecanismo fisiopatológico complexo e não completamente elucidado
Parece haver uma diminuição na resposta dos receptores de glicose presentes no tecido periférico à insulina, levando ao fenômeno de resistência à insulina
As células beta do pâncreas aumentam a produção de insulina e, ao longo dos anos, a resistência à insulina acaba por levar as células beta à exaustão.
Desenvolve-se frequentemente em etapas adultas da vida e é muito frequente a associação com a obesidade e idosos
Vários fármacos e outras causas podem, contudo, causar este tipo de diabetes
É muito frequente a diabetes tipo 2 associada ao uso prolongado de corticoides, frequentemente associado à hemocromatose não tratada.
A diabetes gestacional também envolve uma combinação de secreção e responsividade de insulina inadequados, assemelhando-se à diabetes tipo 2 em diversos aspectos
Ela se desenvolve durante a gravidez e pode melhorar ou desaparecer após o nascimento do bebê
Embora possa ser temporária, a diabetes gestacional pode trazer danos à saúde do feto e/ou da mãe, e cerca de 20% a 50% das mulheres com diabetes gestacional desenvolvem diabetes tipo 2 mais tardiamente na vida.
A diabetes mellitus gestacional (DMG) ocorre em cerca de 2% a 7% de todas as gravidezes
Ela é temporária e completamente tratável mas, se não tratada, pode causar problemas com a gravidez, incluindo macrossomia fetal (peso elevado do bebê ao nascer), malformações fetais e doença cardíaca congênita
Ela requer supervisão médica cuidadosa durante a gravidez
Os riscos fetais/neonatais associados à DMG incluem anomalias congênitas como malformações cardíacas, do sistema nervoso central e de músculos esqueléticos
A insulina fetal aumentada pode inibir a produção de surfactante fetal e pode causar problemas respiratórios
A hiperbilirrubinemia pode causar a destruição de hemácias
Em muitos casos, a morte perinatal pode ocorrer, mais comumente como um resultado da má profusão placentária devido a um prejuízo vascular !
Outros tipos de diabetes <5% de todos os casos diagnosticados:
A tríade clássica dos sintomas da diabetes:
Outros sintomas importantes incluem:
Pode ocorrer perda de peso
Estes sintomas podem se desenvolver bastante rapidamente no tipo 1, particularmente em crianças (semanas ou meses) ou pode ser sutil ou completamente ausente — assim como pode se desenvolver muito mais lentamente — no tipo 2
No tipo 1 pode haver também perda de peso (apesar da fome aumentada ou normal) e fadiga
Estes sintomas podem também se manifestar na diabetes tipo 2 em pacientes cuja doença é mal controlada.
Problemas de visão atingem 40% dos diabéticos insulinodependentes e e 20% dos diabéticos não insulinodependentes
Sendo mais comum em mulheres e entre os 30 aos 65 anos
Caso não seja tratado pode causar catarata, glaucoma e cegueira
Depois de 10 anos de doença, problemas de visão atingem 50% dos pacientes e depois de 30 anos atingem 90%.
Existem várias causas para a diabetes:
Os principais fatores de risco para o diabetes mellitus são:
Ambos os tipos 1 e 2 têm fatores genéticos importantes, sendo o principal fator desencadeante de 20-30% dos casos de tipo 1 e de 5-10% dos casos de diabetes tipo 2
Geralmente essa predisposição genética resulta em disfunção do pâncreas na produção de insulina
O tipo 1 é desencadeado mais cedo, atingindo crianças e adolescentes (principalmente por volta dos 10 aos 14 anos), justamente pelo fator genético
Pode ter tanto origem monogênica (um único gene defeituoso em áreas centrais da produção de insulina) quanto poligênica (vários genes em áreas secundárias)
Os estudos indicam por volta de 20 genes responsáveis mas apenas 13 foram comprovados.
Estudos indicam que cerca de 12% da população ocidental possui um ou mais genes favoráveis ao desenvolvimento de diabetes.
A diabetes tipo 2 (diabetes mellitus tipo 2) também tem um fator genético, ocorrendo simultaneamente em 50 a 80% dos gêmeos idênticos e 20% dos não idênticos
Entre os Pima (nativos americanos do Arizona) 50% da população desenvolve a Diabetes Mellitus tipo 2 enquanto em certos grupos orientais atinge menos de 1%
Porém, é importante lembrar que mesmo com uma genética favorável, hábitos saudáveis servem para prevenir e adiar o aparecimento dessa doença que acomete geralmente apenas os obesos, hipertensos e dislipidêmicos (que compreendem de 90-95% de todos os casos).
O pâncreas é o órgão responsável pela produção do hormônio denominado insulina
Este hormônio é responsável pela regulação da glicemia (glicemia: nível de glicose no sangue)
Para que as células das diversas partes do corpo humano possam realizar o processo de respiração aeróbica (utilizar glicose como fonte de energia), é necessário que a glicose esteja presente na célula
Portanto, as células possuem receptores de insulina (tirosina quínase) que, quando acionados "abrem" a membrana celular para a entrada da glicose presente na circulação sanguínea
Uma falha na produção de insulina resulta em altos níveis de glicose no sangue, já que esta última não é devidamente dirigida ao interior das células.
Visando manter a glicemia constante, o pâncreas também produz outro hormônio antagônico à insulina, denominado glucagon
Ou seja, quando a glicemia cai, mais glucagon é secretado visando restabelecer o nível de glicose na circulação
O glucagon é o hormônio predominante em situações de jejum ou de estresse, enquanto a insulina tem seus níveis aumentados em situações de alimentação recente.
Como a insulina é o principal hormônio que regula a quantidade de glicose absorvida pela maioria das células a partir do sangue (principalmente células musculares e de gordura, mas não células do sistema nervoso central), a sua deficiência ou a insensibilidade de seus receptores desempenham um papel importante em todas as formas da diabetes mellitus.
Grande parte do carboidrato dos alimentos é convertido em poucas horas no monossacarídeo glicose, o principal carboidrato encontrado no sangue
Alguns carboidratos não são convertidos
Alguns exemplos incluem a frutose que é utilizada como um combustível celular, mas não é convertida em glicose e não participa no mecanismo regulatório metabólico da insulina / glicose; adicionalmente, o carboidrato celulose não é convertido em glicose, já que os humanos e muitos animais não têm vias digestivas capazes de digerir a celulose.
A insulina é liberada no sangue pelas células beta (células β) do pâncreas em resposta aos níveis crescentes de glicose no sangue (por exemplo, após uma refeição)
A insulina habilita a maioria das células do corpo a absorverem a glicose do sangue e a utilizarem como combustível, para a conversão em outras moléculas necessárias, ou para armazenamento
A insulina é também o sinal de controle principal para a conversão da glicose (o açúcar básico usado como combustível) em glicogênio para armazenamento interno nas células do fígado e musculares
Níveis reduzidos de glicose resultam em níveis reduzidos de secreção de insulina a partir das células beta e na conversão reversa de glicogênio a glicose quando os níveis de glicose caem.
Níveis aumentados de insulina aumentam muitos processos anabólicos (de crescimento) como o crescimento e duplicação celular, síntese proteica e armazenamento de gordura.
Se a quantidade de insulina disponível é insuficiente, se as células respondem mal aos efeitos da insulina (insensibilidade ou resistência à insulina), ou se a própria insulina está defeituosa, a glicose não será administrada corretamente pelas células do corpo ou armazenada corretamente no fígado e músculos
O efeito dominó são níveis altos persistentes de glicose no sangue, síntese proteica pobre e outros distúrbios metabólicos, como a acidose.
Quando a concentração de glicose no sangue está alta (acima do limiar renal), a reabsorção de glicose no túbulo proximal do rim é incompleta, e parte da glicose é excretada na urina (glicosúria)
Isto aumenta a pressão osmótica da urina e consequentemente inibe a reabsorção de água pelo rim, resultando na produção aumentada de urina (poliúria) e na perda acentuada de líquido
O volume de plasma perdido será reposto osmoticamente da água armazenada nas células do corpo, causando desidratação e sede aumentada.
Quando os níveis altos de glicose permanecem por longos períodos, a glicose causa danos ao sistema circulatório da retina, levando a dificuldades de visão conhecidas como retinopatia diabética
A visão borrada é a reclamação mais comum que leva ao diagnóstico de diabetes; o tipo 1 deve ser suspeito em casos de mudanças rápidas na visão, ao passo que o tipo 2 geralmente causa uma mudança mais gradual.
Pacientes (geralmente os com diabetes tipo 1) podem apresentar também cetoacidose diabética, um estado extremo de desregulação metabólica caracterizada pelo cheiro de acetona na respiração do paciente, respiração de Kussmaul (uma respiração rápida e profunda), poliúria, náusea, vômito e dor abdominal e qualquer um dos vários estados de consciência alterados (confusão, letargia, hostilidade, mania, etc)
Na cetoacidose diabética severa, pode ocorrer o coma (inconsciência), progredindo para a morte
De qualquer forma, a cetoacidose diabética é uma emergência médica e requer atenção de um especialista.
Um estado raro, porém igualmente severo, é o coma hiperosmolar não-cetótico, que é mais comum na diabetes tipo 2, e é principalmente resultante da desidratação devido à perda de líquido corporal
Frequentemente o paciente têm ingerido quantidades imensas de bebidas contendo açúcar, levando a uma desidratação em decorrência da perda de líquido.
Em pacientes que utilizam hipoglicemiantes ou insulina podem ocorrer crises de hipoglicemia se não houver alimentação adequada, uma vez que continua sendo possível a absorção de glicose pelas células
Os sintomas predominantes são confusão mental, agitação ou letargia, sudorese e perda de consciência
Aos primeiros sinais deve ser tentada administração oral de solução doce, mas não sendo possível deverá ser tratado como uma emergência médica e ser medicado com glucagon ou glicose endovenosa.
As complicações da diabetes são muito menos comuns e severas nas pessoas que possuem os níveis glicêmicos (de açúcar no sangue) bem controlados, mantendo-os entre 70 e 100 mg/dl em jejum.
As complicações causadas pela diabetes se dão basicamente pelo excesso de glicose no sangue, sendo assim, existe a possibilidade de glicosilar as proteínas além de retenção de água na corrente sanguínea, e retirada da mesma do espaço intercelular.
A frequência de problemas cardíacos como acidente vascular cerebral (AVC) e ataque cardíaco são entre 2 a 4 vezes maior nas pessoas com diabetes
Os fatores de risco dos problemas crônicos são: hipertensão arterial, alteração do metabolismo das gorduras (aumento do colesterol ruim, aumento dos triglicérides e redução do colesterol bom), tabagismo, obesidade, pouca atividade física e presença de microalbuminúria (proteína na urina).
Para realizar o teste confirmatório do Diabetes o paciente deve permanecer em jejum de 8h (é permitido beber água) antes da primeira coleta de sangue
Em seguida deve-se ingerir 75g de glicose anidra (ou 82,5g de glicose monoidratada), dissolvidas em 250-300ml de água, em no máximo 5 minutos
Uma nova coleta de sangue é feita 2 horas após a ingestão de glicose
Durante a espera o paciente não pode fumar e deve permanecer em repouso.
A diabetes mellitus é caracterizada pela hiperglicemia recorrente ou persistente, e é diagnosticada ao se demonstrar qualquer um dos itens seguintes:
Não é necessário fazer o reteste caso o paciente já possua os sintomas característicos
Caso o nível de glicose esteja entre 140 e 200 após a ingestão da glicose anidra é diagnosticado uma tolerância à glicose diminuída, conhecida como pré-diabetes e que exige que o paciente faça atividade física regular, perca peso e reduza muito seu consumo de carboidratos para não desenvolver diabetes
O mesmo vale para pessoas com nível de glicose no sangue em jejum entre 110 e 126, sendo assim diagnosticados com glicose plasmática de jejum alterada.
Caso a paciente esteja grávida, um nível de glicose acima de 110 em jejum ou de 140 após ingerir 75g de glicose já é suficiente para indicar diabetes gestacional.
Os riscos de complicações em ambos tipos de diabetes podem ser reduzidos com mudanças na dieta e atividades físicas regulares
Os portadores de tolerância diminuída à glicose (TDG) e glicemia de jejum alterada (GJA) devem fazer uma dieta rígida, praticar atividade física pelo menos 3 vezes por semana e, quando necessário e aprovado, usar remédios para evitar complicações
Atividades físicas, dieta rígida e perda de peso entre os grupos de risco diminuem o risco de desenvolvimento do Diabetes tipo 2 pela metade.
A prática de exercícios físicos traz benefícios como a melhor utilização do oxigênio pelo organismo, aumento da captação da glicose pelo músculo e aumento da sensibilidade celular à insulina a partir das primeiras semanas e que dura enquanto eles estiverem sendo regularmente
Com a insulina sendo usada de forma mais eficaz o portador de diabetes passa a precisar de doses menores para queimar a glicose extra.
Em pessoas com pré-diabetes tipo 2, o uso de baixas doses de rosiglitazona (2 mg) e metformina (500 mg) reduz em cerca de 66% o risco de desenvolver diabetes e causa poucos efeitos adversos.
É possível detectar fatores de risco para o desenvolvimento do diabetes tipo 1 utilizando auto anticorpos contra múltiplos antígenos pancreáticos
Existe uma correlação significativa entre a presença de dois ou mais auto anticorpos e o desenvolvimento de diabetes mesmo em indivíduos sem parentes diabéticos (90% dos casos)
Tratamentos com imunossupressores como azatioprina, corticoesteróides e ciclosporina, permitem a diminuição da dose necessária de reposição insulínica porém são poucos efetivos a longo prazo e ao suspender o uso dos imunossupressores além de causarem efeitos colaterais.
Cientistas da Universidade de Maryland descobriram uma proteína, chamada de zonulina, que é produzida em grandes quantidades nas pessoas com doenças autoimunes
Esta superprodução leva numa cadeia de reações à destruição das células beta
Os pesquisadores testaram em ratos uma substância que inibe a ação da zonulina, evitando a progressão das lesões nas células beta pancreáticas
Este inibidor, denominado experimentalmente de AT-1001 agora está sendo testado em humanos.
Quanto melhor o controle, menor será o risco de complicações
Desta maneira, a educação do paciente, compreensão e participação é vital
Os profissionais da saúde que tratam diabetes também tentam conscientizar o paciente a se livrar certos hábitos que sejam prejudiciais à diabetes
Estes incluem ronco, apneia do sono, tabagismo, colesterol elevado (controle ou redução da dieta, exercícios e medicações), obesidade (mesmo uma perda modesta de peso pode ser benéfica), pressão sanguínea alta (exercício e medicações, se necessário) e sedentarismo.
Recomenda-se manter um peso saudável, e ter no mínimo 3 horas de exercício por semana, não ingerir muita gordura, e comer uma boa quantidade de fibras e grãos
Embora os médicos não recomendem o consumo de álcool, um estudo indica que o consumo moderado de álcool pode reduzir o risco.
Segundo estudo de Oliveira e Saito (1989), alguns vegetais brasileiros, podem ser empregados no tratamento da Diabetes Mellitus (DM), o uso de plantas medicinais empregadas no auxilio do tratamento do diabetes vem sendo utilizado há muito tempo
Dentre esses vegetais estão o agrião, alcaçus do Brasil, cajueiro, carqueja amarga, cebola, erva pombinha ou quebra pedras, estevia, hera terrestre, jambolão, pata-de-vaca, pau-ferro, ricinus, sálvia e sucupira.
Na pesquisa, Janebro e colaboradores (2008), utilizaram a farinha da casca de maracujá amarelo (Passiflora edulisf
Flavicarpa Deg.), que possui grande quantidade de pectina, buscando avaliar seu efeito no peso corporal, nos níveis de glicemia e lipídicos dos diabéticos do estudo.
Segundo Janebro e colaboradores (2008) em seu estudo, observaram que a glicemia de jejum obtiveram uma diminuição, quando utilizada a suplementação com a casca do maracujá amarelo já nas quatro semanas do estudo nos pacientes com diabetes
Ou seja, terapias não medicamentosas no tratamento de diabetes também mostram efeito, sendo utilizadas em pacientes que possuem seu metabolismo de forma descompensada ou mesmo os que o tem controlado, de acordo o estudo.
A redução da glicemia de jejum nos pacientes, segundo ensaio clínico mostraram bom resultado após 30 e 60 dias quando realizado tratamento com a farinha da casca do maracujá
De acordo Janebro e colaboradores (2008), esse resultado obtido possivelmente pode ser explicado devido o efeito das fibras contida no maracujá, como a pectina, fazendo com que retarde o esvaziamento gástrico causando no indivíduo uma sensação de saciedade e também retardando o tempo de absorção de carboidratos
Outro fator importante que a pectina traz é que o gel formado, este pode formar complexo com os sais biliares, promovendo a excreção do colesterol, que neste caso pode auxiliar em tratamento de doenças cardiovasculares, obesidade, dislipidemias e na DM.
Na medicina chinesa tradicional, têm sido utilizadas 82 plantas como medicamentos para o tratamento do diabetes
Essas plantas utilizadas em sua maioria apresentam atividade hipoglicemiante, quando submetidas à análise farmacológica e ainda tem elementos químicos que podem ser utilizados como amostra para futuros hipoglicemiantes
(LI et al., 2004 apud Negri, 2005)
Em relação aos legumes e verduras, no estudo de Brito, Buzo e Salado (2009) mostrou-se que 67,47% dos pacientes submetidos informaram que consomem diariamente, pois acreditam que esses alimentos são importantes, fazendo com o que auxiliam no controle glicêmico.
Segundo a Organização Mundial de saúde, a dieta dos portadores de diabetes é algo de suma importância, pois é um fator que ajuda manter os níveis glicêmicos dentro dos padrões estabelecidos.(RIQUE; SOARES; MEIRELLES, 2002 apud Brito; Buzo e Salado, 2009).
A diabetes mellitus é uma doença crônica, sem cura por tratamentos convencionais, e sua ênfase médica deve ser necessariamente em evitar/administrar problemas possivelmente relacionados à diabetes, a longo ou curto prazo.
O tratamento é baseado em cinco conceitos:
É extremamente importante a educação do paciente, o acompanhamento de sua dieta, exercícios físicos, monitoração própria de seus níveis de glicose, com o objetivo de manter os níveis de glicose a longo e curto prazo adequados
Um controle cuidadoso é necessário para reduzir os riscos das complicações a longo prazo.
Isso pode ser alcançado com uma combinação de dietas, exercícios e perda de peso (tipo 2), várias drogas diabéticas orais (tipo 2 somente) e o uso de insulina (tipo 1 e tipo 2 que não esteja respondendo à medicação oral)
Além disso, devido aos altos riscos associados de doença cardiovascular, devem ser feitas modificações no estilo de vida de modo a controlar a pressão arterial e o colesterol, se exercitando mais, fumando menos e consumindo alimentos apropriados para diabéticos, e se necessário, tomando medicamentos para reduzir a pressão.
O uso de bombas de insulina podem ajudar na administração regular de insulina, porém tem custo elevado quando comparadas as seringas comuns
Outras opções incluem as canetas de insulina e os injetores de insulina a jato.
Um estudo feito por médicos franceses publicado na ScienceDirect, confirmou o que médicos já haviam observado, a cirurgia de redução de estômago (gastroplastia) usada no tratamento da obesidade mórbida ajuda a controlar o diabetes mellitus tipo 2, um estudo mais aprofundado feito por Francesco Rubino, levou à criação de uma cirurgia no intestino que tem alta eficiência no tratamento da diabetes tipo 2 para pessoas não obesas.
Atualmente, dispomos de 8 classes diferentes para o tratamento medicamentoso do diabetes, cada uma dessas classes agindo em pontos distintos da complexa fisiopatologia do diabetes
São elas:
Pacientes com diabetes precisam controlar e monitorar seus níveis de glicose no sangue constantemente, como parte do tratamento da doença
Isso vale tanto para pacientes que fazem o uso de insulina, como para os que não fazem.
O automonitoramento, por meio de medidores de glicose portáteis, é um dos principais componentes do gerenciamento da doença.
Com esse controle, os pacientes conseguem entender melhor o impacto da alimentação, da atividade física, dos medicamentos e também começam a reconhecer, tratar e prevenir episódios de hipo ou hiperglicemia.
A falta de controle e as oscilações extremas nos níveis de glicemia, tanto para baixo (hipoglicemia) como para cima (hiperglicemia) causam, em longo prazo, uma série de consequências graves no organismo.
Embora proporcione uma série de benefícios comprovados, o automonitoramento nem sempre é feito da forma adequada
Uma revisão de estudos de países da América Latina descobriu que somente 74% dos pacientes com diabetes tipo 1 e 38,5% dos pacientes tipo 2 são usuários de medidor de glicemia.
O automonitoramento continua sendo um dos principais métodos para fornecer informação imediata e útil entre os intervalos das consultas médicas sobre como a pessoa está lidando com seu controle glicêmico e pode permitir que o paciente decida sobre seu estilo de vida.
Quando os pacientes medem sua glicemia, eles recebem imediatamente o retorno do resultado do seu estilo de vida e tratamento médico e que pode ser usado tanto pelo paciente quanto pelo médico para avaliar e modificar todos os aspectos do tratamento
O automonitoramento também aumenta a autonomia e a adesão ao tratamento pelo paciente.
Estima-se que hoje quase 25 milhões de pessoas na América Latina sejam diabéticas, sendo que metade desses pacientes está no Brasil.
Somente 36% dos pacientes com o tipo 2 da doença e 21% do tipo 1 conseguem controlar os níveis glicêmicos.
Em média, um terço deles deixa de seguir as recomendações médicas um ano após o diagnóstico
A falta de controle da doença, decorrente dos maus hábitos de vida, acarreta em longo prazo em uma série de consequências para o organismo
Sem o controle adequado das taxas de glicose, aumentam as chances de complicações cardiovasculares, renais, oculares, entre outras.
Pacientes diabéticos têm de duas a quatro vezes mais chances de sofrer um infarto ou derrame do que uma pessoa que não tenha a doença
Da mesma forma, 65% dos pacientes estão em risco de ter ou já têm algum grau de disfunção renal, condição que triplica o risco de eventos cardiovasculares
As consequências do diabetes incluem ainda disfunção sexual (presente em 60% dos homens com a doença), alterações oculares como retinopatia e risco de cegueira, e ainda problemas de circulação nos membros inferiores.
Foram identificados atualmente, que mais de 800 tipos de plantas são utilizados no tratamento do DM (Saxena et al., 2004)
Vários estudos científicos avaliaram a ação de plantas medicinais sobre a diabetes, resultados relevantes foram encontrados:
Os cientistas acreditam que o desenvolvimento da edição do genoma humano usando CRISPR pode, eventualmente, resultar em uma nova abordagem para combater as infecções virais e tumores cancerosos, fazendo a edição de gene nas células T do sistema imunológico em laboratório antes de colocá-las de volta no paciente para protege-lo contra uma ampla gama de doenças, de diabetes ao HIV e cancer.
O tratamento do DM tem como parâmetro importante o controle metabólico, com a utilização de terapias farmacológicas ou não (BOAS et al, 2012)
Terapias não farmacológicas são aquelas em que há alteração nos hábitos alimentares e atividade física (BOAS et al, 2012)
Para o indivíduo diabético, a correção de seus hábitos alimentares juntamente com a prática regular de exercícios físicos, são fatores cruciais e tratamento inicial para o controle do diabetes mellitus, conforme mostra estudo de Boas e colaboradores (2012).
De acordo com a Organização Mundial da Saúde, em 2006 havia cerca de 170 milhões de pessoas doentes da diabetes, e esse índice aumenta rapidamente
É estimado que em 2030 esse número dobre
A diabetes mellitus ocorre em todo o mundo, mas é mais comum (especialmente a tipo II) nos países mais desenvolvidos
O maior aumento atualmente é esperado na Ásia e na África, onde a maioria dos diabéticos será visto em 2035
O aumento do índice de diabetes em países em desenvolvimento segue a tendência de urbanização e mudança de estilos de vida.
A diabetes está na lista das cinco doenças de maior índice de morte no mundo, e está chegando cada vez mais perto do topo da lista
Por pelo menos 20 anos, o número de diabéticos na América do Norte está aumentando consideravelmente
Em 2005, eram em torno de 20,8 milhões de pessoas com diabetes somente nos Estados Unidos
De acordo com a American Diabetes Association existem cerca de 6,2 milhões de pessoas não diagnosticadas e cerca de 41 milhões de pessoas que poderiam ser consideradas pré-diabéticas
Os Centros de Controles de Doenças classificaram o aumento da doença como epidêmico, e a NDIC (National Diabetes Information Clearinghouse) fez uma estimativa de US$132 bilhões de dólares, somente para os Estados Unidos este ano.
A diabetes tipo 1 ocorre em frequência menor em indivíduos negros e asiáticos e com frequência maior na população europeia, principalmente nas populações provenientes de regiões do norte da Europa
A frequência entre japoneses é cerca de 20 vezes menor que entre escandinavos
Em São Paulo a incidência do tipo 1 é de 7,6 casos a cada 100.000 habitantes.
A diabetes afeta cerca de 12% da população no Brasil (aproximadamente 22 milhões de pessoas) e 5% da população de Portugal (500 mil pessoas).
O número de pessoas com diabetes em Portugal ultrapassou pela primeira vez a fasquia de um milhão em 2011, mas este foi o ano, na última década, em que se observou a maior queda no total de amputações, uma das principais complicações decorrentes desta doença
Em 2016, quase um milhão de portugueses com mais de 30 anos sofre de diabetes, doença que mata mais de 12 pessoas por dia em Portugal
De acordo com o primeiro relatório global sobre a Diabetes da Organização Mundial da Saúde (OMS), a prevalência da diabetes tem vindo a aumentar nas últimas décadas e Portugal não é exceção, estimando-se que 9,2% dos portugueses (aproximadamente 952 mil pessoas) sofram desta doença, predominantemente homens (10,7%), mas também mulheres (7,8%).
A diabetes mellitus já era conhecida antes da era cristã
No papiro de Ebers descoberto no Egito, correspondente ao século XV antes de Cristo, já se descrevem sintomas que parecem corresponder à diabetes.
Foi Areteu da Capadócia quem, no século II, deu a esta doença o nome de "diabetes", que em grego significa "sifão", referindo-se ao seu sintoma mais chamativo que é a eliminação exagerada de água pelos rins, expressando que a água entrava e saía do organismo do diabético sem fixar-se nele (polidipsia e poliúria, características da doença e por ele avaliadas por esta ordem)
Ainda no século II, Galeno, contemporâneo de Areteu, também se referiu à diabetes, atribuindo-a à incapacidade dos rins em reter água como deveriam.
Nos séculos posteriores não se encontram nos escritos médicos referências a esta enfermidade até que, no século XI, Avicena refere com precisão esta afecção em seu famoso Cânon da Medicina.
Após um longo intervalo, Thomas Willis fez, em 1679, uma magistral descrição da diabetes para a época, ficando desde então reconhecida por sua sintomatologia como entidade clínica
Foi ele quem, referindo-se ao sabor doce da urina, lhe deu o nome de diabetes mellitus (sabor de mel), apesar de esse fato já ter sido registrado cerca de mil anos antes na Índia, por volta do ano 500.
Em 1775, Dopson identificou a presença de glicose na urina
Frank, por essa altura também, classificou a diabetes em duas formas: diabetes mellitus (ou vera), e insípida, esta sem apresentar urina doce
A primeira observação feita através de uma necropsia em um diabético foi realizada por Cawley e publicada no London Medical Journal em 1788
Quase na mesma época o inglês John Rollo, atribuindo à doença uma causa gástrica, conseguiu melhorias notáveis com um regime rico em proteínas e gorduras e limitado em hidratos de carbono.
Os primeiros trabalhos experimentais relacionados com o metabolismo dos glicídios foram realizados por Claude Bernard, o qual descobriu, em 1848, o glicogênio hepático e provocou a aparição de glicose na urina excitando os centros bulbares
Ainda na metade do século XIX, o grande clínico francês Bouchardat assinalou a importância da obesidade e da vida sedentária na origem da diabetes e traçou as normas para o tratamento dietético, baseando-a na restrição dos glicídios e no baixo valor calórico da dieta
Os trabalhos clínicos e anatômico-patológicos adquiriram grande importância em fins do século XIX, nas mãos de Frerichs, Cantani, Naunyn, Lanceraux etc., tendo culminado em experiências de pancreatectomia em cães, realizadas por Mering y Mikowski em 1889.
A busca do suposto hormônio produzido pelas ilhotas de Langerhans, células do pâncreas descritas em 1869 por Paul Langerhans, iniciou-se de imediato
Hedon, Gley, Laguessee Sabolev estiveram muito próximos do almejado triunfo, o qual foi conseguido pelos jovens canadenses Banting e Charles Best, que conseguiram, em 1921, isolar a insulina e demonstrar seu efeito hipoglicêmico
Esta descoberta significou uma das maiores conquistas médicas do século XX, porque transformou as expectativas e a vida dos diabéticos e ampliou horizontes no campo experimental e biológico para o estudo da diabetes e do metabolismo dos glicídios.
Posteriormente, o transplante de pâncreas passou a ser considerado uma alternativa viável à insulina para o tratamento da diabetes mellitus do tipo 1
O primeiro transplante de pâncreas com essa finalidade foi realizado em 1966, na universidade de Manitoba.
Uma linha mais recente de pesquisa na Medicina tem buscado fazer o transplante apenas das ilhotas de Langerhans
O procedimento é simples, tem poucas complicações e exige uma hospitalização de curta duração
O grande problema é a obtenção das células, que são originárias de cadáveres
São necessários em média três doadores para se conseguir um número razoável de células.
O termo latino "diabetes" tem origem no vocábulo grego διαβήτης, por sua vez derivado do verbo διαβαίνω, que significa «passar através»
Também proveniente do latim, o termo mellitus significa «aquilo que contém mel; doce como o mel», numa referência ao excesso de glicose presente na urina do portador da doença.
Quanto ao gênero da palavra diabetes, em português é possível usar igualmente o masculino ("o diabetes"), como o feminino ("a diabetes")
Todavia, de um ponto de vista etimológico e filológico, é mais correto empregar a palavra no gênero masculino para concordar com a palavra latina mellitus, que está no masculino
Neste verbete, por questão de uniformização, optou-se pelo gênero masculino.
Já a palavra "diabete", sem a letra "s" final, é uma «forma não preferencial» segundo o Dicionário Houaiss da Língua Portuguesa.
Uma doença metabólica ocorre quando os processos metabólicos normais do corpo são alterados por reações químicas anormais.
A hiperglicemia (do grego, ὑπέρ- "excesso", γλυκός "açúcar", αἷμα "sangue") é uma condição caracterizada pelo elevado nível de glicose no sangue
Os níveis normais de glicose no sangue está entre 70 e 99mg/dL em jejum 8h e entre 100 e 140mg/dL pós-prandial (depois de comer)
Níveis alterados desses valores podem sugerir crises hipo ou hiperglicêmicas, por diversas etiologias (origens)
Ao persistirem os níveis alterados, a procura a um serviço de saúde se torna essencial, podendo caracterizar-se por quadros patológicos, como a Diabetes Mellitus.


A glicemia pode ser elevada por:
Uma glicemia superior a 200mg/dL pode causar:
Níveis elevados de glicose no sangue podem conduzir, a longo prazo, a alterações irreversíveis nos nervos e nos grandes e pequenos vasos sanguíneos
O diabetes também pode reduzir a capacidade do corpo em resistir a infecções, assim como aumentar a propensão a problemas oculares, doenças renais, pressão alta, ataques cardíacos, acidentes vasculares-cerebrais e amputação de membros superiores e inferiores.
Entre as complicações crónicas da hiperglicemia relacionam-se:
Caracterizada pelo comprometimento dos vasos sanguíneos capilares, por nefropatia e retinopatia.
Caracterizada pelo comprometimento dos vasos arteriais e por deficiência circulatória no cérebro, coração e membros inferiores.
Caracterizada por alterações na visão como a percepção de pontos flutuantes, anéis ou halos coloridos, dificuldade de visão diurna, pressão ou dor sobre os olhos, ou hipersensibilidade à luz.
Caracterizada pela presença de albuminúria persistente (excreção de albumina em níveis superiores a 300 mg/dl) na ausência de outro distúrbio renal.
Caracterizada pela sensação de formigueiros, impotência sexual, alterações digestivas, urinárias e/ou circulatórias, ressecamento da pele, lesões ulcerosas nos pés e pernas, entre outros.
Os diabéticos que fazem a monitorização da glicose rotineiramente podem detectar aumentos da glicemia, sem, entretanto, apresentar sintomas de hiperglicemia
Para estes pacientes recomenda-se regularmente verificar o nível da glicose no sangue
Isto pode ser feito preferencialmente nas seguintes ocasiões:
Mais de 200mg/dL de glicemia a qualquer momento, é critério diagnóstico de diabetes mellitus.
Caso sejam identificados níveis elevados de glicose no sangue, deve-se procurar um médico ou um serviço de saúde para diagnóstico e tratamento apropriados
O controle adequado da hiperglicemia pode auxiliar a prevenir e não evitar os problemas, em conjunto com mudanças saudáveis no estilo de vida do paciente como:
Polaquiúria ou Polaciúria (do grego poli muita, latim aqua água e uria urina) é um sintoma urinário caracterizado por aumento do número de micções com diminuição do volume da urina, ou seja, urinar pouca quantidade muitas vezes ao dia
É comum a queixa ser "vou ao banheiro toda hora, mas só saem algumas gotinhas"
Pode vir associado à disúria (dor ou queimação ao urinar), dor na parte inferior do abdômen e sentir urgência para urinar
Está associado a problemas dos esfíncteres urinários
Poliúria é diferente de polaquiúria, pois significa urinar muito, em grande volume.
Entre as crianças, urinar 5 a 12 vezes é normal, e mais de 12 vezes por dia é excessivo
Entre adolescentes e adultos até 6 vezes é normal, mais que 6 em pequeno volume é poliaquiúria.
Vários fatores podem estar relacionados à micção freqüente, tais como:
Causas menos comuns incluem:
As doenças agudas são aquelas que têm um curso acelerado, terminando com convalescença ou morte em menos de três meses.
A maioria das doenças agudas caracteriza-se em várias fases
O inicio dos sintomas pode ser abrupto ou insidioso, seguindo-se uma fase de deterioração até um máximo de sintomas e danos, fase de plateau, com manutenção dos sintomas e possivelmente novos picos, uma longa recuperação com desaparecimento gradual dos sintomas, e a convalescência, em que já não há sintomas específicos da doença mas o indivíduo ainda não recuperou totalmente as suas forças
A fase de recuperação podem ocorrer as recrudescências, que são exacerbamentos dos sintomas de volta a um máximo ou plateau, e na fase de convalescência as recaídas, devido à presença continuada do factor desencadeante e do estado debilitado do indivíduo, além de (novas) infecções.
As doenças agudas distinguem-se dos episódios agudos das doenças crónicas, que são exacerbação de sintomas normalmente menos intensos nessas condições.
A cetoacidose é um tipo de acidose metabólica causada por altas concentrações de cetoácidos, uma consequência do metabolismo de lipídeos
É mais comum em portadores de diabetes mellitus tipo 1 , quando o fígado quebra a gordura em resposta a uma necessidade percebida pela dificuldade da quebra de glicose
Ela também pode ocorrer após um jejum prolongado.


A quantidade de cetoácidos aumenta quando o corpo é forçado a consumir ácidos graxos para se manter, devido à falta de glicose dentro da célula
Pode ser causada por desnutrição ou jejum prolongado, porém geralmente é uma decorrência de uma falta de insulina grave e de um estado de resistência a insulina, e tem como critérios clínicos:
Os fatores desencadeantes mais comuns variam com a idade:
Deve-se iniciar pelo tratamento do desequilíbrio hidroeletrolítico com soro fisiológico endovenoso para reposição contínua das perdas hídricas, correção dos déficits de eletrólitos e da hiperglicemia
Também pode ser necessário corrigir um desequilíbrio ácido-base, como uma acidose metabólica
O uso correto da insulina intravenosa pode eventualmente corrigir o problema
Diálise pode ser feita em casos de azotemia
Assistência respiratória pode ajudar a equilibrar o dióxido de carbono plasmático a níveis adequados
e Após esse tratamento é importante prescrever uma dieta adequada em proteínas e sais minerais para compensar a degradação de proteínas (catabolismo) e evitar futuros episódios.
Possíveis complicações incluem:
Metabólica: Intervalo aniônico elevado (cetoacidose/cetoacidose diabética, láctica) · Intervalo aniônico normal (hiperclorêmica, tubular renal)
Metabólica: Alcalose de contração

Coma hiperosmolar hiperglicémico é uma complicação da diabetes mellitus (predominantemente do tipo 2), na qual o elevado nível de açúcar no sangue causa desidratação acentuada, o aumento da osmolaridade e risco elevado de complicações, coma e morte
É diagnosticada através de análises sanguíneas.


Doença crónica  ou crônica  é uma doença que não é resolvida num tempo curto, definido usualmente em três meses.
As doenças crónicas são doenças que não põem em risco a vida da pessoa num prazo curto, logo não são emergências médicas
No entanto, elas podem ser extremamente sérias, e várias doenças crónicas, como por exemplo certos tipos de cancro, causam morte certa
As doenças crónicas incluem também todas as condições em que um sintoma existe continuamente, e mesmo não pondo em risco a saúde física da pessoa, são extremamente incômodas levando à disrupção da qualidade de vida e atividades das pessoas
Neste último caso, incluem-se os síndromes dolorosos.
Muitas doenças crónicas são assintomáticas ou quase assintomáticas a maior parte do tempo, mas caracterizam-se por episódios agudos perigosos e/ou muito incômodas.
As doenças crónicas de causa infecciosa são frequentemente causadas por organismos invasores com os quais já foi atingido um equilíbrio
Não é do interesse dos vírus, das bactérias ou dos parasitas matarem o seu hóspede demasiadamente rápido, uma vez que a probabilidade de se espalharem a outros hospedes fica reduzida
Assim doenças infecciosas de morte rápida e mortalidade elevada, como Ébola, aparecem por vezes, mas nunca conseguem estabelecer-se, porque todos os indivíduos susceptíveis morrem em poucos dias, antes de poderem contactar com bastantes outros
Doenças como a SIDA/AIDS, pelo contrário são extremamente eficazes devido ao longo tempo que demoram a matar o hóspede
Mas a melhor acomodação, do ponto de vista do micro-organismo, é permanecer no corpo do hóspede sem causar muitos danos a este até poder infetar a nova geração sem defesas
É o que faz a varicela
O vírus ataca as crianças produzindo a síndrome característica aguda, mas depois da "cura" o vírus permanece, em todos os casos, nos núcleos nervosos dos nervos sensitivos, sem ser detetada e sem estar ativa
Na velhice, com a ligeira imunodeficiência que acompanha a idade avançada, ela frequentemente reaparece sob a forma de zoster uma infeção dolorosa mas não perigosa que ataca os nervos periféricos
As zonas cutâneas com zoster são extremamente infecciosas, permitindo a passagem perpétua do vírus dos idosos às crianças indefesas, sem necessitar de grandes populações de crianças sempre passando o vírus umas às outras, como outros vírus infantis.
Doenças cardiovasculares são uma classe de doenças que afetam o coração ou os vasos sanguíneos
Entre estas doenças estão as doenças arteriais coronárias, como a angina de peito e o enfarte agudo do miocárdio, acidentes vasculares cerebrais (AVC), cardiopatia hipertensiva, febre reumática, miocardiopatia, arritmia cardíaca, cardiopatia congénita, valvulopatias, cardite, aneurisma da aorta, doença arterial periférica e trombose venosa.
Os mecanismos subjacentes variam de acordo com a doença em questão
A doença arterial coronária, os acidentes vasculares cerebrais e a doença arterial periférica envolvem aterosclerose, que pode ser causada por hipertensão arterial, tabagismo, diabetes, falta de exercício físico, obesidade, colesterol elevado, dieta inadequada e consumo excessivo de bebidas alcoólicas
A hipertensão arterial é a causa de 13% das mortes por doenças cardiovasculares, o tabaco de 9%, a diabetes de 6%, a falta de exercício de 6% e a obesidade de 5%
A febre reumática cardíaca pode ter origem numa faringite estreptocócica que não tenha sido tratada.
Estima-se que 90% dos casos de doenças cardiovasculares possam ser evitados com medidas de prevenção
A prevenção da aterosclerose pode ser feita diminuindo os fatores de risco, através de medidas como seguir uma alimentação saudável, praticar exercício físico, evitar a exposição ao fumo de tabaco e limitando o consumo de álcool
O tratamento da hipertensão arterial e da diabetes também é benéfico
O tratamento das pessoas com faringite estreptocócica com antibióticos pode diminuir o risco de febre reumática
Ainda não é claro o benefício do uso de aspirina em pessoas de outra forma saudáveis
O United States Preventive Services Task Force recomenda que a aspirina não seja usada como medida de prevenção em mulheres com menos de 55 e homens com menos de 45 anos de idade, embora seja recomendada em alguns indivíduos mais idosos
O tratamento de pessoas com doenças cardiovasculares melhora o prognóstico.
As doenças cardiovasculares são a principal causa de morte em todo o mundo, exceto em África
Em conjunto, foram responsáveis pela morte de 17,3 milhões de pessoas em 2013 (31,5%), um aumento em relação às 12,3 milhões em 1990 (25,8%)
Quando padronizadas para a idade, as mortes por doenças cardiovasculares são mais comuns e têm vindo a aumentar em grande parte dos países em vias de desenvolvimento, enquanto nos países desenvolvidos têm vindo a diminuir desde a década de 1970
A doença arterial coronária e o AVC são responsáveis por 80% das mortes por doenças cardiovasculares em homens e 75% em mulheres
As doenças cardiovasculares são progressivamente mais comuns com o avanço da idade
Nos Estados Unidos, apenas 11% das pessoas entre os 20 e 40 anos têm doenças cardiovasculares, 37% entre os 40 e 60 anos de idade, 71% entre os 60 e 80 anos de idade e 85% em pessoas com mais de 80 anos
A idade média de morte por doença arterial coronária em países desenvolvidos é de 80 anos, enquanto que nos países em desenvolvimento é de 68 anos
A doença manifesta-se em média sete a dez anos mais cedo em homens do que em mulheres.
Miocardite (Doença de Chagas)
Cardiomiopatia: Dilatada (Alcoólica) · Hipertrófica · Restritiva (Endocardite de Loeffler, Amiloidose cardíaca, Fibroelastose endocardíaca)
Fibrose cardíaca · Cardiomegalia · Hipertrofia ventricular (Esquerdo, Direito/Corpulmonale)
Um acidente vascular cerebral (AVC) ocorre quando problemas na irrigação sanguínea do cérebro causam a morte das células, o que faz com que partes do cérebro deixem de funcionar devidamente
Existem dois tipos principais de AVC: isquémico, causado pela interrupção da irrigação sanguínea, e hemorrágico, causado por uma hemorragia
Entre os sinais e sintomas de um AVC estão a incapacidade de mover ou de sentir um dos lados do corpo, dificuldades em compreender ou em falar, sensação de que os objetos em volta se movimentam ou perda de um dos lados da visão
Na maior parte dos casos, os sinais e sintomas manifestam-se imediatamente após o AVC
Quando a duração dos sintomas é inferior a uma ou duas horas, o episódio denomina-se acidente isquémico transitório (AIT), ou mini-derrame
Uma hemorragia subaracnóidea pode também estar associada a dores de cabeça intensas
Os sintomas de um AVC podem ser permanentes
Entre as complicações a longo prazo estão a pneumonia ou incontinência urinária.
O principal fator de risco de um AVC é a hipertensão arterial
Entre outros fatores de risco estão fumar, a obesidade, colesterol elevado, diabetes, ter tido anteriormente um acidente isquémico transitório e fibrilação auricular
Um AVC isquémico é geralmente causado pelo bloqueio de um vaso sanguíneo, embora existam outras causas menos comuns
Um AVC hemorrágico é causado por um derrame, quer por uma hemorragia diretamente no cérebro quer por uma Hemorragia subaracnóidea no espaço entre as meninges
Estas hemorragias podem ocorrer devido à rutura de um aneurisma cerebral
O diagnóstico é geralmente feito com recurso a imagiologia médica, como uma TAC ou ressonância magnética, acompanhada por uma avaliação física da pessoa
Podem ser realizados outros exames, como análises ao sangue ou eletrocardiograma, para determinar fatores de risco e descartar outras possíveis causas
A hipoglicemia pode provocar sintomas semelhantes a um AVC.
A prevenção consiste em diminuir os fatores de risco, assim como na possibilidade de ser administrada aspirina ou estatinas
Em pessoas com estenose da carótida pode ser considerada uma Endarteriectomia para alargar as artérias do cérebro
Em pessoas fibrilação auricular pode ser administrada varfarina
Um AVC ou AIT geralmente necessita de assistência médica urgente
Quando um AVC isquémico é detectado nas primeiras três horas e meia a quatro horas, é possível ser tratado com medicação trombolítica que dissolve os coágulos sanguíneos e com aspirina
Em alguns AVC hemorrágicos pode ser considerada neurocirurgia
Algumas das funções perdidas durante o AVC podem ser recuperadas com tratamentos de reabilitação e recuperação
No entanto, em muitas regiões do mundo estes tratamentos não estão disponíveis.
Em 2013 cerca de 6,9 milhões de pessoas sofreram um AVC isquémico e 3,4 milhões um AVC hemorrágico
Em 2010, encontravam-se vivas cerca de 33 milhões de pessoas que no passado tinham sofrido um AVC
Entre 1990 e 2010 o número de AVC ocorrido em cada ano diminuiu cerca de 10% nos países desenvolvidos e aumentou cerca de 10% nos países em vias de desenvolvimento
Em 2013, os AVC foram a segunda principal causa de morte, a seguir à doença arterial coronária, tendo sido responsáveis por 6,4 milhões de mortes em todo o mundo, o que corresponde a 12% do total de mortes
Cerca de 3,3 milhões de mortes foram causadas por AVC isquémico e 3,2 milhões por AVC hemorrágico
Cerca de metade das pessoas que sofrem um AVC vivem menos de um ano
Dois terços dos AVC ocorrem em pessoas com mais de 65 anos de idade.


Os acidentes vasculares do cérebro podem ser basicamente decorrentes da obstrução de uma artéria que irriga o cérebro (ou seja, por isquemia) ou podem ser por vazamento de sangue de um vaso sanguíneo (ou seja, hemorrágico)
Cabe ressaltar que o termo "derrame" não é apropriado, visto que em apenas uma parte dos AVC's (na verdade a minoria deles) ocorre um derramamento de sangue no parênquima encefálico.
É o tipo de AVC mais comum, presente em cerca de 80% dos casos
Ocorre pela falta de fluxo sanguíneo cerebral, levando ao sofrimento e enfarte do parênquima do sistema nervoso
Essa queda no fluxo sanguíneo pode ser decorrente de:
Nos primeiros momentos do AVC isquêmico não há morte de tecido cerebral, mas a falta de suprimento sanguíneo provoca a rápida degeneração do tecido cerebral, um tecido metabolicamente muito ativo e que demanda muito oxigénio e glicose para manter seus neurónios vivos
A área central do acidente vascular morre em pouco tempo, pois está praticamente sem nenhum fluxo de sangue
Todavia, existe uma região ao redor do infarto central que possui um fluxo de sangue reduzido, que se mantém viável por mais tempo
A essa área dá-se o nome de penumbra
É na penumbra, uma área parcialmente perfundida, mas ainda viável, que deve-se concentrar os esforços terapêuticos
É por isso também que o tempo do início do ataque vascular cerebral até a reversão da obstrução de sangue é importante na evolução do AVC isquêmico.
O AIT ou ataque isquêmico transitório pode ser considerado um tipo de AVC isquêmico
Corresponde a uma isquemia (entupimento) passageira que não chega a constituir uma lesão neurológica definitiva e não deixa sequela
Ou seja, é um episódio súbito de déficit sanguíneo em uma região do cérebro com manifestações neurológicas que se revertem em minutos ou em até 24 horas sem deixar sequelas (se deixar sequelas por mais de 24 horas, passa a se chamar acidente isquêmico vascular por definição)
Constitui um fator de risco muito importante, visto que uma elevada porcentagem dos pacientes com AIT apresentam um AVC nos dias subsequentes
É possível que a definição de AIT venha a sofrer alterações, pois com exames mais acurados já é possível identificar lesões/sequelas cerebrais antes imperceptíveis em alguns AITs e, além disso, estudos clínicos mostram que a maioria dos AITs dura menos de 1 hora
Assim, o AIT que dura mais de uma hora provavelmente será um AVC e talvez possa provocar uma lesão cerebral, mesmo que imperceptível.
É o acidente vascular cerebral menos comum presente em cerca de 20% dos casos, mas não menos grave
Ocorre pela ruptura de um vaso sanguíneo intracraniano
O sangue em contato com o parênquima nervoso tem ação irritativa
Além disso, a inflamação e o efeito de massa ou pressão exercida pelo coágulo de sangue no tecido nervoso prejudica e degenera o cérebro e a função cerebral
Pode ser divido em dois tipos, O sangramento intraparenquimatoso ou a hemorragia subaracnóidea:
O diagnóstico do AVC é clínico, ou seja, é feito pela história e exame físico do paciente
Os principais sintomas são:
Durante um exame pode-se pedir ao paciente que sorria, levante os dois braços e repita uma frase (como "trinta e três")
Diante desses sintomas, quanto mais rápido o socorro, menor a probabilidade de sequelas, este teste é designado Escala de Cincinnati
Outros sintomas menos específicos, como queda do estado geral e coma, também elevam o risco de AVC.
Os médicos recomendam que a hipótese seja confirmada por um exame de imagem, tomografia computadorizada e ressonância magnética, que permitem ao médico identificar a área do cérebro afetada e o tipo de AVC.
A tomografia pode ser o exame inicial de escolha por sua disponibilidade e rapidez
Serve principalmente para diferenciar o AVC por entupimento/isquemia do hemorrágico, o que muda radicalmente a conduta médica
Uma tomografia normal dentro das primeiras 24 horas de um AVC isquêmico é algo esperado e confirma o diagnóstico, pois a maioria dos ataques isquêmicos não provoca lesões visíveis tão precoces nesse exame
Apenas lesões extensas ou mais antigas podem ser vistas na tomografia no AVC isquêmico ou, ainda, sinais indiretos de AVC como edema cerebral
Já o AVC hemorrágico costuma vir com imagem na tomografia indicando vazamento de sangue
Pode-se, ainda que menos comum, usar mão da retirada por punção lombar do líquor para o diagnóstico de AVC hemorrágico com tomografia normal.
Embora mais precisa que a tomografia, a ressonância magnética não costuma mudar a conduta médica e pode ainda atrasar o tratamento correto, o que pode ter impacto na recuperação do paciente
Contudo, é uma opção que pode ser útil em casos selecionados.
O processo de reabilitação pode ser longo, dependendo das características do próprio AVC, da região afetada, da rapidez de atuação para minimizar os riscos e do apoio que o doente tiver
O sistema nervoso central todo pode ser acometido por esta doença, o que inclui, além do cérebro, o tronco encefálico, o cerebelo e até a medula espinhal.
Assim o lobo frontal está mais ligado às decisões e movimentos; o lobo parietal com os movimentos do corpo, parte da fala e com a sensibilidade do pescoço até os pés; e o lobo occipital com a visão
Já o cerebelo está ligado com o equilíbrio e o tronco cerebral está ligado à respiração e aos movimentos e sensibilidade da cabeça
Claro que isto é uma explicação básica e deve-se ter em mente que todo sistema nervoso está interligado podendo uma lesão em uma mínima parte ter grandes repercussões no todo
A localização e as implicações da lesão podem ser difíceis de diagnosticar, devendo a pessoa acometida ser avaliada por um médico e equipe multidisciplinar, ou seja, com vários profissionais da saúde de diversas áreas.
No caso de um AIT ou acidente isquêmico transitório, não ocorre sequela
No entanto, a prevenção de outro AVC deve ser instituída devido ao alto risco de novo ataque dessas pessoas
No caso de um acidente encefálico associado a déficits motores, necessita-se de acompanhamento da equipe de fisioterapeutas, fonoaudiólogos e terapeutas ocupacionais para potencializar e fortalecer os músculos que ainda possuem a inervação funcionante para assim diminuir as deficiências que podem ter sido causadas; no caso de problemas na fala e/ou deglutição um fonoaudiólogo pode ser necessário.
Vale lembrar que o AVC é uma doença que merece muita atenção pela mudança que pode provocar na dinâmica da vida da vítima, da vida da sua família e das pessoas que dela cuidam
A vítima, antes totalmente funcional, pode se tornar totalmente dependente física e financeiramente de seus cuidadores
Pode, uma vez acamada, desencadear outras complicações, como escaras de decúbito, pneumonia e obstipação
Além disso, existe descrito o stress do cuidador - que, aliás, também deve ser abordado e ouvido no tratamento do paciente acamado, minimizando as sequelas familiares.
A melhor maneira de lidar com o AVC é preveni-lo controlando todos os fatores causais já citados, novamente mencionando que a principal é a hipertensão arterial sistêmica.
O AVC geralmente causa um impacto significativo na vida funcional, cognitiva e social do paciente, sendo comum que o paciente desenvolva transtornos psicológicos após o derrame
Entre 10 e 34% desenvolvem depressão maior, agravando ainda mais o prejuízo funcional, cognitivo e social do paciente
Quanto maior o prejuízo na qualidade de vida e dificuldade de adesão ao tratamento mais importante é o acompanhamento psicológico e psiquiátrico para a reabilitação da vítima do derrame.
Existem diversos fatores considerados de risco para a chance de ter um AVC, sendo o principal a hipertensão arterial sistêmica não controlada e, além dela, também aumentam a possibilidade o diabete melitus, doenças reumatológicas, trombose, uma arritmia cardíaca chamada fibrilação atrial, estenose da válvula mitral, entre outras.
Como todas as doenças vasculares, o melhor tratamento para o AVC é identificar e tratar os fatores de risco como a hipertensão, aterosclerose, o diabetes mellitus, o colesterol elevado, cessar o tabagismo e o etilismo, além de reconhecer e tratar problemas cardíacos
A essa prática se dá o nome de prevenção primária.
Se houver atendimento médico rápido, dentro de um determinado tempo, a área afetada poderá ser normalizada
A essa prática de prevenção que se baseia no atendimento médico eficiente se dá o nome de prevenção secundária.
Caso ocorram sequelas, deve ser iniciado um programa de reabilitação e cuidados com o paciente que inclui equipe multidisciplinar, ou seja, com vários profissionais de diferentes áreas da saúde - fisioterapia, fonoaudiologia, psicologia, técnicos em enfermagem, terapeutas ocupacionais, enfermeiros e médicos
A reabilitação é um tipo de prevenção terciária do paciente.
O manejo da pressão arterial no AVC isquêmico é altamente polêmico, uma vez que tanto pressões muito altas como muito baixas podem ser fatais
Ambas as situações podem apresentar um potencial de morbi-mortalidade, pois a hipertensão pode estar associada à transformação hemorrágica e recorrência do AVC, enquanto a hipotensão é suspeita de levar a uma baixa perfusão, provocando lesões definitivas da zona da penumbra isquêmica e levando a um pior prognóstico
O tratamento de redução da PA desses pacientes já foi associado a uma melhora de prognóstico e a um aumento da eficiência e segurança do tratamento trombolítico, mas outros estudos correlacionam a redução da PA, assim como a hipotensão do AVC com um pior prognóstico neurológico, com maior morbidade e mortalidade
Alguns especialistas chegam a sugerir o aumento induzido da pressão arterial em pacientes hipotensos com AVC
A causa desse aparente paradoxo não é bem esclarecida, e suspeita-se que diferentes modalidades e circunstâncias do AVC determinem um papel diferente para a pressão arterial no prognóstico do paciente.
A maioria dos neurologistas concorda que pressões excessivamente elevadas (PAS > 220 mmHg) estão associadas a um prognóstico pior, mas a hipotensão (PAS < 60 mmHg) parece ser igualmente deletéria
Vários estudos sugerem que uma redução moderada da pressão, se acompanhada por tratamento trombolítico (como o ativador do plasminogênio tecidual, que é um agente fibrinolítico), pode reduzir significantemente a morbi-mortalidade
Os mesmos estudos tendem a concordar que a redução da pressão, se não acompanhada por trombólise, pode não ser segura.
Em presença dessas incertezas, o protocolo de manejo da PA em pacientes com AVC isquêmico agudo se baseia essencialmente na opinião de especialistas, que recomendam reduzir a PA em casos nos quais esta se encontra excessivamente elevada (PAS>220 mmHg), ou quando a redução for associada ao tratamento trombolítico
Nos demais casos a redução da PA não é recomendada.
A gravidade das sequelas dependem de quanto tempo demorou para o paciente ser atendido, sendo que, quanto mais rápido o tratamento apropriado comece, menos sequelas o paciente provavelmente sofrerá.
Embora ainda existam pessoas usando a nomenclatura Acidente Vascular Encefálico (sigla: AVE) no ano de 1996, visando dirimir dúvidas e tentar unificar o termo a ser usado no Brasil, tal assunto foi colocado em discussão durante a Assembleia Geral da Sociedade Brasileira de Doenças Cerebrovasculares (Sigla:SBDCV), ocorrida na cidade de Curitiba, durante o Congresso Brasileiro de Neurologia
Foi aprovado que o termo que deveria ser empregado seria o de "Acidente Vascular Cerebral", quando se dirigir ao público médico e/ou especializado e "derrame" quando for voltado ao público leigo
Tal decisão foi ratificada em 2008, quando este assunto foi novamente discutido, em reunião extraordinária da SBDCV (Quando da elaboração do 2º Consenso do Tratamento da Fase Aguda do AVC) e os termos AVC e derrame foram novamente recomendados.
Em 2010 a Revista Neurociências publicou um artigo intitulado: Acidente Vascular Cerebral ou Acidente Vascular Encefálico? Qual a melhor nomenclatura? Tal artigo explica detalhadamente o porquê dos termos AVC e Derrame serem mantidos.
Doença renal crônica  ou doença renal crónica  é a presença de alterações da estrutura ou funções dos rins, com ou sem alteração da filtração glomerular, por um período maior que 3 meses e com implicações na saúde do indivíduo.
Anteriormente utilizava-se o termo insuficiência renal crônica, definida como a perda da função dos rins de forma progressiva e irreversível
É comum usar a filtração glomerular como sinônimo de função renal, dessa forma a insuficiência renal crônica também era considerada como queda progressiva e irreversível da filtração glomerular, ou seja, da capacidade do rim de excretar substâncias do organismo
A filtração glomerular é mensurada através da taxa de filtração glomerular, sendo assim, a insuficiência renal crônica era sinônimo de redução da taxa de filtração glomerular.
O termo doença renal crônica é mais abrangente que insuficiência renal crônica, pois considera todos os pacientes com alguma lesão renal, independente da taxa de filtração glomerular
Por exemplo, considere um paciente com diabetes mellitus e lesão renal em fase inicial, apenas com albuminúria (Estágio A2), anteriormente denominada microalbuminúria, porém sem alteração da taxa de filtração glomerular
Se classificarmos o paciente somente pela filtração glomerular, o mesmo não tem insuficiência renal crônica, pois a taxa de filtração glomerular ainda está normal
Entretanto, pode-se dizer que ele possui doença renal crônica secundária ao diabetes), mas sem alteração da filtração glomerular
Em outras palavras, o paciente tem lesão renal, mas os rins ainda não estão "insuficientes".


A Kidney Disease: Improving Global Outcomes (KDIGO) define doença renal crônica como a presença de alterações estruturais ou da função dos rins, por um período maior que 3 meses, e com implicações na saúde do indivíduo
Essa definição classifica como portadores de doença renal crônica aqueles pacientes que possuem alguma lesão renal independente da taxa de filtração glomerular, ou seja, pacientes com lesão renal mas sem perda da função dos rins também são considerados como portadores de doença renal crônica
Isso permite detectar pacientes em uma fase inicial da doença, possibilitando a prevenção para evitar a progressão para níveis mais avançados, como a falência renal.
Antes de 2002 não havia consenso sobre a definição de doença renal crônica, dificultado estudos sobre a prevalência e prevenção
As diretrizes sobre doença renal crônica elaboradas a partir do ano de 2002 pela National Kidney Foundation, são internacionalmente adotadas e ajudaram a melhorar a prevenção e obtenção de dados sobre a doença renal crônica.
Essas diretrizes são atualizadas periodicamente, sendo a última atualização feita pela Kidney Disease: Improving Global Outcomes (KDIGO) e publicada em janeiro de 2013
KDIGO é uma fundação sem fins lucrativos, regida por um conselho internacional, administrada pela National Kidney Foundation e que tem a missão de melhorar os cuidados e prognóstico dos pacientes com doença renal.
Pela definição da KDIGO, falência renal é a presença de taxa de filtração glomerular menor que 15 ml/min
Trata-se de um estágio mais avançado da doença renal crônica, onde a maioria dos pacientes já apresenta sinais e sintomas de uremia, com necessidade de iniciar alguma terapia renal substitutiva.
Estágio final da doença renal crônica ou insuficiência renal crônica terminal ou doença renal crônica estádio 5 dialítico / doença renal crônica estádio 5 transplantado, é o termo usado para definir os pacientes portadores de doença renal crônica em estágio bem avançado e em tratamento por hemodiálise, diálise peritoneal ou transplante renal.
Considerando que doença renal crônica é a presença de alterações da estrutura ou função dos rins por um período maior que 3 meses, convém detalhar melhor quais são essas alterações
Alguns exames laboratoriais e de imagem são utilizados para investigar a presença de lesão renal, sendo por isso chamados de marcadores de lesão renal
São eles: dosagem da albuminúria, exame de urina, dosagem dos eletrólitos no sangue, exames de imagem (ultrassom, tomografia, ressonância magnética, angiografia, cintilografia), biópsia e avaliação da taxa de filtração glomerular
Alterações em alguns desses exames podem estar relacionadas a lesão renal, seja estrutural ou funcional.
Exemplos de condições que sugerem presença de lesão renal com alteração estrutural e/ou funcional dos rins:

Diante disso, foram formulados os seguintes critérios para doença renal crônica:
A duração maior que 3 meses é um critério necessário para diferenciar doença renal crônica de lesão renal aguda, definida como um aumento repentino da creatinina sérica ou queda da diurese (menos que 0,5 ml/kg/h durante 6 horas).
A taxa de filtração glomerular (TFG) menor que 60 ml/min foi adotada como critério para doença renal crônica porque alguns pacientes podem ter TFG reduzida porém sem outro marcador de lesão renal, por exemplo: idosos, crianças, vegetarianos, pessoas submetidas a retirada cirúrgica de um rim, portadores de insuficiência cardíaca e cirrose hepática
Pessoas com TFG maior que 60 ml/min e sem marcador de lesão não são, portanto, classificadas como portadoras de doença renal crônica
Por outro lado, aqueles com TFG menor que 60 ml/min, com ou sem marcador de lesão renal presente, são classificados como portadores de doença renal crônica, uma vez que apresentam maior risco de desenvolver complicações secundárias ao problema renal.
A classificação da doença renal crônica é baseada na taxa de filtração glomerular (TFG) e albuminúria
São 5 estágios de acordo com a taxa de filtração glomerular e 3 estágios de acordo com a albuminúria, conforme a tabela abaixo:
Exemplos:
Esta classificação divide os pacientes em grupos de acordo com a gravidade da alteração renal, sendo os pacientes com taxa de filtração glomerular elevada e albuminúria baixa, pertencentes aos grupos com lesão mais amena e menor risco de complicações da doença renal crônica
Já os pacientes com taxa de filtração glomerular baixa e albuminúria elevada têm alteração renal mais grave com maior risco de desenvolver complicações e mais chances de necessidade de terapia de substituição renal
Pode ocorrer mudança de um estágio menos grave para um estágio mais avançado da doença, sendo esse fenômeno conhecido como progressão da doença renal crônica, sendo o estadiamento útil para orientar a equipe de saúde a traçar estratégias mais adequadas, no sentido de impedir a progressão da lesão renal.
São muitas as doenças que acometem os rins, podendo levar à doença renal crônica e prejuízo da função renal
Dados do censo de diálise, elaborado pela Sociedade Brasileira de Nefrologia em 2011, apontam a hipertensão arterial, o diabetes e as glomerulopatias como as principais doenças que levam o paciente à insuficiência renal crônica terminal com necessidade de diálise no Brasil
Esse dados estão de acordo com as estatísticas de outros países, que confirmam essas doenças como os principais motivos que levam o paciente a necessitar de hemodiálise ou diálise peritoneal
É importante ressaltar que a hipertensão arterial e o diabetes são bastante prevalentes na população, o que torna indispensável o controle precoce dessas duas doenças, com finalidade de prevenir o aparecimento e/ou evolução da doença renal, reduzindo assim o risco do paciente necessitar de alguma terapia de substituição renal no futuro.
As principais condições que podem causar DRC estão descritas abaixo:
A perda súbita da função dos rins, como ocorre nos casos de insuficiência renal aguda, gera graves consequências ao organismo, podendo causar levar à morte se não tratada prontamente
Por outro lado, se a lesão renal ocorrer de modo mais lento e insidioso, o rim consegue adaptar-se e garantir a sobrevivência do organismos mesmo em situações onde a função renal esteja quase que 90% comprometida.
A presença de algum insulto renal, por exemplo, hipertensão arterial, diabetes mellitus, glomerulonefrites, rins policísticos, etc., provoca a perda de néfrons no rim
Como os néfrons são as unidades funcionais do rim (o ser humano tem cerca de 1 milhão de néfrons em cada rim), a perda dessas estruturas leva a redução na capacidade do rim de realizar suas funções
Entretanto, os néfrons que sobrevivem à agressão inicial, são capazes de aumentar em muitas vezes sua capacidade funcional, suprindo assim a ausência dos néfrons lesados e garantindo a relativa estabilidade do organismo mesmo nas fases mais avançadas da doença renal crônica.
Cada rim possui cerca de 1 milhão de néfrons e cada néfron é capaz de eliminar os metabólitos do organismo, garantir o equilíbrio hidreletrolítico e ácido-básico do corpo humano
Para exercer essas funções, o néfron utiliza três mecanismos: a filtração, a reabsorção e a secreção
A filtração ocorre na região do néfron chamada glomérulo, onde o sangue, ao passar pelos capilares do glomérulo, deixa extravasar um líquido semelhante ao plasma para o túbulo renal
A saída desse líquido do sangue para o túbulo renal, acontece nos glomérulos e por isso esse processo também é conhecido como filtração glomerular
O líquido produzido pela filtração glomerular recebe o nome de filtrado glomerular
Após sua produção, o filtrado glomerular segue em direção ao túbulo renal, onde ocorre a reabsorção de 99% de todo o volume filtrado
Esse processo recebe o nome de reabsorção tubular
A terceira etapa, a secreção, também ocorre no túbulo renal, onde suas células irão secretar substâncias para o filtrado glomerular
Após ser processado pelo túbulo renal, o filtrado glomerular dará origem a urina excretada pelos rins
Portanto, podemos representar a excreção de substâncias pelo rim da seguinte maneira:




E
=
F
−
R
+
S


{\displaystyle E=F-R+S}


onde E = excreção, F = filtração, R= reabsorção e S = secreção
A quantidade de sangue que chega ao rim por minuto é dividida entre a população de quase 1 milhão de néfrons do órgão
Se por algum motivo, ocorrer redução no número de néfrons, por exemplo, pela metade, a mesma quantidade de sangue que chega ao rim por minuto, agora será dividida para uma população de 500 mil néfrons
Fica claro com esse exemplo que o fluxo de sangue por néfrons remanescente aumenta, assim como a pressão hidrostática dentro do glomérulo
A consequência disso é um aumento da filtração glomerular, sendo assim, nas situações de perda de néfrons, as unidades remanescentes aumentam sua filtração glomerular, chegando a suprir a falta de néfrons
Por isso, os pacientes com doença renal crônica podem se manter estáveis mesmo com perda considerável de seus néfrons
Esse aumento da filtração glomerular por néfron remanescente atenua a queda da filtração glomerular global mas não a detém completamente, sendo esse o motivo da taxa de filtração glomerular cair lenta e continuamente a medida que mais néfrons são perdidos.
Além do aumento da filtração glomerular, os néfrons remanescentes também sofrem outras adaptação para tentar manter o equilíbrio hidroeletrolítico e ácido-básico do corpo
Para evitar a retenção de sódio, os néfrons aumentam a excreção desse íon diminuindo sua reabsorção tubular, já para evitar o excesso de potássio, os néfrons aumentam sua secreção
A retenção de fósforo é prevenida pela redução na sua reabsorção e o equilíbrio ácido-básico é mantido pela maior excreção de ácido pelos néfrons remanescentes
Esses mecanismos adaptativos têm um limite, e por isso, a medida que mais néfrons vão se perdendo, ocorrerá acúmulo de sódio e água no organismo, com formação de edema, além de tendência a hipercaliemia, hiperfosfatemia e acidose metabólica.
Mesmo utilizando os mecanismos de adaptação acima descritos e mesmo na ausência de insultos capazes de provocar a perda de mais néfrons, observa-se que os pacientes com doença renal crônica continuam deteriorando lentamente sua função renal até atingir os estágio finais da doença, onde ocorre perda total das funções dos rins
Esse fenômeno de perda da função renal mesmo quando o insulto inicial já está controlado é denominado progressão da doença renal crônica
No início do quadro, a progressão pode ser controlada, no entretanto, nas fases mais avançadas, a progressão torna-se irreversível levando, mais cedo ou mais tarde, à perda completa da função renal
Atualmente, acredita-se que a progressão da doença renal crônica seja fruto da perda de néfrons e da consequente hipertensão glomerular que se desenvolve
A hipertensão glomerular provoca lesão das células endoteliais, estiramento e lesão dos podócitos e das células mesangiais, proteinúria e extravasamento do filtrado glomerular para o interstício renal através de pontos de ruptura do glomérulo
Todos esses eventos promovem a liberação de mediadores inflamatórios, além do recrutamento e proliferação de células inflamatórias para as proximidades do néfron
Instala-se, assim, uma reação inflamatória que acaba por destruir o néfron, substituindo os tecidos originais por fibrose
Como resultado, na fase de doença renal crônica avançada, observamos fibrose do glomérulo (glomeruloesclerose), atrofia e fibrose dos túbulos e do interstício renal.
Diversas substâncias inflamatórias atuam em conjunto na fisiopatologia da progressão da doença renal crônica
Fatores de crescimento, quimiocinas, citocinas e angiotensina II são algumas das substâncias envolvidas neste processo
Especial atenção é dada ao uso de bloqueadores do sistema renina-angiotensina-aldosterona, que ao reduzirem os níveis de angiotensina II, reduzem a hipertensão glomerular e o processo inflamatório, sendo de grande validade para o controle da progressão da doença.
Em suma, a perda de néfrons e a hipertensão glomerular que se instala nos néfrons remanescentes, é um mecanismo adaptativo e essencial para manter o equilíbrio do organismo mesmo em fases mais avançadas da doença renal crônica
Entretanto, a mesma hipertensão glomerular é o evento inicial que a longo prazo irá destruir o néfron, causando mais perda dessas estruturas e aumentando ainda mais o fluxo de sangue a a hipertensão glomerular das unidades remanescentes
Dessa forma, cria-se um ciclo vicioso até a perda total dos néfrons, mesmo que o insulto original que causou a perda de néfrons, no início do quadro, já não esteja mais presente.
A perda da capacidade dos rins realizarem corretamente suas funções provoca o aparecimento de diversos sintomas
A tabela ao lado mostra as principais funções dos rins e os problemas relacionados quando estes não conseguem desempenhar satisfatoriamente suas funções
Os sintomas da doença renal crônica aparecem gradualmente a medida que a função renal vai se deteriorando
Portanto nas fases iniciais (estágios 1 e 2 ), o único sintoma pode ser a hipertensão arterial
Nos estágios mais avançados vão aparecendo os demais sintomas, até que no estágio 5 todos os sintomas estarão presentes
A presença de proteinúria e hematúria depende muito da doença que está causando a lesão nos rins
Por exemplo, a lesão renal causada por algumas glomerulonefrites podem cursar somente com hematúria, somente proteinúria ou ambas simultaneamente
Dentre os principais sintomas da doença renal crônica temos:
A uremia ou síndrome urêmica são os sintomas associados a incapacidade do rim em excretar substâncias tóxicas ao organismo, as quais interferem no correto funcionamento de vários órgãos e sistemas como: sistema nervoso, muscular, gastrointestinal, imune, endócrino, etc
Embora a ureia seja a toxina mais conhecida e facilmente mensurada através de exames de sangue, várias outras substâncias tóxicas acumulam-se no organismo em virtude da doença renal crônica
Essas substâncias são denominadas de toxinas urêmicas e incluem vários compostos, dentre os quais: ureia, guanidina, oxalato, poliaminas, P-cresol, P-cresilsulfato, homocisteína, indóis, ácido furampropriônico, beta 2 microglobulina, produtos avançados da glicação, etc
De um modo geral, o acúmulo das toxinas urêmicas começa a trazer prejuízo clínico significativo para o paciente a partir do estágio 3 da doença renal crônica
Os principais sintomas da uremia estão descritos abaixo:
O tratamento da doença renal crônica pode ser dividido em duas fases: o tratamento conservador e a terapia renal substitutiva
No tratamento conservador, o objetivo principal é retardar a progressão da doença renal, evitando uma maior perda da função renal, além de tratar suas complicações, como por exemplo a anemia, acidose metabólica e doença mineral óssea
Na fase de terapia renal substitutiva, a função renal já encontra-se bastante deteriorada e o organismo não é mais capaz de manter seu equilíbrio interno, havendo prejuízos claros à saúde do paciente
Neste caso, o tratamento conservador já não é mais capaz de manter o bem estar do indivíduo e existe, portanto, a necessidade de iniciar uma terapia que substitua a função do rim doente (terapia renal substitutiva), ou seja, hemodiálise, diálise peritoneal ou transplante renal
Na fase de terapia renal substitutiva, o tratamento das complicações da doença renal crônica, como a anemia e a doença mineral óssea, também são mantidos
Os pacientes com doença renal crônica no estágios 1 a 4 são frequentemente mantidos em tratamento conservador para evitar perda da função renal ao longo do tempo, sendo que nos estágios 3 e 4 também há necessidade de tratar as possíveis complicações da doença renal crônica
Já no estágio 5, dificilmente o paciente consegue ficar muito tempo em tratamento conservador devido a perda importante da função dos rins
Nesta fase, o paciente é preparado para iniciar alguma das modalidades de terapia renal substitutiva.
Conforme explicado previamente na sessão Progressão da doença renal crônica, a função dos rins pode deteriorar-se lentamente ao longo do tempo, evoluindo dos estágios iniciais da doença renal crônica até os estágios mais avançados, onde pode haver necessidade de iniciar alguma terapia renal substitutiva, devido a perda importante da função renal
O foco principal da terapia conservadora é adotar medidas para brecar a progressão da doença renal crônica
Tais medidas compreendem o uso de medicações, mudança do estilo de vida como perda de peso, cessar tabagismo, atividade física, dieta pobre em sódio, etc
Nesse contexto, podemos descrever os objetivos principais da terapia conservadora:
Deve-se ter em mente que pequenas flutuações nos exames e creatinina e na taxa de filtração glomerular podem ocorrer e isso não necessariamente indica piora da função renal ou progressão da doença renal
A definição de progressão pode ser baseada em um dos seguintes critérios:
Vários fatores estão associados a um aumento no ritmo de progressão da doença renal, levando a uma perda mais acelerada da função renal
Enquanto alguns fatores não são modificáveis (raça, sexo e tipo de doença renal), outros podem ser controlados com uso de medicações específicas e mudança do estilo de vida.
A terapia renal substitutiva está indicada para os pacientes com doença renal crônica em fase avançada onde o tratamento conservador não é mais suficiente para garantir o equilíbrio do organismo e o bem estar do paciente
Geralmente esses pacientes estão no estágio 5 da doença renal crônica, ou seja, com taxa de filtração glomerular abaixo de 15 ml/min
Nesse estágio, o paciente necessita de algum tratamento que substitua a função dos rins, ou seja, necessita de um tratamento que retire as impurezas e o excesso de líquido acumulado no corpo, em decorrência da doença renal crônica
Para isso, existem três modalidades de terapia renal substitutiva: a hemodiálise, a diálise peritoneal e o transplante renal
Mais a frente, essas modalidades serão discutidas detalhadamente.
Em pacientes com doença renal crônica estágio 5 (taxa de filtração glomerular menor que 15 ml/min, a terapia renal substitutiva deve ser considerada se houver um ou mais dos seguintes sintomas:
Pacientes assintomáticos, com taxa de filtração glomerular menor que 15 ml/min, mas que possuam diabetes ou perda acelerada da função renal (mais que 4 ml/min por ano), devem sem reavaliados com mais frequência, num intervalo de tempo menor
Quando essas reavaliações frequentes não são possíveis, recomenda-se o início da terapia renal substitutiva mesmo na ausência dos sintomas acima descritos
O maior cuidado com os pacientes diabéticos justifica-se pelo fato destes apresentarem uma menor tolerância à uremia e maior facilidade de retenção de líquidos
Obviamente, o paciente já deve estar orientado e preparado para a terapia renal substitutiva antes do aparecimentos das condições acima descritas, para que todo o processo ocorra de forma programada e com o mínimo de imprevistos possíveis
Por esse motivo é extremamente importante que o paciente seja acompanhado previamente por uma equipe multidisciplinar formada por médico nefrologista, nutricionista, enfermeiro, psicólogo e assistente social, principalmente quando a taxa de filtração glomerular for menor que 30 ml/min, ou seja, estágios 4 a 5 da doença renal crônica
Existem situações onde o início da terapia renal substitutiva deve ser imediata, devido o alto risco de prejuízo à integridade da saúde do paciente, conforme mostrado na tabela abaixo
Nesses casos, devido ao risco iminente de óbito, o paciente é submetido à hemodiálise de urgência.
A hemodiálise é um procedimento terapêutico, utilizado para remover impurezas e excesso de líquido do organismo, em pacientes com doença renal crônica avançada
Na hemodiálise, o sangue é retirado do paciente através de um vaso sanguíneo, impulsionado até o filtro (dialisador) por uma bomba, onde ocorre a depuração de impurezas e remoção do excesso de água, sendo posteriormente devolvido ao paciente pelo mesmo vaso sanguíneo
Em média, o tempo gasto para uma filtragem ideal do sangue é de 4 horas
Entretanto, pacientes com maior massa e maior superfície corporal, podem precisar de 4 horas e meia a 5 horas para atingirem um nível satisfatório de filtragem do sangue
A frequência de sessão de hemodiálise é de 3 a 6 vezes por semana, dependendo da avaliação e condição clínica do paciente
Em suma, a hemodiálise é realizada 3 vezes por semana com duração de 4 horas cada sessão, podendo ter variações no tempo e frequência dependendo das condições clínicas dos pacientes.
O acesso vascular ou acesso para hemodiálise é a via pela qual o sangue é retirado e devolvido ao paciente, durante a sessão de hemodiálise
Existem dois tipos principais de acessos para hemodiálise: o cateter e a fístula
O cateter, também chamado de cateter venoso central, é um tubo flexível, instalado em uma veia calibrosa do corpo
A veia preferencial é a veia jugular interna, localizada no pescoço
Outros locais para instalação do cateter são: veia femoral (na virilha) e veia subclávia (no tórax)
Esse cateter possui duas vias, uma via identificada pela cor vermelha, por onde o sangue é retirado, e uma via identificada pela cor azul, por onde o sangue e devolvido ao paciente
Já a fístula, é confeccionada através de um procedimento cirúrgico simples, com anestesia local, onde o médico faz a união de uma veia com uma artéria do braço
Dessa forma, o fluxo de sangue pela veia do braço fica mais intenso, permitindo a realização da hemodiálise
Por ser a união de uma veia com uma artéria, a fístula também é chamada de fístula artério venosa
O sangue é retirado da fístula através de uma agulha e devolvido por outra agulha
Após a cirurgia pra a confecção da fístula, demora um certo tempo para que ela fique mais calibrosa e com um bom fluxo de sangue realizar a hemodiálise
Esse tempo transcorrido entre a cirurgia e o momento ideal para usar a fístula é chamado de tempo de maturação da fístula, e varia de paciente para paciente, mas em média, o tempo de maturação é de 6 a 8 semanas
Por isso, a recomendação é confeccionar a fístula bem antes do paciente precisar realizar a hemodiálise, pois assim, haverá tempo hábil para agendar a confecção, aguardar maturação e fazer correções da fístula caso seja necessário
O ideal seria tentar fazer a cirurgia para fístula 6 meses antes de iniciar a hemodiálise
Após a cirurgia, recomenda-se fazer exercícios com braço onde foi feita a fístula, por exemplo, ficar apertando uma bolinha de borracha, o que favorece o aumento de fluxo de sangue e acelera a maturação da fístula
Uma fístula madura possui fluxo de sangue adequada para a realização da hemodiálise, um trajeto que permita uma fácil punção com as agulhas, um diâmetro de aproximadamente 0,6 cm e uma profundida de 0,6 cm a partir da superfície da pele
Com relação ao melhor acesso para hemodiálise, sem dúvidas a fístula é a primeira escolha, pois tem menor incidência de complicações em relação aos cateteres, tais como: infecção, trombose e duram mais tempo.
Cuidados com o cateter 
Cuidados com a fístula 
As sessões de hemodiálise não são dolorosas e geralmente não causam desconforto
Em pacientes que fazem hemodiálise por fístula, um desconforto será sentido no momento que a fístula for puncionada com as agulhas para retirar e devolver o sangue
Durante a sessão, os sintomas mais comuns que acontecem são câimbras e hipotensão (queda da pressão arterial), podendo esta última, ser acompanhada de náuseas, vômitos, mal estar geral, cefaleia
A hipotensão ocorre quando é necessário retirar muito líquido acumulado no organismo
Considerando que os pacientes que fazem hemodiálise possuem pouca ou nenhuma função dos rins, todo o líquido ingerido fica acumulado no organismo, sendo necessário retirar esse excesso na sessão de hemodiálise
Portanto, uma forma de evitar a hipotensão e outros sintomas desconfortáveis na hemodiálise é evitar o acúmulo de grande quantidade de líquidos entre as sessões de hemodiálise
Deve-se sempre seguir a orientação do nutricionista, controlar a quantidade de água ingerida e também a de sal, uma vez que o sódio do sal de cozinha, além de favorecer a retenção de água no organismo, aumenta a sensação de sede, o que induz a uma maior ingestão de água.
Esquema representativo do circuito de hemodiálise.
Máquina de hemodiálise.
Cateter definitivo de hemodiálise.
Paciente realizando sessão de hemodiálise por fístula.
Esquema de uma fístula para hemodiálise.
A diálise peritoneal também é um procedimento terapêutico, utilizado para remover impurezas e excesso de líquido do organismo, em pacientes com doença renal crônica avançada
Na diálise peritoneal, um líquido é infundido dentro do abdome do paciente, através de um cateter próprio para isso
Dentro do abdome, ou seja, dentro da cavidade abdominal, o líquido de diálise fica em contato com uma membrana que reveste os órgãos abdominais chamada peritôneo
Uma característica importante do peritôneo é sua alta permeabilidade, possibilitando a passagem de substâncias da circulação sanguínea para a cavidade abdominal e vice-versa
Assim, quando o líquido de diálise entra em contato com o peritôneo, as impurezas do sangue são transportadas para o líquido de diálise
O líquido de diálise com as impurezas é então retirado da cavidade abdominal pelo cateter, num processo chamado drenagem
Um novo líquido de diálise é novamente colocado na cavidade abdominal pelo cateter, num processo chamado infusão
O liquido de diálise fica então na cavidade peritoneal por um tempo determinado chamado tempo de permanência, sendo que é nesse período que ocorre a passagem das impurezas do sangue para o líquido de diálise
Após o tempo de permanência, é feita nova drenagem e infusão
Portanto, o ciclo de diálise peritoneal é formado pela infusão, permanência e drenagem
Vários ciclos são feitos sucessivamente, garantindo a eliminação de impurezas e excesso de líquido do organismo.
Conexão da bolsa com o líquido de diálise ao cateter
Infusão do líquido de diálise na cavidade abdominal
Início da permanência
Final da permanência (líquido de diálise já com as impurezas do sangue)
Drenagem
O cateter usado para a realização da diálise peritoneal é implantado no paciente através de uma pequena cirurgia, geralmente com anestesia local e uma sedação leve do paciente
Caso não ocorra intercorrências, o paciente poderá receber alta no dia seguinte ou no mesmo dia
Esse cateter é feito de um material plástico, flexível e fica implantado no abdome do paciente por tempo indeterminado; não provoca desconforto ou dor, exceto nos casos onde o cateter esteja mal posicionado ou nos casos de infecção
Nestas situações, deve-se procurar o serviço médico de referência para avaliação mais mais detalhada.
A diálise peritoneal pode ser realizada de forma manual, com o paciente ou familiar, conectando a bolsa de diálise ao cateter para a drenagem e infusão, ou pode ser feita de forma automática, através de um dispositivo chamado cicladora
Como o próprio no diz, a cicladora é responsável por realizar os ciclos de diálise, ou seja, ela faz a infusão e drenagem do líquido de diálise automaticamente
O paciente ou familiar monta a cicladora, conecta o cateter peritoneal ao dispositivo, e a partir daí, a máquina faz os ciclos conforme a programação feita pelao equipe médica
A diálise automática é feita a noite, enquanto o paciente está dormindo
A cicladora é instalada antes do paciente deitar e desinstalada pela manhã
Já na diálise manual, os ciclos são realizados manualmente durante o dia, geralmente 4 a 5 ciclos por dia, sendo que a drenagem a a infusão do novo líquido de diálise leva em média 40 minutos.
De posse das informações acima, podemos definir alguns conceitos básicos de diálise peritoneal:
De um modo geral, não existe superioridade da diálise peritoneal sobre a hemodiálise, ou seja, os dois métodos se mostram igualmente eficientes
A escolha do método ira depender da preferência do paciente e de sua condição clínica.

bexiga urinária: Cistite (Cistite intersticial, Trigonite) - Bexiga neurogênica - Fístula êntero-vesical
uretra: Uretrite (Uretrite não-gonocócica) - Síndrome uretral - Estenose uretral

O pé diabético é uma série de alterações anatomopatológicas e neurológicas periféricas que ocorrem nos pés de pessoas acometidas pelo diabetes mellitus
Essas alterações constituem-se de neuropatia diabética, problemas circulatórios, infecção e menor circulação sanguínea no local
Essas lesões geralmente apresentam contaminação por bactérias, e como o diabetes provoca uma retardação na cicatrização, ocorre o risco do pé ser amputado
O pé diabético ocorre pela ação destrutiva do excesso de glicose no sangue
A nível vascular, causa endurecimento das paredes dos vasos, além de sua oclusão, o que faz a circulação diminuir, provocando isquemia e trombose.


Segundo os artigos: Practical guidelines on the management and prevention of the diabetic foot
e Diabetic foot disorders: a clinical practice guideline (em inglês) , baseados no consenso internacional sobre pé diabético (1997) e preparados por grupos de trabalho distintos, o tratamento de pacientes com feridas de pé diabético segue as segunites diretrizes:
Pé diabético é uma das complicações mais graves, pois, têm um grande impacto socioeconômico incluindo despesas com o tratamento, grandes períodos de internação, incapacidades físicas já que em muitas vezes evoluem para a amputação e sociais como desemprego e perda de produtividade
O tratamento da úlcera diabética é difícil e prolongado, associa-se a altas taxas de insucesso e recidiva, requerendo a combinação de várias modalidades terapêuticas
É importante que o tratamento seja acompanhado por uma equipe de saúde, para que processo de cicatrização seja efetivo e num menor tempo
A cicatrização é um processo lento que depende de condições locais e sistêmicas
As lesões nos pés de pacientes com DM podem levar a graves sequelas mesmo quando tratadas a tempo, quando não há tratamento os danos são quase inevitáveis, as deformações do pé, podem levar a amputação e até mesmo uma infecção sistêmica .
A tabela abaixo mostra diretrizes estabelecidas pelo Consenso Internacional Sobre Pé Diabético, quanto à neuropatia.
2
Cuidados gerais
3
Avaliação anual
2
Cuidados gerais
3
Uso de calçados adequados
4
Avaliação semestral
2
Cuidados gerais
3
Uso de calçados adequados
4
Avaliação trimestral com equipe especializada
2
Cuidados gerais
3
Uso de calçados adequados
4
Avaliação 1 a 3 meses com equipe especializada

Retinopatia diabética é a lesão à retina causada pelas complicações do diabetes mellitus
É causa importante de cegueira.
Em pacientes com Diabetes mellitus tipo 1, sua progressão pode ser lentificada pelo uso de inibidores da enzima de conversão da angiotensina
O principal tratamento da Retinopatia Diabética é o controle clínico rigoroso das glicemias e pressão arterial.

pálpebra: inflamação (Hordéolo, Calázio, Blefarite) - Entrópio - Ectrópio - Lagoftalmo - Blefarocalásia - Ptose - Blefarofimose - Xantelasma - Triquíase
sistema lacrimal: Dacrioadenite - Epífora - Dacriocistite
Estrabismo paralítico: Oftalmoparesia - Oftalmoplegia externa progressiva - Paralisia (III, IV, VI) - Síndrome de Kearns-Sayre Outros estrabismos: Esotropia/Exotropia - Hipertropia - Heterophoria (Esophoria, Exoforia) - Síndrome de Brown - Síndrome de Duane
Outras binoculares: Paralisia do olhar conjugado - Insuficiência de convergência - Oftalmoplegia internuclear - Síndrome do um e meio

Insulina é uma hormona responsável pela redução da glicémia (taxa de glicose no sangue), ao promover a entrada de glicose nas células
Esta é também essencial no metabolismo de sacáridos (hidrato de carbono), na síntese de proteínas e no armazenamento de lípidos (gorduras).
É produzida nas células beta das ilhotas de Langerhans, do pâncreas endócrino
Atua numa grande parte das células do organismo, como nas células presentes no fígado, em músculos e no tecido adiposo, contudo não atua em células específicas cujos transportadores membranares não são sensíveis à insulina, como é o caso das células nervosas.
Quando a produção de insulina é deficiente, a glicose acumula-se no sangue e na urina, destruindo as células por falta de abastecimento: diabetes mellitus
Para doentes nessa condição, a insulina é providenciada através de injeções, ou bombas de insulina
Recentemente foi aprovado o uso de insulina inalada
Porém, ainda existem controvérsias acerca do uso do produto comercializado pela Pfizer
A agência de saúde britânica não recomenda o uso.
A insulina é um polipéptido de estrutura química plenamente conhecida, e pode ser sintetizada a partir de diversos animais
Mais recentemente, surgiram os medicamentos análogos de insulina, que constituem moléculas que, não sendo insulina, possuem as mesmas características químicas e portanto reactivas, são moléculas "de insulina" modificadas em laboratório.
O controlo da produção de insulina pelo corpo é um sistema muito complexo.


Em 1869, Paul Langerhans, um estudante de medicina em Berlim, estudava a estrutura do pâncreas através de um microscópio quando reparou em células, antes desconhecidas, espalhadas pelo tecido exócrino
A função da "pequena porção de células", mais tarde denominada como ilhotas de Langerhans, era desconhecida, mas Edouard Laguesse posteriormente sugeriu que tais células poderiam produzir algum tipo de secreção que participasse no processo de digestão.
Em 1889, o médico germano-polaco Oscar Minkowski em colaboração com Joseph von Mehring removeu o pâncreas de um cão saudável para demonstrar o papel do órgão na digestão de alimentos
Vários dias após a remoção do pâncreas, o guarda do cão reparou que existiam muitas moscas a alimentarem-se da urina do animal
Verificou-se com o teste da urina do cão que havia açúcar nesta, o que demonstrou pela primeira vez a relação entre o pâncreas e a diabetes
Em 1901, outro passo importante foi alcançado por Eugene Opie, quando este estabeleceu claramente a ligação entre as ilhotas de Langerhans e a diabetes: "Diabetes mellitus..
é causada pela destruição das ilhotas de Langerhans e ocorre apenas quando tais células são em parte ou totalmente destruídas".
Durante as duas décadas seguintes foram feitas várias tentativas de isolamento da secreção das ilhotas como um tratamento potencial de diabetes
Em 1906, Georg Ludwig Zuelzer foi parcialmente feliz no tratamento de cães com extrato pancreático, mas teve que interromper o seu trabalho
Entre 1911 e 1912, E
L
Scott da Universidade de Chicago usou extratos pancreáticos aquosos e notou uma leve diminuição da glicosúria, mas não conseguiu convencer o director da instituição com os resultados, e a pesquisa teve de ser encerrada
Israel Kleiner demonstrou efeitos semelhantes na Rockfeller University em 1919, mas o seu trabalho foi interrompido pela Primeira Guerra Mundial
Nicolae Paulescu, um professor de fisiologia da Escola Romena de Medicina, publicou um trabalho parecido em 1921 realizado na França e patenteado na Romênia, e discute-se desde então se Paulescu não tenha sido o verdadeiro descobridor da insulina.
Entretanto, o comitê do Prêmio Nobel em 1923 deu crédito pela extração prática da insulina a uma equipa da Universidade de Toronto
Em outubro de 1920, Frederick Banting lia um dos artigos de Minkowski e concluiu que Minkowski estava a estudar as secreções digestivas originalmente, e por isso não se conseguia extrair a insulina com sucesso
Ele redigiu uma nota para si mesmo: "Ligar duto pancreático do cão
Manter cães vivos até que acinos se degenerem, sobrando ilhotas
Tentar isolar secreção interna delas e aliviar glicosúria".
Ele viajou a Toronto para se encontrar com J
J
R
Macleod, que não se impressionou plenamente com a ideia
De qualquer forma, Macleod deixou à disposição de Banting um laboratório da universidade, e um assistente, Charles Best, e dez cães enquanto saía de férias no verão de 1921
O método de Banting e Best era amarrar uma ligadura ao redor do duto pancreático dos cães e, várias semanas depois, examinar que as células digestivas pancreáticas tinham morrido e sido absorvidas pelo sistema imunológico, deixando milhares de ilhotas
Isolava-se a proteína dessas ilhotas para produzir o que vinham chamando de isletina
Banting e Best mantiveram um cão pancreatectomizado vivo durante todo o verão.
Macleod viu o valor da pesquisa no seu regresso da Europa, mas pediu uma contraprova para saber se o método realmente funcionava
Várias semanas depois ficou claro que o segundo ensaio tinha sido um sucesso, e assim Macleod ajudou na publicação dos resultados em novembro daquele ano
Porém, precisavam de seis semanas para extrair a isletina, o que tornava o ensaio dramaticamente demoroso
Banting sugeriu que tentassem usar pâncreas de feto de bezerro, que ainda não teria desenvolvido glândulas digestivas, e ficou alivado pelo sucesso da empreitada.
Com a solução para a fonte de isletina, faltava agora purificar a proteína
Em dezembro de 1921, Macleod convidou o brilhante bioquímico James Collip para ajudar na tarefa, e num mês prepararam-se para um teste.
Em 11 de janeiro de 1922, Leonard Thompson, um diabético de quatorze anos, recebeu a primeira injeção de insulina
Infelizmente, o extrato estava tão impuro que ele acabou sofrendo uma reação alérgica severa, e injeções adicionais foram canceladas
Durante os doze dias seguintes, Collip trabalhou dia e noite para melhorar o extrato, e uma segunda dose foi injetada no dia 23
Desta vez foi um sucesso, não apenas em não apresentar efeitos colaterais, mas também por eliminar completamente os sintomas de diabetes
Entretanto, Banting e Best não se davam bem com Collip, porque aparentemente viam nele um intruso, e então Collip abandonou-os.
Durante a primavera de 1922, Best conseguiu melhorar as técnicas de preparo a ponto de poder extrair grandes quantidades de insulina, embora o extrato ainda permanecesse impuro
Contudo, receberam uma oferta de ajuda de Eli Lilly logo após as suas publicações em 1921, e aceitaram-na em abril
Em novembro, Lilly conseguiu a façanha de produzir grandes quantidades de insulina bastante pura
Depois disso, a insulina foi lançada no mercado.
Por esta descoberta marcante, Macleod e Banting foram premiados com o Prêmio Nobel em Fisiologia em 1923
Banting, aparentemente insultado porque Best não fora mencionado, dividiu seu prêmio com ele, e Macleod imediatamente dividiu o seu com Collip
A patente da insulina foi vendida à Universidade de Toronto por um dólar.
A sequência exata de aminoácidos contida na molécula de insulina, a chamada estrutura primária, foi determinada pelo biólogo britânico Frederick Sanger
Foi a primeira vez que a estrutura de uma proteína fora completamente determinada
Por isso, ele recebeu o Prêmio Nobel de Química em 1958
Em 1967, após décadas de trabalho, Dorothy Crowfoot Hodgkin determinou a conformação espacial da molécula mediante estudos de difração de raios X
Ela também recebeu um Prêmio Nobel.
A insulina é sintetizada nos humanos e em outros mamíferos dentro das células-beta das ilhotas de Langerhans, no pâncreas
Um a três milhões de ilhotas de Langerhans formam a parte endócrina do pâncreas, que é principalmente uma glândula exócrina
A parte endócrina totaliza apenas 2% da massa total do órgão
Dentro das ilhotas de Langerhans, as células-beta constituem 60-80% do todo.
A insulina é sintetizada a partir da molécula precursora proinsulina pela ação de enzimas proteolíticas conhecidas como prohormônio convertases (PC1 e PC2)
A insulina ativa tem 51 aminoácidos e é um polipeptídeo
A insulina bovina difere da humana em três resíduos de aminoácidos enquanto que a suína, em um resíduo
A insulina de peixes também é muito próxima à humana
Em humanos, a insulina tem um peso molecular de 5808
Ela é formada por duas cadeias de polipeptídeos ligadas por duas pontes dissulfídicas (veja a figura), com uma ligação dissulfídica adicional na cadeia A (não mostrada)
A cadeia A consiste de 21, e a cadeia B, de 30 aminoácidos
A insulina é produzida como uma molécula de prohormônio - proinsulina - que é mais tarde transformada, por ação proteolítica, em hormônio ativo.
A parte restante da molécula de proinsulina é chamada de peptídeo C
Este polipeptídeo é liberado no sangue em quantidades iguais à da insulina
Como insulinas exógenas não contêm peptídeo C, o nível em plasma desse peptídeo é um bom indicador de produção endógena de insulina
Recentemente, descobriu-se que esse peptídeo C também possui atividade biológica, que está aparentemente restrita a um efeito na camada muscular das artérias.
Pacientes com diabetes mellitus tipo 1 dependem de Insulinoterapia, ou seja da administração de insulina exógena (geralmente por via subcutânea), para a sua sobrevivência, pois a hormona não é produzida por seu organismo
Também certos pacientes com diabetes tipo 2 podem eventualmente necessitar de insulina se outras medicações não conseguirem controlar os níveis de glicose no sangue de forma adequada.
Inicialmente a insulina utilizada por diabéticos era extraída do pâncreas de bois e porcos, por ser parecida com a humana, mas esta insulina podia acarretar problemas, como reações alérgicas, ou não ser eficaz em alguns pacientes
Atualmente a insulina é produzida através da técnica de ADN recombinante, primeiro produto da moderna biotecnologia a ser comercializado mundialmente
A técnica surgiu no Brasil em 1990, em um projeto desenvolvido por Marcos Luís Mares Guia, bioquímicos da UFMG e pesquisadores da Biobrás e da Universidade de Brasília
A técnica consiste em introduzir na bactéria Escherichia coli, comum na flora intestinal humana, o gene da pró-insulina humana, para que ela passe a produzir o hormônio, um processo que dura 30 dias, um terço do tempo do método tradicional
Em 2001 somente quatro empresas no mundo, incluindo a Biobrás, tinham tecnologia de produção industrial da insulina recombinante
A Biobrás patenteou o processo nos Estados Unidos em 2000 e em 2002 foi comprada pela dinamarquesa Novo Nordisk
Comprada a Biobrás, a Novo Nordisk elevou rapidamente seus preços de fornecimento ao Ministério da Saúde combinando a importação e produção local, até acabarem fechando a produção dos cristais de insulina no Brasil para aqui fazer só envazamento.
Em 2013 o governo federal anunciou que o Brasil vai retomar a produção de insulina por meio do Laboratório Biomanguinhos, da Fundação Oswaldo Cruz, parte de um acordo firmado entre o governo e o laboratório ucraniano Indar, um dos três produtores remanescentes de insulina no mundo, que vai transferir a tecnologia para a produção nacional do medicamento.
Após o acordo de intenções com a Ucrânia, a Novo Nordisk, embora alegasse que a insulina ucraniana não tinha qualidade, fez proposta de compra do Indar ao governo
Um mês após a assinatura do contrato, em uma nova licitação governamental para aquisição de insulina, os preços da insulina oferecidos pelas empresas concorrentes baixaram quase à metade.
As ações nas células incluem:
Testículos: testosterona • AMH • inibina
Ovário: estradiol · progesterona · activin and inhibin · relaxina (gestação)
O pâncreas é uma glândula de aproximadamente 15 cm de extensão fazendo parte do sistema digestivo e endócrino dos seres humanos que se localiza atrás do estômago e entre o duodeno e o baço
Ele é tanto exócrino (secretando suco pancreático, que contém enzimas digestivas) quanto endócrino (produzindo muitos hormônios importantes, como insulina, glucagon e somatostatina)
Divide-se em cabeça, corpo e cauda
O pâncreas é um órgão produtor de enzimas, proteínas que aumentam a rapidez das transformações químicas.


Em humanos, geralmente o pâncreas é uma glândula longa com 15–25 cm que se localiza no abdômen
Sendo uma das glândulas retroperitoneais, ele é localizado posteriormente ao estômago e está em associação próxima ao duodeno.
É frequentemente descrito como tendo três regiões: a cabeça, corpo e a cauda.
O ducto pancreático (também chamado de ducto de Wirsung) percorre o comprimento do pâncreas e termina na segunda porção do duodeno, na ampola de Vater (hepatopancreática)
O ducto biliar comum geralmente se une ao ducto pancreático neste ponto ou próximo dele
Muitas pessoas também possuem um pequeno ducto acessório, o ducto de Santorini.
O pâncreas é suprido arterialmente pelas artérias pancreaticoduodenais: A artéria mesentérica superior que origina as artérias pancreaticoduodenais inferiores A artéria gastroduodenal que origina as artérias pancreaticoduodenais superiores A artéria esplênica que origina as artérias pancreáticas.
A drenagem venosa é feita através das veias pancreáticas que são tributárias das veias esplênica e mesentérica superior, no entanto a maioria delas terminam na veia esplênica
A veia porta hepática é formada pela união da veia mesentérica superior e veia esplênica posteriormente ao colo do pâncreas
Geralmente a veia mesentérica inferior se une à veia esplênica atrás do pâncreas (em outras pessoas ela simplesmente se une à veia mesentérica superior).
No microscópio, quando corado adequadamente, é fácil se distinguir os dois tipos diferentes de tecidos no pâncreas
Essas regiões correspondem às funções pancreáticas principais:
O pâncreas endócrino é composto de aglomerações de células especiais denominadas ilhotas de Langerhans
O "cansaço" crônico destas células leva ao aparecimento da diabetes no pâncreas.
Existem quatro tipos de células nas ilhotas de Langerhans
Elas são relativamente difíceis de se distinguir ao usar técnicas normais para corar o tecido, mas elas podem ser classificadas de acordo com sua secreção:
Porção que secreta, no duodeno, por meio de um ducto, o suco pancreático, contendo enzimas e bicarbonato.
Devido à sua importância na digestão e na produção de hormônios, as doenças do pâncreas possuem significativa relevância na prática clínica.
Ductos biliares: (bile canaliculus, ducto hepático comum, ducto cístico, ducto colédoco) | Ducto pancreático | Ampola hepatopancreática
As células são as unidades estruturais e funcionais dos organismos vivos
Alguns organismos, tais como as bactérias, são unicelulares (consistem em uma única célula)
Outros, tais como os seres humanos, são pluricelulares (várias células).
O corpo humano é constituído por aproximadamente 10 trilhões (mais de 10) de células; A maioria das células vegetais e animais têm entre 1 e 100 µm e, portanto, são visíveis apenas sob o microscópio; a massa típica da célula é um nanograma.
A célula foi descoberta por Robert Hooke em 1663 / 1665
Em 1837, antes de a teoria final da célula estar desenvolvida, Jan Evangelista Purkyně observou "pequenos grãos" ao olhar um tecido vegetal através de um microscópio
A teoria da célula, desenvolvida primeiramente em 1838 por Matthias Jakob Schleiden e por Theodor Schwann, indica que todos os organismos são compostos de uma ou mais células
Todas as células vêm de células preexistentes
As funções vitais de um organismo ocorrem dentro das células, e todas elas contêm informação genética necessária para funções de regulamento da célula, e para transmitir a informação para a geração seguinte de células.
A palavra "célula" vem do latim: cellula (quarto pequeno)
O nome descrito para a menor estrutura viva foi escolhido por Robert Hooke
Em um livro que publicou em 1665, ele comparou as células da cortiça com os pequenos quartos onde os monges viviam.


As células foram descobertas entre 1663 e 1665 pelo inglês Robert Hooke
Ao examinar em um microscópio rudimentar, uma fatia de cortiça, verificou que ela era constituída por cavidades poliédricas, às quais chamou de células (do latim "cella", pequena cavidade)
Na realidade Hooke observou blocos hexagonais que eram as paredes de células vegetais mortas.
Enquanto isso, Antonie van Leeuwenhoek (1632–1723), um holandês que ganhava a vida vendendo roupas e botões, estava gastando seu tempo livre moendo lentes e construindo microscópios de qualidade notável
Ele desenhou protozoários, tais como o Vorticella da água da chuva, e bactérias de sua própria boca
Van Leeuwenhoek foi contemporâneo e amigo do pintor Johannes Vermeer (1632-1675) da cidade de Delft que foi pioneiro no uso da luz e da sombra na arte ao mesmo tempo em que van Leeuwenhoek estava explorando o uso da luz para descobrir o mundo microscópico.
Em 1838 Matthias Schleiden e Theodor Schwann, estabeleceram o que ficou conhecido como teoria celular: "todo o ser vivo é formado por células tronco".
As células são envolvidas pela membrana celular e preenchidas com uma solução aquosa concentrada de substâncias químicas e substâncias físicas, o citoplasma em que se encontram dispersos organelos (por vezes escrito organelas, organóides, orgânulos ou organitos).
As formas mais simples de vida são organismos unicelulares que se propagam por cissiparidade
As células podem também constituir arranjos ordenados, os tecidos.
De acordo com a organização estrutural, as células são divididas em: eucarióticas e procarióticas
As células procarióticas são geralmente independentes, enquanto que as células eucarióticas são frequentemente encontradas em organismos multicelulares.
As células procarióticas, também chamadas de protocélulas, são muito diferentes das eucariontes
Em geral, são bem menores e menos complexas estruturalmente do que as células eucarióticas.
A sua principal característica é a ausência da carioteca individualizando o núcleo celular ao qual chamamos de nucleoide., pela ausência de alguns organelos e pelo pequeno tamanho que se acredita que se deve ao fato de não possuírem compartimentos membranosos originados por evaginação ou invaginação
Também possuem DNA na forma de um anel associado a proteínas básicas e não a histonas (como acontece nas células eucarióticas, nas quais o DNA se dispõe em filamentos espiralados e associados a histonas).
Estas células são desprovidas de mitocôndrias, plastídeos, complexo de Golgi, retículo endoplasmático e sobretudo cariomembrana o que faz com que o DNA fique disperso no citoplasma
Como organela, só possuem ribossomos
A este grupo pertencem:
As bactérias dos grupos das Rickettsias e das clamídias são muito pequenas, sendo denominadas células incompletas por não apresentarem capacidade de auto-duplicação independente da colaboração de outras células, isto é, só proliferarem no interior de outras células completas, sendo, portanto, parasitas intracelulares obrigatórios.
Diversas doenças de importância médica tem sido descritas para organismos destes grupos, incluindo algumas vinculadas aos psitacídeos (papagaios e outras aves, a psitacose) e carrapatos (a febre maculosa, causada pela Rickettsia rickettsii).
Estas bactérias são diferente dos vírus por apresentarem:
1
Cloroplasto
2
Vacúolo
3
Núcleo
As células eucariontes ou eucarióticas, também chamadas de eucélulas, são mais complexas que as procariontes
Possuem membrana nuclear individualizada e vários tipos de organelas
Todos os animais e plantas são dotados deste tipo de células.
É altamente provável que estas células tenham surgido por um processo de aperfeiçoamento contínuo das células procariontes, o que chamamos de Endossimbiose.
Não é possível avaliar com precisão quanto tempo a célula "primitiva" levou para sofrer aperfeiçoamentos na sua estrutura até originar o modelo que hoje se repete na imensa maioria das células, mas é provável que tenha demorado milhões de anos
Acredita-se que a célula "primitiva" tivesse sido bem pequena e para que sua fisiologia estivesse melhor adequada à relação tamanho × funcionamento era necessário que crescesse.
Acredita-se que a membrana da célula "primitiva" tenha emitido internamente prolongamentos ou invaginações da sua superfície, os quais se multiplicaram, adquiriram complexidade crescente, conglomeraram-se ao redor do bloco inicial até o ponto de formarem a intrincada malha do retículo endoplasmático
Dali ela teria sofrido outros processos de dobramentos e originou outras estruturas intracelulares como o complexo de Golgi, vacúolos, lisossomos e outras.
Quanto aos cloroplastos (e outros plastídeos) e mitocôndrias, atualmente há uma corrente de cientistas que acreditam que a melhor teoria que explica a existência destes orgânulos é a Teoria da Endossimbiose, segundo a qual um ser com uma célula maior possuía dentro de sí uma célula menor mas com melhores características, fornecendo um refúgio à menor e esta a capacidade de fotossintetizar ou de sintetizar proteínas com interesse para a outra.
Nesse grupo encontram-se:
Todas as células, tanto procariontes quanto eucariontes, tem uma membrana que envolve a célula, que separa o interior de seu ambiente, regula o que se move dentro e para fora (seletivamente permeável), e mantém o potencial elétrico da célula
Dentro da membrana, um citoplasma salino ocupa a maior parte do volume da célula
Todas as células possuem DNA, o material hereditário dos genes, e RNA, contendo as informações necessárias para sintetizar várias proteínas como enzimas, as máquinas primária da célula
Existem também outros tipos de biomoléculas nas células
Esta seção lista estes componentes primários da célula, e em seguida, descreve brevemente a sua função.
O citoplasma de uma célula está rodeado por uma membrana celular ou membrana plasmática
A membrana plasmática em plantas e procariontes é normalmente coberta por uma parede celular
Esta membrana serve para separar e proteger uma célula do seu ambiente circundante e é feita principalmente a partir de uma camada dupla de lipídeos (hidrófoba semelhante as moléculas de gordura) e moléculas de fósforo hidrofílicas
Assim, a camada é chamada uma bicamada de fosfolípido
Pode também ser chamada de uma membrana mosaico fluido
Incorporadas dentro desta membrana há uma variedade de moléculas de proteínas que actuam como canais e bombas que movem diferentes moléculas para dentro e para fora da célula
A membrana é dita ser 'semi-permeável', na medida em que pode deixar uma substância (molécula ou íon) passar livremente, passar através de uma forma limitada ou não passar de jeito nenhum
As membranas da superfície celular também contém proteínas receptoras que permitem que as células detectem moléculas externas de sinalização, tais como hormonas.
O citoesqueleto atua para organizar e manter a forma da célula; âncorar organelas no lugar; ajuda durante a endocitose, a absorção de materiais externos por uma célula, e na citocinese, a separação de células filhas após a divisão celular; e move partes da célula em processos de crescimento e de mobilidade
Normalmente, 20-35% das proteínas de uma célula estão ligadas ao citoesqueleto embora esta quantidade possa variar sendo consideravelmente maior nas células musculares
O citoesqueleto eucariótico é composto por microfilamentos, filamentos intermediários e microtúbulos
Existe um grande número de proteínas associadas a eles, cada uma controlando uma estrutura da célula, orientando, agrupando, e alinhando os filamentos
O citoesqueleto procariótico é bem menos estudado, mas está envolvido na manutenção da forma da célula, na polaridade e na citocinese.
Dois tipos diferentes de material genético existem: ácido desoxirribonucleico (DNA) e ácido ribonucleico (RNA)
A maioria dos organismos usa o DNA para o seu armazenamento de informação de longo prazo, mas alguns vírus (por exemplo, os retrovírus) têm RNA como seu material genético
A informação biológica contida num organismo é codificado em seu DNA ou em sua sequência de RNA
O RNA é também utilizado para o transporte de informação (por exemplo, RNA mensageiro) e funções enzimáticas (por exemplo, o ARN ribossomal) em organismos que utilizam DNA para o código genético em si
Moléculas de RNA de transporte (RNA) são usadas para adicionar aminoácidos durante a tradução de proteínas.
O material genético procariótico é organizado em uma molécula de DNA circular simples (o cromossoma bacteriano) na região nucleoide do citoplasma
O material genético eucariótico é dividido em diferentes moléculas, lineares chamadas cromossomas dentro de um núcleo discreto, geralmente com material genético adicional, em algumas organelas como mitocôndrias e cloroplastos
(ver Teoria da endossimbiose).
O corpo humano contém muitos órgãos diferentes, tais como o coração, pulmão e rim, com cada órgão exercendo uma função diferente
As células também possuem um conjunto de "pequenos órgãos", chamado de organelas, que são adaptados e/ou especializados para a realização de uma ou mais funções vitais
Ambas as células eucarióticas e procarióticas têm organelas mas organelas em eucarioticas são geralmente mais complexa e pode ser envoltas em uma membrana.
Existem vários tipos de organelas em uma célula
Algumas (tais como o núcleo e o complexo de Golgi) são tipicamente solitárias, enquanto outras (tais como mitocôndrias, peroxissomas e lisossomas) podem ser numerosas (centenas a milhares)
O citosol é o fluido gelatinoso que preenche a célula e rodeia os organelos.
Em citologia, cílios são apêndices das células eucarióticas com movimento constante numa única direção
Este nome provém do latim, com o significado de pestana, pela sua similaridade aparente.
Uma cápsula gelatinosa está presente em algumas bactérias fora da parede celular
A cápsula pode ser de polissacárido como no pneumococos, meningococos ou de polipéptido como Bacillus anthracis ou ácido hialurónico como em estreptococos
As cápsulas não são marcadas por coloração comum e podem ser detectadas por coloração especial.
Flagelos são os organelos de mobilidade celular
Eles surgem a partir do citoplasma por extrusão através da parede celular
Eles são longos e grossos apêndices filamentados, proteínas em sua natureza
São mais comumente encontrados em células de bactérias, mas também são encontrados em algumas células animais
Alguns flagelos atuam como uma hélice rotativa em contraste aos cílios que agem mais como um remo.
Fímbrias são apêndices em forma de filamentos ou franjas presentes em bactérias
Este apêndices são menores, mais curtos e mais numerosos que os flagelos
Eles são filamentos curtos e finos como cabelos, formados de proteína chamada pilin (antigénico)
Fímbrias são responsáveis pela fixação das bactérias aos receptores específicos de células humanas (aderência).
O tabagismo é uma toxicomania caracterizada pela dependência física e psicológica do consumo de nicotina, substância presente no tabaco.
Segundo o Ministério da Saúde do Brasil, os cigarros contém cerca de 4720 substâncias tóxicas, sendo uma delas, a nicotina, responsável pela dependência.
De acordo com a Organização Pan-Americana da Saúde (OPAS), o tabagismo é o responsável por cerca de 30% das mortes por cancro (câncer no Brasil), 90% das mortes por cancro do pulmão, 25% das mortes por doença coronariana, 85% das mortes por doença pulmonar obstrutiva crónica e 25% das mortes por derrame cerebral
Ainda de acordo com a OPAS, não existem níveis seguros de consumo do tabaco.
As doenças ocasionadas pelo consumo de tabaco matam 4,9 milhões de pessoas por ano, o que significa cerca de 10 mil mortes por dia, com uma projeção estimada de óbitos em torno de 10 milhões até o ano 2030 - das quais 7 milhões ocorrerão nos países em desenvolvimento e metade dos afetados em idade ativa dos 35-70 anos
Vale a pena sublinhar que o tabagismo, hoje, mata mais que a soma das mortes por AIDS, cocaína, heroína, álcool, suicídios e acidentes de trânsito
As doenças causadas pelo tabaco são responsáveis por perdas econômicas de aproximadamente US$ 200 bilhões de dólares, no mundo.
O método de avaliação de Fagerström é, hoje, utilizado por especialistas, para ajudar a definir a melhor estratégia para quem quer largar o cigarro
Trata-se de um questionário utilizado por médicos a fim de determinar se uma pessoa está seriamente viciada na nicotina.


Em 15 de outubro de 1492 folhas secas de tabaco foram oferecidas a Cristovão Colombo pelos índios americanos.
Chegou a Europa como proposta curativa (o tabaco era mascado).
A relação entre o Tabagismo e Saúde é conhecida de forma geral pela maioria das pessoas
Sabe-se que "faz mal" mas o vício é de tal forma elevado que leva as pessoas a permanecer a sua atividade nociva com consequências variadas
O Tabagismo é responsável por:
No Brasil, estima-se que cerca de 290 mil mortes por ano são decorrentes do tabagismo
A proporção de fumantes no país é de 23,9% da população
Segundo dados da PNAD, em 2008, o Brasil tinha 24,6 milhões de fumantes habituais com idade a partir de 15 anos ou 17,2% da população de pessoas dessa faixa etária, sendo 15,1% fumantes diários.
Cerca de 90% dos fumantes tornam-se dependentes da nicotina entre os 5 e os 19 anos de idade
Há 2,8 milhões de fumantes nessa faixa etária, mas a maior concentração de fumantes está na faixa etária de 20 a 49 anos.
A região Sul do país é a que apresenta maior proporção de dependentes - 45% dos fumantes
Em 2008, a região Sul, com 19,3%, tinha o maior percentual de fumantes correntes.
No Nordeste, os fumantes dependentes são 31%
Os moradores da zona rural também fumam mais que os das zonas urbanas.
O fumo é responsável por 95% dos casos de câncer de boca; 90% das inflamações de mama; 80% da incidência de câncer no pulmão; por 97% dos casos de câncer da laringe; 50% dos casos de câncer de pele; 45% das mortes por doença coronariana (infarto do miocárdio) e também 25% das mortes por doença vascular-cerebral (derrames cerebrais).
O tabagismo, incluindo o passivo, é o fator de risco mais comum para a DPOC, Doença Pulmonar Obstrutiva Crônica
No Brasil, estima-se que a doença atinja cerca de 6 milhões de pessoas
Somente 12% dos pacientes são diagnosticados e, desses, apenas 18% recebem tratamento
Já no cenário mundial, a estimativa é de que aproximadamente 210 milhões de pessoas tenham DPOC e a previsão é que a doença se torne a terceira principal causa de morte por volta de 2020
Outros fatores que contribuem para o desenvolvimento da doença são a inalação de poeiras e produtos químicos em fábricas ou ambientes profissionais similares, poluição do ar, desenvolvimento pulmonar prejudicado e fatores genéticos.
Segundo uma pesquisa realizada em 20 países, o brasileiro, com 91%, é o que mais se arrepende de ter começado a fumar
Entre os fumantes brasileiros do estudo internacional, 63% apóiam campanhas e leis contra o fumo e 82% relatam que o fumo já lhes causou algum problema de saúde
Segundo os dados da Kantar Health, mesmo com restrições impostas, os fumantes parecem observar com razoável conforto as legislações que visam evitar que não fumantes sejam incomodados pela fumaça de cigarros, charutos e cachimbos
Dentre os respondentes do Reino Unido, França, EUA, China, Brasil e Espanha, a maioria alega não achar difícil restringir o consumo em locais restritos.
O Brasil é o maior exportador e quarto maior produtor mundial de tabaco - depois da China, EUA e Índia.
Deve-se ressaltar que o cultivo do tabaco expõe trabalhadores rurais a uma grande variedade de agrotóxicos aumentando o risco de manifestação de efeitos agudos e crônicos à saúde, como transtornos mentais e câncer
Durante a colheita das folhas de tabaco pode haver absorção dérmica da nicotina presente nas folhas úmidas, podendo ocasionar a denominada Doença da Folha Verde do Tabaco, cujos sintomas são muito semelhantes aos quadros de intoxicação por agrotóxicos e outras doenças.
Em 2015, um em cada quatro portugueses (25%) é fumador, mais dois pontos percentuais do que em 2012, 12% deixaram de fumar e quase dois terços (63%) nunca fumaram.
Na União Europeia (UE), a média de fumadores é de 26%, uma quebra de dois pontos na comparação com o inquérito de 2012.
Em Portugal, fumam mais os homens (34%) do que as mulheres (18%), em linha com a média da UE: 31% e 22%, respetivamente.
A maior prevalência é dada no grupo etário 25 a 34 anos (45,6% nos homens e 25,1% nas mulheres) e as mais baixas no grupo etário 65 a 74 anos (10,8% nos homens e 2,5% nas mulheres).
A expressão pressão arterial (PA) ou pressão sanguínea refere-se à pressão exercida pelo sangue contra a parede das artérias
A pressão arterial bem como a de todo o sistema circulatório encontra-se normalmente um pouco acima da pressão atmosférica, sendo a diferença de pressões responsável por manter as artérias e demais vasos não colapsados
Em uma pessoa saudável, o valor da pressão pode variar continuamente, dependendo do stress, a emotividade ou se está fazendo atividade fisica.


Denomina-se ciclo cardíaco o conjunto de acontecimentos desde o fim de um batimento cardíaco até o fim do seguinte.
No momento em que o coração bombeia seu conteúdo na aorta mediante contração do ventrículo esquerdo, encontrando-se a válvula mitral fechada e a válvula aórtica aberta, quando a pressão ventricular esquerda é máxima, a pressão calculada a nível das artérias também é máxima
Como esta fase do ciclo cardíaco se chama sístole, a pressão calculada neste momento é chamada de pressão arterial sistólica.
Imediatamente antes do próximo batimento cardíaco, com a válvula aórtica fechada e a mitral aberta, o ventrículo esquerdo está em relaxamento e a receber o sangue das aurículas
Neste momento a pressão arterial nas artérias é baixa, e, como este período do ciclo cardíaco se chama diástole, é denominada pressão arterial diastólica
No entanto, esta pressão mínima ainda é consideravelmente superior à pressão presente do lado exterior da aorta e de todo o sistema arterial, sendo esta certamente maior do que a pressão atmosférica razão pela qual as artérias não colapsam nesta fase do ciclo.
A determinação indireta da pressão arterial só se tornou possível a partir de 1880, quando von Basch, na Alemanha, idealizou o primeiro aparelho, que nada mais era que uma bolsa de borracha cheia de água e ligada a uma coluna de mercúrio ou a um manômetro
Comprimindo-se a bolsa de borracha sobre a artéria até ao desaparecimento do pulso obtinha-se a pressão sistólica
Em 1896, um médico italiano, Riva-Rocci, substituiu a bolsa por um manguito de borracha e a água pelo ar
A medida da pressão diastólica teve que esperar por mais 9 anos, até que um jovem médico russo, Nikolai Korotkov descobrisse os sons produzidos durante a descompressão da artéria.

Não existe uma combinação precisa de medidas para se dizer qual é a pressão normal, mas em termos gerais, diz-se que os valores 120/80 mmHg são valores considerados ideais no adulto jovem
Contudo, medidas até 140 mmHg para a pressão sistólica, e 90 mmHg para a diastólica, podem ser aceitas como normais.
O local mais comum de verificação da pressão arterial é o braço, usando como ponto de auscultação a artéria braquial
O equipamento usado é o esfigmomanômetro ou tensiômetro, que possui uma braçadeira insuflável ou manguito, e para auscultar os batimentos, usa-se o estetoscópio.
Quando se fala em dois valores de pressão arterial (145 por 90 mmHg, por exemplo), estamos falando de 145 no pico da sístole e 90 no final da diástole, portanto pressão sistólica e pressão diastólica.
A pressão arterial pode ser medida a vários níveis do sistema circulatório, diminuindo a pressão à medida que o ponto de medida se afasta do coração
Assim, na grande circulação podem ser medidas pressões a todos os níveis mas na prática clínica diária só se usa a pressão máxima e a mínima.
Na pequena circulação existem todos os equivalentes acima, seguidos do termo "Pulmonar", como em "Pressão Arterial Pulmonar"
Hipoglicemia é uma condição em que a taxa de glicose no sangue diminui para valores inferiores ao normal
A condição causa vários sintomas, entre os quais desorientação, dificuldade em falar, estado de confusão, perda de consciência, convulsões ou morte
Podem ainda estar presentes sintomas como fome, sudação em excesso, tremores e fadiga
Geralmente os sintomas manifestam-se de forma súbita
A condição oposta é a hiperglicemia.
A causa mais comum de hipoglicemia são os medicamentos antidiabéticos usados no tratamento da diabetes, como a insulina e as sulfonilureias
O risco é maior em diabéticos que comeram menos do que é habitual ou que ingeriram bebidas alcoólicas
Entre outras possíveis causas estão a insuficiência renal, alguns tumores como o insulinoma, doenças hepáticas, hipotiroidismo, inanição, erro metabólico hereditário, infeções graves, hipoglicemia reativa e uma série de drogas, incluindo álcool
A hipoglicemia pode também ocorrer em bebés de outro modo saudáveis que não tenham comido durante várias horas.
A taxa de glicose no sangue que define a hipoglicemia varia
Em pessoas com diabetes, o diagnóstico corresponde a uma taxa inferior a 3,9 mmol/L (70 mg/dL)
Em adultos sem diabetes, o diagnóstico é confirmado quando se verifica simultaneamente sintomas relacionados com a hipoglicemia, baixa glicose no sangue durante os sintomas, e melhoria desses sintomas assim que a taxa regressa ao normal
Quando não se manifestam sintomas, pode ser usado um valor de referência inferior a 2,8 mmol/L (50 mg/dL) em jejum ou após a realização de exercício físico
Em recém-nascidos, uma taxa inferior a 2,2 mmol/L (40 mg/dL), ou inferior a 3,3 mmol/L (60 mg/dL) quando acompanhada de sintomas, indica a presença de hipoglicemia
Os valores de glicose são medidos com análises ao sangue
Entre outros exames que podem ser úteis para determinar a causa estão os valores de insulina e de peptídeos-C no sangue.
Nas pessoas com diabetes, a prevenção da hipoglicemia consiste em adequar a dieta à quantidade de exercício físico praticado e aos medicamentos usados
Quando as pessoas sentem que a taxa de glicose pode estar a diminuir, recomenda-se o uso de um medidor de glicemia portátil
Como algumas pessoas manifestam poucos sintomas iniciais quando a taxa de glicose diminui, recomenda-se a este grupo que monitorize frequentemente a taxa de glicose
O tratamento consiste em ingerir alimentos ricos em açúcares simples ou na toma de dextrose
Nos casos em que a pessoa não consegue ingerir alimentos pela boca, pode ser necessária uma injeção de glicagina
O tratamento da hipoglicemia sem relação com a diabetes consiste em tratar também o problema subjacente e numa dieta saudável.


Os sintomas hipoglicêmicos podem ser divididos naqueles produzidos pelos hormônios contra-regulatórios (adrenalina e glucagon), acionados pelo declínio da glicose, e naqueles produzidos pela redução de açúcar no cérebro.
Nem todas as manifestações anteriores ocorrem em casos de hipoglicemia
Não há ordem certa no aparecimento dos sintomas
Manifestações específicas variam de acordo com a idade e com a severidade da hipoglicemia
Em crianças jovens com hipoglicemia matinal, há vômito frequentemente acompanhado de cetose
Em crianças maiores e em adultos, a hipoglicemia moderadamente severa pode parecer mania, distúrbio mental, intoxicação por drogas ou embriaguez
Nos idosos, a hipoglicemia pode produzir efeitos parecidos com uma isquemia focal ou mal-estar sem explicação.
Em recém-nascidos, a hipoglicemia pode produzir irritabilidade, agitação, ataque mioclônico, cianose, dificuldade respiratória, episódios de apneia, sudorese, hipotermia, sonolência, hipotonia, recusa a se alimentar e convulsões
Também pode parecer asfixia, hipocalcemia, sepse ou falha cardíaca.
Em ambos, pacientes de longa data ou não, o cérebro pode se habituar a níveis baixos de glicose, com redução dos sintomas perceptíveis em momentos de neuroglicopenia
Diabéticos insulinodependentes chamam a neuroglicopenia incondicionalmente de hipoglicemia, e que é um problema clínico importante quando tenta-se melhorar o controle glicêmico desses pacientes
Outro aspecto desse fenômeno ocorre em glicogenose tipo I, onde a hipoglicemia crônica antes do diagnóstico pode ser mais bem tolerada do que episódios agudos após o início do tratamento.
Quase sempre a hipoglicemia severa a ponto de ocasionar convulsões ou inconsciência pode ser revertida sem danos ao cérebro
Os casos de morte ou dano neurológico permanente que ocorreram com um único episódio envolvem ocorrências conjuntas de inconsciência não tratada ou prolongada, ou interferência na respiração, ou doenças concorrentes severas ou outros tipos de vulnerabilidade
De qualquer maneira, hipoglicemias severas podem eventualmente resultar em morte ou dano cerebral.
Mais raramente, a hipoglicemia pode revelar:
Da mesma forma que a maioria das células de animais, o metabolismo cerebral depende primeiramente de glicose para trabalhar
Em casos de privação de glicose, pode-se conseguir uma quantidade limitada dela armazenada nos astrócitos, mas que é consumida em minutos
De qualquer forma, o cérebro é dependente de fornecimento contínuo de glicose, que difunde do sangue ao tecido intersticial dentro do sistema nervoso central, e aos próprios neurônios.
Por isso, se a quantidade de glicose suprida pelo sangue cai, o cérebro é um dos primeiros órgãos a percebê-lo
Na maioria das pessoas, a eficiência mental parece diminuir quando a glicemia cai abaixo de 65 mg/dL (3,6 mM)
Ocorre limitação de ações e de julgamento geralmente quando a glicemia cai abaixo de 40 mg/dL (2,2 mM)
Se cair ainda mais, podem ocorrer convulsões
Próxima ou abaixo de 10 mg/dL, a maior parte dos neurônios fica eletricamente desligada, resultando no coma.
A importância de um fornecimento adequado de glicose ao cérebro é clara pelo fato de ocorrerem inúmeras respostas nervosas, hormonais e metabólicas para combater uma hipoglicemia
A maior parte delas é defensiva ou adaptiva: ou tentando aumentar o açúcar no sangue via gliconeogênese e glicogenólise, ou providenciando formas de energia alternativas.
Embora se cite que 70 mg/dL (3.9 mmol/L) seja o limite inferior da glicemia normal, podem definir-se diferentes valores como baixos em diferentes populações, propósitos e circunstâncias
O nível preciso de glicemia considerado baixo o bastante para se definir uma hipoglicemia depende de: (1) método de medição; (2) idade da pessoa; (3) presença ou ausência de sintomas.
O nível de glicose neste artigo é o de plasma venoso ou em soro, medido por métodos-padrão de glicose oxidase usados em laboratórios
Para finalidades clínicas, tanto o nível no plasma quanto o no soro são similares o bastante para serem intercambiados
O plasma arterial ou em soro são levemente superiores do que os níveis venosos, e os níveis capilares estão entre os arteriais e os venosos
A diferença entre os níveis arterial e venoso é pequena sob jejum, mas é amplificada e pode ser até 20% maior em estado pós-prandial
Por outro lado, os níveis de glicemia totais (por exemplo os medidos por glicosímetros digitais) são cerca de 10-15% menores do que os níveis em plasma venoso
Além disso, os glicosímetros disponíveis garantem apenas exatidões de 15% em relação a valores de laboratórios clínicos.
Dois outros fatores afetam significantemente a medição da glicose
A disparidade entre a concentração venosa e a concentração total é maior quando o hematócrito é alto, como no caso de recém-nascidos
Em segundo, a menos que a amostra tenha sido colocada em um tubo de fluoreto ou processada imediatamente para separar o soro ou plasma das células, a glicose mensurável será gradualmente metabolizada in vitro.
Dados estatísticos de crianças e adultos saudáveis mostram que glicemias em jejum abaixo de 60 mg/dL (3,3 mM) ou acima de 100 mg/dL (5,6 mM) são encontradas em menos de 5% da população
Em até 10% dos recém-nascidos e crianças jovens, foram encontrados níveis abaixo de 60 mg/dL depois de jejum noturno
Em outras palavras, muitas pessoas saudáveis podem eventualmente ter níveis glicêmicos na faixa de hipoglicemia sem apresentar sintomas ou distúrbios.
A faixa glicêmica normal de recém-nascidos ainda é motivo de debate
As estatísticas e a experiência revelam níveis de açúcar frequentemente abaixo de 40 mg/dL (2,2 mM) e, mais raramente, abaixo de 30 mg/dL (1,7 mM) em bebês saudáveis de gravidez a termo nos primeiros dias de vida
Foi proposto que os cérebros de recém-nascidos são mais facilmente capazes de usar combustíveis alternativos quando os níveis glicêmicos estão baixos, em relação a adultos
Os especialistas continuam o debate quanto à significância e ao risco desses níveis glicêmicos, embora a tendência seja recomendar a manutenção dos níveis de glicose acima de 60–70 mg/dL (3,3-3,9 mM) após os primeiros dias de vida
Em bebês prematuros, adoecidos ou abaixo do peso é mais comum encontrar baixos níveis de glicose, mas há um consenso de que os açúcares devam ser mantidos ao menos acima de 50 mg/dL (2,8 mM) nestas circunstâncias
Alguns especialistas defendem 70 mg/dL (3,9mM) como um objetivo terapêutico, especialmente em circunstâncias tais como hiperinsulinismo, onde combustíveis alternativos podem ser mais escassos.
Pesquisas mostram que a eficiência mental diminui levemente mas de modo sensível quando a glicemia cai abaixo de 65 mg/dL (3,6 mM), em adultos saudáveis
Os mecanismos de defesa hormonal (adrenalina e glucagon) são ativados assim que a glicemia passa por limiares (cerca de 55 mg/dL ou 3,0 mM para a maioria das pessoas), produzindo tremores e disforia
Por outro lado, não ocorre com frequência um prejuízo de capacidade mental até que a glicemia caia abaixo de 40 mg/dL (2,2 mM), e até 10% da população pode eventualmente ter níveis de glicose abaixo de 65 (3,6) pela manhã sem efeitos aparentes
Os efeitos da hipoglicemia, chamados de neuroglicopenia, é que determinam quando um certo nível glicêmico é realmente um problema ao indivíduo.
É preferível que a pessoa com hipoglicemia use tanto os sintomas quanto os dados numéricos de seu glicosímetro para determinar as medidas a serem tomadas
É fácil notar hipoglicemia quando o valor lido é 50 mg/dL (2,8 mM); porém, um paciente que está com a diabetes descompensada e frequentemente lê valores acima de 200 mg/dL (11,1 mM) pode sentir sintomas de hipoglicemia quando o nível de glicose no sangue chegar a valores "normais" de 90 mg/dL (5,0 mM)
Neste caso, a pessoa não apresenta uma hipoglicemia clássica, mas terá alívio de sintomas com o tratamento rotineiro para hipoglicemias
Além disso, quando a glicemia diminui a uma taxa rápida, também podem surgir sintomas de hipoglicemia.
Este critério é por si só complicado de se admitir pelo fato de os sintomas da hipoglicemia serem vagos e poderem ser produzidos por outros motivos; além do que, quando a pessoa passa por níveis baixos de glicemia com recorrência, ela pode perder a sensação de limiar, de forma que pode haver agravamento de seus sintomas (por neuroglicopenia) sem que ela note
Para completar a dificuldade, os glicosímetros são inexatos para baixos valores, o que descredita a sua utilidade nessas horas.
Procure sempre encontrar a causa de uma baixa glicémia
A glicémia diária normal não deverá ser inferior a 90 mg/dl (5 mmol/l)
Utilize os testes à glicémia para evitar a hipoglicémia
É particularmente importante testar a glicémia ao deitar
Nenhuma criança diabética deverá deitar-se antes das refeições sem que lhe seja feito o teste da glicémia
Não injete insulina antes duma refeição se o valor for inferior a 90 mg/dl (5 mmol/l)
Espere que a criança acabe a refeição e só depois injete insulina
O açúcar sanguíneo pode subir ao valor normal em minutos da seguinte forma: consumindo (por conta própria) ou recebendo (por outrem) 10-20 g de carboidrato
Pode ser em forma de alimento ou bebida caso a pessoa esteja consciente e seja capaz de engolir
Essa quantidade de carboidrato está contida nos seguintes alimentos:
O amido é rapidamente transformado em glicose, mas a adição de gordura ou proteína retarda a digestão
Os sintomas começam a melhorar em 5 minutos, embora demore 10-20 min até a recuperação completa
O abuso de alimentos não acelera a recuperação e se a pessoa for diabética isto simplesmente causará uma hiperglicemia mais tarde.
Se a pessoa está sofrendo de efeitos severos de hipoglicemia de maneira que não possa (devido a combatividade) ou não deva (devido a convulsões ou inconsciência) ser alimentada, pode-se dar a ela uma infusão intravenosa de glicose ou uma injeção de glucagon..
A prevenção depende da causa da hipoglicemia
O risco de novos episódios pode ser frequentemente reduzida pelo abaixamento da dose de insulina ou medicamento, ou pela atenção maior à glicemia durante eventos inesperados, diminuição do ritmo de exercícios físicos ou de ingestão de álcool.
Muitos tipos de disfunções congêneres do metabolismo requerem evitar ou encurtar os intervalos de jejum, ou evitar carboidratos extras
Para distúrbios mais severos, como a glicogenose tipo I, isto pode ser feito pelo consumo de amido de milho de hora em hora ou por infusão gástrica contínua.
Vários tratamentos são usados em caso de hipoglicemia hiperinsulinêmica, dependendo da forma exata e do grau de severidade
Algumas formas de hiperinsulinismo congênito respondem bem ao diazóxido ou octreótido
A remoção cirúrgica da parte hiper-reativa do pâncreas é eficaz com risco mínimo quando o hiperinsulinismo é focal, ou devido a um tumor benigno produtor de insulina
Quando o hiperinsulinismo congênito é difuso ou imune às medicações, a pancreatectomia subtotal pode ser o tratamento de último caso, mas neste caso é menos efetivo e passível de várias complicações.
A hipoglicemia devida a deficiências hormonais como hipopituitarismo ou insuficiência adrenal geralmente cessa quando se administra o hormônio apropriado.
A hipoglicemia devida à síndrome do empachamento (ou Síndrome de dumping no português brasileiro) e outras condições pós-cirúrgicas é mais bem tratada com alteração da dieta
A inclusão de gordura e proteína com carboidratos pode retardar a digestão e reduzir a secreção antecipada de insulina
Alguns desses casos respondem a tratamento com um inibidor de glicosidase, que retarda a digestão de amido.
A hipoglicemia reativa com baixa glicose no açúcar é frequentemente um incômodo previsível, que pode ser evitado pelo consumo de gordura e proteína com carboidratos, pela adição de lanches pela manhã e à tarde e pela redução do consumo de álcool.
A síndrome pós-prandial idiopática sem níveis baixos de glicose no momento dos sintomas pode ser mesmo um desafio de conduta
Muitas pessoas encontram melhorias com a mudança no padrão de alimentação (refeições menores, evitando açúcar em demasia, refeições mistas em detrimento de carboidratos), ou fazendo mudanças no estilo de vida para evitar o estresse, ou diminuindo o consumo de estimulantes como cafeína.
Gastroplastia, também chamada de Cirurgia Bariátrica, Cirurgia da Obesidade ou ainda de Cirurgia de redução do estômago, é, literalmente, a plástica do estômago (gastro = estômago, plastia = plástica) que tem como o objetivo reduzir o peso de pessoas com o IMC muito elevado.
É uma cirurgia realizada em pessoas com o peso muito acima do ideal, os chamados obesos mórbidos.
O Brasil é o 2º colocado em número absoluto de cirurgias bariátricas, com 60 mil por ano, ficando atrás apenas dos EUA, onde são realizadas 300 mil.


A classificação da obesidade é de acordo com o IMC =(Peso/altura²) O aumento de peso atualmente está divido em:
Mas esses índices variam
Um atleta pode ter um alto IMC sem ser obeso, já que músculos pesam mais do que gordura.
O tratamento clínico é escolha em pacientes com sobrepeso e obesidade leve (IMC entre 30-34,9 Kg/m²)
Hoje está estabelecido que o tratamento cirúrgico está indicado em pacientes definidos com obesidade moderada (IMC > 35 Kg/m²) que tenham comorbidades como apneia do sono, hipertensão, diabetes mellitus, dislipidemia, artropatias ou aqueles pacientes com IMC > 40 Kg/m² independente de haver comorbidades ou não
Isso porque já foi evidenciado que existe um risco muito maior do paciente morrer por complicações clínicas relacionadas à obesidade do que morrer com a realização da cirurgia e os benefícios que ela traz.
A mortalidade por cirurgia bariátrica laparoscópica em 2009 é 0,3%
Estudos vão ainda mais longe demonstrando que o risco de morte em pacientes obesos submetidos à cirurgia bariátrica é 35% menor do que aqueles que seguem tentando realizar somente tratamentos clínico com IMC > 35 Kg/m² com comorbidades ou IMC>40 Kg/m²  .
Tipo de mecanismo das cirurgias bariátricas:
Os tipos de cirurgias bariátricas mais frequentemente realizados segundo Kawahara são:
A técnica mais conhecida e estudada é a chamada Cirurgia de Bypass em Y de Roux
A cirurgia inicia com uma videolaparoscopia
Na sequência, os procedimentos são idênticos
O estômago, que tem capacidade para cerca de dois litros é seccionado com um grampeador cirúrgico de maneira a se obter um novo estômago com capacidade para apenas 15-30ml
Uma alça intestinal é anastomosada ao novo estômago para permitir a saída e a absorção dos alimentos que é chamada anastomose gastrojejunal
O funcionamento da cirurgia é através da restrição da ingestão de alimentos, e em menor parte por disabsorção, uma vez que cerca de 150 cm de intestino delgado são desviados (técnica mista - predominantemente restritiva)
O emagrecimento acentuado pode requerer cirurgias plásticas para a retirada do excesso de pele.
Um outro grupo de cirurgias para redução de peso é o das cirurgias chamadas "predominantemente disabsortivas" e as principais representantes deste grupo são as realizadas pela técnica de Scopinaro e o "Duodenal Switch"
O paciente pode apresentar diarreia ao ingerir alimentos gordurosos e ter desnutrição proteica sobretudo no Scopinaro
Tanto o Scopinaro quanto o Duodenal Switch podem ser feitos por laparoscopia.
Em todas as técnicas, o paciente precisa ser acompanhado de perto por uma equipe especializada multidisciplinar e receber suplementos de vitamina B12, Cálcio e polivitamínicos.
O dólar dos Estados Unidos (em inglês: United States dollar) ou dólar americano (em inglês: American dollar) é a moeda oficial dos Estados Unidos e utilizada no mundo inteiro, tanto em reservas internacionais como em livre circulação em alguns países
Atualmente, a sua expedição é controlada pela Reserva Federal dos Estados Unidos.


O nome dollar deriva de thaler (em português táler), abreviação de Joachimsthaler, uma moeda de prata cunhada pela primeira vez em 1518, com prata extraída das minas situadas em torno da cidade de Joachimsthal ("Vale de São Joaquim"), atual Jáchymov, na Boêmia
1815
O código ISO 4217 para o dólar dos Estados Unidos é USD (que significa United States Dollar), e o Fundo Monetário Internacional refere-se ao mesmo como US$, abreviação que também é muito comum fora dos EUA para designá-lo, uma vez que o dólar foi criado pelos estadunidenses.
Usa-se também o símbolo $, normalmente escrito antes do valor numérico, para o dólar dos EUA, assim como para muitas outras moedas
O sinal foi o resultado de uma evolução, no fim do século XVIII, da sigla "p", do peso
O p e s, passaram a ser escritos um sobre o outro, dando origem ao $.
Outra explicação popular é que ele vem das Colunas de Hércules no brasão espanhol da moeda espanhola cunhadas no Novo Mundo na Cidade do México, Potosí (Bolívia) e em Lima (Peru)
Estas Colunas de Hércules nas moedas espanholas de prata assumiram a forma de duas barras verticais (||) com uma faixa de pano balançando na forma de um "S".
Há ainda outra explicação ficcional que sugere que o sinal do dólar foi formado a partir das letras maiúsculas U e S escritas ou impressas uma em cima da outra
Esta teoria, popularizada pela escritora Ayn Rand em Atlas Shrugged , ignora o fato de que o símbolo já estava em uso antes da formação dos Estados Unidos.
O dólar dos Estados Unidos é dividido em 100 cêntimos ou então em 10 dimes, mas este último é usado hoje em dia somente para designar a moeda de 10 cents
Moedas e notas de um dólar existem simultaneamente, embora notas sejam encontradas mais facilmente
Denominações menores que um dólar são emitidas em moedas, enquanto que as que o superam são emitidas em notas da Reserva Federal (Federal Reserve).
Até 1944, quando ocorreu a Conferência de Bretton Woods, era difícil determinar o valor do dólar em comparação ao de outras unidades monetárias, sendo a dificuldade ainda maior com os fortes abalos causados pela Segunda Guerra Mundial
Geralmente as cotações se baseavam nas reservas em ouro dos países, por ser o ouro um parâmetro universal
A esta altura os EUA já eram a maior potência mundial, por isso tentou-se estabelecer um padrão em que o grama de ouro teria um valor fixo em dólares.
O sistema durou até o início da década de 1970, quando o dólar já estava seriamente desvalorizado em relação ao valor acordado originalmente
Em 1971, o dólar deixou de ser diretamente conversível em ouro e, graças aos avanços tecnológicos que permitem negociações rápidas e em grandes volumes, surgiu o câmbio flutuante englobando vários pares de moedas
Foi assim que nasceu o Forex.
Em 1995, mais de 380 bilhões de dólares dos Estados Unidos estavam em circulação, dois terços disso fora dos EUA
Em abril de 2004, aproximadamente 700 bilhões estavam em circulação, com uma estimativa de metade de dois terços dele fora dos EUA.
Os Estados Unidos são um dos vários países que usam a moeda dólar
Vários países usam o dólar dos Estados Unidos como sua moeda oficial, e muitos outros permitem que ela seja usada de facto.
Nas décadas de 1980 e 1990, muitos economistas viam, com grande simpatia, a dolarização da economia brasileira como forma de romper o círculo vicioso da inflação, que, na época, já podia ser considerada hiperinflação
Adotando o dólar como lastro para a moeda nacional, o Brasil poderia se ver livre do tão terrível dragão inflacionário
Outros economistas tinham receio na adoção dessa solução, principalmente quando viram a Argentina sofrer com a incapacidade de pagamento, resultando no abandono desse sistema.
Alguns dizem que o Plano Real foi, por um breve período, um tipo de dolarização da economia brasileira, visto que a URV — Unidade Real de Valor —, tinha, mais ou menos, o mesmo valor de 1 dólar
Após a desvalorização do real em 1999, houve o descolamento da moeda estadunidense, com a adoção do câmbio flutuante.
Notas acima de US$ 100 eram produzidas antigamente, porém a produção parou em 1946 e foram retiradas de circulação em 1969
Estas notas eram usadas em transações entre bancos ou pelo crime organizado; foi o uso ilícito que fez com que o presidente Richard Nixon mandasse uma ordem executiva em 1969 proibindo seu uso
Com o advento das transações eletrônicas, as notas tornaram-se desnecessárias
As notas com valor acima de US$ 100 eram as de US$ 500, US$ 1.000, US$ 5.000, US$ 10.000 e US$ 100.000.
Recentemente foram lançadas novas notas de US$ 10 a US$ 100, com projeto gráfico diferenciado, entretanto, as antigas continuam valendo, devendo ser retiradas de circulação conforme forem se desgastando.

O(a) diabetes insípido(a) (DI
Em latim, diabetes insipidus) é uma doença caracterizada pela sede pronunciada e pela excreção de grandes quantidades de urina muito diluída
Esta diluição não diminui quando a ingestão de líquidos é reduzida
Isto denota a incapacidade renal de concentrar a urina
A DI é ocasionada pela deficiência do hormônio antidiurético (vasopressina) ou pela insensibilidade dos rins a este hormônio.
O hormônio antidiurético é produzido normalmente no hipotálamo do cérebro e liberado pela neuro-hipófise
Ele controla o modo como os rins removem, filtram e reabsorvem fluidos dentro da corrente sanguínea
Quando ocorre a falta desse hormônio (ou quando os rins não podem responder ao hormônio) os fluidos passam pelos rins e se perdem por meio da micção
Assim, uma pessoa com diabetes insípido precisa ingerir grande quantidade de água em resposta à sede extrema para compensar a perda de água.


"Diabetes" vem do grego diabétes, através do latim diabetes
Insipidus é o termo latino para "insípido" (sem sabor) e se refere ao fato de a urina do doente não apresentar excesso de glicose, ao contrário do doente de diabetes melito.
A diurese excessiva e a sede intensa são típicos da DI
Os sintomas do diabetes insipidus são similares aos da diabetes mellitus, com a distinção de que não ocorre a glicosúria (urina doce) e não há hiperglicemia (glicose do sangue elevada)
Problemas de visão são raros
A primeira manifestação do diabetes insípido costuma ser nictúria pela perda de capacidade de concentração da urina no período da noite.
A apresentação clínica ocorre com poliúria aumento da freqüência urinária e volume (volume urinário em 24 horas > 3 l [> 40 ml/kg] em adolescentes e adultos e > 2 l/m2 de superfície corporal [> 100 ml/kg] em crianças) e consequente aumento da ingestão de água (polidipsia), sede intensa, com ingestão de grande quantidade de líquidos
A velocidade de instalação dos sintomas é importante, visto que, na maioria dos pacientes com diabetes insípido renal hereditário, a manifestação se verifica já na primeira semana de vida
Nos casos de diabetes insípido central hereditário, a manifestação pode ocorrer na infância após o primeiro ano de vida ou na adolescência.
Em adultos, o início dos sintomas costuma se dar de forma súbita nos casos de diabetes insípido central e de forma insidiosa nos casos de diabetes insípido renal
O aumento do volume urinário, que pode chegar a 18 l em 24 horas, é compensado com o aumento da ingestão hídrica
O excesso de diurese continua dia e noite
Estes pacientes tem uma grande suscetibilidade à desidratação e distúrbios hidroeletrolíticos
Em pacientes sem acesso livre a água (por exemplo, sedados), com alteração hipotalâmica no centro da sede (por exemplo, lesões hipotalâmicas) e naqueles com grande volume urinário, pode haver distúrbios hidroeletrolíticos graves.
Em crianças, a DI pode interferir no apetite, no ganho de peso e no crescimento
Ela pode levar à febre, vómitos ou diarreia
Adultos com uma DI sem tratamento permanecem saudáveis por décadas desde que a ingestão de água seja suficiente para compensar as perdas urinárias
Entretanto, há um risco contínuo de desidratação.
Para identificação da causa da poliúria, a glicemia (glicose do sangue) e o cálcio sérico devem ser testados
Os eletrólitos podem se mostrar alterados; hipernatremia (excesso de sódio) são comuns nos casos graves
O exame parcial de urina mostra baixos níveis de electrólitos, e a osmolaridade e densidade urinárias são baixas.
Um "teste de privação de água" ajuda a determinar se a DI é causada por:
Este teste mede modificações no peso corporal, volume urinário e composição urinária
Dosagens de Hormônio Antidiurético (ADH) no sangue pode ser necessário para o diagnóstico final.
Para distinguir entre as várias formas, a estimulação com desmopressina (um análogo mais potente da vasopressina), pode também ser utilizada, injectável, via spray nasal ou via oral
Caso ocorra redução do volume urinário e aumento da densidade urinária, a produção do ADH pela glândula pituitária é deficiente e a resposta renal é normal
Caso haja falta de resposta renal a desmopressina não fará efeito.
Se a DI central é suspeitada, testa-se outro hormónios produzidos pela pituitária e realiza-se uma ressonância nuclear magnética (MRI) para descobrir se alguma outra doença está afectando a pituitária, como um prolactinoma.
A concentração urinária que ocorre em pessoas normais é devida à secreção do hormônio antidiurético (ADH) pela porção posterior da glândula hipofisária e pela ação deste hormônio nos rins, onde ocorre a concentração urinária.
Há dois tipos distintos de diabete insípido: o central, onde ocorre uma deficiência da glândula hipofisária em liberar o ADH, e que pode ser primário ou secundário
É primário quando não há uma lesão identificável na hipófise, podendo ser genético ou esporádico (idiopático); é secundário, quando há danos na hipófise ou no hipotálamo, como cirurgias, infecções ou traumas
O outro tipo de diabete insípido é o nefrogênico, onde a hipófise produz adequadamente o ADH, mas os rins não respondem em função de um defeito nos túbulos renais que interferem na reabsorção da água
Esta forma pode ser genética ou adquirida, ocorrendo em doenças como amiloidose, mieloma, síndrome de Sjogren, anemia falciforme e hipercalcemia crônica.
Basicamente, pode ocorrer por deficiência do hormônio antidiurético (ADH) ou por resistência à sua ação nos túbulos renais.
Quando há deficiência na síntese do ADH, o diabetes insípido é chamado central, neuro-hipofisário ou neurogênico;
Quando há resistência à sua ação nos túbulos renais, é dito renal ou nefrogênico.
O diagnóstico diferencial de diabetes insípido inclui polidipsia primária (polidipsia psicogênica) e causas de diurese osmótica
Na polidipsia primária, o distúrbio inicial é o aumento da ingestão de água, manifestando-se principalmente em pacientes com transtornos psiquiátricos e mais raramente em pacientes com lesões hipotalâmicas que afetam o centro de controle da sede
O diagnóstico de diurese osmótica ocorre por aumento da filtração de um soluto osmoticamente ativo e consequente aumento do volume urinário
A mais comum, dentre as causas de diurese osmótica, é o diabetes melito, com o aumento da diurese devido à ação osmótica da glicose na urina
É importante a diferenciação entre os tipos de diabetes insípido
Os tratamentos para o diabetes insípido central e para o renal são distintos
O diabetes insípido central, associado à redução na secreção de ADH, é mais frequentemente idiopático, ou associado a trauma, cirurgia, tumores da região hipotalâmica ou a encefalopatia hipóxica/isquêmica
Já o diabetes insípido renal, associado a diferentes graus de resistência à ação do ADH, ocorre nas formas hereditárias, induzido por fármacos (por exemplo, lítio) ou secundário à hipercalcemia.
O diabetes insípido gestacional, por expressão de vasopressinases (enzimas que degradam o ADH) pela placenta, é uma forma rara e transitória da doença, que se manifesta mais comumente no terceiro trimestre da gestação e apresenta resolução do quadro alguns dias após o parto,
Classificação para fins didáticos:
A DI central e a DI gestacional respondem ao uso de desmopressina
Na DI dipsogênica e na DI nefrogênica, a desmopressina não surte efeito.
Independentemente da presença ou não de tumor, o tratamento do diabetes insípido central está indicado
Serão incluídos os pacientes que tenham diagnóstico de diabetes insípido central baseado nos dois critérios abaixo:
• poliúria (volume urinário em 24 horas acima de 3 l [> 40 ml/kg] em adultos e adolescentes e > 2 l/m2 de superfície corporal [> 100 ml/kg] em crianças); e • resposta à administração de desmopressina - na vigência de osmolalidade plasmática > 295 mOsm/kg ou sódio plasmático > 147mEq/l - com aumento na osmolalidade urinária > 15% e osmolaridade urinária > 600 mOsm/kg.
Serão excluídos, deste protocolo de tratamento, os pacientes que apresentarem hipersensibilidade ou intolerância a desmopressina.
Pacientes com diabetes insípido gestacional que atendam aos critérios de inclusão deverão receber tratamento ao longo da gestação até a normalização do quadro, conforme especificado no Item Monitorização, e ser monitorizadas após o parto para identificar-se a necessidade de manutenção do uso de desmopressina.
Desmopressina é um análogo sintético do ADH com maior tempo de ação, maior potência antidiurética e menor efeito pressórico quando comparado ao ADH
O tratamento do diabetes insípido com desmopressina tem embasamento em séries de casos
O primeiro relato de seu uso no tratamento de diabetes insípido central envolveu uma série de 10 pacientes com a condição
Nesse estudo, que utilizou como controles os dados históricos dos 10 pacientes no período em que usavam o ADH como tratamento, a desmopressina mostrou-se segura e apresentou vantagens em relação ao ADH, principalmente quanto ao número de aplicações do medicamento (6-10 doses/dia com ADH e 1-3 doses/dia com desmopressina) e aos efeitos adversos (comuns com ADH e não detectados com desmopressina.
Pela inequívoca demonstração de tratar-se de um fármaco com perfil de segurança e efetividade favoráveis, a desmopressina no tratamento do diabetes insípido central foi amplamente adotada, não existindo ensaios clínicos randomizados comparando ADH e desmopressina no tratamento da condição
Desmopressina, que é um peptídio resistente à ação das vasopressinases placentárias, é também o tratamento de escolha no diabetes insípido gestacional, com dados de segurança favoráveis tanto para a gestante como para o feto
• Desmopressina: 0,1 mg/ml (100 mg/ml) com aplicação nasal (frasco de 2,5 ml em solução
Há duas apresentações de aplicação nasal de desmopressina disponíveis, com algumas particularidades quanto à sua administração
A solução nasal é aplicada através de túbulo plástico, que deve ser preenchido com a dose a ser utilizada, por capilaridade (encostando uma ponta do túbulo na solução contida no frasco)
Após assegurar-se de que a dose está correta, uma das extremidades do túbulo é colocada na cavidade nasal, e outra, na boca do paciente
Através da extremidade colocada na boca, o medicamento é soprado para a cavidade nasal, onde é absorvido
Já a aplicação por spray nasal é realizada através de jato nasal com dose fixa de 10 mg/jato
O uso do spray nasal é mais simples, porém não permite a flexibilidade das doses que a solução nasal possibilita
O spray nasal fornece doses fixas múltiplas de 10 mg (por exemplo, 10, 20, 30 mg).
Já a solução nasal possibilita a aplicação de doses múltiplas de 5 mg (por exemplo, 5, 10, 15, 20 mg), o que pode ser mais adequado para alguns pacientes, principalmente para os pediátricos
A dose inicial de desmopressina recomendada é de 10 mg em adultos e adolescentes e de 5 mg em crianças
Sugere-se que a dose inicial seja administrada à noite e que o incremento gradual no número de aplicações e na dose seja feito de forma individualizada, de acordo com a resposta do paciente
Existem graus muito variáveis de deficiência do ADH, o que repercute na variabilidade da dose de manutenção da desmopressinna, conforme a seguir:
• desmopressina solução nasal - 5–20 mg, 1 a 3 vezes ao dia • desmopressina spray nasal - 10–20 mg, 1 a 3 vezes ao dia ou spray)
O tratamento do diabetes insípido central deve ser mantido por toda a vida, visto que a supressão de desmopressina pode causar risco ao paciente.
não há benefícios
1
Clínica Clim, Protocolo Operacional Padrão, Diabetes Insipidus, Ribeira do Pombal, Bahia, Brasil - 2011, agosto, 28
2
Jane JA, Jr., Vance ML, Laws ER
Neurogenic diabetes insipidus
Pituitary
2006;9(4):327-9.
3
Sands JM, Bichet DG
Nephrogenic diabetes insipidus
Ann Intern Med
2006 Feb 7;144(3):186-94.
4
Schrier RW
Body water homeostasis: clinical disorders of urinary dilution and concentration
J Am Soc Nephrol
2006 Jul;17(7):1820-32.
5
Kalelioglu I, Kubat Uzum A, Yildirim A, Ozkan T, Gungor F, Has R
Transient gestational diabetes insipidus diagnosed in successive pregnancies: review of pathophysiology, diagnosis, treatment, and management of delivery
Pituitary
2007;10(1):87-93.
6
Brewster UC, Hayslett JP
Diabetes insipidus in the third trimester of pregnancy
Obstet Gynecol
2005 May;105(5 Pt 2):1173-6.
7
Mavrakis AN, Tritos NA
Diabetes insipidus with deficient thirst: report of a patient and review of the literature
Am J Kidney Dis
2008 May;51(5):851-9.
8
Kim RJ, Malattia C, Allen M, Moshang T, Jr., Maghnie M
Vasopressin and desmopressin in central diabetes insipidus: adverse effects and clinical considerations
Pediatr
Endocrinol
Rev
2004 Nov;2 Suppl 1:115-23.
9
Andersson KE, Arner B
Effects of DDAVP, a synthetic analogue of vasopressin, in patients with cranial diabetes insipidus
Acta Med Scand
1972 Jul-Aug;192(1-2):21-7.
10
Bichet D
Diagnosis of polyuria and diabetes insipidus
In: Post T, editor
UpToDate v.17.3; 2009.
11
Miller M, Dalakos T, Moses AM, Fellerman H, Streeten DH
Recognition of partial defects in antidiuretic hormone secretion
Ann Intern Med
1970 Nov;73(5):721-9.
12
Ray JG
DDAVP use during pregnancy: an analysis of its safety for mother and child
Obstet Gynecol Surv
1998 Jul;53(7):450-5.
13
Majzoub JA, Srivatsa A
Diabetes insipidus: clinical and basic aspects
Pediatr Endocrinol Rev
2006 Dec;4 Suppl 1:60-5.
bexiga urinária: Cistite (Cistite intersticial, Trigonite) - Bexiga neurogênica - Fístula êntero-vesical
uretra: Uretrite (Uretrite não-gonocócica) - Síndrome uretral - Estenose uretral
A língua latina ou latim é uma antiga língua indo-europeia do ramo itálico originalmente falada no Lácio, a região do entorno da cidade de Roma
Foi amplamente difundida, especialmente na Europa Ocidental, como a língua oficial da República Romana, do Império Romano e, após a conversão deste último ao cristianismo, da Igreja Católica Romana
Através da Igreja Católica, tornou-se a língua dos acadêmicos e filósofos europeus medievais
Por ser uma língua altamente flexiva e sintética, a sua sintaxe (ordem das palavras) é, em alguma medida, variável, se comparada com a de idiomas analíticos como o português, embora em prosa os romanos tendessem a preferir a ordem SOV
A sintaxe é indicada por uma estrutura de afixos ligados a temas
O alfabeto latino, derivado dos alfabetos etrusco e grego (por sua vez, derivados do alfabeto fenício), continua a ser o mais amplamente usado no mundo.
Embora o latim seja hoje uma língua morta, ou seja, uma língua que não mais possui falantes nativos, ele ainda é empregado pela Igreja Católica para fins rituais e burocráticos
Exerceu enorme influência sobre diversas línguas vivas, ao servir de fonte vocabular para a ciência, o mundo acadêmico e o direito
O latim vulgar, nome dado ao latim no seu uso popular inculto, é o ancestral das línguas neolatinas (italiano, francês, espanhol, português, romeno, catalão, romanche e outros idiomas e dialetos regionais da área); muitas palavras adaptadas do latim foram adotadas por outras línguas modernas, como o inglês
O fato de haver sido a lingua franca do mundo ocidental por mais de mil anos é prova de sua influência.
O latim ainda é a língua oficial da Cidade do Vaticano e do Rito Romano da Igreja Católica
Foi a principal língua litúrgica até o Concílio Vaticano Segundo nos anos 1960
O latim clássico, a língua literária do final da República e do início do Império Romano, ainda hoje é ensinado em muitas escolas primárias e secundárias, embora seu papel se tenha reduzido desde o início do século XX.


O latim inclui-se entre as línguas itálicas, e seu alfabeto baseia-se no alfabeto itálico antigo, derivado do alfabeto grego
No século IX a.C
ou VIII a.C., o latim foi trazido para a península Itálica pelos migrantes latinos, que se fixaram numa região que recebeu o nome de Lácio, situda ao longo do rio Tibre, onde a civilização romana viria a desenvolver-se
Naqueles primeiros anos, o latim sofreu a influência da língua etrusca, proveniente do norte da península e que não era uma língua indo-europeia.
A importância do latim na península Itálica firmou-se gradativamente
A princípio, era apenas a língua de Roma, uma pequena cidade circundada por vários centros menores (Lanúvio, Preneste, Tívoli), nos quais se falavam dialetos latinos ou afins ao latim (o falisco, língua da antiga cidade de Falérios)
Já a poucos quilômetros de Roma, eram faladas línguas muito diversas: o etrusco e sobretudo línguas do grupo indo-europeu - o umbro, no norte, e o osco, na porção mais ao sul, até a atual Calábria
Na Itália setentrional falavam-se outras línguas indo-europeias como o lígure, o gálico e o venético
O grego era difundido nas numerosas colônias gregas da Sicília e da Magna Grécia
Ao longo de toda a era republicana, a situação linguística da Itália permaneceu muito variada: o plurilinguismo era uma condição comum, e os primeiros autores da literatura, como Ênio e Plauto dominavam o latim, o grego e o osco.
Além das variações regionais, mesmo o latim de Roma não foi uma língua sempre igual a si mesma, apresentando fortes diferenças diacrônicas e sociolinguísticas
Do ponto de vista diacrônico, deve-se distinguir:
Embora a literatura romana sobrevivente seja composta quase inteiramente de obras em latim clássico, a língua falada no Império Romano do Ocidente na Antiguidade tardia (200 a 600 d.C) era o latim vulgar, que diferia do primeiro em sua gramática, vocabulário e pronúncia.
O latim manteve-se por muito tempo como a língua jurídica e governamental do Império Romano, mas, com o tempo, o grego passou a predominar entre os membros da elite culta romana, já que grande parte da literatura e da filosofia estudada pela classe alta havia sido produzida por autores gregos, em geral atenienses
Na metade oriental do Império, que viria a tornar-se o Império Bizantino, o grego terminou por suplantar o latim como idioma governamental e era a lingua franca da maioria dos cidadãos orientais, de todas as classes.
A difusão do latim por um território cada vez mais vasto teve duas consequências:
Geralmente, as populações submetidas desejavam elevar-se culturalmente adotando o latim, coisa que ocorre sempre que dois povos entram em contato: prevalece linguisticamente aquele que possui maior prestígio cultural
Dessa forma Roma conseguiu fazer prevalecer o latim sobre o etrusco, o osco e o umbro, mas não sobre o grego, cujo prestígio cultural era maior.
As populações submetidas e as federadas, antes de perder sua língua em favor do latim, atravessaram um período mais ou menos longo de bilinguismo; de fato, algumas das línguas pré-romanas tiveram, no território romanizado, considerável vitalidade durante muito tempo
E essas línguas originárias deram uma cor específica a cada língua neolatina (ou românica) surgente, permanecendo presentes em topônimos dessas regiões até hoje.
Após a sua transformação nas línguas românicas, o latim continuou a fornecer um repertório de termos para muitos campos semânticos, especialmente culturais e técnicos, em uma ampla variedade de línguas.
O latim é uma língua flexiva
No caso dos substantivos e adjetivos a flexão é denominada declinação; no caso dos verbos, conjugação.
No latim clássico cada substantivo ou adjetivo pode tomar seis formas ou casos:
Também existem resquícios de um sétimo caso de origem indo-europeia, o locativo, que indica localização (por exemplo: domī , "em casa"), no entanto, este é limitado a palavras específicas.
Outra característica distintiva do latim é o uso de formas simples para expressar a voz passiva dos verbos, além de uma forma verbo-nominal muito frequente chamada de supino
Ambas formas se perderam nas línguas românicas.
Os romanos usavam o alfabeto latino, derivado do alfabeto itálico antigo, o qual por sua vez advinha do alfabeto grego
O alfabeto latino sobrevive atualmente como sistema de escrita das línguas românicas (como o português), célticas, germânicas (inclusive o inglês) e muitas outras.
Os antigos romanos não usavam pontuação, macros (mas empregavam ápices para distinguir entre vogais longas e breves), nem as letras j e u, letras minúsculas (embora usassem uma forma de escrita cursiva) ou espaço entre palavras (mas por vezes empregavam-se pontos entre palavras para evitar confusões)
Assim, um romano escreveria a frase "Lamentai, ó Vênus e cupidos" da seguinte maneira:
Esta frase seria escrita numa edição moderna como:
Ou, com macros:
A escrita cursiva romana é encontrada nos diversos tabletes de cera escavados em sítios como fortes, como por exemplo os descobertos em Vindolanda, na Muralha de Adriano, na Grã-Bretanha.
A chamada pronúncia reconstituída ou restaurada baseia-se em pesquisas recentes sobre os mais prováveis sons que os romanos antigos atribuíam a cada letra e, embora não haja uniformidade de opiniões em alguns pontos, vem sendo adotada em escolas de todo o mundo.
Há dois outros tipos de pronúncia: a pronúncia tradicional lusófona, também a mais usada em fórmulas jurídicas, e a pronúncia adotada pela Igreja Católica (latim eclesiástico)
Quanto à ortografia, não há diferenças.
A seguir, as principais características da pronúncia restaurada (entre parênteses as pronúncia e a marcação do acento tônico): 

Os romanos antigos faziam distinção entre vogais breves e vogais longas, estas últimas com o dobro de duração das primeiras e, para efeitos de acentuação tônica, usavam a regra da penúltima, segundo a qual o critério de acentação tônica é a duração (longa ou breve) da penúltima vogal: se a penúltima vogal é longa, ela recebe o acento; se é curta, o acento recua para a antepenúltima vogal
Existem ainda alguns aspectos a notar, como, por exemplo:
1) vogal seguida de outra vogal é geralmente breve: filius (pronuncia-se 'fílius': o i antes do u é breve e, portanto, o acento recua).
2) vogal seguida de duas consoantes é geralmente longa: puella (o e vem antes de duas consoantes e, portanto, é longo e acentuado).
3) em latim não existem palavras com acento na última sílaba (oxítonas).
Todas as vogais de uma palavra têm sua duração bem definida e dessa duração depende a compreensão dos ritmos da poesia latina.
O latim não possui artigos.
Os substantivos têm dois números (singular e plural) e seis casos (nominativo, vocativo, acusativo, genitivo, dativo e ablativo)
Organizam-se em cinco declinações, que se distinguem pela terminação da forma de genitivo singular: 1ª: -ae, 2ª: -i, 3ª: -is, 4ª: -us e 5ª: -ei
Nem sempre a forma de nominativo correspondente é determinável a partir da forma de genitivo
Por exemplo, nominativo uerbum, genitivo uerbi ("palavra"); mas nominativo puer, genitivo pueri (menino)
Assim, para se saber declinar um nome em todas as suas formas, é preciso saber a forma de nominativo e a de genitivo; tipicamente os dicionários fornecem ambas: uerbum, uerbi e puer, pueri.
Há três géneros gramaticais: masculino, feminino e neutro
O género de um nome depende em certa medida da declinação que o nome segue, mas a associação não é completamente rígida
Os nomes da primeira declinação são quase todos femininos (p
ex., rosa, rosae "rosa"), mas os que têm referentes humanos geralmente respeitam o género natural e por isso alguns são masculinos (p
ex., nauta, nautae "marinheiro")
Os nomes da segunda declinação cujo nominativo singular termina em -um são todos neutros
Os restantes nomes desta declinação (com nominativo em -us or -r, como dominus, domini "senhor", ager, agri "campo", uir, uiri homem) são quase todos masculinos, mas há muitos nomes de árvores em -us, -i e estes são todos femininos: ficus, fici "figueira"
Nas restantes declinações o género é mais arbitrário.
O adjetivo concorda com o nome que modifica ou de que é predicado em número, género e caso.
A numeração é: unus/una/unum, duo/duae/duo, tres/tria, quattuor, quinque, sex, septem, octo, novem, decem; 11 undecim, 12 duodecim, 13 tredecim, 20 viginti, 30 triginta, 100 centum.
Os verbos flexionam em pessoa, número, tempo, modo, aspeto e voz
Cada verbo pertence a uma de quatro conjugações, que se distinguem por exemplo pela forma de infinitivo presente ativo: 1ª: -are, 2ª: -ēre, 3ª: -ěre, 4ª: -ire
O lema de um verbo latino (isto é a forma de dicionário) não é contudo uma forma de infinitivo mas sim a forma de primeira pessoa singular do presente do indicativo ativo: p.ex., o verbo sum ("sou"), não esse ("ser").
O latim possui muito poucos nomes e verbos com flexão verdadeiramente irregular, mas contém muitíssimos verbos cujas formas se baseiam em radicais diferentes e que não são previsíveis entre si
Por exemplo, o verbo cano ("cantar"), tem formas como cano ("canto", radical can-), cecini ("cantei", radical cecin-) e cantum ("para cantar", radical cant-).
O pronome interrogativo é quis (masculino e feminino) "quem?", quid "quê?"
Quis possui formas plurais qui/quae/qua
Os demonstrativos são is/ea/id, hic/haec/hoc, "este/esta/isto", iste, ista, istud "esse, essa, isso", ille/illa/illud "aquele/aquela/aquilo"
Os pronomes pessoais são: singular ego "eu", tu "tu"; plural nos "nós", uos "vós"
Para a terceira pessoa podem usar-se demonstrativos ou sobretudo sujeitos nulos.
A ordem canónica do latim clássico é SOV, mas é uma língua não configuracional: a ordem das palavras não está diretamente ligada a funções gramaticais, pois a flexão em caso é muitas vezes suficiente para determinar estas funções
Por exemplo, as seguintes frases latinas significam todas "Marco ama Cornélia", uma vez que a forma Marcus é nominativa e a forma Corneliam é acusativa:
A frase "Cornélia ama Marco" seria Cornelia Marcum amat.
-a no singular Ex: "Bona discipula sum" ("Boa discípula sou", ou, "[Eu] sou [uma] boa discípula")
-ae no plural Ex: "Ideo servae sedulae sunt" ("Por isso, escravas aplicadas são", ou, "Por isso, [as] escravas são aplicadas")
-am no singular Ex.: Staphyla Phaedram amat
"Estáfila ama Fedra"
-as no plural Ex.: Staphyla Phaedras amat
"Estáfila ama as Fedras".
Em português, diferenciamos os complementos verbais por posição e por preposições
Em orações afirmativas, por exemplo, o sujeito vem tipicamente antes do verbo e os outros complementos vêm tipicamente depois do verbo
Abaixo temos os sujeitos em negrito e os outros complementos com a primeira letra em negrito.
Em latim, contudo, além da posição relativa dos complementos e das preposições, também se diferenciavam os complementos verbais pela escolha das terminações dos nomes.
Os sujeitos, no latim, ocorrem tipicamente no caso nominativo e "denotativo"
Podem também ocorrer no caso acusativo quando uma oração complementar representa o que alguém imagina, deseja, percebe ou diz.
Aquilo que se faz, imagina, deseja, percebe ou se diz ocorre tipicamente no caso acusativo.
Aquilo com que se atinge ou que se dá a alguém ocorre tipicamente no caso acusativo.
Alguém a quem se dá ou se diz algo ocorre tipicamente no caso dativo.
Alguém a quem algo pertence também ocorre tipicamente no caso dativo.
Aquilo que se usa ocorre no caso ablativo.
(Em latim, não existem pronomes do caso reto para a 3ª pessoa do singular: faz-se o uso de pronomes demonstrativos para indicar essa ausência).
Os numerais latinos podem ser Cardinais, Ordinais, Multiplicativos e Distributivos.
Os três primeiros cardinais declinam nos 3 gêneros (M, F, N), no singular / plural e nos 5 casos (Nom., Acu., Gen., Dat., Abl.)
O cardinal 3 utiliza a mesma forma para os gêneros M e F
Os demais cardinais até 100 não declinam.
Os cardinais são:
Os ordinais indicam em latim, além da sequência, as frações
São declináveis como adjetivos da primeira classe
Apresentam as formas como segue:
Os adjetivos declinam conforme adjetivos de segunda classe e são: simplex, duplex, triplex, etc.
Os advérbios (uma vez, duas vezes, etc) não tem declinação e são: semer, bis, ter, quater, etc.
São também declináveis, indicam "de um em um", "de dois em dois" e assim por diante
Apresentam a forma: singuli, bini, terni, quaterni, etc.
até nuoeni, deni; dezenas: viceni, triceni, etc

A expansão do Império Romano espalhou o latim por toda a Europa e o latim vulgar terminou por dialetar-se, com base no lugar em que se encontrava o falante
O latim vulgar evoluiu gradualmente de modo a tornar-se cada uma das distintas línguas românicas, um processo que continuou pelo menos até o século IX
Tais idiomas mantiveram-se por muitos séculos como línguas orais, apenas, pois o latim ainda era usado para escrever
Por exemplo, o latim foi a língua oficial de Portugal até 1296, quando foi substituído pelo português
Estas línguas derivadas, como o italiano, o francês, o espanhol, o português, o catalão e o romeno, floresceram e afastaram-se umas das outras com o tempo.
Dentre as línguas românicas, o italiano é a que mais conserva o latim em seu léxico, enquanto que o sardo é o que mais preserva a fonologia latina.
Algumas das diferenças entre o latim clássico e as línguas românicas têm sido estudadas na tentativa de se reconstruir o latim vulgar
Por exemplo, as línguas românicas apresentam um acento tônico distinto em certas sílabas, ao qual o latim acrescentava uma quantidade vocálica distinta
O italiano e o sardo logudorês possuem, além do acento tônico, uma ênfase consonantal distinta; o espanhol e o português, apenas o acento tônico; e no francês, a quantidade vocálica e o acento tônico já não são distintos
Outra grande diferença entre as línguas românicas e o latim é que as primeiras, com exceção do romeno, perderam os seus casos gramaticais para a maioria das palavras, afora alguns pronomes
A língua romena possui um caso direto (nominativo/acusativo), um indireto (dativo/genitivo), um vocativo e é o único idioma que preservou do latim o gênero neutro e parte da declinação.
Embora não seja uma língua românica, o inglês sofreu forte influência do latim
Sessenta por cento do seu vocabulário são de origem latina, em geral por intermédio do francês
O mesmo ocorreu com o maltês, uma língua semítica falada na República de Malta, na costa sul da Itália, que fora influenciado por 50% de palavras italianas e sicilianas e, em menor grau, pelo francês em seu léxico, e que mais recentemente fora influenciado pelo inglês em 20% de seu léxico
Também herdou o alfabeto latino, sendo a única língua semítica a ser escrita neste alfabeto.
Ademais do português, outras línguas românicas surgidas a partir do latim incluem o espanhol, o francês, o sardo, o italiano, o romeno, o galego, o occitano, o rético, o catalão e o dalmático - este, já extinto
As áreas onde as línguas românicas extintas eram faladas, são denominadas Romania submersa.
Como o contato com o latim escrito se manteve ao longo dos tempos, mesmo muito depois de o latim deixar de ter falantes nativos, muitas palavras latinas foram sendo introduzidas em muitas línguas
Este fenómeno acentuou-se desde o Renascimento, altura em que a cultura clássica foi revalorizada
Sobretudo o inglês e as línguas românicas receberam (e continuam a receber) muitas palavras de origem latina, mas bastantes outras línguas também o fizeram
Em especial, muitos novos termos dos domínios técnicos e científicos têm na sua base palavras latinas.
O latim vive sob a forma do latim eclesiástico usado para éditos e bulas emitidos pela Igreja Católica, e sob a forma de uma pequena quantidade esparsa de artigos científicos ou sociais escritos utilizando a língua, bem como em inúmeros clubes latinos
O vocabulário latino é usado na ciência, na universidade e no direito
O latim clássico é ensinado em muitas escolas, muitas vezes combinado com o grego, no estudo de clássicos, embora o seu papel tenha diminuído desde o início do século XX
O alfabeto latino, juntamente com suas variantes modernas, como os alfabetos inglês, espanhol, francês, português e alemão, é o alfabeto mais utilizado no mundo
Terminologia decorrente de palavras e conceitos em latim é amplamente utilizada, entre outros domínios, na filosofia, medicina, biologia e direito, em termos e abreviações como subpoena duces tecum, lato sensu, etc., i.e., q.i.d
(quater in die: "quatro vezes por dia") e inter alia (entre outras coisas)
Estes termos em latim são utilizados isoladamente, como termos técnicos
Em nomes científicos para organismos, o latim é geralmente o idioma preferido, seguido pelo grego.
A maior organização que ainda usa o latim em contextos oficiais e semioficiais é a Igreja Católica (principalmente na Igreja Católica de Rito Latino)
A Missa tridentina usa o latim, apesar do rito romano costumar utilizar o vernáculo local; no entanto, pode ser e muitas vezes é rezado em latim, particularmente no Vaticano
Na verdade, o latim ainda é a língua padrão oficial do rito romano da Igreja Católica e o Concílio Vaticano II apenas autorizou que os livros litúrgicos fossem traduzidos e, opcionalmente, usados nas línguas vernáculas
O latim é a língua oficial da Santa Sé e do Vaticano
A Cidade do Vaticano é também onde está instalado o único caixa eletrônico onde as instruções são dadas em latim.
Nos casos em que é importante empregar uma língua neutra, como em nomes científicos de organismos, costuma-se usar o latim.
Alguns filmes, como A Paixão de Cristo, apresentam diálogos em latim
A música 'Nirvana' do Grupo El Bosco é cantada, parte em latim, e em seguida em inglês.
Muitas instituições ainda hoje ostentam lemas em latim, a exemplo do estado brasileiro de Minas Gerais (libertas quæ sera tamen).
Se existir um WikiProjeto mais adequado, por favor corrija esta predefinição.
Rim (lat
ren, grc
νεφρός) é cada um dos dois órgãos excretores, em forma de feijão (tendo no ser humano, aproximadamente 11 cm de comprimento, 5 cm de largura e 3 cm de espessura)
É o principal órgão do sistema excretor e osmoregulador dos vertebrados
Os rins filtram produtos do metabolismo de aminoácidos (especialmente ureia) do sangue, e os excretam, com água, na urina; a urina sai dos rins através dos ureteres, para a bexiga.


Em humanos, os rins estão localizados na região posterior do abdómen, atrás do peritónio, motivo pelo qual são chamados de órgãos retroperitoneais
Existe um rim em cada lado da coluna; o direito encontra-se logo abaixo do fígado e o esquerdo abaixo do baço
Em cima de cada rim encontramos a glândula suprarrenal.
Os rins estão, aproximadamente no mesmo nível que as vértebras T12 a L3, sendo que o rim direito localiza-se um pouco mais inferiormente que o esquerdo
O polo superior de cada rim está encostado na décima primeira e décima segunda costelas e ambos encontram-se envoltos por um coxim de gordura, com finalidade de proteção mecânica.
Os rins são duas glândulas da cor vermelha escura colocadas simetricamente ao lado da coluna vertebral, na região lombar
Medem 10cm de largura e pesam cerca de 150gr cada um
O peritónio, membrana serosa que cobre a superfície superior do abdómen, prende-os fortemente contra a parede abdominal
A extremidade superior de cada rim é coberta por uma glândula edócrina, a glândula suprarrenal.
No adulto o rim tem cerca de 11 a 13 cm de comprimento, 5 a 7,5 cm de largura, 2,5 a 3 cm de espessura, com aproximadamente 125 a 170 gramas no homem e 115 a 155 gramas na mulher.
Cada rim possui a forma de um grão de feijão com duas faces (anterior e posterior), duas bordas (medial e lateral) e dois polos ou extremidades (superior e inferior)
Na borda medial encontra-se o hilo, por onde passam o ureter, artéria e veia renal, linfáticos e nervos
Os rins estão envolvidos em toda sua superfície por um tecido fibroso fino chamado cápsula renal
Ao redor do rim existe um acúmulo de tecido adiposo chamado gordura perirrenal, que por sua vez está envolvida por uma condensação de tecido conjuntivo, representando a fáscia de Gerota ou fáscia renal.
Ao corte frontal, que divide o rim em duas partes, é possível reconhecer o córtex renal, uma camada mais externa e pálida, e a medula renal, uma camada mais interna e escura
O córtex emite projeções para a medula denominadas colunas renais, que separam porções cônicas da medula chamadas pirâmides.
As pirâmides têm bases voltadas para o córtex e ápices voltados para a medula, sendo que seus ápices são denominados papilas renais
É na papila que desembocam os ductos coletores pelos quais a urina escoa atingindo a pelve renal e o ureter
A pelve é a extremidade dilatada do ureter e está dividida em dois ou três tubos chamados cálices maiores, os quais subdividem-se em um número variado de cálices menores
Cada cálice menor apresenta um encaixe em forma de taça com a papila renal.
Os rins são supridos pela artéria renal, que se origina da aorta
A artéria renal divide-se no hilo em um ramo anterior e um ramo posterior
Estes, dividem-se em várias artérias segmentares que irão irrigar vários segmentos do rim
Essas artérias, por sua vez, dão origem às artérias interlobares, que na junção cortico-medular dividem-se para formar as artérias arqueadas e posteriormente as artérias interlobulares
Dessas artérias surgem as arteríolas aferentes, as quais sofrem divisão formando os capilares dos glomérulos, que em seguida, confluem-se para formar a arteríola eferente
A arteríola eferente dá origem aos capilares peritubulares a às arteríolas retas, responsáveis pelo suprimento arterial da medula renal.
A drenagem venosa costuma seguir paralelamente o trajeto do sistema arterial
O sangue do córtex drena para as veias arqueadas e destas para as veias interlobares, segmentares, veia renal e finalmente veia cava inferior.
No córtex há numerosos linfáticos que drenam para a cápsula ou junção córtico-medular
Na medula, os linfáticos correm do ápice das pirâmides para a junção córtico-medular, onde formam linfáticos arqueados que acompanham os vasos sanguíneos até o hilo para drenar em linfonodos para-aórticos.
As fibras simpáticas alcançam o rim através do plexo celíaco
Essas fibras envolvem e seguem os vasos arteriais através do córtex e medula
As fibras para a sensibilidade dolorosa alcançam a medula espinhal pelos nervos esplânicos ou pelas raízes dorsais dos nervos espinhais de T12 a L2.
Cada rim é formado por cerca de 1 milhão de pequenas estruturas chamadas néfron
Cada néfron é capaz de eliminar resíduos do metabolismo do sangue, manter o equilíbrio hidroeletrolítico e ácido-básico do corpo humano, controlar a quantidade de líquidos no organismo, regular a pressão arterial e secretar hormônios, além de produzir a urina
Por esse motivo dizemos que o néfron é a unidade funcional do rim, pois apenas um néfron é capaz de realizar todas as funções renais.
O néfron é formado pela cápsula de Bowman, pelo glomérulo, túbulo contorcido proximal, alça de Henle, túbulo contorcido distal e túbulo coletor, arteríolas aferente e eferente, capilares peritubulares.
Além de excretar substâncias tóxicas, os rins também desempenham muitas outras funções
Abaixo estão listadas as principais funções renais:
Inicialmente o sangue vem por um vaso chamado arteríola aferente passa pelo glomérulo e sai pela arteríola eferente
O sangue é filtrado ao passar pelo glomérulo num processo chamado filtração glomerular
A quantidade de líquido que passa do glomérulo para a cápsula de Bowman (conhecido como filtrado glomerular) é muito grande, cerca de 170 litros por dia, sendo 99% desse total reabsorvidos pelos túbulos renais, resultando em aproximadamente 1,7 a 2 litros de urina por dia.
O mecanismo de passagem do líquido e sua composição é devido ao equilíbrio entre as forças que tendem a manter o líquido nos vasos e as que tendem a expulsá-lo (Forças de Starling)
Os dois principais fatores são a pressão hidrostática, que favorece a passagem de líquido do sangue para a cápsula de Bowman, e a pressão osmótica, que impede a saída de líquidos do sangue.
Após ser produzido pelo glomérulo, o filtrado glomerular segue para os túbulos renais onde será processado para dar origem à urina
Em cada segmento dos túbulos renais, ocorrem movimentos ativos (com gasto de energia) e passivos (sem gasto de energia) para a reabsorção de água e eletrólitos
Algumas substâncias, como eletrólitos e medicamentos, são secretadas do sangue para o filtrado glomerular pelos túbulos renais
O líquido final resultante do processamento tubular é a urina.
Os rins atuam na manutenção do equilíbrio ácido-básico, regulam a concentração de bicarbonato (HCO3), o qual possui a função de tamponamento, excretando íons de hidrogênio e regulam a produção de eritrócitos, através da secreção de eritropoetina, um hormônio que estimula a síntese de eritrócitos, na regulação do volume sanguíneo, na regulação da pressão arterial, no PH do sangue e no nível de glicose do sangue.
Os rins são os principais produtores de eritropoetina (juntamente com o fígado)
Uma insuficiência renal crônica leva, geralmente, a uma deficiência de EPO
Esta citocinina controla a eritropoiese, produção de eritrócitos
Quando a sua concentração é baixa, a produção é comprometida e há uma anemia hipoplásica porque há uma diminuição do número de eritrócitos.
Hiperaldosteronismo primário é caracterizado pelo excesso de produção de aldosterona pela suprarrenal
Leva a hipertensão arterial associada a hipocaliémia, esta é normalmente uma pista para o diagnóstico
A síndrome de Conn é um exemplo desta patologia, em que há um processo neoplásico (adenoma) produtor de aldosterona, localizado na suprarrenal.
Hiperaldosteronismo secundário é caracterizado pela grande actividade do sistema renina-angiotensina-aldosterona e que leva à produção de grande quantidade de aldostero.
A consequência mais grave do hiperaldosteronismo é a hipertensão arterial, que embora possa passar despercebida ocasionalmente, noutros casos é evidenciada por sintomas característicos: dor de cabeça, palpitações, náuseas e tonturas
Caso a hipertensão seja muito intensa e não seja corrigida com o tratamento adequado, pode provocar, a longo prazo, insuficiência cardíaca e acidentes vasculares cerebrais
Como a aldosterona promove a eliminação de potássio através da urina, é igualmente frequente o aparecimento de sintomas que indicam uma redução da concentração de potássio no sangue, sobretudo alterações neurológicas, bem como parestesia (formigamentos), debilidade muscular e paralisia.
Dependendo da causa e outros factores, o hiperaldosteronismo pode ser tratado cirurgicamente e/ou medicamente por antagonistas de aldosterona.
Consiste na diminuição na concentração de aldosterona
Esta pode ser devida a diversas causas, nomeadamente à diminuição da sua produção
O tratamento depende da sua etiologia, sendo prescritos substituintes diretos das hormonas em défice.

Cápsula de Bowman ( Células parietais • Podócitos)
Glomérulo (Células endoteliais • Membrana basal glomerular)
Mesângio (Células mesangiais • Matriz mesangial)
Túbulo de conexão
Junção ureteropiélica • Junção ureterovesical
Úraco • Fundo • Ápice • Corpo • Trígono • Colo • Úvula
Esfíncter interno • Esfíncter externo
Testículos: testosterona • AMH • inibina
Ovário: estradiol · progesterona · activin and inhibin · relaxina (gestação)
Hipófise (também denominada glândula pituitária) é uma pequena glândula com cerca de 1 cm de diâmetro alojada na sela túrcica ou fossa hipofisária do osso esfenoide na base do cérebro
Está localizada abaixo do hipotálamo e posteriormente ao quiasma óptico, sendo ligada ao hipotálamo pela haste pedúnculo hipofisário ou infundíbulo, é envolvida pela dura-máter (exceto o infundíbulo)
A hipófise é considerada uma glândula mestra, pois secreta hormônios que controlam o funcionamento de outras glândulas, sendo grande parte de suas funções reguladas pelo hipotálamo.
Do ponto de vista fisiológico, a hipófise é divida anatomicamente e funcionalmente em duas partes distintas: o lobo anterior (adeno - hipófise) e o lobo posterior (neuro - hipófise)
A adeno-hipófise possui origem de células epiteliais, enquanto neuro - hipófise possui origem nervosa
Entre essas duas porções existe uma zona pouco vascularizada chamada de parte intermédia, praticamente ausente em humanos, mas bem desenvolvida e funcional em outros animais.
É responsável pela regulação da atividade de outras glândulas e de várias funções do organismo como o crescimento (hormônio do crescimento - adeno - hipófise) e secreção do leite através dos seios (ocitocina - neuro - hipófise)
Possui dimensões aproximadas a um grão de ervilha, pesando de 0,5 a 1 grama.


O lobo posterior é conectado à parte do cérebro chamada de hipotálamo através do infundíbulo
A neurohipófise não produz nenhum hormônio apenas armazena os secretados pelo hipotálamo, e estes hormônios são então transportados pelos axônios das células nervosas em direção à hipófise posterior.
Os hormônios secretados pela hipófise posterior são
O lado anterior é derivado do ectoderma oral e é composto de epitélio glandular
Através da conexão vascular da hipófise anterior com o hipotálamo, o hipotálamo integra sinais estimulatórios e inibitórios centrais e periféricos para os cinco tipos fenotipicamente distintos de células da hipófise.
Os hormônios hipotalâmicos viajam até o lobo anterior por um sistema especial de capilares, chamados de vasos portais hipotalâmico-hipofisários.
Também existe uma interação entre os hormônios do hipotálamo, por exemplo, o TRH induz a secreção de prolactina.
Os hormônios tróficos ou trópicos atuam sobre outras glândulas endócrinas regulando suas secreções
O sistema nervoso central manifesta seu controle sobre a hipófise através do hipotálamo via ligações nervosas ou substâncias parecidas com hormônios conhecidas como fatores de liberação no sexo.
Os hormônios tróficos são classificados em:
As artérias para a hipófise são as artérias hipofisárias superiores, ramos da carótida interna ou da artéria comunicante posterior, e as artérias hipofisárias inferiores, ramos da carótida interna mas atravessam o seio cavernoso
Os ramos das artérias superiores abastecem a haste e as partes adjacentes do lobo anterior
Os ramos das artérias inferiores suprem o lobo posterior
A suplência sanguínea da parte distal é feita sobretudo através de veias de um sistema porta
O sangue dos capilares da parte tuberal e adjacências da haste drena para as veias, que descem ai longo do infundíbulo e terminam em numerosos capilares sinusoídes da parte distal.
As veias da hipófise são as veias hipofisárias laterais que drenam para os seios cavernosos e intercavernosos.
Nervos: A parte distal não tem inervação específica
Fibras do gânglio cervical superior do sistema simpático têm sido seguidas ao longo dos vasos sanguíneos, mas não foram associadas as células glandulares
A neuro - hopófise recebe fibras dos núcloes supra - ópticos e paraventrincular do hipotálamo
Grânulos osmiofilos análogos de neurossecreção são encontrados nas células deste núcleos e em seus prolongamentos, que se dirigem em direção caudal para o lobo posterior e constituem o feixe hipotalâmico - hipofisário.
As secreções da hipófise são controladas por sinais hormonais ou nervosos provenientes do hipotálamo
A secreção do lobo posterior da hipófise é controlada por sinais nervosos que se originam no hipotálamo e terminam na neuro - hipófise
Em contraste, pois a secreção pelo lobo anterior da hipófise é controlada por hormônios denominados hormônios ou fatores hipotalâmicos de liberação ou inibição secretados pelo próprio hipotálamo e, posteriormente, transportados até a adeno - hipófise por meio de pequenos vasos sanguíneos, conhecidos como vasos porta hipotalâmicos - hipofisários
Na adeno- hipófise, esses hormônios de liberação e inibição atuam sobre as células glandulares, controlando sua secreção.
O sistema porta hipotalâmico hipofisário é constituído por pequenos vasos comuns á extremidade inferior do hipotálamo e á hipófise anterior, unidos através do infundíbulo
Neurônios especias, situados no hipotálamo, sintetizam e secretam os hormônios hipotalâmicos liberados e inibidores
A função desses hormônios é a de controlar a secreção dos hormônios da hipófise anterior
O hipotálamo recebe sinais de quase todas as fontes possíveis do sistema nervoso
Por conseguinte, o hipotálamo é um centro coletor da informação, relacionada com o bem - estar interno do organismo; por sua vez, grande parte dessa informação é utilizada no controle das secreções dos numerosos hormônios hipofisários importantes.
Os hormônios (ou fatores) hipotalâmicos de liberação e de inibição de maior importância incluem: Hormônio liberador de tireotrofina (TRH), que ocasiona a liberação do hormônio tireoestimulante; Hormônio liberador de corticotrofina (CRH), que induz a liberação de adrenocorticotropina; Hormônio liberador do hormônio do crescimento (GHRH), que promove a liberação do hormônio do crescimento; Hormônio inibidor de GH (Somatostatina), de efeito oposto; Hormônio liberador de gonadotrofinas ( GnRH), que causa liberação dos dois hormônios gonadotrópicos, hormônio luteinizante (LH) e hormônio folículo - estimulante (FSH); Hormônio inibidor de prolactina ( dopamina), que causa inibição da secreção de prolactina e o Hormônio liberador de prolactina (PRH), de efeito contrário.
Distúrbios envolvendo a hipófise:
Há, igualmente, indicações no sentido de que distúrbios na hipófise (especialmente no eixo hipotálamo-hipofisário) possam estar interligados à Síndrome do Ovário Policístico.
Hipófise e pineal
Sistema endócrino
Artérias da base do cérebro
Cérebro seccionado no plano sagital mediano
Secção sagital do nariz, boca, faringe e laringe.
Diabetes mellitus tipo 1 é uma forma de diabetes mellitus em que o corpo não produz insulina em quantidade suficiente, o que resulta em excesso de glicose no sangue
Os sintomas clássicos são micção frequente, sede excessiva, fome excessiva e perda de peso
Entre outros possíveis sintomas estão visão enevoada, fadiga e feridas que não cicatrizam corretamente
Os sintomas geralmente manifestam-se após um curto período de tempo.
Desconhece-se a causa da diabetes de tipo 1
No entanto, acredita-se que envolva uma combinação de fatores genéticos e ambientais
Entre os fatores de risco estão antecedentes familiares da doença
O mecanismo subjacente envolve uma destruição autoimune das células beta que produzem insulina no pâncreas
O diagnóstico de diabetes é feito com a avaliação da quantidade de glicose ou hemoglobina glicosilada no sangue
A diabetes do tipo 1 distingue-se da do tipo 2 pela presença de autoanticorpos.
Não existe forma de prevenir a diabetes do tipo 1
Para sobreviver, é necessário tratamento com insulina
A insulinoterapia é geralmente realizada com uma injeção subcutânea, embora possa também ser realizada com uma bomba de insulina
Seguir uma dieta diabética e preticar exercício físico com regularidade são uma parte essencial do tratamento
Caso não seja tratada, a diabetes pode resultar em várias complicações
Entre as complicações a relativamente curto prazo estão a cetoacidose diabética e o coma hiperosmolar hiperglicémico
Entre as complicações a longo prazo estão doenças cardiovasculares, acidentes vasculares cerebrais, doença renal crónica, pé diabético e retinopatia diabética
Podem ainda ocorrer complicações derivadas da pouca quantidade de glicose no sangue devido uma dose excessiva de insulina.
Estima-se que a diabetes do tipo 1 seja responsável por 5 a 10% de todos os casos de diabetes
Desconhece-se o número de pessoas afetadas em todo o mundo, embora se estime que em cada ano cerca de 80 000 crianças desenvolvam a doença
A prevalência da doença varia significativamente, desde aproximadamente 1 novo caso por 100 000 pessoas por ano na Ásia Oriental e na América Latina, até cerca de 30 novos casos por 100 000 pessoas por ano na Escandinávia e no Kuwait
Geralmente a doença manifesta-se durante a infância ou no início da idade adulta.


O diabetes tipo 1 é induzido por um ou mais dos seguintes fatores: susceptibilidade genética, um ativador diabetogênico e/ou exposição a um antígeno diabetogênico.
O Diabetes tipo 1 é uma doença poligênica, isto é, muitos genes diferentes contribuem para o seu aparecimento
O gene que mais influi para o desenvolvimento do diabetes tipo 1, IDDM1, está localizado na região do MHC Classe II do cromossomo 6, na região de marcação 6p21
Certas variantes deste gene aumentam os riscos para diminuição de histocompatibilidade em pacientes tipo 1, dentre elas DRB1 0401, DRB1 0402, DRB1 0405, DQA 0301, DQB1 0302 e DQB1 0201, as quais são comuns em norte-americanos de descendência europeia e em europeus
Algumas variantes também parecem ser protetoras.
Os riscos de uma criança desenvolver o diabetes tipo 1 são de 8% se o pai possui a doença, 10% se um irmão a tiver, aproximadamente 4% se a mãe for diabética tipo 1 e tinha 25 anos de idade ou menos quando deu à luz, e de cerca de 1% se a mãe tinha mais de 25 anos
Caso ambos os pais tenham diabetes tipo 1, as chances da criança compartilhar a doença chega a 30%.
Gêmeos idênticos, e que portanto possuem exatamente os mesmos genomas, apresentam diferenças na expressão do diabetes tipo 1
Pesquisas indicam que, se um dos irmãos possuir diabetes tipo 1, o outro terá de 30% a 50% de chances de compartilhar a condição
Isto sugere que fatores ambientais também atuam de maneira determinante no aparecimento da doença.
Outras indicações de que existem fatores ambientais em jogo são encontradas nas estatísticas de prevalência da doença na Europa (entre caucasianos, há diferenças de mais de 10 vezes dependendo do país) e a tendência de imigrantes adquirirem a incidência da doença no país para o qual se mudaram.
De acordo com uma teoria, o diabetes tipo 1 é uma resposta autoimune desencadeada por uma invasão viral, na qual o sistema imune ataca as células infectadas pelos vírus juntamente com as células beta, produtoras de insulina, do pâncreas
Implicadas nesta hipótese estão as famílias de vírus Coxsackie ou rubéola
As evidências quanto a sua validade ainda são inconclusivas.
Nem todas as pessoas infectadas com vírus das famílias acima necessariamente desenvolvem o diabetes tipo 1
Isto sugere que há uma vulnerabilidade genética presente, suportada pelos registros de hereditariedade na tendência de se desenvolver a condição
Esta vulnerabilidade foi associada a determinados genótipos HLA
Ainda assim, a conexão entre estes genótipos e o desencadeamento da reação autoimune ainda é pouco compreendida.
Alguns pesquisadores acreditam, apesar de nenhuma ligação conclusiva ter sido até agora encontrada, que a resposta autoimune é influenciada por anticorpos contra proteínas do leite de vaca == Pesquisa realizada na Finlândia - país no qual a incidência de raios solares é baixa e onde, portanto, costumeiramente ingere-se vitamina D suplementar – observou que doses de 2000 IU por dia dadas durante o primeiro ano de vida de uma criança diminuíam em 80% as chances de ela desenvolver diabetes tipo 1 no futuro
A relação causal entre estes fatos continua obscura.
Algumas substâncias químicas e drogas destroem preferencialmente células pancreáticas
O Pyrinuron (Vacor, N-3-piridimetil-N'-p-nitrofenil uréia), um veneno para roedores introduzido nos Estados Unidos em 1976, destrói seletivamente células beta do pâncreas, resultando em diabetes tipo 1 caso ingerido acidental ou intencionalmente
A droga foi retirada de circulação nos EUA em 1979, mas continua sendo empregada em outros países.
Zanosar é a marca registrada para a streptozotocina, um antibiótico e agente antineoplástico usado em quimioterapias contra câncer pancreático
Ele destrói também células beta, o que resulta em diminuição na produção de insulina.
Demais problemas pancreáticos, como trauma, pancreatite e tumores (tanto benignos quanto malignos) podem também levar à diminuição na produção insulínica.


O sistema imunitário, sistema imunológico ou ainda sistema imune é um sistema de estruturas e processos biológicos que protege o organismo contra doenças
De modo a funcionar corretamente, o sistema imunitário deve detectar uma imensa variedade de agentes, desde os vírus aos parasitas, e distingui-los do tecido saudável do próprio corpo.
Os agentes patogénicos podem rapidamente evoluir e adaptar-se de modo a evitar a detecção e neutralização por parte do sistema imunitário, pelo que os vários mecanismos de defesa também evoluíram no sentido de os reconhecer e neutralizar
Até mesmo os simples organismos unicelulares possuem um sistema imunitário rudimentar, na forma de enzimas que os protegem de infecções por bacteriófagos
Outros mecanismos imunitários básicos acompanharam a evolução dos eucariotas e estão hoje presentes nos seus descendentes contemporâneos, como as plantas e os insectos
Entre estes mecanismos estão a fagocitose, os peptídeos antimicrobianos designados defensinas, e o sistema complemento
Os vertebrados mandibulares, entre os quais o ser humano, desenvolveram mecanismos de defesa ainda mais complexos, entre os quais a capacidade de ao longo do tempo se adaptarem para reconhecer de forma eficiente agentes patogénicos específicos
Através da imunidade adquirida, o organismo cria memória imunitária na sequência de uma resposta inicial a um agente específico, o que lhe permite responder de forma mais eficaz a novos ataques pelo mesmo agente
O processo de imunidade adquirida é a base da vacinação.
Os transtornos do sistema imunitário podem levar ao aparecimento de doenças autoimunes, inflamações e cancro
A imunodeficiência verifica-se quando a actividade do sistema imunitário é inferior ao normal, o que está na origem de infecções recorrentes e onde existe risco de vida
No ser humano, a imunodeficiência pode ser consequência de uma doença genética, de uma condição adquirida como o VIH/SIDA, ou do uso de imunossupressores
Por oposição, a autoimunidade é a consequência de um sistema imunitário hiperactivo que ataca tecido normal como se fosse um agente externo, como é o caso da artrite reumatóide ou a diabetes de tipo 1
A imunologia é a área científica que estuda todos os aspectos do sistema imunitário.


O sistema imunitário protege o organismo de infecções através de mecanismos de defesa estratificados com especificidade progressiva
Em termos simples, as barreiras físicas impedem a entrada dos agentes patogénicos
No caso de um patógeno penetrar estas barreiras, o sistema imunitário inato, presente em todas as plantas e animais, desencadeia uma resposta imediata, embora não específica
Caso o patógeno evite a resposta inata, os vertebrados possuem um segundo nível de defesa, o sistema imune adquirido, que é activado pela resposta inata e através do qual o sistema imunitário adapta a sua resposta durante uma infecção de acordo com a identificação do patógeno
Através da memória imunológica, o corpo memoriza esta resposta, o que permite ao sistema imunitário adquirido realizar ataques cada vez mais rápidos e robustos cada vez que esse mesmo patógeno é detectado.
Tanto a imunidade inata como adquirida dependem da capacidade do sistema imunitário em distinguir as moléculas exteriores das suas próprias moléculas
Em imunologia, as moléculas próprias são os componentes do organismo que o sistema imunitário consegue diferenciar de substâncias externas
Pelo contrário, as moléculas que não são próprias são aquelas que reconhece como estranhas
Uma classe destas moléculas são os antigénios, substâncias que se ligam a receptores imunológicos específicos e provocam uma resposta imunitária.
O sistema inato é composto por mecanismos de defesa não-específicos, que constituem uma resposta indiferenciada ao agente invasor
Constituem as estratégias de defesa mais antigas, sendo algumas destas formas encontradas nos seres multicelulares mais primitivos, nas plantas e fungos.
Existem várias barreiras mecânicas, químicas e biológicas que protegem os organismos de infecções
A cutícula cerosa de determinadas folhas, o exoesqueleto dos insetos, a casca e as membranas dos ovos ou a pele são exemplos de barreiras mecânicas que são a primeira linha de defesa contra as infecções
No entanto, uma vez que os organismos não podem ser completamente estanques em relação ao meio ambiente, existem outros sistemas destinados a proteger os orifícios do corpo como os pulmões, intestino ou o sistema genito-urinário
Nos pulmões, a tosse e os espirros expelem mecanicamente agentes patogénicos e irritantes do trato respiratório
A lavagem proporcionada pelo fluido lacrimal e pela urina expele igualmente os patógenos, enquanto que o muco segregado pelos tratos respiratório e digestivo retém os microorganismos.
A pele e o trato respiratório segregam peptídeos antimicrobianos como as β defensinas
Há determinadas enzimas com função antisséptica, como a lisozima e a fosfolipase A2, presentes na saliva e no leite materno
As secreções vaginais após a menarca proporcionam uma barreira química, ao tornarem-se ligeiramente ácidas, enquanto que o sémen contém defensinas e zinco para eliminar os patógenos
No estômago, o suco gástrico e as proteases actuam como poderosas defesas químicas contra os patógenos ingeridos.
No interior dos tratos genito-urinário e gastrointestinal, a flora comensal actua como barreira biológica ao competir com bactérias patogénicas por espaço e alimentação e, nalguns casos, alterando as próprias condições do meio, como o pH
Isto reduz a probabilidade dos patógenos virem a atingir um número suficiente para causar uma infecção
No entanto, uma vez que a maior parte dos antibióticos atacam todas as bactérias e não afectam os fungos, os antibióticos orais podem fazer com que haja um crescimento excessivo dos fungos e, por sua vez, dar origem a infecções fúngicas como a candidíase.
Os microorganismos ou toxinas que conseguem penetrar no organismo deparam-se com as células e os mecanismos do sistema imune inato
A resposta inata é normalmente espoletada quando os receptores de reconhecimento de padrões, que identificam componentes comuns a um vasto número de microorganismos, ou quando as células danificadas, lesadas ou em stresse enviam sinais de alarme, muitos dos quais são identificados pelos mesmos receptores que identificam os patógenos
As defesas do sistema imune inato não são específicas, o que significa que respondem a patógenos de forma genérica
O sistema inato não confere imunidade permanente contra um patógeno
A imunidade inata é o sistema de defesa predominante na maior parte dos organismos.
O sistema complemento é uma cascata bioquímica que ataca a superfície das células invasoras
É composto por mais de vinte proteínas diferentes e complementa o processo de eliminação dos patógenos pelos anticorpos
O sistema complemento é o maior componente humoral da resposta imune inata
Muitas espécies têm sistemas complemento, até mesmo fora dos mamíferos, como as plantas, peixes e alguns invertebrados.
No ser humano, esta resposta é activada pela ligação complementar a anticorpos que se juntaram a estes micróbios ou pela ligação de proteínas complementares aos hidratos de carbono na superfície dos micróbios
Este sinal de reconhecimento desencadeia uma resposta de eliminação rápida
A velocidade da resposta dá-se em função da amplificação do sinal que ocorre após a activação proteolítica das moléculas complementares, que são também proteases
Quando as proteínas complemento se ligam ao micróbio, a sua actividade protease é activada, e por sua vez activa outras proteases complemento
Isto dá origem a uma cascata catalítica que amplifica o sinal inicial através de retroalimentação positiva controlada
A cascata provoca a produção de peptídeos que atraem células do sistema imune, aumentam a permeabilidade vascular e revestem a superfície dos microorganismos com opsonina, marcando-os para serem destruídos
Este revestimento pode também ser capaz de matar directamente as células através da destruição da sua membrana plasmática.
Os leucócitos compreendem a segunda linha de defesa do sistema imune inato e actuam como organismos independentes e unicelulares
Os leucócitos inatos podem ser divididos em:
Estas células identificam e eliminam os patógenos, quer atacando os patógenos maiores através de contactos, quer fagocitando e matando os micro-organismos ou as células infectadas
As células inatas são também mediadores importantes na activação do sistema imune adquirido, sendo realizadas pelas Células Apresentadoras de Antígenos.
A fagocitose é uma característica importante da imunidade inata celular, sendo desempenhada por células denominadas fagócitos que envolvem, ou se alimentam de, patógenos ou partículas
Os fagócitos normalmente patrulham o corpo à procura de patógenos, mas podem ser chamados pelas citocinas a atuar em locais específicos
Quando um patógeno é envolto por um fagócito, fica imobilizado dentro de uma vesícula intracelular denominada fagossoma, que depois se funde com outra vesícula denominada lisossoma para formar um fagolisossoma
O patógeno é morto através da atividade de enzimas digestivas ou na sequência de uma explosão oxidativa que liberta radicais livres para o fagolissoma
A fagocitose é talvez a mais antiga forma de defesa imunitária, tendo sido identificados fagócitos tanto em vertebrados como invertebrados
A fagocitose desenvolveu-se com o intuito de obter nutrientes, mas este papel nos fagócitos foi alargado de modo a incluir a absorção de patógenos enquanto mecanismo de defesa.
Os neutrófilos e macrófagos são fagócitos que percorrem o corpo à procura de patógenos invasores
Os neutrófilos encontram-se normalmente na corrente sanguínea e são o tipo mais abundante de fagócito, correspondente a entre 50% e 60% do total de leucócitos em circulação
Durante a fase aguda das inflamações, sobretudo das que são o resultado de infecções bacterianas, os neutrófilos deslocam-se para o local da inflamação durante um processo denominado quimiotaxia, e são habitualmente as primeiras células a chegar ao local da infecção
Os macrófagos são células versáteis no interior dos tecidos que produzem um vasto leque de químicos, incluindo enzimas, proteínas complemento e factores reguladores como a interleucina 1
Os macrófagos também actuam como necrófagos, eliminando do corpo células mortas e outros detritos, e como células apresentadora de antígeno que activam o sistema imune adquirido.
As células dendríticas são fagócitos que se encontram em tecidos em contacto com o ambiente externo, sobretudo na pele, nariz, pulmões, estômago e intestinos
São assim denominadas pela sua semelhança com os dendritos neuronais, embora as células dendríticas não tenham qualquer relação com o sistema nervoso
Estas células actuam como ligação entre os tecidos corporais e os sistemas inato e adquirido, pois atuam como Célula apresentadora de antígeno principalmente aos linfócitos T, um dos tipos essenciais de células do sistema imune adquirido.
Os mastócitos estão alojados no tecido conjuntivo e nas mucosas, e são responsáveis pela regulação da resposta inflamatória
São frequentemente associados às alergias e a anafilaxia
Os basófilos e eosinófilos estão relacionados com os neutrófilos
Segregam mediadores químicos envolvidos na defesa contra parasitas e têm um papel activo nas reacções alérgicas como a asma
As células NK são leucócitos que atacam e destroem células tumorais ou células infectadas por vírus.
Para que células do sistema imune inato reconheçam os micro-organismo invasores de um hospedeiro é necessário que na superfície externa de suas membranas, ou no meio intracelular, contenham receptores capazes de diferenciar os padrões moleculares das células próprias (moléculas que fazem parte do organismo hospedeiro) dos padrões moleculares do micro-organismo e reagir contra estes no caso da identificação dessas moléculas estranhas os hospedeiro
Há três tipos de receptores característicos da resposta imune inata por não apresentarem especificidade, são eles:
moléculas PAMPs-que são padrões moleculares associados aos patógenos, ou capazes de reconhecer moléculas DAMPs- que são padrões moleculares associados à danos.
A inflamação é uma das primeiras respostas do sistema imunitário à infecção
A inflamação manifesta-se através de vermelhidão, inchaço, sensação de calor e dor localizada, causadas pelo aumento da circulação sanguínea nos tecidos afectados
É o resultado da acção de eicosanoides e citocinas, libertadas pelas células danificadas ou infectadas
Entre os eicosanoides estão as prostaglandinas, que provocam febre e vasodilatação dos vasos sanguíneos associados à infecção, e os leucotrienos, que atraem determinados leucócitos (glóbulos brancos)
Entre as citocinas mais comuns estão as interleucinas, responsáveis pela comunicação entre os leucócitos; as quemoquinas, que promovem a quimiotaxia; e os interferões, que têm propriedades antivirais, como por exemplo paralisar a síntese proteica na célula anfitriã
Podem também ser libertados factores de crescimento e factores citotóxicos
As citocinas, entre outros químicos, recrutam células imunes para o local da infecção e promovem a cura de qualquer tecido danificado posteriormente à remoção dos patógenos.
Todo o sistema específico se concentra na capacidade das células imunitárias distinguirem proteínas produzidas pelas células do próprio corpo (antigénio "self" - ou seja do próprio organismo), e proteínas produzidas por invasores ou pelas células humanas sob o controlo de vírus (antigénio "non-self" - ou seja, que não é reconhecido como sendo do próprio organismo)
Esta distinção é feita através de receptores, os TCR (T-cell receptors) ou BCR (B cell receptors que são anticorpos presos à membrana)
Estes receptores, TCR ou BCR, para serem eficazes têm de ser produzidos com milhões de conformações
De outro modo não se ligariam a muitos tipos de proteínas de invasores, e não os reconheceriam
Esta diversidade de receptores não caberia no genoma da célula, e milhões de genes, cada um para cada receptor possível, não seria prático
O que acontece é que há algumas famílias de genes, tendo cada uma vários membros ligeiramente diferentes
Através de um processo especial e único nas células humanas, estes genes nos linfócitos recombinam-se, num único gene, de forma totalmente aleatória.
Assim, por exemplo, cada anticorpo ou BCR dos linfócitos B tem seis porções, e é criado de dois genes únicos desse linfócito, gerados pela recombinação (união) de um gene aleatório de cada família
Se houver seis famílias, com 50, 30, 9, 6, 40, 5 membros, o número possível total de anticorpos diferentes é de 50x30x6x9x40x5 = 16 milhões.
Além disso há outros processos muito complexos que aumentam a diversidade dos BCR ou TCR ainda mais, por mutação acelerada dos genes em causa
A variabilidade dos anticorpos é na práctica ilimitada, e o sistema imunitário cria anticorpos contra qualquer molécula, e mesmo contra moléculas artificiais nunca existentes na natureza.
Muitos dos TCR e BCR assim gerados vão reagir com péptidos próprios
Uma das funções do Timo e Medula óssea é manter os jovens linfócitos sequestrados até que seja possível determinar quais reagem com moléculas do próprio organismo
Essa função é feita por células especializadas desses órgãos que apresentam aos linfócitos jovens moléculas produzidas por elas (e portanto próprias)
Todos os linfócitos que reagem a elas são destruídos, e apenas aqueles indiferentes a própria (mais possivelmente reactivos a não-próprios) são largados na corrente sanguínea.
Os linfócitos que não reagem a própria são milhões, cada um com milhões de configurações possíveis de receptores e haverá inclusive vários, cada um com receptor para zonas diferentes de cada proteína microbiana possível
A esmagadora maioria dos linfócitos nunca encontra uma proteína para a qual o seu receptor seja espécifico
Aqueles poucos que a encontram, são estimulados e multiplicam-se
São geradas células efectoras com o receptor específico (produtoras de anticorpos ou citotóxicas, ou ainda coordenadoras) e células memória
As células de memória são quiescentes, têm vida longa e são capazes de reconhecer esse antigénio mesmo muito depois, multiplicando-se em maior número e respondendo mais rapidamente a infecções futuras.
O sistema imunitário especifico é controlado e efectuado largamente pelos linfócitos
Há vários tipos de linfócitos.
Os linfócitos B possuem um BCR, que é em tudo semelhante ao anticorpo, mas está preso na membrana
Os linfócitos B concentram-se nos gânglios linfáticos, onde filtram a linfa, à espera de uma molécula que não seja do próprio organismo, e assim, reaja especificamente com o seu receptor aleatório
Para cada molécula possível há vários linfócitos específicos
Logo assim que haja uma ligação específica antigénio-receptor e se o linfócito for estimulado simultaneamente por citocinas produzidas pelos linfócitos T CD4 (reguladores,ou Helper), eles multiplicam-se e diferenciam-se em plasmócitos e em células-memória (Linfócito B de memória)
Estas, se a infecção se repetir muitos anos depois, podem iniciar a reposta mais rapidamente
Os plasmócitos produzem então grandes quantidades BCR solúvel e não preso à membrana, ou seja, anticorpos específicos para aquela molécula.
Os anticorpos são assim proteínas receptoras livres no sangue, que são especificas e se ligam à molecula não-self e possivelmente invasora
Os anticorpos podem assim ligar-se a antígenos na superfície de bactérias, vírus ou parasitas
Eles os eliminam de várias formas
Podem neutralizar o invasor directamente (cobrindo a superfície de um vírus e impedindo-o de se ligar aos seus receptores nas células por exemplo); atrair fagócitos (que reconhecem e são estimulados por eles); activar o sistema complemento de forma a lisa-los; ou ainda estimular as células citotóxicas (assassinas) para destruírem as células identificadas pelo anticorpo.
Os linfócitos que produzem anticorpos algo eficazes (do tipo IgM) ainda sofrem novo processo de selecção nos foliculos linfóides
Aí, multiplicam-se rodeadas de linfócitos T CD4 que secretam citocinas, as quais induzem por mecanismos complexos altas taxas de mutação nos seus genes dos anticorpos
Depois destroem os linfócitos B que produzem anticorpos com menor afinidade para o antigénio e estimulam a divisão dos que têm maior afinidade (graças a mutações fortuitas), podendo esta no final ser muitas vezes superior nos sobreviventes.
Há vários tipos de anticorpos: IgM é sempre o primeiro tipo a ser produzido; IgG é o principal grupo de anticorpos sanguíneos e há vários subtipos, aparece mais tarde que IgMs, e têm maior afinidade após hipermutação; os IgAs são anticorpos secretados para as mucosas, como intestino, genitais e brônquios; as IgE têm funções de luta contra parasitoses; os IgD estimula o sistema imunitário.
Os Linfócitos T CD8 são os linfócitos citotóxicos ou também chamado de Killers
Naturais Killers (NK) não são a mesma coisa que Linfócito citotóxico CD8 pois não possuem TCR que é um dímero, mas também são linfócitos
Eles têm cada um, um tipo de receptor especifico nas suas membranas, gerado aleatoriamente numa fase de recombinação genética do seu desenvolvimento, denominado de TCR (T-cell receptor, semelhante aos anticorpos da célula B, mas de localização membranar)
Esses receptores ligam-se a outros que todas as células humanas possuem (complexo MHC I), e que apresentam péptidos (fragmentos de proteínas) que elas estejam a produzir à superficie da célula
No caso que os complexos MHC I (Complexo de Histocompatibilidade) - péptido seja reconhecidos por uma célula T CD8, esta última desencadeará a morte da célula que apresenta o péptido através de enzimas citoliticas chamadas de porinas que induzem a apoptose da célula alvo por desequilíbrio osmótico.
Todos os linfócitos T CD8 que têm receptores que reagem a substâncias do próprio corpo morrem durante o seu "estágio" no timo
Quando o linfócito T CD8 reconhece um antígeno não-self com o seu receptor numa molécula MHC classe I de uma célula do organismo, ele liberta substâncias (perforina) que criam um poro na membrana, lisando (rompendo osmoticamente) a célula, ou então libertam mediadores (granzima) que induzem a célula a iniciar a apoptose (morte celular programada)
Há milhões de linfócitos CD8 em circulação no organismo, cada um com receptores aleatórios para todos os péptidos possíveis não-self
Normalmente o linfócito T CD8 naïve só mata as células se for estimulado por citocinas dos linfócitos T CD4 (reguladores: ver mais à frente)
Se um linfócito T CD8 com determinado receptor for estimulado dessa forma, ele divide-se em mais células citotóxicas e um pequeno grupo de células quiescentes e de longa esperança de vida, as células memória Memory T cells (ver na wiki em Inglês), manter-se-ão em circulação (entre o sangue e os gânglios linfáticos)
Estas células de memória podem ser activadas mais tarde de uma forma mais eficiente, mais rápida e independentemente da presença de citocinas produzidas pelos linfócitos CD4, após reconhecimento do péptido para o qual são específicas apresentado por uma molécula de MHC classe I.
Apesar de os fagócitos serem um mecanismo inato, já que respondem a qualquer corpo estranho, eles também são efectores de primeira linha das decisões dos linfócitos.
Os fagócitos, especialmente os macrófagos, respondem a citocinas geradas pelos linfócitos (IL-1)
Os monócitos são os precursores dos macrófagos e eles transformam-se em macrófagos se estimulados por citocinas dos T4
Além disso são atraídos por outras citocinas e factores libertados de células em locais de infecção activa.
Se estimulados apropriadamente pelas citocinas libertadas de forma localizada e controlada pelos linfócitos T4, os macrófagos libertam suficientes quantidades de enzimas e radicais livres para destruir totalmente uma região localizada, matando ambos invasores e células humanas.
Além disso, sob controle dos linfócitos, os macrófagos são responsáveis por algumas reacções imunológicas especificas como o granuloma e o abcesso
O granuloma ocorre na invasão por micobactérias e fungos, sendo o exemplo mais célebre a tuberculose
É uma reacção ordenada por citocinas dos T4, quando há infecção intracelular dos próprios fagocitos
De forma a impedir a disseminação pelo sangue do invasor dentro dessas células móveis, os linfócitos T4 secretam citocinas que chamam mais macrófagos, e os tornam mais resistentes à infecção ("alerta de bactéria endocelular")
Além disso as citocinas provocam a adaptação pelos macrófagos de morfologia epitelial em volta do núcleo da invasão, com numerosas camadas de células imobilizadas ligadas por conexões impermeáveis, de forma a sequestrar o invasor
A micobactéria da tuberculose não se pode disseminar e permanece localizada
Hoje mil milhões de pessoas saudáveis têm micobactérias controladas dessa forma nos seus pulmões (visível nas radiografias)
Só naqueles poucos que têm um episódio de grande debilidade imunitária é que o organismo escapa e se inicia a tuberculose propriamente dita
O abcesso é semelhante mas em redor de um cisto/quisto de pus
É importante para sequestrar bactérias piogénicas cuja toxicidade mata os fagócitos (formando o pus) e não permite a limpeza eficaz.
Os Linfócitos T4, ou helper, são os controladores de toda a resposta imunitária
São eles que "decidem" que reacções desenvolver a uma invasão, activando ou inibindo todas as outras células imunitárias através de citocinas (espécie de hormonas ou mediadores moleculares)
Daí que na doença que ataca os próprios T4, a SIDA/AIDS, todo o sistema imunitário colapse.
Os linfócitos T4 conseguem decidir se há invasão ou não porque cada um deles contêm um receptor gerado aleatoriamente o TCR (T-cell receptor, semelhante aos anticorpos da célula B, mas membranar)
Todos os fagócitos e ainda algumas outras células como as células dendriticas ou de Langerhans, depois de digerir as proteínas do invasor, apresentam péptidos (pedaços) delas numa proteína membranar, o MHC II (major histocompatibility complex)
Os TCR dos T4 ligam-se a essas MHC2 com péptido e se a ligação for eficaz, libertam citocinas
Nenhum linfócito T4 tem receptores para proteínas do próprio corpo porque esses foram destruídos na sua fase de desenvolvimento no Timo
Se os niveis dessas citocinas forem suficientemente altos, e se outros factores menos bem conhecidos existirem no sangue, o T4 "decide" que há uma invasão e de que tipo é, dando origem a uma resposta imunitária especifica
Ele então produz outras citocinas estimulando todas as outras células para o tipo de resposta apropriado
Tal como todos os outros linfócitos, os T4 estimulados multiplicam-se e alguns servem de células-memória para mais rápida resposta ao mesmo invasor no futuro.
Há basicamente dois tipos de células T4 helper, correspondendo a dois tipos de resposta
Não se sabe exactamente o que desencadeia um tipo ou o outro
A resposta TH1 caracteriza-se por produção de citocinas como IL-2, IFN-gama e TNF-beta
Há activação dos macrófagos e da fagocitose, e dos mecanismos citotóxicos (linfócitos T), levando a extensa destruição das zonas infectadas
É eficaz na eliminação dos patogénios intracelulares (vírus e bactérias intracelulares)
Na resposta TH2 há secreção de IL-4 e IL-5
Caracteriza-se pelo estimulo da produção de anticorpos pelos linfócitos B
É eficaz contra organismos que circulem no sangue, como bactérias extracelulares e parasitas.
Que resposta, TH1 ou TH2, é produzida, tem importância para a progressão da infecção
Por exemplo na Lepra, uma infecção pela bactéria intracelular Mycobacterium leprae, a resposta TH1 é extremamente eficaz e os danos são mínimos (lepra tuberculoide); mas se for activada uma resposta TH2, ineficaz contra organismos intracelulares, surge a lepra comum, com danos profundos e desprendimento de pele (lepra lepromatosa).
Há ainda um terceiro tipo de linfócito T regulador, os linfócitos supressores, que limitam e suprimem a reacção imunitária, um mecanismo muito importante considerando a destruição extrema que o sistema imunitário pode produzir.
Complementando o que foi visto acima,os mastócitos são células do tecido conjuntivo, originadas a partir de células mesenquimatosas (células de grande potência de diferenciação que dão origem às células do tecido conjuntivo)
Possuem citoplasma rico em grânulos basófilos (coram-se por corantes básicos)
Sua principal função é armazenar potentes mediadores químicos da inflamação, como a histamina, heparina, ECF-A (fator quimiotáxico – de atração- dos eosinófilos) e fatores quimiotáxicos (de atração) dos neutrófilos
Elas participam de reações alérgicas (de hipersensibilidade), atraindo os leucócitos até o local e proporcionando uma vasodilatação.
A vasodilatação aumenta a temperatura no local inflamado, dificultando a proliferação de microrganismos e estimulando a migração de células de defesa
Algumas das substâncias liberadas no local da inflamação alcançam o centro termorregulador localizado no hipotálamo, originando a febre (elevação da temperatura corporal)
Apesar do mal-estar e desconforto, a febre é um importante fator no combate às infecções, pois além de ser desfavorável para a sobrevivência dos microorganismos invasores, também estimula muitos dos mecanismos de defesa de nosso corpo.
As citocinas são hormonios do sistema imunitário que permitem às células comunicar entre si e com outras de outros órgãos
São um sistema incrivelmente complexo e inteligente ainda pouco conhecido
Algumas citocinas mais importantes:
O sistema imune é uma estrutura notável que incorpora especificidade, indutibilidade e adaptação
No entanto, ocorrem falhas na defesa, que são classificadas em três grupos genéricos: imunodeficiências, autoimunidade e hipersensibilidades.
As imunodeficiências ocorrem quando um ou mais dos componentes do sistema imunitário estão inactivos
A capacidade do sistema imunitário de resposta aos patógenos é menor nas camadas mais jovens e mais velhas da população
A resposta imunitária entra em declínio por volta dos 50 anos de idade devido à imunossenescência
Em países desenvolvidos, a obesidade, o alcoolismo e o uso de drogas são as causas mais comuns da insuficiência imunitária
No entanto, a má nutrição é a causa mais comum de imunodeficiência em países em desenvolvimento
Uma dieta insuficiente em proteínas está associada com debilidades na imunidade mediada por células, actividade complementar, funcionamento dos fagócitos, concentrações de anticorpos IgA e na produção de citocina
Para além disso, a perda do timo em idade precoce através de mutação genética ou remoção cirúrgica está na origem de uma imunodeficiência severa e elevada susceptibilidade a infecções.
As imunodeficiências também podem ser herdadas ou adquiridas
Um exemplo de imunodeficiência congénita, ou herdada, é a doença granulomatosa crónica, na qual os fagócitos têm dificuldade em destruir os patógenos
A SIDA e alguns tipos de cancro estão na origem de imunodeficiência adquirida.
No outro extremo das disfunções imunes estão as respostas imunes em excesso, sobretudo os transtornos autoimunes
Neste tipo de transtornos, o sistema imunitário não consegue distinguir as células externas das suas próprias células e ataca partes do seu próprio corpo
Em circunstâncias normais, muitos dos linfócitos T e anticorpos reagem com peptídeos próprios
Existem células especializadas, localizadas no timo e na medula óssea, cuja função é apresentar aos novos linfócitos produzidos os antigénios produzidos pelo corpo e eliminar as células que são capazes de reconhecer os antígenos próprios, prevenindo assim a autoimunidade.
A hipersensibilidade é uma resposta imunitária que danifica os tecidos do próprio corpo
Divide-se em quatro classes (tipos I a IV) com base nos mecanismos envolvidos e no intervalo de tempo da reacção hipersensível
A hipersensibilidade do tipo I é uma reacção anafilática, normalmente associada à alergia
Os sintomas variam entre algum desconforto e a morte
O tipo I é mediado pela imunoglobulina E, que espoleta a degranulação dos mastócitos e dos basófilos quando ligados por um antigénio
A hipersensibilidade do tipo II ocorre quando os anticorpos se ligam a antigénios nas próprias células do indivíduo, marcando-as para destruição
Este tipo também é denominado hipersensibilidade citotóxica dependente de anticorpos, e é mediada pelos anticorpos IgG e IgM
Os complexos imunes (agregados de antigénios, proteínas complemento e anticorpos IgG e IgM) depositados em vários tecidos desencadeiam reacções hipersensíveis do tipo III
A hipersensibilidade do tipo IV (também conhecida por hipersensibilidade mediada por células) normalmente leva entre dois a três dias para se desenvolver
As reacções do tipo IV fazem parte de muitas doenças autoimunes e infecciosas, embora possam também estar associadas com a dermatite de contacto
Estas reacções são mediadas pelos linfócitos, monócitos e macrófagos.
É provável que o sistema imune adaptativo e multicomponente tenha surgido com os primeiros vertebrados, uma vez que os invertebrados não produzem linfócitos ou qualquer resposta imunitária humoral
No entanto, muitas espécies utilizam mecanismos que aparentam ser precursores destes aspectos da imunidade em vertebrados
Os sistemas imunitários podem ser observados até mesmo nas formas de vida mais simples
As bactérias usam um mecanismo de defesa único, denominado sistema de restrição modificação como defesa em relação a patógenos virais, ou fagos
Os procariontes também possuem imunidade adquirida através de um sistema que usa sequências CRISPR para conservar fragmentos do genoma de fagos com que tiveram contacto no passado, o que lhes permite bloquear a replicação dos vírus através da interferência de RNA.
Os receptores de reconhecimento padrão são proteínas usadas por praticamente qualquer organismo para identificar moléculas associadas com os patógenos
As defensinas, peptídeos antimicrobianos, são um componente conservado durante a evolução presente em todos os animais e plantas, e representam a principal forma de imunidade sistémica dos invertebrados
O sistema complemento e os fagócitos são também usados por maior parte das formas de vida invertebrada
A ribonuclease e o processo de interferência RNA estão presentes em todos os eukaryota, e pensa-se que tenham um papel na resposta imunitária contra vírus.
Ao contrário dos animais, as plantas não têm células fagócitas, mas grande parte das respostas imunitárias nas plantas envolvem sinalização química sistémica enviada através do seu organismo
Cada célula nas plantas responde de forma individual a moléculas associadas a patógenos conhecidas como padrão molecular associado a patógenos
Quando parte da planta é infectada, a planta produz uma resposta hipersensível localizada, durante a qual as células no local da infecção sofrem uma apoptose extremamente rápida de modo a evitar a propagação a outras partes da planta
A Rresistência sistémica adquirida é um tipo de resposta defensiva usada por plantas que torna toda a planta resistente a determinado agente infeccioso
Os mecanismos de silenciamento de RNA são particularmente importantes para esta resposta sistémica, uma vez que são capazes de impedir a replicação de vírus.
Outro papel importante do sistema imunitário é a identificação e a eliminação de tumores
As células modificadas dos tumores expressam antigénios que não estão presentes em células normais
O sistema imunitário interpreta este antigénios como exteriores e a sua presença leva a que as células imunitárias ataquem as células do tumor
Os antigénios expressos por tumores podem ter várias origens
Alguns são derivados de vírus cercinogénicos, como o vírus do papiloma humano que provoca o cancro do colo do útero, enquanto que outros têm origem nas próprias proteínas do organismo, tendo pouca intensidade em células normais mas atingindo valores elevados nas células dos tumores
Um exemplo é a tirosinase que, quando expressa em níveis elevados, transforma determinadas células da pele (melanócitos) em tumores denominados melanomas
Uma terceira fonte para os antígenos tumorais são as proteínas normalmente importantes para a regulação do crescimento celular, que de forma frequente sofrem mutação para molécula indutoras do cancro denominadas oncogenes.
A principal resposta do sistema imunitário aos tumores é a destruição das células anormais com recurso a linfócitos T citotóxicos, por vezes com a assistência de linfócitos T auxiliares
Os antígenos tumorais são apresentados em moléculas MHC Classe I de forma semelhante aos antígenos virais
Isto permite aos linfócitos T citotóxicos reconhecer como anormal a célula do tumor
As células NK também eliminam células tumorais da mesma forma, sobretudo se as células do tumor tiverem menos moléculas MHC Classe I na sua superfície do que o normal; fenómeno comum entre tumores
Sometimes antibodies are generated against tumor cells allowing for their destruction by the complement system.
Alguns tumores conseguem evadir o sistema imunitário e evoluem até se tornarem cancros
As células dos tumores têm muitas vezes poucas moléculas MHC Classe I na superfície, evitando assim a sua detecção pelos linfócitos T citotóxicos.Algumas das células dos tumores também libertam substâncias que inibem a resposta imunitária; por exemplo, através da segregação da citocina TGF-β, que impede a acção dos macrófagos e os linfócitos
Para além disso, pode-se desenvolver tolerância imunológica em relação aos antígenos dos tumores, o que faz com que o sistema imunitário deixe de atacar as células tumorais.Paradoxalmente, os macrófagos podem promover o crescimento dos tumores.
As hormonas podem actuar como imunomoduladores, alterando a sensibilidade do sistema imunitário
Por exemplo, as hormonas sexuais femininas são imunoestimulantes, tanto da resposta do sistema adquirido como do inato
Algumas doenças autoimunes, como o lupus eritematoso, têm maior prevalência no sexo feminino e o seu aparecimento muitas vezes coincide com a puberdade
Pelo contrário, as hormonas sexuais masculinas como a testosterona aparentam ser imunossupressoras
Há outras hormonas que também aparentam regular o sistema imunitário, particularmente a prolactina, a hormona do crescimento e a vitamina D.
Ao encontrar um patógeno externo, um linfócito T estende um receptor da vitamina D
Isto é essencialmente um dispositivo de sinalização que permite ao linfócito ligar-se à forma activa da vitamina D, a hormona esteroide calcitriol
Os linfócitos T apresentam uma relação simbiótica com a vitamina D
O linfócito não só estende o receptor, como também expressa o gene CYP27B1, responsável pela conversão da versão pré-hormona da vitamina D (calcidiol) na versão hormona esteroide (calcitriol)
Só depois de se ligarem ao calcitriol é que os linfócitos podem desempenhar a sua função
Entre as células do sistema imunitário que se sabe expressarem o gene CYP27B1, activando assim o calcidiol, estão as células dendríticas, os queratinócitos e os macrófagos.
Leventa-se a hipótese de que o declínio progressivo dos níveis hormonais com a idade seja parcialmente responsável pela diminuição da resposta imune em idosos
Da mesma forma, algumas hormonas são também reguladas pelo sistema imunitário, sobretudo a actividade da hormona tiroideia
O declínio da função imune provocado pela idade está também relacionado com a diminuição do nível de vitamina D em idosos
À medida que as pessoas envelhecem, verificam-se duas situações que afectam negativamente a quantidade de vitamina D; primeiro, como permanecem mais tempo dentro de casa estão menos expostas ao sol e produzem menos colecalciferol através de radiação UVB: segundo, a própria pele torna-se menos apta a produzir vitamina D.
O sistema imunitário é afectado pela qualidade do sono e descanso, e e privação de sono prejudica a função imune
Os circuitos complexos de realimentação que envolvem citocinas também aparentam ter algum papel na regulação do sono REM
Desta forma, a resposta imunitária à infecção pode ter como consequência alterações no ciclo do sono, entre as quais um aumento da fase sono de ondas lentas em relação às fases REM.
A sobrenutrição está associada a doenças como a diabetes e obesidade, as quais se sabe afectarem a função imune
A malnutrição moderada, assim como determinadas deficiências em minerais e noutrientes, podem também comprometer a resposta imune
O subdesenvolvimento do feto pode também ter como consequência deficiências imunitárias ao longo da vida
Por outro lado, os alimentos ricos em determinados ácidos gordos podem promover um sistema imunitário saudável.
A resposta imune pode ser manipulada para suprimir respostas indesejadas provocadas pela autoimunidade, alergias ou rejeição de transplantes, e para estimular respostas protectores conta patógenos que contornam o sistema imunitário
São usados fármacos imunossupressores para controlar transtornos ou inflamações autoimunes, quando se verifique danos excessivos nos tecidos, e para prevenir a rejeição de órgãos após o transplante.
Os fármacos anti-inflamatórios são regularmente usados para controlar os efeitos da inflamação
Os glicocorticoides são os mais potentes, embora esta classe de fármacos possa ter vários efeitos secundários indesejáveis, como a obesidade abdominal, hiperglicemia ou osteoporose, pelo que o seu uso deve obedecer a critérios rígidos
Muitas vezes são administradas doses reduzidas de anti-inflamatórios em conjunto com fármacos citotóxicos ou imunosupressores como o metotrexato ou a azatioprina
Os fármacos citotóxicos inibem a resposta imunitária ao matar as células durante o processo de divisão, como os linfócitos T activados
No entanto, a morte é indiscriminada e também são afectadas células em constante divisão, o que provoca efeitos adversos tóxicos
Os fármacos imunossupressores como a ciclosporina impedem os linfócitos T de responder correctamente aos sinais através da inibição dos caminhos de transdução de sinal.
Os fármacos maiores (<500 Da) podem provocar uma reposta imunitária neutralizadora, sobretudo se são administrados repetidamente ou em doses elevadas
Isto limita a eficácia das drogas baseados nos peptídeos maiores e nas proteínas  Nalguns casos, não é o próprio fármaco que é imunogénico, mas pode ser administrado em conjunto com um composto imunogénico, como acontece com o paclitaxel
Têm sido desenvolvidos modelos computacionais que tentam prever a imunogenicidade dos peptídeos e das proteínas, sendo úteis sobretudo no desenho de anticorpos terapêuticos, avaliando a probabilidade de virulência das mutações em partículas de revestimento virais, e na validação de novos tratamentos à base de peptídeos
As técnicas anteriores baseavam-se principalmente na observação de que os aminoácidos hidrófilos estão sobrerrepresentados nas regiões do epítopo em relação aos aminoácidos hidrófugos
No entanto, os métodos atuais baseiam-se em técnicas de aprendizagem de máquina que recorrem a bases de dados de epítopos conhecidos, normalmente em vírus de proteínas amplamente estudados, tendo sido implementada uma base de dados de acesso público para a catalogação dos epítopos a partir de patógenos que se saiba serem reconhecidos pelos linfócitos B
A área emergente do estudo da imunogenicidade com base na bioinformática é designado por "imunoinformática".
O êxito de determinado patógeno depende da sua capacidade em iludir a resposta imune do hospedeiro, tendo para isso desenvolvido vários métodos ao longo da evolução
As bactérias muito frequentemente superam as barreiras físicas ao segregar enzimas que destroem essas barreiras usando, por exemplo, um sistema secretor do tipo II
Por outro lado, usando um sistema do tipo III são capazes de inserir um tubo oco na célula hospedeira, abrindo assim uma via de passagem direta para as proteínas do patógeno para o hospedeiro
Estas proteínas são depois usadas para desativar as suas defesas.
Uma das estratégias evasivas usadas por vários patógenos para contornar o sistema imunitário é através da sua ocultação entre as células do hospedeiro (também designado por patogénese intracelular)
Através deste recurso, o patógeno passa a maior parte do seu ciclo de vida no interior das células, onde está protegido do contacto direto com as células imunitárias, anticorpos e sistema complemento
Entre estes patógenos intracelulares estão os vírus, a Salmonella e os parasitas que provocam a malária
Outro tipo de bactérias, como a Mycobacterium tuberculosis, vivem no interior de uma cápsula protetora que impede a sua lise por parte do sistema complemento
Muitos patógenos segregam compostos que diminuem ou desviam a resposta do sistema imune
Algumas bactérias formam biofilmes para se protegerem do sistema imunitário, biofilmes esses que estão presentes em muitas infecções bem sucedidas, como a Pseudomonas aeruginosa crónica e a Burkholderia cenocepacia, características da fibrose cística
Há outras bactérias que geram proteínas de superfície que se ligam aos anticorpos, tornando-os ineficazes, como a Streptococcus (proteína G), Staphylococcus aureus (proteína A), ou a Peptostreptococcus magnus (proteína L).
Os mecanismos usados pelos patógenos para evadir o sistema imune adquirido são ainda mais complexos
A abordagem mais simples é alterar rapidamente os epítopos não essenciais (aminoácidos ou açúcares) na sua superfície, enquanto mantêm os epítopos essenciais resguardados
Isto designa-se por variação antigénica
Um exemplo é o VIH, cujas mutações rápidas levam a que as proteínas no seu envelope viral, essenciais para entrar na célula hospedeira, estejam em constante mudança
Estas alterações frequentes nos antígenos podem explicar a razão das falhas nas vacinas destinadas a este vírus
O parasita Trypanosoma brucei recorre a uma técnica semelhante, alternando constantemente entre dois tipos de proteínas de superfície, permitindo-lhe manter-se um passo à frente da resposta imune
Outra estratégia comum é disfarçar os antígenos com moléculas do hospedeiro
No VIH, o envelope que reveste o vírus é formado a partir da membrana exterior da célula hospedeira, tornando muito difícil a sua detecção como estruturas externas pelo sistema imune.
Uma criança (do latim creantia) é um ser humano no início de seu desenvolvimento
São chamadas recém-nascidas do nascimento até um mês de idade; bebê, entre o segundo e o décimo-oitavo mês, e criança quando têm entre dezoito meses até doze anos de idade
O ramo da medicina que cuida do desenvolvimento físico e das doenças e/ou traumas físicos nas crianças é a pediatria.
Os aspectos psicológicos do desenvolvimento da personalidade, com presença ou não de transtornos do comportamento, de transtornos emocionais e/ou presença de neurose infantil - incluídos toda ordem de carências, negligências, violências e abusos, que não os deixa "funcionar" saudavelmente, com a alegria e interesses que lhes são natural - recebem a atenção da Psicologia Clínica Infantil (Psicólogos), através da Psicoterapia Lúdica
Os aspectos cognitivos (intelectual e social) é realizada pela Pedagogia (Professores), nas formalidades da vida escolar, desde a pré-escola, aos cinco anos de idade, ou até antes, aos 3 anos de idade.
A infância é o período que vai desde o nascimento até aproximadamente o décimo-segundo ano de vida de uma pessoa
É um período de grande desenvolvimento físico, marcado pelo gradual crescimento da altura e do peso da criança - especialmente nos primeiros três anos de vida e durante a puberdade
Mais do que isto, é um período onde o ser humano desenvolve-se psicologicamente, envolvendo graduais mudanças no comportamento da pessoa e na adquisição das bases de sua personalidade.


A infância é um período onde há grande desenvolvimento da criança, deve-se esclarecer que elas ainda não têm maturidade psicológica suficiente para serem consideradas adolescentes, mesmo tendo seu porte físico
Do nascimento até o início da adolescência os pais são os principais modelos da criança, com quem elas aprendem, principalmente por imitação
Filhos de pais que os abusam ou negligenciam tendem a sofrer de vários problemas psicológicos, inclusive, depressão
A principal atividade das crianças são as brincadeiras, as quais são responsáveis por estimular o desenvolvimento do intelecto infantil, a coordenação motora e diversos outros aspectos importantes ao desenvolvimento pleno da criança.
Segundo o Estatuto da Criança e do Adolescente, uma pessoa é considerada criança do nascimento até os 12 anos incompletos.
Neste estágio, o bebê é totalmente dependente de terceiros (geralmente, dos pais) para quaisquer coisas como locomoção, alimentação ou higiene
Neste período, o bebé aprende actos básicos de locomoção como sentar, engatinhar, andar
Recomenda-se o aleitamento materno exclusivo até que o sexto mês de vida; isso porque o leite materno tem uma composição mais adequada e exige cuidados mais simples em relação a outros tipos de leite, bem como possui anticorpos e outros fatores para proteger o lactente de infecções, e ainda fortalece a relação entre a mãe e seu filho
Caso haja empecilho ou, raramente, contra-indicação, ao aleitamento materno, leites substitutos como de vaca, cabra ou soja podem ser usados, além de leites de vaca modificados para ter composição mais semelhante ao humano
Esses leites, porém, têm maior risco de induzir alergias na criança (especialmente os leites animais in natura), e exigem suplementação de nutrientes como ferro ou ácido fólico, exceto aqueles que têm adição de vitaminas
Após o sexto mês de vida, a dieta alimentar de um bebê começa a variar, com a introdução lenta e gradual de novos alimentos.
Neste estágio da vida, a criança cresce muito rapidamente
Os primeiros cabelos, bem como os primeiros dentes, aparecem neste estágio
Aos 18 meses de vida, a maioria dos bebês já soltaram suas primeiras palavras
Este período é caracterizado pelo egocentrismo, pois o bebê não compreende que faz parte de uma sociedade, e o mundo para ele gira em torno de si mesmo.
Neste estágio a criança cresce menos do que durante os primeiros 18 meses de vida, já pode correr uma curta distância por si mesma, comer sem a ajuda de terceiros, falar algumas palavras que têm significado (por exemplo, mamãe, papai, bola, etc), e a expectativa é que a criança continue a melhorar estas habilidades.
O principal aspecto desta faixa etária é o desenvolvimento gradual da fala e da linguagem
Aos três anos de idade, a criança já pode formar algumas frases completas (e corretas gramaticalmente) usando palavras já aprendidas, e possui um vocabulário de aproximadamente 800 a mil palavras
Lentamente passa a compreender melhor o mundo à sua volta, e a aprender que neste mundo há regras que precisam ser obedecidas, embora ainda seja bastante egocêntrica - comumente vendo outras pessoas mais como objetos do que pessoas, não sabendo que estas possuem sentimentos próprios
Assim sendo, a criança muitas vezes prefere brincar sozinha a brincar com outras crianças da mesma faixa etária
No final desta faixa etária, uma criança geralmente já sabe diferenciar pessoas do sexo masculino e pessoas do sexo feminino, e também já começa a ter suas próprias preferências, como roupas e entretenimentos, por exemplo
Pode também ser capaz de se vestir sem a ajuda de terceiros, e de antecipar acontecimentos.
Crianças desta faixa etária começam a desenvolver os aspectos básicos de responsabilidade e de independência, preparando a criança para o próximo estágio da infância e os anos iniciais de escola
As crianças desta faixa etária são altamente ativas em geral, constantemente explorando o mundo à sua volta
As crianças passam também a aprender que na sociedade existem coisas que eles podem ou não fazer.
Nesta faixa etária, a criança já compreende melhor o mundo à sua volta , tornando-se gradualmente menos egocêntrica e melhor compreendendo que suas ações podem afetar as pessoas à sua volta
Também passam a compreender que outras pessoas também possuem seus próprios sentimentos
Assim sendo, as crianças gradualmente aprendem sobre a existência de padrões de comportamentos , ações que podem ou devem ser feitas, e ações que não devem ser feitas
Os pais da criança são os principais modelos da criança nesta faixa etária 
geralmente determinam se uma dada ação da criança foi boa ou má, muitas vezes recompensando a criança pelas suas boas ações e castigando a criança pelas suas más ações.
Crianças, a partir dos três anos de idade, também passam a aprender padrões de comportamento de um processo chamado identificação
As crianças passam a se identificar com outra pessoa por causa de vários motivos, incluindo laços de amizade (um amigo ou uma pessoa próxima como outro parente ou uma babá, por exemplo) e semelhanças físicas e psicológicas
Também a partir dos três anos de idade que as crianças passam a ver diferenças entre pessoas do sexo masculino e feminino, tanto nos aspectos físicos quanto nos aspectos psicológicos, como os estereótipos dados a ambos os sexos pela sociedade (exemplos: menino brinca com bola, menina brinca com boneca).
A grande maioria das crianças abandona as fraldas nesta faixa etária
A partir dos três anos de idade, a criança cresce lentamente, em contraste com o crescimento acelerado ocorrido desde o nascimento até os dezoito meses de vida
Meninos e meninas têm peso e altura semelhantes.
O período entre cinco a nove anos de idade é marcado pelo desenvolvimento psicológico da criança
Esta continua a se desenvolver fisicamente, lenta e gradualmente, mas acima de tudo elas se desenvolvem e amadurecem socialmente, emocionalmente e mentalmente.
Na maioria das sociedades, as crianças já aprenderam regras e padrões de comportamento básicos da sociedade por volta do quinto ano de vida
Elas aprendem então a discernir se uma dada ação é certa ou errada
A vida social da criança passa a ser cada vez mais importante, e é comum nesta faixa etária o que se chama de o(a) melhor amigo(a).
Na maioria dos países, crianças precisam ir à escola, geralmente a partir do sexto ou do sétimo ano de vida
Atualmente, no Brasil o governo aderiu obrigação dos pais levarem as crianças na escola a partir dos cinco anos de idade
Nesta faixa etária, regras básicas da sociedade são mais bem compreendidas
Aqui, é dada ênfase à capacidade de resolução de problemas, uma habilidade que é aperfeiçoada com o passar do tempo
A racionalização também é uma habilidade que é aprendida e constantemente melhorada
Até o quinto ou sexto ano de vida, as crianças muitas vezes procuram resolver problemas através da primeira solução - certa ou não, racional ou não - que vem à sua mente
Após o quinto ou o sexto ano de vida, a criança passa procurar por diversas soluções, e a reconhecer a solução correta ou aquela que mais se aplica ao solucionamento do problema.
Por volta dos sete ou oito anos de idade, as crianças passam a racionalizar seus pensamentos e suas crenças, procurando as razões, os porquês por trás de um problema ou de um fato
Assim, as próprias crianças passam a analisar os padrões de comportamento ensinados pela família e sociedade
Além disso, a partir dos seis anos de idade, as crianças passam a se comparar com outras crianças da mesma faixa etária
Estes dois fatos, aliados ao crescimento da vida social da criança, diminuem a importância dos pais e da família como modelos de comportamento da criança, e aumentam a importância dos amigos e dos professores.
A comparação que uma dada criança faz de si mesma à outra também afeta a auto-imagem e a auto-estima da criança - a opinião que uma pessoa tem de si mesma
O tipo de auto-imagem formada durante a infância pode influenciar o comportamento desta pessoa na adolescência e na vida adulta
As crianças passam a desenvolver a auto-imagem após os três anos de idade, à medida que as crianças se identificam com seus pais, parentes, e posteriormente, pessoas próximas
Esta auto-imagem pode ser positiva ou negativa, dependendo das atitudes e das emoções das pessoas com as quais a criança se identifica
Crianças com auto-imagens positivas geralmente possuem boas impressões de seus pais e uma ativa vida social; por outro lado, auto-imagens negativas costumam ser fruto de famílias disfuncionais, onde o relacionamento entre seus membros seja problemático
A comparação que uma criança faz em relação a outras crianças pode alterar esta auto-imagem
Além disso, vários outros fatores podem influenciar o comportamento de uma criança, como abuso infantil, problemas sócio-psicológicos (vítima de agressão na escola, por exemplo) e eventos marcantes (perda de um parente ou amigo, por exemplo).
Os dentes de leite começam a cair no sexto ano de vida, um por um, até a adolescência
O crescimento de peso e altura é pequeno e semelhante entre meninos e meninas, que continuam a ter peso e altura semelhantes
Quanto à força física, em teoria, meninos e meninas desta faixa etária têm força física semelhante, mas meninos, por geralmente serem mais incentivados pela sociedade a participar de atividades físico-esportistas, tendem a ter um pouco mais de força física do que as meninas.
Faixa etária que vai desde o décimo ano de vida é época de intensas mudanças físicas e psicológicas: é a chamada pré-adolescência
A criança nesta faixa etária passa a compreender mais a sociedade, ordens sociais e grupos, o que torna esta faixa etária uma área instável de desenvolvimento psicológico.
A participação num grupo de amigos que possuem gostos em comum passa a ser de maior importância para a criança, onde o modelo dado pelos amigos começa a obscurecer o modelo dado pelos pais
Começam as preocupações como a expectativa de ser aceito por um grupo, ou certas diferenças em relação a outras crianças da mesma faixa etária se agravam aqui, e são um aspecto de maior importância na adolescência
Muitas vezes, pré-adolescentes sentem-se rejeitados pela sociedade, podendo desencadear problemas psicológicos tais como depressão ou anorexia.
A pré-adolescência é marcada pelo início das intensas transformações físicas que transformam a criança em um adulto; é o início da puberdade, marcada principalmente pelo aumento do ritmo de crescimento corporal e pelo amadurecimento dos órgãos sexuais.
A puberdade para as meninas chega entre o 10º e o 12º ano de vida, onde os primeiros pelos pubianos e nas axilas aparecem, vem a primeira (os quadris começam a se formar e depois vem os seios e depois o ciclo da menstruação)
Neste período, as meninas passam, em média, a ser mais altas e mais pesadas que os meninos, onde a puberdade ainda não começou
O amadurecimento dos órgãos sexuais inicia-se geralmente depois, no 11º ao 14º ano de vida.
Somente mais tarde, no 11º ao 14º anos de vida, a puberdade começa para os meninos, começo de um alto crescimento físico (em altura, peso e força muscular), crescimento de pelos pubianos e nas axilas e engrossamento do timbre de voz
Com o pico do crescimento físico da maioria das meninas já havendo terminado, os meninos passam à frente das meninas, definitivamente, em peso, altura e força muscular
O amadurecimento dos órgãos sexuais dá-se geralmente depois, no 14º ao 15º ano de vida.
Alguns grupos de pessoas não aceitam essa classificação, colocando os pré-adolescentes já como adolescentes.
Crianças do sexo feminino são chamadas de meninas, e crianças do sexo masculinos são chamados de meninos
Uma pequena percentagem dos humanos são hermafroditas - embora o hermafroditismo seja apenas uma distinção biológica, e não necessariamente social ou psicológica
Fora as diferenças existentes no sistema reprodutor, meninos e meninas não diferem muito fisicamente entre si até o início da puberdade, com crianças de ambos os sexos, com a mesma idade, possuindo aproximadamente a mesma altura e o mesmo peso.
As crianças de ambos os sexos crescem em altura por igual até os nove - onze anos anos de idade, quando o início da puberdade nas meninas faz com que elas se tornem, na média, mais altas do que os meninos, até os doze anos de idade, quando a puberdade tem início nos meninos, com a altura e o peso médio dos meninos superando os das meninas
Uma criança de nove anos possui em média entre 130 a 140 centímetros de altura, nos Estados Unidos
Quanto à massa corporal, o peso médio dos meninos é entre 25 a 37 quilogramas, enquanto o peso médio das meninas é geralmente um pouco menor - possivelmente por causa de estereótipos impostos pela sociedade, embora alguns especialistas creem que diferenças genéticas estejam por trás desta diferença
Uma criança não é necessariamente anormal se seu peso e/ou altura são maiores ou menores do que a média.
Um assunto muito discutido são as diferenças psicológicas entre meninos e meninas no que se refere à identidade sexual das crianças
Enquanto a maioria dos psicólogos acreditam que as diferenças psicológicas entre ambos os sexos seja determinada primariamente pelo ambiente onde a criança vive e pelos estereótipos impostos à criança pela sociedade, alguns especialistas, primariamente geneticistas, consideram que a genética possui maior peso nestas diferenças.
As diferenças de inteligência entre diferentes crianças são feitas através de testes de quociente de inteligência
Tais testes servem para indicar a habilidade mental no geral de uma criança em relação à média de outras crianças da mesma idade
A média é igual a 100
A performance da criança no teste é pontuada
Cerca de dois terços das crianças são consideradas normais (pontuação entre 84 a 116)
Um sexto pontuam mais do que 116, e são consideradas super-dotadas
Um sexto das crianças pontuam menos de que 84, neste caso, a presença de uma deficiência mental (e muitas vezes permanente - com vários graus de severidade) é considerada - embora várias crianças pontuem menos do que a média por causa de problemas psicológicos.
Os testes de quociente de inteligência são usados especialmente para o auxílio do diagnóstico de problemas neurológicos ou psicológicos, e também em testes que visam ao estudo da genética, seu papel no desenvolvimento de uma pessoa e no seu papel do desenvolvimento das diferenças entre diferenças psicológicas entre diversas pessoas
A pontuação de pessoas relacionadas geneticamente (ou seja, possuem laços de família) que fizeram pelo quociente de inteligência geralmente diferem menos do que as diferenças entre a pontuação de pessoas não relacionadas geneticamente, o que sugere que a genética tem um peso considerável - se não majoritário - na habilidade mental de uma pessoa
Porém, outros especialistas acreditam que é o ambiente no qual a criança vive que é o fator primário na formação psicológica e da habilidade mental
Estes especialistas fazem uso de estudos entre crianças culturalmente deprivadas - crianças que são criadas sem os estímulos necessários que as ajudam na educação escolar e/ou que sofrem de abuso infantil, e que possuem no geral um quociente de inteligência menor do que a média
O quociente de inteligência destas crianças, nos estudos realizados, aumentou muito após receberem cuidados especiais.
Já outros especialistas questionam o uso destes testes, e que tais testes não são eficientes para medir a habilidade mental e a inteligência como um todo de uma criança
Estes especialistas alegam que a inteligência envolve vários fatores - memória, lógica e originalidade, por exemplo, e que uma criança pode destacar-se em uma ou mais áreas enquanto sofre dificuldades em outras.
Os pais de uma criança possuem um papel fundamental no desenvolvimento psicológico da criança, além de serem os responsáveis pela sustentação dela
Uma das principais preocupações dos pais é ajudar a criança em desenvolvimento a crescer normalmente
A palavra normal possui dois sentidos, quando relacionada com o desenvolvimento infantil
A primeira delas é a ausência de anormalidades físicas e/ou psicológicas, que são consideradas anormais em toda sociedade e cultura
Estas anormalidades incluem epilepsia, esquizofrenia e doenças genéticas
A maioria destas doenças surgem por motivos que não relacionados com a forma com o qual os pais criaram a criança.
A segunda definição - onde os pais possuem grande influência - é se a criança possui certas habilidades ou traços, algumas delas valorizadas pelos pais, outras valorizadas pela sociedade onde a criança vive
Uma criança é considerada normal se ela possui estas características
Algumas destas características valorizadas internacionalmente incluem viver amigavelmente com outras pessoas, agir inteligentemente e de maneira responsável, e a comunicação
Estas últimas habilidades são essenciais para a vida de uma pessoa dentro de uma sociedade, e os pais possuem grande influência no desenvolvimento destas características
Os pais também têm papel crucial em ensinar às crianças, desde tenra idade, a lidar com traços como vaidade, timidez e ciúmes
Crianças vítimas de negligência ou de abuso infantil (por parte dos pais), por exemplo, muitas vezes se comportam de maneira agressiva ou muito retraída com outras pessoas, por exemplo.
Já outras habilidades e traços são valorizados apenas por certas culturas
Por exemplo, nos países desenvolvidos e em vários países em desenvolvimento, espera-se da criança que ela aprenda eventualmente a ler e a escrever
Uma criança incapaz de adquirir esta habilidade pode ser vista como anormal
Porém, em vários países em desenvolvimento, espera-se muitas vezes que uma criança ajude seus pais a sustentar sua família
Tais crianças são consideradas muitas vezes normais - na sociedade onde elas vivem - se elas adquirem as habilidades necessárias para trabalhar e sustentar a sua família, bem como não são vistas como anormais se não sabem ler e escrever
Certas culturas como a "cultura ocidental" vêm o sexo masculino e o sexo feminino como iguais - ambos possuem os mesmos direitos - e meninos e meninas são criados igualmente
Já em outras culturas, traços considerados masculinos - como independência e competitividade - são considerados anormais entre mulheres, e, portanto, meninos muitas vezes são incentivados pelos pais a ter tais traços, enquanto tais traços entre meninas são reprimidos.
Os pais são especialmente responsáveis em cuidar da criança e de suas necessidades físico-psicológicas, do uso de recompensas e punições, e como modelos de comportamento
Em muitos casos onde há omissão dos pais em termos de afeto e relacionamento as crianças podem desenvolver sérios problemas emocionais
A chamada "terceirização da infância", termo usado pelo pesquisador José Martins Filho em seu livro "A criança terceirizada: os descaminhos das relações familiares no mundo contemporâneo", é uma realidade em várias partes do mundo e, principalmente, no Brasil.
Todas as crianças possuem algumas necessidades físico-psicológicas que precisam ser cumpridas e atendidas para que a criança cresça normalmente.
A principal necessidade física da criança é a alimentação, da qual as crianças são totalmente dependentes dos adultos nos primeiros anos de vida
Outras necessidades físicas importantes são limpeza e higiene, vestuário adequado e um abrigo
Espaço também é importante - para o exercício de jogos e brincadeiras
Além disso, a criança também depende dos adultos quanto ao aprendizado de bons hábitos de comportamento, tanto à sociedade que o cerca quanto a si mesma - mantendo uma higiene adequada, por exemplo, lavando as mãos antes de comer, não comer nada que tenha caído no chão, escovar os dentes diariamente, etc.
O desenvolvimento das vacinas diminuiu bastante as taxas de mortalidade infantil em muitos países - especialmente em doenças como sarampo, paralisia infantil e varíola (esta última já extinta)
Em muitos países, os pais são obrigados a vacinar a criança, pelo menos contra certas doenças como sarampo, paralisia infantil, tuberculose, tétano e difteria, por exemplo
Caso os pais não levem as crianças a postos de vacinação, as crianças poderão ser suspensas da escola, e em casos mais graves, os pais podem perder a guarda da criança
Algumas destas vacinas requerem reimunização - a aplicação de uma nova dose da vacina - regularmente.
As necessidades psicológicas da criança são determinadas pelas habilidades e pelos traços de personalidade que os pais esperam que seu filho desenvolva
Algumas destas são incentivadas em toda sociedade, outras apenas em certas culturas
Todas as crianças possuem certas necessidades psicológicas - como sentir-se amadas e queridas pelos pais.
Espera-se mais responsabilidade e maturidade da criança quando esta passa a ir à escola regularmente - a partir dos seis ou sete anos de idade
As crianças passam a frequentar regularmente um lugar onde regras existem, que devem ser cumpridas - e onde os padrões de comportamento não mudam de um dia para o outro.
Muitas crianças (principalmente em países subdesenvolvidos) experimentam diversos problemas como alimentação reduzida ou desequilibrada (desnutrição), trabalho infantil, ausência de habitação, AIDS, entre outros
Com o objectivo de solucionar estes problemas a UNICEF promove diversas campanhas de recolhimento de fundos monetários para poder apoiá-las nesses países.
O choro é o meio mais eficaz para manifestar uma necessidade ou um mal-estar
Os psicólogos têm procurado identificar os vários tipos de choro com as situações que o motivam
Assim, distinguem-se geralmente quatro padrões de choro: choro básico de fome, choro de raiva, choro de frustração e choro de dor, e/ou ainda de cansaço e desconforto.
O sorriso é uma das formas de comunicação que desencadeia confiança e afeto reforçando os esforços dos adultos em satisfazer o bebê
O primeiro sorriso pode ocorrer após o nascimento, de modo espontâneo, efeito da atividade do sistema nervoso central.
Depois da alimentação e ao adormecer, é frequente esboçar um sorriso que pode ser também desencadeado pelos sons emitidos pelos progenitores
Estes sorrisos são automáticos, reflexos e involuntários.
O sorriso é um sinal que reforça as relações positivas do adulto favorecendo a sua repetição
É um comportamento intencional que visa manter a comunicação com aqueles que tratam do bebê.
Dada a especificidade da infância, diversas representações sobre este período da vida do indivíduo marcam a produção literária, artística e cultural dos diversos grupos e sociedades
As representações sobre a infância portam tanto uma interpretação deste momento da vida quanto um projeto para o adulto que a criança se tornará
Buscando exemplificar esta variedade de representações, uma vez que sempre que a criança e a infância são retratada elas são representadas, teremos:
O surgimento de um discurso sobre a infância está vinculado à emergência da percepção da especificidade do infantil na modernidade, como demonstra Philippe Ariès em A história Social da Criança e da Família.
Adolescência é a fase que marca a transição entre a infância e a idade adulta
Caracteriza-se por alterações em diversos níveis - físico, mental e social - e representa para o indivíduo um processo de distanciamento de formas de comportamento e privilégios típicos da infância e de aquisição de características e competências que o capacitem a assumir os deveres e papéis sociais do adulto.
Os termos "adolescência" e "juventude" são por vezes usados como sinónimos (como em alemão Jugend e Adoleszenz, inglês Youth e Adolescence) e por vezes como duas fases distintas mas que se sobrepõem: para Steinberg a adolescência se estende aproximadamente dos 15 aos 21 anos de vida, enquanto a ONU define juventude (em inglês, youth) como a fase entre 15 e 24 anos de idade - sendo que deixa aberta a possibilidade de diferentes nações definirem o termo de outra maneira; a Organização Mundial da Saúde define adolescente como o indivíduo que se encontra entre os dez e dezenove anos de idade e, no Brasil, a legislação, através Estatuto da Criança e do Adolescente, estabelece ainda uma faixa etária para menores de idade - dos 12 anos completos aos 18 anos, período durante o qual a pessoa nessa faixa de idade (legalmente considerada "adolescente"), se cometer um crime pode receber medidas socioeducativas, inclusive de restrição da liberdade através de apreensão
Além disso Oerter e Montada descrevem uma "idade adulta inicial" (al
frühes Erwachsenenalter), que vai dos 18 aos 29 anos e que se sobrepõe às definições de "juventude" previamente apresentadas, o que é seguido em parte pela legislação brasileira: o Estatuto da Juventude, no Brasil, diz que a juventude vai dos 15 anos até aos 29 anos - o que diverge da Assembleia Geral das Nações Unidas, que afirma que a juventude vai até os 24 anos.
O início e o fim da adolescência variam culturalmente de nação para nação, e entre cultura e legislação: no Brasil, por exemplo, a adolescência legalmente começa ao se completar 12 anos e termina ao se completar 18 anos
O termo é geralmente utilizado em um contexto científico com relação ao processo de desenvolvimento bio-psico-social; o fim da adolescência não é marcado por mudanças de ordem fisiológica, mas sobretudo de ordem sociocultural.


O termo adolescência é usado com vários significados em contextos diversos:
Adolescência e juventude são fenômenos de forte caracterização cultural e sua definição está intimamente ligada à transformação da compreensão do desenvolvimento humano e também à transformação da forma como cada geração adulta se define a si própria.
A ideia de que a adolescência é uma fase qualitativamente diferente da infância e da idade adulta tem sua origem já na antiguidade
A base sócio-política dessa diferenciação só surgiu, no entanto, com a transformação das estruturas sociais ocorrida em fins do século XIX que permitiram que os jovens (adolescentes) fossem retirados do mercado de trabalho para frequentarem a escola e outras instituições educacionais
Ligados a essa ideia de adolescência como fase de formação para o trabalho foram propostos os termos "adolescência encurtada" e "adolescência estendida", que descrevem as diferentes oportunidades de formação e educação que têm pessoas que entram no mercado de trabalho mais cedo ou mais tarde - normalmente de acordo com a situação cultural e a possibilidade financeira da família
O aumento da complexidade das funções e papéis a serem exercidos na idade adulta levam a um aumento progressivo dessa fase de formação.
As fases da adolescência e da juventude são objeto de estudo de diferentes disciplinas, como sociologia, política, psicologia, pedagogia, biologia, medicina, direito e outras, apresentando diferentes significados
Tais significados abrangem, por exemplo, "juventude como fase do desenvolvimento individual", "juventude como ideal e mito" (com uma correspondente idealização dessa fase da vida) e "juventude como grupo social" que possui uma cultura própria.
Se, do ponto de vista da psicologia do desenvolvimento, o início da adolescência é claramente marcado pelo início do amadurecimento sexual (puberdade), o seu fim não se define apenas pelo desenvolvimento corporal, mas sobretudo pela maturidade social - que inclui, entre outras coisas, a entrada no mercado de trabalho e o assumir do papel social de adulto.
A adolescência não é, no entanto, uma fase homogênea
Pelo contrário, é uma fase dinâmica que, para o seu estudo, exige uma maior diferenciação
Steinberg propõe uma divisão em três fases: (1) Adolescência inicial, dos 11 aos 14 anos; (2) adolescência média, dos 15 aos 17 anos e (3) adolescência final, dos 18 aos 21
Essa última fase sobrepõe-se à "juventude" em sentido estrito, que marca o início da idade adulta, definida por Oerter e Montada como a fase entre os 18 e os 29 anos de idade.
O desenvolvimento cognitivo é, ao lado das mudanças corporais tratadas mais abaixo, uma das características mais marcantes da adolescência
Tal desenvolvimento se mostra sobretudo através:
Dessa maneira o adolescente adquire a base cognitiva para redefinir as formas com que lida com os desafios do meio-ambiente, que se torna cada vez mais complexo, e das mudanças psicofisiológicas
As principais características desse desenvolvimento são:
Durante a adolescência, o corpo do indivíduo cresce continuamente até a idade de 16 a 19 anos, quando a estatura adulta é alcançada - os rapazes atingem a estatura adulta em média dois anos mais tarde do que as moças
Tal crescimento, no entanto, não se dá de maneira contínua: aproximadamente aos 14-15 anos os rapazes - as moças dois anos antes - têm um "salto no crescimento", ou seja eles crescem em um ano mais do que nos anos anteriores e nos seguintes
Depois desse salto, a velocidade do crescimento diminui marcadamente até o indivíduo atingir sua altura final
Paralelamente ao crescimento físico há um aumento no peso, que, no entanto, é dependente da alimentação e da forma de vida.
As diferentes partes do corpo também crescem com velocidades diferentes
De maneira geral os membros superiores (braços) e inferiores (pernas) e a cabeça crescem mais rapidamente que o resto do corpo, atingindo seu tamanho final mais cedo
Isso leva a uma desproporção visível com relação ao tronco, que cresce mais devagar
Essa desproporção é observável também nos movimentos por vezes desajeitados, típicos da adolescência.
Até a idade de 11 anos, meninos e meninas tem aproximadamente a mesma força muscular
O crescimento muscular dos rapazes é, no entanto, maior, o que explica a maior força física média dos homens na idade adulta.
Apesar das muitas diferenças individuais no crescimento e no desenvolvimento sexual, o processo de amadurecimento sexual apresenta uma certa sequência, comum tanto aos rapazes como às raparigas
Para as moças, no entanto, esse processo tem início, em média, dois anos mais cedo do que nos rapazes.
Em uma pesquisa realizada na Alemanha Schmid-Tannwald e Kluge registraram uma tendência entre as meninas de terem a menarca aproximadamente 1,3 anos mais cedo do que em uma pesquisa anterior de 1981
As meninas que foram preparadas pelos pais para esse fenômeno corporal relataram terem-no visto como natural, enquanto as moças que não haviam sido preparadas relataram terem tido um sentimento desagradável
Também entre os meninos o mesmo estudo registrou uma tendência de uma primeira ejaculação aproximadamente 1,7 anos mais cedo do que dez anos antes
Dos adolescentes entrevistados apenas 43% tiveram uma primeira ejaculação espontânea; 31% a tiveram através de masturbação e 5% através do ato sexual.
A ação dos hormônios, muito importantes na regulação do metabolismo, é muito complexa e ainda não completamente compreendida
Com relação ao crescimento corporal dois hormônios desempenham um papel preponderante: a somatotrofina, hormônio do crescimento produzido pela hipófise, e a tiroxina, produzida pela tiróide
A somatotrofina regula o crescimento do corpo como um todo; já a tiroxina, que só é produzida "sob instrução" da hipófise através da tirotrofina, regula principalmente o crescimento do cérebro, dos dentes e dos ossos.
A puberdade traz consigo uma mudança na ação dos hormônios
Ativada pelo hipotálamo a hipófise começa a secretar novos hormônios que agem sobre os órgãos sexuais (gonadotrofinas: hormônio folículo-estimulante e hormônio luteinizante) e sobre as glândulas supra-renais (hormônio adrenocorticotrófico)
Nos meninos, aproximadamente aos 11 anos, o hormônio folículo-estimulante provoca o desenvolvimento das células que produzem os espermatozóides e o hormônio luteinizante leva à produção do hormônio masculino, a testosterona
Esta, por sua vez, conduz aos desenvolvimentos das características típicas masculinas
Já nas meninas, aproximadamente aos 9 anos, o hormônio folículo-estimulante leva ao amadurecimento dos folículos de Graaf no ovário, que produzem os óvulos, e o hormônio luteinizante à menstruação
Os ovários produzem, por sua vez, dois hormônios: o estrogênio, que regula o crescimento dos seios, dos pelos pubianos e a acumulação de gordura, e a progesterona, que regula o ciclo menstrual e a gravidez.
Como se viu, as mudanças típicas da adolescência iniciam, em média, em uma idade específica
No entanto alguns adolescentes iniciam o seu amadurecimento mais cedo do que a média enquanto outros o fazem mais tarde
Dos primeiros se diz que seu amadurecimento é acelerado, enquanto o dos segundo é retardado
Importante é notar que tal comparação só pode ser feita em algumas situações, pois tais diferenças existem entre pessoas de diferentes raças e de diferentes gerações.
Em nenhuma outra fase da vida há uma variação tão grande entre pessoas da mesma idade como na adolescência
Essa situação é ainda mais confusa porque o desenvolvimento físico, o social e o cognitivo (ver abaixo) não andam necessariamente juntos
O meio-ambiente, no entanto, reage de forma diferente, de acordo com o desenvolvimento visível da pessoa - meninos que parecem mais velhos tendem a ser tratados como mais velhos e vice-versa
Essa reação do meio ambiente influencia o desenvolvimento social e psicológico dos adolescentes de maneira marcante
Adolescentes com desenvolvimento retardado tendem a ser emocionalmente menos estáveis e menos satisfeitos; tendem a ter uma autoimagem mais negativa, a ser menos responsáveis e mais inseguros
Já os adolescentes com desenvolvimento acelerado têm um maior risco de terem problemas com drogas e com o comportamento social, provavelmente por terem acesso mais cedo a grupos mais velhos
Outros estudos registraram que rapazes com desenvolvimento acelerado apresentam algumas vantagens com relação a seus coetâneos: mesmo na idade de 38 anos eles se mostraram mais responsáveis, cooperativos, seguros, controlados e mais adaptados socialmente; ao mesmo tempo se mostraram mais convencionais, conformistas e com menos senso de humor; já os rapazes com desenvolvimento retardado mostraram-se, mesmo com 38 anos, mais impulsivos, instáveis emocionalmente, mas em compensação mais capazes de reconhecer seus erros, mais inovativos e divertidos
Também com relação ao desenvolvimento da identidade há diferenças entre rapazes com desenvolvimento acelerado e retardado
Como têm mais tempo para desenvolver seu conhecimento e suas estratégias de coping os rapazes com desenvolvimento retardado tendem a ter melhores possibilidades no desenvolvimento da própria identidade, enquanto os rapazes com desenvolvimento acelerado acabam sendo introduzidos mais cedo no muno adulto e acabam assumindo uma identidade mais próxima aos padrões socialmente estabelecidos
Já no caso das moças a situação é um pouco distinta
Moças com desenvolvimento acelerado tendem a ter uma autoestima mais baixa por crescerem mais rapidamente e assim não corresponderem ao ideal de beleza culturalmente estabelecido
Por outro lado moças com uma menarca muito tardia parecem também mostrarem uma tendência a terem uma autoestima mais baixa
Resumindo: aceleração e retardo no desenvolvimento são dois fenômenos que podem trazer consigo certos riscos para o desenvolvimento da pessoa
No entanto um trabalho de esclarecimento dos pais e dos adolescentes pode reduzir esses risco de maneira drástica, oferecendo aos adolescentes melhores condições de desenvolvimento.
Outro fenômeno muito discutido é o da chamada aceleração secular, ou seja, a tendência, nos países ocidentais, de a puberdade iniciar cada vez mais cedo
Em um estudo comparativo, Tanner mostra como desde 1840 a idade média da menarca caiu de 17 anos para 13,5 anos na Noruega, fenômeno observável também em outros países europeus e nos Estados Unidos
Os adolescentes atingem, assim, a maturidade corporal cada vez mais cedo
Por outro lado o início da idade adulta - entrada no mercado de trabalho e formação de uma família - tende a ocorrer cada vez mais tarde devido à longa formação necessária (escola, universidade)
Essas duas tendências contrárias geram novas oportunidades mas também novos desafios - e estresse - para os adolescentes.
Paralelamente ao início da maturidade sexual também o comportamento sexual começa a se desenvolver
Esse desenvolvimento é um processo muito complexo e é fruto da interação de vários fatores - desenvolvimento físico, psicosocial, a exposição a estímulos sexuais (que é definida pela cultura), os grupos de contatos sociais (amigos, grupos de esporte, etc.), e as situações específicas que permitem o acesso à experiência erótica.
O início do desenvolvimento sexual se encontra já na infância
Não apenas os casos de abuso sexual, mas também as experiências quotidianas de troca de carinho e afeto, de relacionamentos interpessoais e de comunicação sobre a sexualidade desempenham um papel importantíssimo para o desenvolvimento do comportamento sexual e afetivo do adolescente e, posteriormente, do adulto
Importantes aqui são sobretudo processos de aprendizado através do modelo dos pais: em famílias em que carinho e afeto são trocados abertamente e em que a sexualidade não é um tabu os adolescentes desenvolvem outras formas de comportamento do que em famílias em que esses temas são evitados e considerados inconvenientes.
Baseados em seus estudos com adolescentes alemães Schmid-Tannwald e Kluge (1998) defendem três teses que resumem o resultado desse trabalho:
Um outro ponto importante é a preferência dos adolescentes por relacionamentos estáveis ao invés de liberalidade sexual
Sobretudo para as moças uma vida sexual satisfatória está fortemente relacionada a um relacionamento estável .
No estudo de 1983, 40% das moças e 50% dos rapazes diziam ter tido a primeira relação sem proteção, por crerem que não se engravida tão facilmente; já em 1994, 80% das moças e 76% dos rapazes alemães diziam ter utilizado algum tipo de método contraceptivo já no primeiro ano de vida sexual ativa
As principais razão para a pouca proteção é sobretudo pouco ou mesmo falso conhecimento: os adolescentes frequentemente não conhecem suficientemente o ciclo menstrual mas julgam saber quando podem ter sexo sem proteção e sem risco de gravidez
Em comparação às moças os rapazes têm um maior defict de conhecimento
O esclarecimento sobre a sexualidade ainda tende a ser feito por amigos ou livros e não em casa.
A partir dos dados disponíveis, Oerter e Dreher (2002) enfatizam três ponto principais:
O termo "identidade" corresponde à resposta à pergunta "quem sou eu?"
A resposta a essa pergunta se desenvolve num longo e complexo processo que começa nas primeiras horas de vida e se estende até a mais alta idade
Nesse longo processo a adolescência representa um momento chave, de grande significado
No processo de desenvolvimento da identidade agem duas forças motrizes: o desejo do indivíduo de conhecer a si mesmo (autoconhecimento) e a busca de dar forma a si, de construir sua personalidade, se aprimorar e se desenvolver (autodesenvolvimento).
Durante muito tempo a adolescência foi vista como uma fase de "tempestades e tormentas" (Sturm umd Drang, por exemplo por Granvillle S
Hall)
Com o auxílio da pesquisa mais atual, no entanto, essa visão tem se tornado mais diferenciada
Por exemplo, quando medidas através de questionários, a autoimagem e a autoestima mantém-se relativamente estáveis durante toda a adolescência - se bem que em uma importante minoria, sobretudo entre as moças, há uma tendência de diminuição da autoestima.
Enquanto a autoimagem e a autoestima parecem permanecer constantes, a complexidade da estrutura da identidade aumenta constantemente durante a adolescência
Esse aumento de complexidade se mostra nos seguintes pontos:
Higgins (1987) descreveu três tipos de "si mesmo" - o si mesmo real, o si mesmo ideal (como a pessoa gostaria de ser) e o si mesmo como deveria ser (que representa a identificação da pessoa com determinadas obrigações e tarefas apresentadas pelo ambiente social)
O ambiente social tem, ele mesmo (ou melhor, a pessoas que dele fazem parte), uma imagem de como o indivíduo é e de como ele deveria ser (expectativas)
O aumento da complexidade na compreensão de si mesmo expõem o adolescente assim a diferentes tipos de discrepância:
A tomada de consciência desses conflitos de interesses expõe o adolescente ao estresse e, dependendo da carga genética e do ambiente em que se desenvolve, ao risco de diversos tipos de problemas sociais e psicológicos - desde transtornos alimentares (anorexia, bulimia) até o suicídio, passando por problemas de desempenho escolar, abuso e dependência de substâncias químicas, fobias e depressão
Segundo estudos epidemiológicos europeus entre 15% e 22% da população infanto-juvenil apresenta alguma forma de distúrbio mental nessa faixa etária.
Os adolescentes são um alvo cobiçado pelo comércio
Telemóveis, música contemporânea, jogos eletrónicos e roupas "da moda" são populares entre adolescentes, desde os últimos anos do século XX
Da mesma forma, a propaganda utiliza a imagem do próprio adolescente para vender seus produtos, buscando mostrar a ideia de jovialidade, mudança e independência.
Em muitas culturas há cerimônias que celebram a passagem da adolescência ao mundo adulto, geralmente ocorrendo na adolescência
Por exemplo, a tradição judaica considera como adultos (membros da sociedade) os homens aos 13 e as mulheres aos 12 anos de idade, sendo a cerimônia de transição chamada Bat Mitzvah para as garotas e Bar Mitzvah para os rapazes
Os jovens católicos de ambos os sexos recebem o sacramento da Crisma por volta da mesma idade (16 anos)
No Japão, a passagem do jovem para a idade adulta é celebrada pelo Seijin Shiki (ou “cerimônia adulta” em tradução literal), marcando o genpuku (do japonês), cerimônia de passagem à idade adulta
Em África, muitos grupos étnicos indígenas praticam ritos de iniciação, por vezes associada à circuncisão masculina ou feminina, esta com aspetos que têm sido postos em causa, por alegadamente atentarem contra a saúde física ou mental das jovens, como a excisão do clitoris e a infibulação.
Em muitos países, pessoas maiores de uma certa idade (18 anos, em vários casos, apesar de variar de país a país) são legalmente considerados adultos
Pessoas que têm menos que essa delimitada idade podem ser considerados jovens demais para serem considerados culpados por crime
Isto chama-se defesa da infância
O direito a votar em eleições é dado a pessoas com idade mínima entre 16 e 21 anos, em muitos países.
A venda de certos produtos como cigarros, álcool, filmes e jogos eletrônicos com conteúdo pornográfico ou violento é proibido a menores de idade
Tais restrições de idade variam de país a país
Na prática, é possível encontrar pessoas que tiveram contato com estes produtos antes da maioridade.
A relação sexual entre adultos e adolescentes é regulada pelas leis de cada país referentes à idade de consentimento
Alguns países permitem o relacionamento a partir de uma idade mínima (12 anos na Arábia Saudita, 13 anos na Espanha, 14 no Brasil, Portugal, Itália, Alemanha e Áustria, 15 na França e Dinamarca, 16 na Noruega)
Para além das restrições legais, a questão é muitas vezes tratada como um problema social, chegando alguns setores da sociedade a pregar a abstinência sexual nesta faixa etária.
Um exemplo de relacionamento com grande diferença de idade foi dramatizado no romance Lolita, de Vladimir Nabokov levado ao cinema pela primeira vez por Stanley Kubrick em 1962.
No Japão, o termo joshi-kousei (女子高生) indica as estudantes femininas de ensino médio e é usado por garotas de 16 a 18 anos
Elas são frequentemente notadas por suas obsessões por roupas, cultura pop e telefones celulares
A prostituição por parte delas, chamada enjo kosai (援助交際), tornou-se uma preocupação social japonesa a partir da década de 1990
O problema da prostituição juvenil e mesmo infantil é aliás preocupação em muitas sociedades.
Pornografia envolvendo pessoas abaixo de certa idade (geralmente 18) é também considerado inaceitável e é proibida na maioria dos países.
A emancipação de menores é um mecanismo legal através do qual uma pessoa abaixo da idade da maioridade adquire certos direitos civis, geralmente idênticos àqueles dos adultos
A extensão dos direitos adquiridos, assim como as proibições remanescentes, variam de acordo com a legislação local.
No Brasil, porém, ainda que esteja emancipado, o menor de idade de 18 anos não comete crime e sim ato infracionário
Os efeitos da emancipação alcançam apenas a esfera civil, ou seja, o emancipado abaixo de 18 anos continua penalmente inimputável.
As células beta são células endócrinas nas ilhotas de Langerhans do pâncreas
Elas são responsáveis por sintetizar e secretar o hormônio insulina, que regula os níveis de glicose no sangue
Em roedores, as células-alfa estão localizadas na periferia das ilhotas, em humanos a arquitetura das ilhotas é geralmente menos organizada e as células alfa são frequentemente observadas dentro das ilhas.

O pâncreas é uma glândula de aproximadamente 15 cm de extensão fazendo parte do sistema digestivo e endócrino dos seres humanos que se localiza atrás do estômago e entre o duodeno e o baço
Ele é tanto exócrino (secretando suco pancreático, que contém enzimas digestivas) quanto endócrino (produzindo muitos hormônios importantes, como insulina, glucagon e somatostatina)
Divide-se em cabeça, corpo e cauda
O pâncreas é um órgão produtor de enzimas, proteínas que aumentam a rapidez das transformações químicas.


Em humanos, geralmente o pâncreas é uma glândula longa com 15–25 cm que se localiza no abdômen
Sendo uma das glândulas retroperitoneais, ele é localizado posteriormente ao estômago e está em associação próxima ao duodeno.
É frequentemente descrito como tendo três regiões: a cabeça, corpo e a cauda.
O ducto pancreático (também chamado de ducto de Wirsung) percorre o comprimento do pâncreas e termina na segunda porção do duodeno, na ampola de Vater (hepatopancreática)
O ducto biliar comum geralmente se une ao ducto pancreático neste ponto ou próximo dele
Muitas pessoas também possuem um pequeno ducto acessório, o ducto de Santorini.
O pâncreas é suprido arterialmente pelas artérias pancreaticoduodenais: A artéria mesentérica superior que origina as artérias pancreaticoduodenais inferiores A artéria gastroduodenal que origina as artérias pancreaticoduodenais superiores A artéria esplênica que origina as artérias pancreáticas.
A drenagem venosa é feita através das veias pancreáticas que são tributárias das veias esplênica e mesentérica superior, no entanto a maioria delas terminam na veia esplênica
A veia porta hepática é formada pela união da veia mesentérica superior e veia esplênica posteriormente ao colo do pâncreas
Geralmente a veia mesentérica inferior se une à veia esplênica atrás do pâncreas (em outras pessoas ela simplesmente se une à veia mesentérica superior).
No microscópio, quando corado adequadamente, é fácil se distinguir os dois tipos diferentes de tecidos no pâncreas
Essas regiões correspondem às funções pancreáticas principais:
O pâncreas endócrino é composto de aglomerações de células especiais denominadas ilhotas de Langerhans
O "cansaço" crônico destas células leva ao aparecimento da diabetes no pâncreas.
Existem quatro tipos de células nas ilhotas de Langerhans
Elas são relativamente difíceis de se distinguir ao usar técnicas normais para corar o tecido, mas elas podem ser classificadas de acordo com sua secreção:
Porção que secreta, no duodeno, por meio de um ducto, o suco pancreático, contendo enzimas e bicarbonato.
Devido à sua importância na digestão e na produção de hormônios, as doenças do pâncreas possuem significativa relevância na prática clínica.
Ductos biliares: (bile canaliculus, ducto hepático comum, ducto cístico, ducto colédoco) | Ducto pancreático | Ampola hepatopancreática
Idiopático é um adjetivo usado primeiramente na medicina significando surgido espontaneamente ou de causa obscura ou desconhecida
Derivado do grego ἴδιος, idios (de si próprio) + πάθος, pathos (sofrimento).
É tecnicamente um termo da nosologia, ramo da medicina que estuda a classificação das doenças
Para a maioria das condições médicas, uma ou mais causas são conhecidas, mas em certa percentagem de pessoas afetadas pela doença, a causa pode não estar aparente ou ser caracterizada
Nesses casos, a origem da doença é dita "idiopática"
Como exemplo de doença, a polineuropatia axonal idiopática crônica.
Em seu livro "The Human Body" (O corpo humano), Isaac Asimov escreveu um comentário feito sobre o termo "Idiopático" na 20ª edição do Stedman's Medical Dictionary: "um termo pretensioso para ocultar ignorância".
A Ginástica aeróbica , pode ter vários tipos como a step, espetacular, jump e outras, em sentido amplo, é uma combinação de ginástica clássica com dança
É um treinamento dinâmico com movimentos rítmicos flanqueado com música motivadora
Os elementos principais da ginástica aeróbica são coordenação motora e fitness.
Esta modalidade não pertence ao calendário olímpico, como as modalidades artística, de trampolim e rítmica
Porém, já possui campeonatos realizados pela FIG a nível internacional
Essa modalidade requer do ginasta um elevado nível de força, agilidade, flexibilidade e coordenação.


Em sentido estrito, chama-se ginástica aeróbica as atividades físicas caracterizadas por movimentos rítmicos e intensos com elevado gasto calórico pois, exige bastante da pessoa e gera impacto sobre as articulações, deixando a pessoa mais saudável a partir do momento em que ela começa a se exercitar e criar movimentos estes causadores de esforço físico que pode ser suprido pela oxigenação normal da respiração, quase sempre acompanhados de música, e que produzem um aumento metabólico e uso de substratos benéficos ao organismo.
Ginástica aeróbica pode ser qualquer atividade física caracterizada pela prática de exercícios isotônicos, ou seja, esforços musculares em que existe a manutenção da tonicidade muscular, com modificação do comprimento e volume da mesma medida do tempo
Geralmente são exercícios em que não há uma exaustão por acúmulo excessivo de ácido láctico, onde o consumo de oxigênio pelo músculo é proporcional, e que por conseguinte o ganho anabólico é menor quando comparado com os exercícios anaeróbios.
Na década de 1990, esta disciplina foi uma "febre da moda" nas academias, pois ajuda muito a emagrecer e favorece a redução de percentual de gordura e produzem corpos esculpidos.
Os exercícios aeróbicos usam grandes grupos musculares, rítmica e continuamente, elevando os batimentos cardíacos e a respiração durante algum tempo
O exercício aeróbico é longo em duração e moderada em intensidade
Dentre algumas das atividades aeróbicas mais comuns estão: andar, correr, pedalar e remar
Aeróbica por definição, significa com ar ou oxigênio.
Além dos benefícios para a queima de substratos (gordura, glicose e em último caso proteína) os exercícios aeróbicos são muito benéficos também para melhorar a saúde de modo geral.
É uma ginástica composta por exercícios que estimulam a melhora do desempenho cardiovascular através da utilização do uso do oxigênio pelo corpo do indivíduo e permitindo que o coração trabalhe com mais força e com maior frequência.
A ginástica aeróbica (d)esportiva (ou ginástica aeróbica de competição, ou ainda pelos acrônimos GAE ou GAD) caracteriza-se por ser uma atividade intensa, alegre, com movimentos e expressões corporais diversificados e bem marcados, com um acompanhamento rítmico e musical
Os atletas precisam demonstrar muito dinamismo, força, flexibilidade, coordenação e ritmo sincronizados com o acompanhamento musical
Seus eventos são divididos em cinco: individual feminino e masculino, pares mistos, trios e grupos de cinco.
A cetose foi identificada pelo Dr
Alfred Bauer em 1962 e é um estágio no catabolismo que ocorre quando o Fígado converte gorduras em ácidos graxos e corpos cetônicos, que podem ser usados pelo corpo para energia.
A cetose nada mais é do que um estado normal do metabolismo, que ocorre na ausência de glicose
É bastante diferente da cetoacidose, condição decorrente da diabetes, devido à ordem de grandeza da concentração de corpos cetônicos no sangue
Tipicamente, os valores para cetose nutricional ficam na faixa de 0 a 5 mmol/L, enquanto na cetoacidose eles são na faixa de 15 a 25 mmol/L.
A cetose acontece quando o organismo usa os depósitos de gordura como fonte energética (quando não há mais glicogênios).
A cetose é induzida por dietas baixas em carboidratos, ou mesmo em condições de jejum prolongado.
Hipoglicemia é uma condição em que a taxa de glicose no sangue diminui para valores inferiores ao normal
A condição causa vários sintomas, entre os quais desorientação, dificuldade em falar, estado de confusão, perda de consciência, convulsões ou morte
Podem ainda estar presentes sintomas como fome, sudação em excesso, tremores e fadiga
Geralmente os sintomas manifestam-se de forma súbita
A condição oposta é a hiperglicemia.
A causa mais comum de hipoglicemia são os medicamentos antidiabéticos usados no tratamento da diabetes, como a insulina e as sulfonilureias
O risco é maior em diabéticos que comeram menos do que é habitual ou que ingeriram bebidas alcoólicas
Entre outras possíveis causas estão a insuficiência renal, alguns tumores como o insulinoma, doenças hepáticas, hipotiroidismo, inanição, erro metabólico hereditário, infeções graves, hipoglicemia reativa e uma série de drogas, incluindo álcool
A hipoglicemia pode também ocorrer em bebés de outro modo saudáveis que não tenham comido durante várias horas.
A taxa de glicose no sangue que define a hipoglicemia varia
Em pessoas com diabetes, o diagnóstico corresponde a uma taxa inferior a 3,9 mmol/L (70 mg/dL)
Em adultos sem diabetes, o diagnóstico é confirmado quando se verifica simultaneamente sintomas relacionados com a hipoglicemia, baixa glicose no sangue durante os sintomas, e melhoria desses sintomas assim que a taxa regressa ao normal
Quando não se manifestam sintomas, pode ser usado um valor de referência inferior a 2,8 mmol/L (50 mg/dL) em jejum ou após a realização de exercício físico
Em recém-nascidos, uma taxa inferior a 2,2 mmol/L (40 mg/dL), ou inferior a 3,3 mmol/L (60 mg/dL) quando acompanhada de sintomas, indica a presença de hipoglicemia
Os valores de glicose são medidos com análises ao sangue
Entre outros exames que podem ser úteis para determinar a causa estão os valores de insulina e de peptídeos-C no sangue.
Nas pessoas com diabetes, a prevenção da hipoglicemia consiste em adequar a dieta à quantidade de exercício físico praticado e aos medicamentos usados
Quando as pessoas sentem que a taxa de glicose pode estar a diminuir, recomenda-se o uso de um medidor de glicemia portátil
Como algumas pessoas manifestam poucos sintomas iniciais quando a taxa de glicose diminui, recomenda-se a este grupo que monitorize frequentemente a taxa de glicose
O tratamento consiste em ingerir alimentos ricos em açúcares simples ou na toma de dextrose
Nos casos em que a pessoa não consegue ingerir alimentos pela boca, pode ser necessária uma injeção de glicagina
O tratamento da hipoglicemia sem relação com a diabetes consiste em tratar também o problema subjacente e numa dieta saudável.


Os sintomas hipoglicêmicos podem ser divididos naqueles produzidos pelos hormônios contra-regulatórios (adrenalina e glucagon), acionados pelo declínio da glicose, e naqueles produzidos pela redução de açúcar no cérebro.
Nem todas as manifestações anteriores ocorrem em casos de hipoglicemia
Não há ordem certa no aparecimento dos sintomas
Manifestações específicas variam de acordo com a idade e com a severidade da hipoglicemia
Em crianças jovens com hipoglicemia matinal, há vômito frequentemente acompanhado de cetose
Em crianças maiores e em adultos, a hipoglicemia moderadamente severa pode parecer mania, distúrbio mental, intoxicação por drogas ou embriaguez
Nos idosos, a hipoglicemia pode produzir efeitos parecidos com uma isquemia focal ou mal-estar sem explicação.
Em recém-nascidos, a hipoglicemia pode produzir irritabilidade, agitação, ataque mioclônico, cianose, dificuldade respiratória, episódios de apneia, sudorese, hipotermia, sonolência, hipotonia, recusa a se alimentar e convulsões
Também pode parecer asfixia, hipocalcemia, sepse ou falha cardíaca.
Em ambos, pacientes de longa data ou não, o cérebro pode se habituar a níveis baixos de glicose, com redução dos sintomas perceptíveis em momentos de neuroglicopenia
Diabéticos insulinodependentes chamam a neuroglicopenia incondicionalmente de hipoglicemia, e que é um problema clínico importante quando tenta-se melhorar o controle glicêmico desses pacientes
Outro aspecto desse fenômeno ocorre em glicogenose tipo I, onde a hipoglicemia crônica antes do diagnóstico pode ser mais bem tolerada do que episódios agudos após o início do tratamento.
Quase sempre a hipoglicemia severa a ponto de ocasionar convulsões ou inconsciência pode ser revertida sem danos ao cérebro
Os casos de morte ou dano neurológico permanente que ocorreram com um único episódio envolvem ocorrências conjuntas de inconsciência não tratada ou prolongada, ou interferência na respiração, ou doenças concorrentes severas ou outros tipos de vulnerabilidade
De qualquer maneira, hipoglicemias severas podem eventualmente resultar em morte ou dano cerebral.
Mais raramente, a hipoglicemia pode revelar:
Da mesma forma que a maioria das células de animais, o metabolismo cerebral depende primeiramente de glicose para trabalhar
Em casos de privação de glicose, pode-se conseguir uma quantidade limitada dela armazenada nos astrócitos, mas que é consumida em minutos
De qualquer forma, o cérebro é dependente de fornecimento contínuo de glicose, que difunde do sangue ao tecido intersticial dentro do sistema nervoso central, e aos próprios neurônios.
Por isso, se a quantidade de glicose suprida pelo sangue cai, o cérebro é um dos primeiros órgãos a percebê-lo
Na maioria das pessoas, a eficiência mental parece diminuir quando a glicemia cai abaixo de 65 mg/dL (3,6 mM)
Ocorre limitação de ações e de julgamento geralmente quando a glicemia cai abaixo de 40 mg/dL (2,2 mM)
Se cair ainda mais, podem ocorrer convulsões
Próxima ou abaixo de 10 mg/dL, a maior parte dos neurônios fica eletricamente desligada, resultando no coma.
A importância de um fornecimento adequado de glicose ao cérebro é clara pelo fato de ocorrerem inúmeras respostas nervosas, hormonais e metabólicas para combater uma hipoglicemia
A maior parte delas é defensiva ou adaptiva: ou tentando aumentar o açúcar no sangue via gliconeogênese e glicogenólise, ou providenciando formas de energia alternativas.
Embora se cite que 70 mg/dL (3.9 mmol/L) seja o limite inferior da glicemia normal, podem definir-se diferentes valores como baixos em diferentes populações, propósitos e circunstâncias
O nível preciso de glicemia considerado baixo o bastante para se definir uma hipoglicemia depende de: (1) método de medição; (2) idade da pessoa; (3) presença ou ausência de sintomas.
O nível de glicose neste artigo é o de plasma venoso ou em soro, medido por métodos-padrão de glicose oxidase usados em laboratórios
Para finalidades clínicas, tanto o nível no plasma quanto o no soro são similares o bastante para serem intercambiados
O plasma arterial ou em soro são levemente superiores do que os níveis venosos, e os níveis capilares estão entre os arteriais e os venosos
A diferença entre os níveis arterial e venoso é pequena sob jejum, mas é amplificada e pode ser até 20% maior em estado pós-prandial
Por outro lado, os níveis de glicemia totais (por exemplo os medidos por glicosímetros digitais) são cerca de 10-15% menores do que os níveis em plasma venoso
Além disso, os glicosímetros disponíveis garantem apenas exatidões de 15% em relação a valores de laboratórios clínicos.
Dois outros fatores afetam significantemente a medição da glicose
A disparidade entre a concentração venosa e a concentração total é maior quando o hematócrito é alto, como no caso de recém-nascidos
Em segundo, a menos que a amostra tenha sido colocada em um tubo de fluoreto ou processada imediatamente para separar o soro ou plasma das células, a glicose mensurável será gradualmente metabolizada in vitro.
Dados estatísticos de crianças e adultos saudáveis mostram que glicemias em jejum abaixo de 60 mg/dL (3,3 mM) ou acima de 100 mg/dL (5,6 mM) são encontradas em menos de 5% da população
Em até 10% dos recém-nascidos e crianças jovens, foram encontrados níveis abaixo de 60 mg/dL depois de jejum noturno
Em outras palavras, muitas pessoas saudáveis podem eventualmente ter níveis glicêmicos na faixa de hipoglicemia sem apresentar sintomas ou distúrbios.
A faixa glicêmica normal de recém-nascidos ainda é motivo de debate
As estatísticas e a experiência revelam níveis de açúcar frequentemente abaixo de 40 mg/dL (2,2 mM) e, mais raramente, abaixo de 30 mg/dL (1,7 mM) em bebês saudáveis de gravidez a termo nos primeiros dias de vida
Foi proposto que os cérebros de recém-nascidos são mais facilmente capazes de usar combustíveis alternativos quando os níveis glicêmicos estão baixos, em relação a adultos
Os especialistas continuam o debate quanto à significância e ao risco desses níveis glicêmicos, embora a tendência seja recomendar a manutenção dos níveis de glicose acima de 60–70 mg/dL (3,3-3,9 mM) após os primeiros dias de vida
Em bebês prematuros, adoecidos ou abaixo do peso é mais comum encontrar baixos níveis de glicose, mas há um consenso de que os açúcares devam ser mantidos ao menos acima de 50 mg/dL (2,8 mM) nestas circunstâncias
Alguns especialistas defendem 70 mg/dL (3,9mM) como um objetivo terapêutico, especialmente em circunstâncias tais como hiperinsulinismo, onde combustíveis alternativos podem ser mais escassos.
Pesquisas mostram que a eficiência mental diminui levemente mas de modo sensível quando a glicemia cai abaixo de 65 mg/dL (3,6 mM), em adultos saudáveis
Os mecanismos de defesa hormonal (adrenalina e glucagon) são ativados assim que a glicemia passa por limiares (cerca de 55 mg/dL ou 3,0 mM para a maioria das pessoas), produzindo tremores e disforia
Por outro lado, não ocorre com frequência um prejuízo de capacidade mental até que a glicemia caia abaixo de 40 mg/dL (2,2 mM), e até 10% da população pode eventualmente ter níveis de glicose abaixo de 65 (3,6) pela manhã sem efeitos aparentes
Os efeitos da hipoglicemia, chamados de neuroglicopenia, é que determinam quando um certo nível glicêmico é realmente um problema ao indivíduo.
É preferível que a pessoa com hipoglicemia use tanto os sintomas quanto os dados numéricos de seu glicosímetro para determinar as medidas a serem tomadas
É fácil notar hipoglicemia quando o valor lido é 50 mg/dL (2,8 mM); porém, um paciente que está com a diabetes descompensada e frequentemente lê valores acima de 200 mg/dL (11,1 mM) pode sentir sintomas de hipoglicemia quando o nível de glicose no sangue chegar a valores "normais" de 90 mg/dL (5,0 mM)
Neste caso, a pessoa não apresenta uma hipoglicemia clássica, mas terá alívio de sintomas com o tratamento rotineiro para hipoglicemias
Além disso, quando a glicemia diminui a uma taxa rápida, também podem surgir sintomas de hipoglicemia.
Este critério é por si só complicado de se admitir pelo fato de os sintomas da hipoglicemia serem vagos e poderem ser produzidos por outros motivos; além do que, quando a pessoa passa por níveis baixos de glicemia com recorrência, ela pode perder a sensação de limiar, de forma que pode haver agravamento de seus sintomas (por neuroglicopenia) sem que ela note
Para completar a dificuldade, os glicosímetros são inexatos para baixos valores, o que descredita a sua utilidade nessas horas.
Procure sempre encontrar a causa de uma baixa glicémia
A glicémia diária normal não deverá ser inferior a 90 mg/dl (5 mmol/l)
Utilize os testes à glicémia para evitar a hipoglicémia
É particularmente importante testar a glicémia ao deitar
Nenhuma criança diabética deverá deitar-se antes das refeições sem que lhe seja feito o teste da glicémia
Não injete insulina antes duma refeição se o valor for inferior a 90 mg/dl (5 mmol/l)
Espere que a criança acabe a refeição e só depois injete insulina
O açúcar sanguíneo pode subir ao valor normal em minutos da seguinte forma: consumindo (por conta própria) ou recebendo (por outrem) 10-20 g de carboidrato
Pode ser em forma de alimento ou bebida caso a pessoa esteja consciente e seja capaz de engolir
Essa quantidade de carboidrato está contida nos seguintes alimentos:
O amido é rapidamente transformado em glicose, mas a adição de gordura ou proteína retarda a digestão
Os sintomas começam a melhorar em 5 minutos, embora demore 10-20 min até a recuperação completa
O abuso de alimentos não acelera a recuperação e se a pessoa for diabética isto simplesmente causará uma hiperglicemia mais tarde.
Se a pessoa está sofrendo de efeitos severos de hipoglicemia de maneira que não possa (devido a combatividade) ou não deva (devido a convulsões ou inconsciência) ser alimentada, pode-se dar a ela uma infusão intravenosa de glicose ou uma injeção de glucagon..
A prevenção depende da causa da hipoglicemia
O risco de novos episódios pode ser frequentemente reduzida pelo abaixamento da dose de insulina ou medicamento, ou pela atenção maior à glicemia durante eventos inesperados, diminuição do ritmo de exercícios físicos ou de ingestão de álcool.
Muitos tipos de disfunções congêneres do metabolismo requerem evitar ou encurtar os intervalos de jejum, ou evitar carboidratos extras
Para distúrbios mais severos, como a glicogenose tipo I, isto pode ser feito pelo consumo de amido de milho de hora em hora ou por infusão gástrica contínua.
Vários tratamentos são usados em caso de hipoglicemia hiperinsulinêmica, dependendo da forma exata e do grau de severidade
Algumas formas de hiperinsulinismo congênito respondem bem ao diazóxido ou octreótido
A remoção cirúrgica da parte hiper-reativa do pâncreas é eficaz com risco mínimo quando o hiperinsulinismo é focal, ou devido a um tumor benigno produtor de insulina
Quando o hiperinsulinismo congênito é difuso ou imune às medicações, a pancreatectomia subtotal pode ser o tratamento de último caso, mas neste caso é menos efetivo e passível de várias complicações.
A hipoglicemia devida a deficiências hormonais como hipopituitarismo ou insuficiência adrenal geralmente cessa quando se administra o hormônio apropriado.
A hipoglicemia devida à síndrome do empachamento (ou Síndrome de dumping no português brasileiro) e outras condições pós-cirúrgicas é mais bem tratada com alteração da dieta
A inclusão de gordura e proteína com carboidratos pode retardar a digestão e reduzir a secreção antecipada de insulina
Alguns desses casos respondem a tratamento com um inibidor de glicosidase, que retarda a digestão de amido.
A hipoglicemia reativa com baixa glicose no açúcar é frequentemente um incômodo previsível, que pode ser evitado pelo consumo de gordura e proteína com carboidratos, pela adição de lanches pela manhã e à tarde e pela redução do consumo de álcool.
A síndrome pós-prandial idiopática sem níveis baixos de glicose no momento dos sintomas pode ser mesmo um desafio de conduta
Muitas pessoas encontram melhorias com a mudança no padrão de alimentação (refeições menores, evitando açúcar em demasia, refeições mistas em detrimento de carboidratos), ou fazendo mudanças no estilo de vida para evitar o estresse, ou diminuindo o consumo de estimulantes como cafeína.
Diabetes gestacional é a a condição em que uma mulher sem diabetes apresenta níveis elevados de glicose no sangue durante a gravidez
A diabetes gestacional geralmente manifesta poucos sintomas
No entanto, aumenta o risco de pré-eclampsia, depressão e necessidade de uma cesariana
Os bebés de mães com diabetes gestacional tratada de forma ineficaz apresentam risco acrescido de macrossomia, de baixos níveis de glicose após o nascimento e de icterícia
Quando não é tratada, a doença pode resultar em nado-morto
A longo prazo, as crianças apresentam maior risco de sobrepeso e de desenvolver diabetes do tipo 2.
A diabetes gestacional é causada pela quantidade insuficiente de insulina no contexto de resistência à insulina
Os fatores de risco incluem ter sobrepeso, ter tido anteriormente diabetes gestacional, história na família de diabetes do tipo 2 e ter síndrome do ovário policístico
O diagnóstico é feito por análises ao sangue
Em pessoas de risco normal, o rastreio é recomendado entre a 24ª e a 28ª semanas de gestação
Em pessoas de elevado risco, o rastreio pode ter lugar na primeira consulta pré-natal.
A prevenção consiste em manter um peso saudável e na prática de exercício físico antes da gravidez
A diabetes gestacional pode ser tratada com uma dieta diabética, exercício adequado e possivelmente injeções de insulina
A maior parte das mulheres consegue controlar os níveis de glicose apenas com dieta e exercício
É muitas vezes recomendada a medição da glicose em mulheres afetadas seja realizada quatro vezes ao dia
Após o nascimento, recomenda-se que a amamentação seja iniciada assim que possível.
A diabetes gestacional afeta entre 3 e 9% de todas as gravidezes, dependendo da população estudada
A doença é particularmente comum durante o terceiro trimestre de gravidez
A prevalência varia com a idade
A doença afeta apenas 1% das grávidas com menos de 20 anos de idade, enquanto que afeta 13% das grávidas com mais de 44 anos de idade
Alguns grupos étnicos apresentam maior risco de diabetes gestacional, entre os quais asiáticos, nativos norte-americanos, aborígenes australianos e habitantes das ilhas do Pacífico
Em 90% dos casos, após o parto a doença resolve-se por si própria
No entanto, existem vários riscos associados à doença não tratada, incluindo o risco de desenvolver diabetes do tipo 2.
Gravidez é o período de cerca de nove meses de gestação nos seres humanos, contado a partir da fecundação e implantação de um óvulo no útero até ao nascimento
Durante a gravidez, o organismo materno passa por diversas alterações fisiológicas que sustentam o bebé em crescimento e preparam o parto
A fecundação pode dar-se através de relações sexuais ou ser medicamente assistida
Após a fecundação, o óvulo fecundado desloca-se ao longo de uma das trompas de Falópio e implanta-se na parede do útero, onde forma o embrião e a placenta que o alimentará
O desenvolvimento do embrião tem início com a divisão do óvulo em múltiplas células e é nesta fase que se começam a formar a maior parte dos órgãos, muitos deles funcionais
A partir das oito semanas de idade gestacional, o embrião passa a ser designado feto e apresenta já a forma humana que se desenvolverá continuamente até ao nascimento
O parto ocorre em média cerca de 38 semanas após a fecundação, o que corresponde a aproximadamente 40 semanas após o início do último período menstrual
Uma gravidez múltipla é a gravidez em que existe mais do que um embrião ou feto, como é o caso dos gémeos.
Os primeiros sinais que indicam uma possível gravidez são a ausência de menstruação, sensibilidade nas mamas, náuseas, vómitos e aumento da frequência urinária
Uma gravidez pode ser confirmada com um teste de gravidez disponível em farmácias
A gravidez é convencionalmente dividida em três trimestres, de forma a simplificar a referência às diferentes fases do desenvolvimento pré-natal
O primeiro trimestre tem início com a fecundação e termina às doze semanas de idade gestacional, durante o qual existe risco acrescido de aborto espontâneo (morte natural do embrião ou do feto)
Durante o segundo trimestre, o risco de aborto espontâneo diminui acentuadamente, a mãe começa a sentir o bebé, são visíveis os primeiros sinais exteriores da gravidez e o seu desenvolvimento é mais facilmente monitorizado
O terceiro trimestre é marcado pelo desenvolvimento completo do feto até ao nascimento.
Os cuidados de saúde e os exames pré-natais apresentam uma série de benefícios para a saúde da grávida e do bebé
Entre os cuidados de saúde essenciais estão a suplementação com ácido fólico, a restrição do consumo de tabaco, álcool e drogas, a prática de exercício físico adequado à gravidez, a comparência às consultas de acompanhamento e a realização dos exames médicos e ecografias recomendados
Entre as complicações mais comuns estão a hipertensão, diabetes gestacional, anemia por deficiência de ferro e náuseas e vómitos graves
O termo da gravidez ocorre entre as 37 e as 41 semanas
Os bebés que nascem antes das 37 semanas são considerados pré-termo e depois das 41 semanas pós-termo
Os bebés prematuros apresentam risco acrescido de problemas de saúde
A indução de parto e cesariana não são recomendadas antes das 39 semanas, exceto por motivos médicos.
Em 2012 ocorreram 213 milhões de gravidezes, das quais 190 milhões em países em vias de desenvolvimento e 23 milhões em países desenvolvidos
Isto corresponde a 133 gravidezes por cada 1000 mulheres entre os 15 e 44 anos de idade
Cerca de 10 a 15% das gravidezes diagnosticadas terminam em aborto
Em 2013, as complicações da gravidez causaram a morte a 230 000 pessoas, uma diminuição em relação às 377 000 em 1990
Entre as causas mais comuns estão as hemorragias maternas, complicações de um aborto, hipertensão arterial, infeções, e complicações do parto
Cerca de 40% das gravidezes em todo o mundo não são planeadas, das quais metade resultam em aborto.
"Gestação" ou "gravidez" designa a condição de uma mulher ("gestante") que já concebeu e que na qual evolui o produto da concepção
"Gestação a termo" é a gestação com duração entre 37 semanas completas e 42 semanas
"Gestação pré-termo" é a gestação com duração inferior a 37 semanas, enquanto que "gestação pós-termo" corresponde à gestação de período igual ou superior a 42 semanas
A gestante pode ser classificada segundo o número de gestações: "primigesta" é a mulher que se encontra grávida pela primeira vez, "secundigesta" é a mulher grávida pela segunda vez, "tercigesta" pela terceira vez, "quadrigesta" pela quarta vez e assim sucessivamente
A gestante pode ainda ser classificada segundo o número de partos: "nulípara" é a mulher que nunca deu à luz; "primípara" é a mulher que deu uma única vez à luz um feto, com 20 ou mais semanas, vivo ou morto; "multípara" é a mulher que deu à luz duas ou mais vezes.
A "idade gestacional" é a duração da gestação a partir do primeiro dia do último período menstrual normal, sendo medida em dias ou semanas completas
A "fecundação" é a fase da reprodução em que o espermatozoide se funde com o óvulo
Durante as primeiras oito semanas, o produto da fecundação é denominado "embrião"; a partir da oitava semana e até ao parto passa a ser denominado "feto".
O parto pode ser classificado segundo a idade gestacional a que ocorre
Aborto designa a perda da gravidez antes da 20ª semana de gestação, podendo ser espontâneo ou induzido
O "parto pré-termo" é o parto ocorrido entre as 20ª e 37ª semanas de gravidez; o "parto a termo" é o parto ocorrido entre as 37 semanas completas e as 42 semanas incompletas; e o "parto pós-termo" é o parto que ocorre após as 42 semanas completas
O parto pode também ser classificado conforme a sua evolução e resolução
O "parto espontâneo" ou "parto natural" é o parto que ocorre espontaneamente sem qualquer intervenção
O "parto induzido" é o parto provocado por medicamentos ou outras técnicas
O "parto dirigido" é o parto assistido por ação médica
O "parto eutócito", "normal", "espontâneo" ou "fisiológico" denomina a expulsão espontânea do feto por vias normais, enquanto que o "parto distócito" é o parto que decorre de forma anormal
Uma cesariana é uma intervenção cirúrgica destinada a retirar o feto por via abdominal através de uma incisão no útero, quando não é possível ou desaconselhado o "parto vaginal"
Numa "cesariana segmentária" a abertura no útero é feita no segmento inferior, enquanto que na "cesariana corporal" a incisão é feita até ao fundo uterino
"Puérpera" é a mulher que se encontra no "puerpério", o período de 6 a 8 semanas desde o fim do parto até ao momento em que os órgãos voltam ao estado normal anterior à gestação
O "período neonatal" é o período entre o nascimento do bebé e os primeiros 28 dias de vida.
Os primeiros sinais e sintomas de uma gravidez são a ausência do período menstrual, náuseas, vómitos e dor ou sensibilidade nas mamas
Os testes de gravidez biológicos têm uma precisão de 95% e detectam a presença na urina ou no sangue de gonadotrofina coriónica humana, uma hormona produzida pela placenta durante a gravidez
A partir das 16-20 semanas é possível ouvir com um estetoscópio o batimento cardíaco fetal e confirmar em definitivo a gravidez
Ao longo da gestação, as ecografias permitem observar o feto em crescimento e por volta das 18-20 semanas é possível começar a sentir os movimentos fetais.
A maior parte das mulheres grávidas apresenta uma série de sinais e sintomas que podem ser indicadores de uma gravidez
O sinal inicial de gravidez mais confiável e perceptível é ausência de um período menstrual, ou um período muito ligeiro com pouca quantidade de sangue
Entre os sintomas iniciais mais comuns estão o cansaço e fadiga em excesso; náuseas, com ou sem vómitos (durante todo o dia mas principalmente de manhã); sensibilidade ou dor nas mamas (principalmente em mulheres jovens) e aumento da frequência urinária (principalmente durante a noite)
No início da gravidez são também comuns outros sintomas, embora nem sempre se manifestem, como a obstipação, aumento do corrimento vaginal ou ligeira hemorragia 10 a 14 dias após a fecundação, alteração do palato (sabor metálico na boca, desejo por determinados alimentos que não consome regularmente e rejeição de outros), aumento da sensibilidade olfativa (capaz de provocar náuseas), cólicas uterinas ligeiras, tonturas e alterações de humor
No entanto, todos estes sintomas não são exclusivos da gravidez, ao mesmo tempo que é possível estar grávida sem que nenhum destes sintomas se manifeste.
Existem também uma série de sinais associados à gravidez e que se manifestam logo a partir das primeiras semanas após a conceção
No entanto, estes sinais não são universais; isto é, em muitos casos as grávidas não apresentam alguns dos sinais e os sinais que apresentam podem ser diferentes de grávida para grávida
Nos casos em que estes sinais se manifestem isoladamente não é possível determinar um diagnóstico definitivo, mas caso se manifestem vários sinais em conjunto é possível assumir um diagnóstico de gravidez
Estes sinais incluem a presença de gonadotrofina coriónica humana (hCG) no sangue e na urina, hemorragia devido à nidação do embrião no útero na terceira ou quarta semana após o último período menstrual, aumento da temperatura corporal basal de forma sustentada duas semanas após a ovulação, sinal de Chadwick (escurecimento do colo do útero, vagina e vulva), sinal de Goodell (amolecimento da parte vaginal do útero), sinal de Hegar (amolecimento do istmo do útero) e presença da linea nigra (escurecimento da pele ao longo de uma linha no abdómen, provocado pela hiperpigmentação resultante das alterações hormonais, que geralmente se manifesta a meio da gravidez).
Existem, no entanto, uma série de condições médicas cujos sinais e sintomas se podem confundir com os de uma gravidez
A ausência do período menstrual pode ser causada por doença crónica, por distúrbios emocionais ou alimentares ou pela menopausa
As náuseas e os vómitos podem ter apenas origem gastrointestinal, enquanto a sensibilidade nas mamas se pode dever a distúrbios hormonais
As condições que causam congestão pélvica, como o cancro do colo do útero, podem provocar sintomas semelhantes a uma gravidez, e alguns tumores raros produzem falsos positivos nos testes de gravidez
Em alguns casos, mulheres com o forte desejo de engravidar acreditam vincadamente que estão grávidas, apesar de não o estarem, manifestando inclusive algumas das alterações físicas da gravidez, uma condição denominada pseudociese
Por outro lado, e apesar de terem presentes vários sinais, algumas mulheres só se apercebem da gravidez quando esta já está numa fase avançada
Em alguns casos extremos, a mulher só se apercebe da gravidez durante o trabalho de parto
Isto pode ser causado por diversos factores, entre os quais períodos irregulares, alguns medicamentos e mulheres obesas que não dão importância ao aumento de peso
Cerca de 1 em 475 mulheres às vinte semanas e 1 em 2500 mulheres na data do parto recusam reconhecer que estão grávidas.
Os testes de gravidez permitem detectar com bastante precisão uma gravidez a partir do 12º dia posterior à nidação
A maior parte dos testes de gravidez acusa a presença na urina ou no sangue da subunidade beta da gonadotrofina coriónica humana (hCG), uma hormona produzida pela placenta recém-formada
A hCG pode ser detectada após a nidação, que ocorre seis a doze dias após a fecundação
A presença de gonadotrofina coriónica no sangue significa apenas que a mulher alberga tecido placentário vivo, não permitindo determinar a condição do feto
Os testes ao sangue quantitativos têm maior sensibilidade do que os à urina, devido ao menor número de falsos negativos, sendo capazes de detectar quantidades de hCG a partir de 1 mIU/mL, enquanto que as tiras reagentes de urina só detectam a partir de 10 mIU/mL a 100 mIU/mL.
Os testes disponíveis nas farmácias para utilização em casa são testes à urina
Nestes testes, aplica-se uma pequena quantidade de urina numa tira química que, em caso de resultado positivo, muda de cor ou aparece um símbolo, conforme o fabricante
Têm, em média, uma precisão de 95% para uma utilização correta; valor muito idêntico aos testes profissionais em laboratório (97,4%)
A maior parte dos falsos negativos e falsos positivos, que pode atingir os 20% numa utilização típica, tem origem na utilização incorreta do dispositivo, devido aos utilizadores não seguirem corretamente as instruções da embalagem ou fazerem o exame demasiado cedo
A possibilidade de falsos negativos e de falsos positivos, ainda que ínfima numa utilização correta, faz com que o resultado apenas indique uma elevada probabilidade de estar ou não grávida, e não uma garantia absoluta
Os falsos positivos podem dever-se a uma série de razões, entre as quais a utilização incorreta do teste, o uso de fármacos com hCG, como a clorpromazina, fenotiazina ou metadona, e a ocorrência de doenças doenças hepáticas, cancro ou condições médicas que produzem quantidades elevadas de hCG
As mulheres que foram submetidas a uma injeção de hCG no contexto de um tratamento de fertilidade também apresentam sempre resultados positivos, independentemente de estarem ou não grávidas
Um resultado positivo num teste de farmácia pode ser confirmado com um teste de laboratório ou com um exame pélvico realizado por um médico
Por serem qualitativos, os exames de laboratório têm uma precisão ligeiramente superior.
O tempo médio de uma gravidez é de 268 dias (38 semanas e dois dias) contados a partir da ovulação, com um desvio padrão de 10 dias ou coeficiente de variação de 3,7%
A idade gestacional é calculada a partir do primeiro dia do último ciclo menstrual normal da mulher
Escolhe-se este momento porque não existe forma de determinar com precisão a data em que ocorreu a fecundação
A fecundação geralmente ocorre cerca de duas semanas antes do próximo ciclo menstrual, pelo é comum acrescentar 14 dias à idade embrionária para obter a idade gestacional e vice-versa
Assim, na 1ª e 2ª semanas de idade gestacional, a mulher ainda não está grávida
No entanto, o método mais preciso para determinar a idade gestacional é através de ecografia durante o primeiro trimestre de gravidez, o qual tem um intervalo de precisão de sete dias
Ao contrário do cálculo da idade gestacional, em que o evento inicial é o primeiro dia do último período menstrual, no cálculo da "idade fetal", "idade embrionária" ou "idade de fecundação" o evento inicial é a fecundação.
Os obstetras estimam a data prevista de parto (DPP) acrescentando sete dias ao primeiro dia do último período menstrual e mais nove meses de calendário
Por exemplo, se o último período menstrual teve início em 10 de janeiro, a data prevista de parto será 17 de outubro
No entanto, apenas 5% dos nascimentos é que ocorrem na data prevista de parto e em que se completam as 40 semanas de idade gestacional
50% dos nascimentos ocorre entre uma semana antes ou uma semana depois da data prevista
80% ocorre entre duas semanas antes ou depois
Na estimativa da data prevista de parto, as aplicações móveis oferecem estimativas consistentes entre si e corrigem os anos bissextos, enquanto que os discos gestacionais de papel podem apresentar variações até sete dias e geralmente não contabilizam anos bissextos
Uma vez estimada a data do parto, raramente é alterada, já que que a estimativa é mais precisa no início da gravidez.
Ao longo da gravidez, a mulher passa por diversas alterações fisiológicas perfeitamente normais, incluindo alterações cardiovasculares, hematológicas, metabólicas, renais e respiratórias, que asseguram a viabilidade do feto e têm um papel fundamental no caso de complicações
A gravidez é geralmente dividida em três trimestres, cada um com a duração aproximada de três meses
Os obstetras definem cada trimestre com a duração de 14 semanas, num total de 42
Embora não haja limites precisos entre eles, esta distinção é útil para descrever as diferentes alterações fisiológicas e anatómicas que ocorrem em cada um deles.
Uma gravidez tem início com a fecundação de um óvulo (gâmeta feminino) por um espermatozoide (gâmeta masculino)
Ao longo do ciclo menstrual que antecede a gravidez o corpo da mulher sofre alterações no sentido de se preparar para uma possível fecundação
Com a ovulação, o óvulo maduro liberta-se do seu folículo e deposita-se numa das trompas de falópio
Através da ejaculação de sémen durante uma relação sexual são depositados na vagina milhões de espermatozoides, que percorrem todo o útero e trompas de falópio até cercarem o óvulo
Ao entrar na trompa, o óvulo perde a camada exterior de células devido à ação de substâncias nos espermatozoides e no revestimento da parede das trompas
Ao perder a camada exterior, o óvulo permite que alguns espermatozoides penetrem na sua superfície; no entanto, geralmente só um dos espermatozoides é que realiza a fecundação
Depois de penetrar no óvulo, a cabeça do espermatozoide separa-se da cauda
Embora a cauda desapareça gradualmente, a cabeça e o respetivo núcleo sobrevivem
À medida que vai avançando em direção ao núcleo do óvulo, nesta fase designado pronúcleo feminino, a cabeça do espermatozoide aumenta de tamanho e torna-se o pronúcleo masculino
Os pronúcleos unem-se no centro do óvulo, onde a cromatina de ambos se organiza em cromossomas.
O núcleo feminino tem inicialmente 44 cromossomas não sexuais (autossomas) e dois cromossomas sexuais (X, X), num total de 46
Antes da fecundação, uma forma particular de divisão celular denominada meiose reduz para metade (23) o total de cromossomas no pronúcelo feminino, entre os quais apenas um cromossoma sexual X
O gâmeta masculino tem também 44 autossomas e dois cromossomas sexuais (X, Y)
Após a meiose, este número é igualmente reduzido para metade, entre os quais apenas um cromossoma sexual que pode ser X ou Y
Com a união dos pronúcleos feminino e masculino, os cromossomas de ambos unem-se através de um processo denominado mitose
Após a mitose, o óvulo fecundado, agora denominado zigoto, divide-se em duas células-filhas de igual tamanho
O sexo das células-filhas é determinado pelo cromossoma sexual masculino que resultou da meiose, conforme seja X ou Y.
A formação de gémeos depende de eventos ocorridos na fecundação
Os gémeos verdadeiros ocorrem quando, após ser fecundado por um espermatozoide, um óvulo se divide em dois
Os gémeos verdadeiros partilham a mesma informação genética, são do mesmo sexo e têm personalidades semelhantes
Só 2/3 dos gémeos verdadeiros é que partilham a mesma placenta no útero, embora tenham sacos amnióticos diferentes
Os gémeos falsos ocorrem quando a mulher produz dois óvulos distintos que são fecundados por dois espermatozoides diferentes
Os gémeos falsos são tão parecidos entre si como qualquer irmão, podendo ser de sexos diferentes, uma vez que só metade da sua informação genética é igual
Cada gémeo falso tem a sua própria placenta e saco amniótico
A probabilidade de ter gémeos aumenta no caso da mulher estar a ser submetida a tratamentos de fertilidade ou houver antecedentes familiares, especialmente da parte da mãe.
Nos seres humanos, a embriogénese, ou período embrionário, tem início com a fecundação e prolonga-se até ao início do período fetal
Após a fecundação, o zigoto desloca-se lentamente ao longo da trompa de Falópio em direção ao útero
Ao longo desta viagem de mais de uma semana, o zigoto divide-se em células idênticas
Esta divisão celular tem início aproximadamente entre 24 a 36 horas após a fecundação
Ao fim do 4º dia de divisão celular, o zigoto dá origem a uma esfera sólida de 16 ou 32 células denominada mórula
Ao chegar ao útero, cinco dias após a fecundação, esta esfera apresenta-se oca e tem entre 50 e 100 células
Nesta fase passa a ser denominada blastócito, demorando cerca de seis dias até nidificar na parede uterina
O revestimento de proteínas do blastócito dissolve-se, o que permite às suas células trofoblásticas entrar em contacto e aderir às células endometriais da parede uterina
O embrião une-se com o endométrio através de um processo denominado nidação, que ocorre oito a dez dias após a ovulação
Após alguns dias, forma-se o celoma extra-embrionário que se tornará na cavidade coriónica, a qual irá conter o embrião, o líquido amniótico e o cordão umbilical
Desenvolve-se também a cavidade amniótica entre o citotrofoblasto e a massa de células interna
Desenvolve-se também a placa pré-cordal, que indica o futuro local da boca e da região cranial
Nesta fase, o embrião cresce rapidamente e começam a tomar forma as principais características externas
Este processo, denominado diferenciação celular, produz os diferentes tipos de células do organismo.
Durante a quarta semana de idade gestacional (segunda semana de idade embrionária), as células trofoblásticas que envolvem as células embrionárias penetram profundamente no revestimento uterino, formando a placenta e as membranas embrionárias
Começa-se também a formar a vesícula vitelina, as células embrionárias formam um disco embrionário com duas células de espessura, desenvolve-se a linha primitiva e aparecem as vilosidades coriónicas
Na quinta semana de idade gestacional (terceira semana de idade embrionária) tem início a gastrulação, forma-se a corda dorsal no centro do disco embrionário, começa-se a formar o que virá a ser a medula espinal, com uma saliência que corresponderá ao cérebro, e aparecem os primeiros neurómeros
Já no final da semana, começam também a formar-se os vasos do coração primitivo e a desenvolver-se vascularização no disco embrionário.
Embora entre a 5ª e 6ª semana de gestação seja possível detectar atividade elétrica no cérebro, isto é apenas considerado atividade neural primitiva, e não ainda o início do pensamento consciente, algo que só se desenvolverá muito mais tarde
As sinapses só se começam a formar por volta das 17 semanas e, no início da 28ª semana, começam-se a multiplicar a um ritmo acentuado que se prolonga até 3 a 4 meses após o nascimento.
À sexta semana de idade gestacional (quarta semana de idade embrionária), o embrião mede cerca de 4 mm de comprimento e começa-se a curvar em forma de C
O coração desenvolve-se e começa a bater a um ritmo regular, aparece o septo primário e formam-se as cavidades que irão dar origem às estruturas da face e do pescoço, sendo já visível o início da formação dos braços e de uma cauda
O tubo neural encerra, aparecem os primeiros traços do pulmão e do fígado, aparecem ainda as estruturas que formarão o pâncreas e o baço e rompe-se a membrana bucofaríngea que formará boca
Na medula espinal, começa-se a diferenciar o corno anterior e posterior
Durante a sétima semana de idade gestacional (quinta semana de idade embrionária) o embrião mede cerca de 9 mm de comprimento
Nesta semana, começam-se a desenvolver as estruturas que formarão os olhos e o nariz e os brotos das pernas e das mãos
O cérebro divide-se em cinco vesículas, incluindo o telencéfalo primitivo e inicia-se a diferenciação do estômago
Existe já uma circulação sanguínea primitiva entre os vasos que ligam a vesícula vitelina e as vilosidades coriónicas
Inicia-se ainda o desenvolvimento do metanefro, precursor dos rins.
Durante a oitava semana de idade gestacional (sexta semana de idade embrionária) o embrião mede aproximadamente 13 mm de comprimento
Começam-se a formar os pulmões, o sistema linfático e os órgãos genitais externos, sendo também visível a crista gonadal
Os braços e as pernas aumentam de comprimento, sendo agora visíveis as áreas dos pés e das mãos, as quais já têm dedos mas que ainda estão unidos
Durante a nona semana de idade gestacional (sétima semana de idade embrionária) o embrião mede cerca de 18 mm de comprimento, estando já em processo de formação todos os órgãos essenciais
É possível ouvir o som do batimento cardíaco através de doppler e pode ser possível observar movimentos espontâneos dos membros através de ecografia
Começam-se a formar os folículos pilosos e os mamilos, são visíveis os cotovelos e os dedos dos pés e o ducto vitelino é geralmente encerrado
Ao fim da nona semana, decorreram 49 dias desde a fecundação e 63 dias desde o primeiro dia do último período menstrual
Ao longo da décima semana de gestação (oitava semana de idade embrionária), as pálpebras estão mais desenvolvidas e começam-se a fechar e as orelhas e as características faciais tornam-se mais distintas.
Ao fim da décima semana de idade gestacional, o embrião passa a ser denominado feto
Termina assim o período embrionário e inicia-se o período fetal
No início da fase fetal, o risco de aborto diminui acentuadamente
O feto tem agora cerca de 30 mm de comprimento e através de ecografia é possível observar o batimento cardíaco e a realização de vários movimentos involuntários
Entre as 11 e 14 semanas de idade gestacional, as pálpebras do feto estão cerradas e só se voltarão a abrir por volta da 28ª semana
A face está bastante desenvolvida, os membros apresentam-se longos e esguios e o fígado já produz glóbulos vermelhos
Neste intervalo aparecem as unhas nos pés e nas mãos, os órgãos genitais e os brotos para os futuros dentes
A cabeça é proporcionalmente muito grande, cerca de metade do tamanho do feto
Entre as 15 e 18 semanas de gestação o bebé começa-se a mexer e a esticar
A pele é praticamente transparente e surge um tipo de cabelo muito fino denominado lanugo
Desenvolvem-se os tecidos musculares, os ossos tornam-se mais fortes e o fígado e o pâncreas já produzem secreções.
Entre as 19 e as 21 semanas de gestação o bebé já consegue ouvir e é muito mais ativo em relação às semanas anteriores, sendo capaz de engolir
A mãe começa a ter uma sensação semelhante ao bater de asas de borboleta no baixo ventre, que corresponde aos primeiros movimentos do bebé
À 22ª semana, o bebé está mais ativo e algumas mães já conseguem sentir claramente o bebé a mover-se
O lanugo cobre a totalidade do corpo, aparecem as sobrancelhas e as pestanas, as unhas crescem até às extremidades dos dedos, o aparelho digestivo começa a produzir mecónio e é possível ouvir o batimento cardíaco apenas com um estetoscópio
Entre as 23 e 25 semanas, a medula óssea começa a produzir células sanguíneas, desenvolvem-se as vias respiratórias e o feto começa a armazenar gordura
À 26ª semana, as sobrancelhas e pestanas já se encontram formadas, os olhos estão plenamente desenvolvidos e as impressões digitais estão em formação
O feto sobressalta-se em resposta a ruídos altos e formam-se nos pulmões alvéolos, embora o feto não seja ainda capaz de respirar no exterior.
Entre as 27 e as 30 semanas de gestação o cérebro do feto cresce aceleradamente e o sistema nervoso encontra-se suficientemente desenvolvido para controlar algumas funções corporais
As pálpebras são capazes de abrir e fechar e o aparelho respiratório, embora imaturo, produz tensioativos que permitem encher os pulmões com ar
Entre as 31 e 34 semanas o feto cresce muito rapidamente e armazena uma quantidade assinalável de gordura, ferro, cálcio e fósforo
Os ossos encontram-se desenvolvidos, embora sejam ainda moles
O feto começa a respirar de forma ritmada, embora os pulmões não estejam completamente desenvolvidos
Entre as 35 e 37 semanas o feto pesa já cerca de 2,5 kg e continuará a ganhar mais peso, embora provavelmente o comprimento já não deva aumentar significativamente
Devido à gordura acumulada, a pele já não é tão rugosa
O feto tem padrões de sono definidos, o coração e os vasos sanguíneos estão completos e os músculos e ossos totalmente desenvolvidos
Entre as 38 e 40 semanas de gestação, o lanugo desaparece, exceto nos ombros, o cabelo é mais denso e espesso, as unhas crescem para além das extremidades dos dedos e estão presentes mamilos em ambos os sexos
À 40ª semana de idade gestacional decorreram 38 semanas desde a fecundação e o trabalho de parto pode começar a qualquer momento.
Durante a gravidez, o organismo materno passa por diversas adaptações e alterações fisiológicas fundamentais para sustentar o feto em crescimento e preparar o parto
Embora as alterações mais evidentes sejam as decorrentes do aumento do volume uterino, ocorre também um grande número de alterações hormonais, metabólicas, bioquímicas e anatómicas.
O corpo lúteo, que normalmente se desintegra no fim do ciclo menstrual e dá origem à menstruação, é, em caso de gravidez, preservado por hormonas segregadas pela recém-formada placenta
Isto acontece porque o corpo lúteo produz duas hormonas essenciais à gravidez, a progesterona e o estrogéneo, e só após algumas semanas é que a placenta é capaz de produzir estas hormonas de forma autónoma e sem colocar em risco a gravidez
Durante os primeiros meses, o ovário onde se situa o corpo lúteo em funcionamento é consideravelmente maior, normalmente regredindo no fim da gravidez
O papel das trompas de Falópio na gravidez restringe-se à alimentação do zigoto enquanto se desloca entre o ovário e o útero
Ao longo da gravidez, a cor geralmente rosada da vagina altera-se para um tom azulado devido à dilatação dos vasos sanguíneos e, mais tarde, para vermelho devido à maior afluência de sangue
O número e o tamanho das células da mucosa vaginal aumentam, produzindo maior quantidade secreções
A superfície torna-se mais macia, flexível e relaxada com o objetivo de preparar a passagem do feto durante o parto.
O útero é um órgão de forma semelhante a uma pêra, que compreende uma extremidade inferior, denominada colo do útero (ou cérvix), adjacente a uma parte bolbosa maior, denominada corpo do útero
Numa mulher não grávida com cerca de vinte anos, o útero mede aproximadamente sete centímetros de comprimento e pesa cerca de 30 gramas
No termo de uma gravidez, o útero mede cerca de 30 cm de comprimento, pesa cerca de 1200 g e tem uma capacidade líquida entre 4 e 5 litros
Este aumento significativo de tamanho durante a gravidez deve-se ao aumento da quantidade de fibras musculares, vasos sanguíneos, nervos e vasos linfáticos na parede uterina
A própria fibra muscular aumenta entre cinco a dez vezes de tamanho e o diâmetro dos vasos sanguíneos e capilares aumenta consideravelmente
Durante as primeiras semanas de gestação, a forma do útero mantém-se inalterada
Por volta da 14ª semana, o corpo do útero apresenta a forma de uma esfera achatada, enquanto o colo se apresenta muito mais macio e adquire um rolhão mucoso que o protege
À medida que o feto em crescimento vai exigindo mais espaço, o corpo do útero alonga-se e a parede torna-se mais fina
A determinado ponto, sobe para além da pélvis e preenche a cavidade abdominal, exercendo pressão no diafragma e nos outros órgãos
Com a aproximação da data de termo, a cabeça do feto começa a descer em direção à pélvis, fazendo com que todo o útero acompanhe o movimento, dando origem ao que popularmente se denomina "descida da barriga"
No entanto, este processo pode só ocorrer durante o parto ou não ocorrer caso o feto esteja numa posição fora do esperado
No termo da gravidez, o colo do útero vai-se tornando gradualmente mais fino e macio e, durante o parto, dilata para a passagem do bebé.
A placenta é uma estrutura em forma de disco que envolve e protege o feto e o líquido amniótico
No termo da gravidez, pesa entre 500 e 1000 gramas, mede 16 a 20 cm de diâmetro e 3 a 4 cm de espessura
Este órgão encontra-se unido às vilosidades coriónicas que revestem todo o útero, tem aparência lisa e brilhante e é constituída por diversos vasos sanguíneos que se unem no ponto onde começa o cordão umbilical
O sangue materno flui entre os vasos uterinos e o espaço interviloso, onde se acumula
Em cada vilosidade existe uma rede de vasos sanguíneos que fazem parte do sistema circulatório fetal e cuja circulação é impulsionada pelo coração do feto
Esta divisão entre a circulação materna e fetal denomina-se barreira placentária
À medida que a gravidez avança, a barreira torna-se mais fina
Esta barreira impede a passagem de células sanguíneas e de bactérias, embora permita a passagem de nutrientes, sal, vírus, hormonas e diversas substâncias, entre as quais drogas nocivas ao feto.
Na região pélvica, os vasos sanguíneos e linfáticos aumentam de tamanho e desenvolvem novas ramificações de modo a suportar o aumento de fluxo de sangue ao útero e restante órgãos
À medida que a gravidez avança, os músculos, ligamentos e outros tecidos da região tornam-se gradualmente mais pronunciados, elásticos e fortes de modo a permitir que o útero cresça para além da pélvis e que o bebé possa atravessar o canal de parto com maior facilidade
Os ossos pélvicos sofrem poucas alterações durante a gravidez
No entanto, a hormona relaxina relaxa a união entre os ossos frontais da bacia e entre a bacia e o sacro.
Durante o início da gravidez, uma das alterações mais percetíveis nas mamas é o agravamento da sensação de desconforto e saturação características do período pré-menstrual, que é de tal forma específica que pode ser um sinal da gravidez
À medida que a gravidez avança, os seios aumentam de tamanho, a pigmentação da aréola torna-se cada vez mais escura, e as artérias por baixo da pele e as glândulas de Montgomery tornam-se mais proeminentes
Estas alterações são causadas pelo aumento da quantidade de estrogéneo e progesterona no sangue, as quais também preparam o tecido mamário para a ação da hormona prolactina, responsável pela produção de leite após o parto
No final da gestação os ductos lactíferos começam a segregar colostro, um líquido leitoso que servirá para alimentar o bebé nos primeiros dias de vida
A produção de prolactina e a lactação continuam enquanto a mãe continuar a amamentar.
Um dos sinais mais visíveis da gravidez é o aparecimento de estrias nas mamas e nos abdómen, devido ao rompimento das fibras elásticas da pele e à deposição de gordura subcutânea
Após o parto, estas marcas podem-se tornar permanentes, embora não se manifestem em muitas mulheres
Outro sinal universal é o aumento da pigmentação da pele, sobretudo das aréolas e da vulva
Também comuns são a descoloração das palmas das mãos e o aparecimento de vasos sanguíneos avermelhados na pele dos braços e da cara
Durante a gravidez, aumenta também a produção de sebo e suor pela pele, o que pode acentuar o odor
Em alguns casos, o cabelo e as unhas tornam-se mais finos
No entanto, a maior parte destas alterações desaparece após o parto.
Durante a gravidez, a necessidade cada vez maior de sangue, oxigénio e nutrientes por parte do feto e dos tecidos coloca um esforço acrescido no coração da mãe
Entre as 9 e as 14 semanas de gestação, o débito cardíaco começa a aumentar significativamente, só voltando a diminuir perto da data do parto
Entre as 28 e 30 semanas, o esforço do coração é 25 a 30% superior ao período anterior à gravidez, embora o órgão não aumente de volume
No entanto, empurrado pelo diafragma e pelo útero em crescimento, o coração da grávida fica mais perto da parede torácica, o que pode distorcer os sons ouvidos ao estetoscópio
Uma gravidez normal não provoca o aumento da pressão arterial, verificando-se, pelo contrário, uma ligeira diminuição
Aliás, o aumento da pressão arterial é um sinal de alarme, geralmente indicando a possibilidade de pré-eclampsia
Por outro lado, a pulsação arterial é ligeiramente superior durante a gravidez, causada pelo aumento do débito cardíaco, necessário para deslocar o maior volume de sangue
O aumento da circulação de sangue na pele (circulação periférica) causa, em algumas mulheres, o aumento da temperatura da pele, tendência para suar e vermelhidão das palmas das mãos.
A alteração mais perceptível no sistema circulatório é o abrandamento da circulação sanguínea nos membros inferiores, o que leva ao aumento da pressão nas veias e estagnação do sangue nas pernas
Estas alterações são provocadas pela compressão da veia cava inferior pelo útero e pelo aumento da produção de hormonas
Embora sejam cada vez mais proeminentes ao longo da gravidez, podendo causar varizes e inchaço das pernas, estas alterações geralmente desaparecem após o parto
A pressão do útero em crescimento nos vasos linfáticos da pélvis provoca a diminuição da drenagem linfática das pernas, o que causa inchaço e dilatação das pernas e pés
O inchaço generalizado noutras partes do corpo é geralmente um sinal de alarme
O volume plasmático aumenta progressivamente a partir da sexta semana e o volume de hemácias aumenta depois da oitava semana
Ambos os volumes tornam-se estáveis nas últimas semanas, mas, como o aumento do volume plasmático é mais precoce e tende a ser mais acentuado do que o aumento do volume de hemácias, ocorre um efeito de diluição responsável pela chamada anemia fisiológica da gravidez
A alteração dos fatores de coagulação prepara o organismo da mulher para o momento do parto, permitindo controlar rapidamente eventuais hemorragias, embora durante a gestação e puerpério aumente o risco de trombose.
No termo da gravidez, a quantidade de sangue de uma mulher grávida é aproximadamente 25% superior em relação ao estado de não gravidez, de modo a preencher os vasos do útero, a transportar uma maior quantidade de oxigénio e nutrientes para o feto e servir de reserva em caso de hemorragias
Este aumento é consequência do aumento do número de glóbulos vermelhos (20%) produzidos na medula óssea e pelo aumento do volume do plasma (30%), causado pela retenção de líquidos
Esta diferença de valores faz diminuir a viscosidade do sangue e causa uma anemia aparente.
Durante a gravidez, o diâmetro da caixa torácica aumenta, fazendo com que também aumente o volume ocupado pelos pulmões
No primeiro trimestre, a quantidade de ar que é inspirada e expirada por minuto aumenta 40%
Isto deve-se à atuação da progesterona nos centros respiratórios do bulbo raquidiano, o que contribui para o aumento das trocas gasosas na placenta
Imediatamente antes do parto, o número de ciclos respiratórios por minuto é aproximadamente o dobro em relação ao período posterior ao parto.
A intolerância a alimentos gordos, indigestão, desconforto e azia na parte superior do abdómen que se manifestam na maior parte das grávidas são causados por distúrbios na função gástrica
Durante a gravidez, o estômago produz quantidades cada vez menores de ácido clorídrico e pepsina, os quais são necessários para uma digestão adequada e para a regulação da acidez no estômago
Devido ao efeito relaxante da progesterona sobre as fibras musculares lisas presentes em todo o sistema gastrointestinal, os músculos da parede do estômago perdem tensão, o que diminui a sua capacidade de contração e faz com que demore mais tempo a esvaziar o seu conteúdo
A diminuição da tensão muscular também no intestino provoca a diminuição dos movimentos peristálticos
Isto faz com que aumente quantidade de tempo que a comida demora a percorrer o trato intestinal, o que causa obstipação e, consequentemente, hemorroidas, embora o aparecimento destas também se deva à pressão do útero no soalho pélvico
A alteração do paladar e do olfato é relativamente comum durante os primeiros meses de gestação, podendo a grávida passar a achar desagradáveis odores ou alimentos que anteriormente considerava agradáveis e vice-versa
Muitas grávidas queixam-se de inflamações nas gengivas e na boca; no entanto, as causas são geralmente anemia, insuficiência de vitaminas e higiene oral inadequada, e não a própria gravidez.
As várias alterações na bexiga e na uretra são causadas pelo relaxamento dos músculos, por alterações na posição do órgão e pela pressão exercida pelo útero
Durante os primeiros meses, a pressão do útero provoca vontade de urinar frequente que diminui a partir do meio da gravidez, embora possa voltar a ocorrer perto do termo, quando o feto desce
Como consequência das alterações anatómicas, a parede da bexiga torna-se mais espessa com a dilatação dos vasos sanguíneos, retendo líquido, o que provoca inchaço ligeiro e inflamação mecânica da parede
No fim da gravidez, isto pode levar ao aparecimento de inflamações urinárias que se manifestam através de dor ao urinar e que, se não forem tratadas, podem dar origem a problemas urinários mais graves
Como consequência do relaxamento dos músculos que controlam a micção, é comum que a grávida perca alguma urina de forma involuntária ao tossir, espirrar ou rir
À medida que a gravidez avança, os uréteres e a pelve renal dilatam, perdendo capacidade de contração, o que faz com que a urina se acumule e escoe mais lentamente.
A função dos rins é filtrar égua, sódio, potássio, cloretos, proteínas e outras substâncias do sangue, mantendo o equilíbrio eletrolítico e químico do corpo, e recolher excedentes do sangue, expelindo-os através de urina
Durante a gravidez, o esforço que é solicitado aos rins aumenta consideravelmente devido à maior quantidade de água e sangue em circulação
Durante o início da gravidez, a secreção de grande quantidade de urina com pouca acidez, a par da pressão do útero na bexiga, provoca vontade de urinar constante
À medida que a gravidez avança, a acumulação de nitrogénio faz diminuir a excreção de ureia
A presença de proteínas na urina durante a gravidez é, geralmente, um sinal de alarme para a pré-eclampsia ou doenças renais
Durante a gravidez, a capacidade do rim de absorver glicose é menor e a sua presença na urina pode ser indicador de diabetes.
Durante a gravidez, a maior parte das glândulas endócrinas aumentam de tamanho e algumas sofrem modificações funcionais
No início da gravidez, o lobo anterior da hipófise aumenta de tamanho, segregando as hormonas que vão estimular as restantes glândulas endócrinas e, no fim da gravidez, a hormona prolactina que vai estimular a produção de leite
Embora a tiroide aumente de tamanho, não há alterações significativas na sua função
Ao longo da gravidez, aumenta também a produção da hormona aldosterona, responsável pela retenção de sal e água pelo corpo
As ilhotas de Langerhans no pâncreas, responsáveis pela produção de insulina, aumentam de tamanho, de modo a dar resposta à maior necessidade do corpo de produtos resultantes do metabolismo dos hidratos de carbono
A progesterona, em conjunto com a prolactina, induz a maturação das mamas durante a gravidez, o que vai permitir a produção de leite e amamentação após o parto, ao mesmo tempo que inibe a produção até ao momento do parto.
O fígado é responsável por muitos dos processos metabólicos vitais, incluindo a eliminação das substâncias nocivas produzidas pelos processos metabólicos do feto
Durante a gravidez, aumenta de tamanho e peso e os seus vasos sanguíneos dilatam, ajustando-se à maior quantidade de hormonas e glóbulos vermelhos em circulação no sangue
A taxa metabólica basal começa a aumentar a partir do terceiro mês, de modo a responder às necessidades conjuntas da mãe e do feto
O corpo da grávida necessita de maior quantidade de nitrogénio, obtido a partir do metabolismo das proteínas ingeridas e fundamental para o crescimento do feto e dos tecidos
Ao longo da gravidez, a quantidade de lípidos no sangue aumenta de 600–700 mg/dL para 900–1000 mg/dL
Embora os rins processem maior quantidade de sangue, são incapazes de reabsorver a maior quantidade de glicose, pelo que a grávida tolera uma menor quantidade de açúcar no sangue.
A quantidade de água no corpo também aumenta, sendo acrescentados mais 3500-4000 mL de líquido ao já existente nos tecidos
Este acréscimo é retido principalmente pelo útero, pelo líquido amniótico, pelo feto e também pelos músculos, tecidos moles da pélvis e mamas
Entre um a dois meses antes da data de termo, acumula-se nas extremidades inferiores da grávida uma quantidade significativa de líquido, o que causa inchaço das pernas
Esta retenção de líquidos é acompanhada pela retenção de eletrólitos, sobretudo sódio
Quando a retenção de água e sódio é excessiva, verifica-se inchaço generalizado do corpo.
O parto é o processo pelo qual nasce o bebé
Considera-se que a mulher está em trabalho de parto quando começa a sentir contrações uterinas em intervalos regulares e progressivas que gradualmente fazem descer o feto pelo colo do útero e pela vagina (canal de parto) até à sua expulsão para o exterior
Estas contrações são acompanhadas por alterações no colo do útero, o qual dilata e se torna cada vez mais fino até desaparecer
Embora a maior parte dos nascimentos ocorra por parto vaginal, podem surgir determinadas complicações que obriguem à realização de uma cesariana.
 A maioria dos partos tem início num intervalo de duas semanas antes ou depois da data prevista de parto
Na situação mais desejável, o trabalho de parto ocorre de forma espontânea e quando a mulher se encontra na data de termo
A gravidez é considerada a termo quando a gestação durou entre 37 e 42 semanas
Os eventos ocorridos antes das 37 semanas completas são considerados pré-termo e os eventos ocorridos após as 42 semanas são considerados pós-termo
Os bebés nascidos entre as 39 e as 41 semanas de gestação são os que apresentam o melhor prognóstico de saúde possível, em comparação com aqueles que nascem antes ou depois deste intervalo
A não ser que exista uma recomendação médica em contrário, o parto planeado não deve acontecer antes das 39 semanas completas, a apenas com indicação médica e no caso do colo do útero ser favorável.
O parto pré-termo, ou prematuro, está associado a uma série de riscos e problemas, pelo que é evitado sempre que possível até a gravidez se encontrar a termo
No entanto, existem situações em que o parto prematuro é inevitável, como no caso de contrações uterinas ou rotura prematura das membranas antes das 39 semanas
Quando uma gravidez excede as 42 semanas, o risco de complicações para a mulher e para o feto aumenta significativamente
Neste casos, e quando não existam outras complicações, os obstetras geralmente optam por induzir o parto entre as 41 e 42 semanas.
Os primeiros sinais que indicam o início de trabalho de parto são a expulsão do rolhão mucoso, a rotura da bolsa de águas e contrações uterinas em intervalos regulares
A expulsão do rolhão mucoso consiste na expulsão pela vagina de um muco gelatinoso, o qual pode ser rosado ou acastanhado
Esta expulsão pode ocorrer horas ou até mesmo dias antes do parto, significando que o nascimento poderá ocorrer em breve
A rotura da bolsa de águas é a saída do líquido amniótico pela vagina, causada pela rotura das membranas que envolvem o bebé
O líquido amniótico é normalmente claro e transparente e a sua saída pode ocorrer de forma lenta e gradual ou bruscamente e em grande quantidade
No início do trabalho de parto as contrações são irregulares e pouco frequentes e, gradualmente, vão-se tornando mais regulares, intensas e próximas
As contrações do trabalho de parto, regulares e dolorosas, não devem ser confundidas com as contrações de Braxton Hicks, que são contrações irregulares e indolores comuns nas últimas semanas de estação.
Na grande maioria das gravidezes (80-90%), o trabalho de parto começa nas 24 horas a seguir à rotura da bolsa de águas
Geralmente recomenda-se a deslocação para a instituição de saúde onde irá ocorrer o parto quando rompem as águas ou quando as contrações são regulares, dolorosas e com intervalos de dez minutos entre cada uma delas
Na primeira gravidez, o trabalho de parto geralmente não demora mais do que 12-14 horas
Em gravidezes posteriores é mais curto, demorando em média 6-8 horas
Pensa-se que o parto seja provocado pela ação da ocitocina, uma hormona que causa a contração do útero
O trabalho de parto vaginal divide-se em 3 etapas: dilatação, expulsão e dequitadura
Geralmente, as 4 horas posteriores à expulsão da placenta são também denominadas quarta etapa do trabalho de parto.
O período de dilatação é o intervalo de tempo desde o início do trabalho de parto até à dilatação completa do colo do útero (cerca de 10 cm)
Esta etapa é a mais longa do trabalho de parto, podendo ultrapassar as 12 horas no primeiro filho
A etapa de dilatação pode ser dividida em duas fases: a fase latente e a fase ativa
Na fase latente, que dura em média 8,5 horas na primeira gravidez, as contrações do útero tornam-se gradualmente mais intensas e ritmadas, o colo do útero contrai-se e dilata até cerca de 4 cm e a sensação de desconforto ainda é mínima
Na fase ativa, o colo do útero dilata entre 4 e 10 cm e a parte com que o bebé se apresenta (geralmente a cabeça) começa a descer pelo canal de parto, pelo que a mãe começa a sentir a necessidade de fazer força
A fase ativa dura em média 5 horas na primeira gravidez e 2 nas gravidezes seguintes.
Se, ao fim de 24 horas após a rotura das membranas, o trabalho de parto ainda não tiver começado, geralmente é necessária a indução do parto para reduzir o risco de infeção causado pela entrada das bactérias da vagina no útero
O parto é geralmente induzido com a administração de ocitocina
Ao dar entrada no hospital, geralmente com contrações fortes de 5 em 5 minutos e uma dilatação superior a 4 cm, são feitos vários exames e análises de sangue e urina, controla-se o ritmo cardíaco da mãe e do feto e é avaliada a apresentação do feto
Se, durante a rotura das membranas, o líquido amniótico se apresentar com uma coloração esverdeada, significa que o feto defecou mecónio para o líquido e pode ser um indicador de sofrimento fetal.
A fase expulsiva é o intervalo de tempo desde a dilatação completa do colo uterino até à expulsão completa do bebé pela vagina
Esta etapa pode durar até 60 minutos na primeira gravidez e cerca de 15-30 minutos nas gravidezes seguintes
A posição e apresentação do feto determinam como vai passar pela vagina
Nas semanas anteriores ao parto, normalmente o bebé dá a volta para que a cabeça se apresente de frente para a vagina (apresentação cefálica)
Esta é a apresentação mais segura e frequente
A apresentação de nádegas (podálica) e de ombros (transversal) fazem com que o parto seja mais complicado, ao tornarem mais difícil a passagem do feto no canal vaginal
É durante esta etapa que é pedido à mãe que faça força em cada contração, de modo a deslocar o feto pela vagina, descontraindo entre as contrações
Em algumas situações é necessário realizar um pequeno corte cirúrgico do períneo (episiotomia) para evitar rompimentos dos tecidos.
A dequitadura é o intervalo de tempo entre a expulsão do bebé e a expulsão da placenta e normalmente dura poucos minutos
A expulsão da placenta tem início com o desprendimento fisiológico da placenta da parede do útero
Mais de metade das mortes maternas acontece nas 24 horas posteriores ao parto e são causadas principalmente por hemorragias pós-parto
A Organização Mundial de Saúde recomenda que seja feita a gestão ativa da terceira etapa do parto, de modo a diminuir o risco de hemorragias pós-parto
A gestão ativa consiste na administração de uterotónicos durante ou após a expulsão do feto, na remoção controlada do cordão umbilical e da placenta e em massagem uterina.
O puerpério, ou período pós-natal, tem início imediatamente a seguir ao nascimento e prolonga-se por seis semanas
Durante este intervalo, o corpo da mãe regressa ao estado anterior à gravidez, incluindo a alteração na quantidade de hormonas e no tamanho do útero
No período imediatamente a seguir ao nascimento, a libertação de hormonas faz com que a mãe e o bebé criem uma ligação única
A mãe liberta ocitocina, a qual também é libertada durante a amamentação
O contacto entre a pele da mãe e do recém-nascido imediatamente a seguir ao parto apresenta benefícios para ambos: diminui o choro, melhora a interação mãe-filho e ajuda a mãe a conseguir amamentar
A Organização Mundial de Saúde recomenda que se promova o contacto entre a pele da mãe e do recém-nascido nas duas horas imediatamente a seguir ao parto, uma vez que é neste intervalo de tempo que estão mais alertas, em comparação com as horas seguintes.
Uma cesariana é um procedimento cirúrgico em que é feita uma ou mais incisões no abdómen e útero da grávida para fazer nascer o bebé
Este procedimento é geralmente realizado quando um parto vaginal coloca em risco a saúde da mãe ou do bebé
Antes da incisão são administrados antibióticos
É feita uma incisão no útero, a qual é alargada ao longo do eixo céfalo-caudal, sendo depois extraído o bebé e, por fim, a placenta
É usada anestesia local em 95% das cesarianas, sendo as mais comuns a anestesia espinhal e a combinação de anestesia espinhal com anestesia epidural
Em ambas a grávida permanece acordada.
Entre as razões médicas mais comuns que justificam a realização de uma cesariana estão a placenta prévia, infeção por VIH, pélvis contraída, apresentação do feto difícil ou uma cesariana anterior
Entre os potenciais benefícios são citados a maior segurança para o bebé, menor trauma no soalho pélvico para a mulher, conveniência e ausência das dores do trabalho de parto
No entanto, as cesarianas também estão associadas ao aumento do risco de morbilidade ou mortalidade para a mãe, sequelas psicológicas adversas, infeções pós parto e problemas nas gravidezes futuras, incluindo rotura do útero e um risco acrescido de morbilidade neonatal
Pensa-se também que as diferenças fisiológicas da cesariana para o parto vaginal possam ter implicações no bebé, uma vez que a cesariana pode aumentar o risco de problemas de saúde a curto e a longo prazo.
No entanto, e apesar dos riscos, algumas cesarianas são realizadas a pedido da mãe e sem uma razão médica que a justifique
A Organização Mundial de Saúde e as recomendações internacionais alertam para que não sejam realizadas cesarianas antes das 39 semanas e que não sejam realizadas cesarianas sem que exista uma justificação médica
Em muitos países, recorre-se a cesarianas com maior frequência daquilo que é necessário (idealmente entre 10 e 15%), pelo que muitos governos e instituições promovem programas para diminuir a prevalência de cesarianas em relação ao parto vaginal.
Ao longo da gravidez, são realizados de forma periódica vários exames e consultas
Os exames de rastreio destinam-se a avaliar o grau de risco da gravidez e incluem análises ao sangue, análises à urina e ecografias Alguns são exames de rotina realizados em todas as grávidas, enquanto que outros são realizados apenas em determinado grupo de risco
Quando um exame de rastreio indica risco acrescido para determinada doença, geralmente é seguido por um exame de diagnóstico que confirma a presença dessa doença.
A primeira consulta médica durante a gravidez é geralmente realizada entre as seis e oito semanas de gestação, ou entre duas e quatro semanas de atraso do período menstrual
Nesta primeira consulta exaustiva são calculadas a idade gestacional e a data prevista de parto e realizados diversos exames e análises para determinar o estado de saúde da grávida e potenciais riscos à gravidez
Determina-se o peso, altura e a pressão arterial e são examinados o pescoço, tiroide, mamas, abdómen, membros, coração, pulmões e os olhos
São também pedidas análises sanguíneas para a contagem de células, determinação do grupo sanguíneo, antiRH e deteção de doenças sexualmente transmissíveis como a sífilis, hepatite, gonorreia, VIH, rubéola e clamídia
É também realizado um exame ginecológico que determina o tamanho e posição do útero e eventuais anomalias
Pode ser realizado um teste de Papanicolau para a presença de cancro do colo do útero e exames genéticos em mulheres em grupos de risco para o desenvolvimento de fetos com malformações genéticas
Em mulheres negras e de origem mediterrânica podem ser feitos testes à drepanocitose.
As consultas de acompanhamento são geralmente agendadas de quatro em quatro semanas até às 32 semanas de gestação, sendo a partir daí de 2 em 2 semanas até às 36 semanas, e uma vez por semana até ao parto
Nestas consultas são anotados o peso, tensão arterial e tamanho e forma do útero
Em cada consulta é recolhida e analisada uma amostra de urina para detectar a presença de açúcar, que pode ser um sinal de diabetes, e de proteínas, que podem ser um sinal de pré-eclampsia.
Na primeira consulta são geralmente realizadas análises ao sangue de rotina a todas as grávidas
Se a grávida fizer parte de um grupo de risco, podem ser adicionalmente realizadas análises a biomarcadores específicos
Nas situações em que a grávida apresenta um risco acrescido de síndroma de Down, por volta das dez semanas são realizadas análises para determinar o nível das hormonas fetais, da proteína plasmática associada à gravidez (PAPP-A) e da gonadotrofina coriónica humana (HCG)
Por volta das dezasseis semanas, algumas instituições de saúde realizam análises adicionais
Dependendo da instituição e do risco da gravidez, podem ser requisitadas análises para medição da alfafetoproteína (AFP), uma análise tripla (AFP, HCG e estriol) ou uma análise quádrupla (que também analisa a inibina-A)
Quando o fator Rh do sangue da mãe é negativo e existe a possibilidade de doença de Rhesus, geralmente confirma-se a presença de anticorpos antiRh no sangue.
Um valor elevado de alfafetoproteína no sangue da grávida indica uma maior probabilidade de doenças do tubo neural como espinha bífida, anencefalia e outras anomalias no feto
Por outro lado, um valor baixo de alfafetoproteína no sangue em conjunto com um valor elevado de gonadotrofina coriónica humana e um valor baixo de estriol indicam uma maior probabilidade de síndrome de Down
No entanto, existem outras causas que explicam valores elevados: erro no cálculo da idade gestacional, a existência de mais do que um feto, ameaça de aborto ou morte do feto
Em caso de valores elevados, geralmente é recomendada a realização de uma ecografia
No entanto, em 2% dos casos a ecografia não revela a causa do aumento dos valores, situação em que se recomenda a realização de uma amniocentese para medir os valores de alfaproteína no líquido amniótico.
A ecografia é um exame seguro que não implica nenhum risco para a grávida ou para o feto e que permite detectar algumas doenças congénitas durante a fase inicial da gravidez, estimar com maior precisão a idade gestacional e a data prevista de parto e detetar uma gravidez múltipla
A partir das cinco semanas e meia de gestação já é possível observar o embrião
Quando este atinge 5mm é possível observar o batimento cardíaco por ecografia pélvica, embora em alguns casos só seja visível quando atinge os 7mm, o que acontece por volta da 7ª semana
As recomendações internacionais de saúde pública recomendam que seja realizada pelo menos uma ecografia de rotina a todas as grávidas entre as 18 e as 22 semanas de gestação (ecografia do segundo trimestre) e, em países com recursos, que seja também realizada uma ecografia de rotina entre as 11 semanas e as 13 semanas e seis dias de idade gestacional (ecografia do primeiro trimestre)
Em alguns países realiza-se ainda uma ecografia de rotina entre as 30 e as 32 semanas (ecografia do terceiro trimestre)
Em todas as ecografias de rotina de uma gravidez de baixo risco são avaliados o número de fetos e placentas, a atividade cardíaca, os movimentos fetais, a localização da placenta, a quantidade de líquido amniótico e os valores biométricos
Para além destes parâmetros gerais, em cada trimestre são também avaliados parâmetros específicos.
Na ecografia do primeiro trimestre são geralmente avaliados o comprimento crânio-caudal, a frequência cardíaca do feto, a medida da translucência da nuca, se gémeos partilham ou não a placenta (corionicidade) e a anatomia do feto (pólo cefálico, coluna vertebral, estômago, parede abdominal e membros)
O comprimento crânio-caudal permite determinar a idade gestacional com uma precisão ligeiramente superior aos cálculos com base no último período menstrual
Uma vez determinada a idade gestacional por ecografia, não será alterada até ao fim da gravidez
Durante a ecografia do primeiro trimestre é também calculado o risco de trissomia 21
Este risco é calculado através da ponderação conjunta do valor de translucência da nuca medido por ecografia, da idade da mãe e, sempre que possível, do rastreio por análises clínicas da fração livre da gonadotrofina coriónica humana e da proteína plasmática associada à gravidez
Este rastreio combinado identifica 90% dos casos de trissomia 21 e outras principais doenças congénitas.
A ecografia do segundo semestre, ou ecografia morfológica, para além de confirmar alguns dados do primeiro trimestre, destina-se principalmente a identificar malformações do feto
São avaliados o contorno craniano e cérebro, face e pescoço, coração, pulmões, abdómen, coluna vertebral, membros, cordão umbilical e genitais externos
É possível distinguir o sexo do feto por ecografia a partir das 11 semanas de gestação
No entanto, só a partir das 13 semanas é que é possível fazê-lo com uma precisão entre 99% e 100%
Na ecografia do terceiro trimestre são avaliados a apresentação fetal, o perímetro cefálico, perímetro abdominal, comprimento do fémur e vários parâmetros biofísicos.
Os exames de diagnóstico são geralmente propostos a grávidas que apresentem um risco acrescido de doenças cromossómicas
Os fatores de risco mais comuns são a idade superior a 35 anos, antecedentes familiares de doenças cromossómicas, como a síndrome de Down, ou de doenças genéticas, como a fibrose cística, um problema detectado na ecografia ou um risco elevado detectado nos exames de rastreio ou em função de um valor de translucência nucal elevado.
A amniocentese é um exame de diagnóstico utilizado para confirmar a presença de defeitos na espinal medula, de diversas anomalias cromossómicas, como a síndrome de Down, e de doenças autossómicas recessivas como a fibrose cística e a doença de Tay-Sachs
Este exame também permite determinar com 100% de certeza o sexo do bebé
No entanto, nem todas as malformações podem ser detectadas através de amniocentese
O exame consiste na inserção de uma agulha no abdómen para recolha de uma amostra de líquido amniótico
Como este exame apresenta um risco de aborto espontâneo, embora muito baixo (0,06% ou 1:1600), não é um procedimento de rotina e é apenas apresentado como opção a mulheres com idade superior a 35 anos, a mulheres com resultados fora do normal nas análises triplas do primeiro trimestre e a mulheres com historial familiar de determinadas doenças ou malformações
A amniocentese é geralmente realizada a partir das 16 semanas de gestação e os resultados demoram, no mínimo, duas semanas a ser obtidos.
A biópsia das vilosidades coriónicas é um exame de diagnóstico que consiste na recolha de uma amostra das vilosidades coriónicas do útero, as membranas embriónicas exteriores
Embora semelhante à amniocentese, este exame pode ser realizado bastante mais cedo, geralmente entre as oito e doze semanas de gestação, o que em caso de resultados desfavoráveis permite optar pela interrupção da gravidez numa fase precoce
Por ser realizado mais cedo, apresenta um risco de aborto espontâneo significativamente superior ao da amniocentese (1-2%).
Existem diversas medidas que a grávida pode tomar para promover a saúde e o bem-estar dela e do bebé em crescimento
Por outro lado, é também importante que conheça os comportamentos de risco que colocam em risco a saúde do feto
Entre os cuidados de saúde essenciais estão a suplementação com ácido fólico, a abstenção do consumo de tabaco, álcool e drogas, a prática de exercício físico adequado à gravidez, a comparência às consultas de acompanhamento e exames médicos e ecografias recomendados.
Durante a gravidez, é de especial importância seguir uma dieta equilibrada, aumentando a qualidade nutricional dos alimentos de modo a responder às exigências do bebé em crescimento
As necessidades diárias de uma grávida incluem 2-3 doses de proteínas, 2-3 doses de lacticínios e 5 doses de fruta e legumes
Do total de calorias ingeridas por dia, pelo menos um terço devem ser hidratos de carbono complexos; no máximo um terço devem ser lípidos (gorduras); enquanto que o consumo de hidratos de carbono simples (açúcares) deve ser mínimo
No último trimestre, a grávida necessita de aumentar a ingestão diária de calorias de 2000 para 2200.
As proteínas podem ser obtidas de alimentos como o peixe, carne, lacticínios, feijão, leguminosas, lentilhas, nozes e derivados de soja, e o seu consumo durante a gravidez deve aumentar 13%
É importante separar o excesso de gordura da carne e a pele das aves
Devem ser incluídos na dieta uma variedade de lacticínios, especialmente durante o fim da gravidez
Os hidratos de carbono complexos, como o pão, os cereais ou as batatas, que são a base de qualquer dieta, assumem particular importância durante a gravidez, já que devem constituir a principal fonte de energia, em vez das gorduras
Há maiores benefícios no pão escuro ou integral, arroz e massas integrais, batatas, cuscuz e cereais como a aveia, cevada e centeio
As frutas e legumes fornecem vitaminas, sais minerais e fibras
Os citrinos, pêssegos, mangas e quivis fornecem vitamina C que ajuda à absorção de ferro
Entre os alimentos ricos em ácido fólico estão os espinafres (frescos, congelados ou enlatados), legumes verdes (alface, bróculos, espargos), citrinos, melão, grão-de-bico, e ovos.
O ómega-3 DHA é um ácido gordo essencial para o desenvolvimento do cérebro, nervos e retina, estando naturalmente presente no leite materno
É importante que a mulher consuma uma quantidade adequada de ómega-3 durante a gravidez e amamentação, uma vez que os bebés ainda em desenvolvimento não o conseguem produzir de forma eficaz e necessitam de receber este nutriente vital através da mãe
Pode ser obtido a partir dos peixes gordos, como a cavala, arenque, sardinha, salmão, truta, atum fresco, avelãs e nos óleos de colza e de linhaça
Deve-se evitar as gorduras da comida processada e e substituir as gorduras saturadas (como a manteiga, natas ou banha de porco) por gorduras monoinsaturadas (como o azeite) e poliinsaturadas (como o óleo de girassol)
Devem-se evitar os açúcares.
A ingestão adequada de suplementos de ácido fólico (também denominado Vitamina B9) no período periconcecional diminui o risco de malformações fetais graves, principalmente defeitos do tubo neural como a espinha bífida, uma doença congénita grave
O tubo neural desenvolve-se durante os primeiros 28 dias da gravidez, pelo que é importante que a toma de ácido fólico seja iniciada ainda antes da concepção
Alguns micronutrientes são importantes para a saúde do feto em desenvolvimento, principalmente em regiões onde a subnutrição é prevalente
Em países desenvolvidos, como na Europa ocidental e na América do Norte, pode ser necessária a suplementação com determinados nutrientes como a vitamina D e o cálcio, necessários para o desenvolvimento ósseo.
Durante a gravidez, o sistema imunitário da mulher encontra-se diminuído para que o corpo não rejeite o ADN do bebé em crescimento
No entanto, Isto faz com que o corpo esteja também mais susceptível a intoxicações alimentares, pelo que a grávida deve ter cuidados acrescidos com a higiene dos alimentos e evitar o consumo de determinados alimentos
Os alimentos podem ser contaminados por algumas bactérias ou parasitas perigosos para a gravidez, como a Listeria e a Toxoplasma gondii
A lavagem criteriosa da fruta e dos vegetais crus pode remover alguns destes patógenos
A carne crua, a carne processada e todas as sobras de comida devem ser sempre cozinhadas e sempre bem passadas
As mulheres grávidas estão também mais suscetíveis a infeções por salmonelas a partir de ovos ou carne de aves, os quais devem também ser plenamente cozinhados e nunca ingeridos crus.
É seguro comer queijos curados e alguns moles, desde que pasteurizados
No entanto, devido ao risco de listeriose e salmonelose devem ser evitados todos os queijos moles que são amadurecidos na forma, como o brie e o camembert, e todos os queijos que não forem pasteurizados
Só deve ser consumido leite ultrapasteurizado
Devem ser evitados gelados e sorvetes caseiros ou de quiosques
Não se deve consumir qualquer alimento que contenha ovos crus ou mal passados, como a maionese caseira, mousses, ovos cozidos moles, omeletas, ovos mexidos ou escalfados e pratos com ovos pouco cozinhados como o tiramisu, leite-creme e merengues
Devido ao risco de toxoplasmose e listeriose, devem ser evitados todos os legumes e fruta não lavados
Podem ser consumidos desde que sejam cozinhados ou crus, desde que bem lavados em água corrente ou descascados.
Devido ao risco de toxoplasmose e E
coli, não deve ser comida carne crua, mal passada ou pré-cozinhada; carnes fumadas e curadas não cozinhadas, como toucinho, fiambre, presunto e enchidos como o chouriço, salame ou mortadela
Também não deve ser consumido fígado e produtos derivados, devido à elevada quantidade de retinol, nocivo para o bebé em gestação
No entanto, é seguro consumir carne bem cozinhada e carnes curadas, desde que cozinhadas
Pode ser consumido frango cozinhado pré-embalado, desde que aquecido por completo
Devido ao risco de toxoplasmose, não deve ser comido peixe cru, mal passado ou fumado não cozinhado, como sushi ou sashimi
O peixe deve ser bem cozinhado, sendo também seguro consumir peixe enlatado
O tubarão, peixe-espada e o espadarte contêm níveis excessivos de mercúrio
Devido ao risco de salmonelose e campilobactéria deve ser evitado o consumo de marisco cru, como as ostras, e qualquer marisco à venda sem data de validade, embora possa ser consumido marisco bem cozinhado quente
Devem também ser evitados alimentos pré-cozinhados frios, como quiches, devendo ser aquecidos na totalidade para poderem ser consumidos.
A quantidade de peso adquirida durante a gravidez varia de mulher para mulher
Em pessoas com peso normal (IMC de 18,5–24,9), o valor de referência para o ganho total de peso numa gravidez com um único feto é entre 11,3 e e 15,9 kg
Em mulheres com baixo peso (IMC < 18,5), o aumento de peso deve ser entre 12,7 e 18 kg; as mulheres com pré-obesidade (IMC 25–29,9) são aconselhadas a ganhar entre 6,8 e 11,3 kg; e mulheres obesas (IMC ≥30) devem aumentar apenas entre 5 e 9 kg
Um aumento excessivo de peso durante a gravidez potencia o risco de complicações para a mãe e para o bebé, incluindo a necessidade de uma cesariana, hipertensão gestacional, pré-eclampsia, macrossomia fetal e distócia de ombro, enquanto que o aumento insuficiente de peso coloca em risco o fornecimento adequado de nutrientes
A dieta é a forma mais eficaz de diminuir o aumento excessivo de peso durante a gravidez e os riscos associados
No entanto, ainda não é clara qual é a melhor intervenção para ganhar peso em mulheres que não adquirem peso suficiente.
A maior parte do peso é adquirida numa fase avançada da gravidez, e só uma parte desse peso é que se deve ao bebé
Numa gravidez média, o feto, a placenta e os líquidos no útero pesam cerca de 4,5 kg; o aumento de tamanho do útero e das mamas corresponde a cerca de 2,25 kg; e o aumento de líquidos e gordura no corpo a 2,25 kg
Durante o parto, a mulher perde 7 kg e os restantes 2,25 kg de líquidos são eliminados à medida que o útero encolhe
No entanto, caso a mulher não limite a ingestão de calorias após o parto, pode não perder o restante peso.
Muitos medicamentos de venda livre para tratar doenças comuns, como tosse, constipações ou gripe, são nocivos durante a gravidez
O uso recreativo de drogas e o consumo de tabaco e álcool durante a gravidez podem causar diversas complicações graves na saúde do feto.
O uso de determinados fármacos durante a gravidez pode causar efeitos temporários ou permanentes no feto
Muitos médicos optam por não prescrever medicamentos a mulheres grávidas, devido sobretudo ao risco de teratogenicidade desses fármacos
Do ponto de vista da segurança de uso na gravidez, as categorias farmacológicas na gravidez classificam os medicamentos nas categorias A, B, C, D e X
Isto baseia-se no sistema de classificação da Food and Drug Administration norte-americana, o qual tem por base os potenciais benefícios e riscos para o feto
Os medicamentos, incluindo suplementos vitamínicos, que não tenham demonstrado riscos para o feto em estudos controlados em seres humanos são classificados na categoria A
Por outro lado, medicamentos como a talidomida, com riscos que superam todos os benefícios, são classificados na categoria X.
Entre os medicamentos mais comuns, a aspirina deve ser evitada, já que pode afetar a circulação sanguínea
A codeína está associada a algumas deficiências congénitas
O ibuprofeno está associado a problemas no crescimento do coração e do feto
O paracetamol é seguro em pequenas doses, embora a sobredosagem possa causar problemas nos rins e no fígado do bebé
A maior parte dos medicamentos para a tosse, constipação e gripe contêm codeína, aspirina, ibuprofeno ou paracetamol
Os medicamentos para enxaquecas geralmente têm codeína
Os medicamentos para a diarreia não são seguros porque atrasam o funcionamento do estômago e do intestino, já de si lento devido à gravidez
Os laxantes que contêm sene, cáscara ou bisacodil não são seguros, uma vez que estes fármacos podem atravessar a placenta e impedir os intestino de funcionar corretamente, impedindo o bebé de receber nutrientes
Alguns antibióticos são seguros
Os cremes vaporizantes também são seguros
A isotretinoína, usada em alguns medicamentos para o tratamento de acne, é teratogénica, havendo o risco elevado de causar malformações no feto se tomada durante a gravidez.
O consumo de etanol pode provocar síndrome alcoólica fetal
Vários estudos demonstraram que, embora o consumo ocasional de bebidas alcoólicas possa não apresentar riscos imediatos para o feto, não é possível garantir a total segurança do consumo de álcool, mesmo que seja ingerido em quantidades pequenas
Beber sete ou mais bebidas por semana pode ser prejudicial e pode causar restrições de crescimento no feto
O consumo excessivo pode causar dificuldades de aprendizagem, problemas de comportamento e deficiências físicas na criança
As políticas de saúde pública geralmente reconhecem que é pouco provável que o consumo ocasional possa causar problemas, mas que só a abstinência total é que elimina todos os possíveis riscos.
O consumo de tabaco durante a gravidez pode provocar uma série de dificuldades neurológicas, físicas e comportamentais
Fumar durante a gravidez duplica o risco de ruptura prematura de membranas, descolamento prematuro da placenta e placenta prévia
Aumenta também em 30% o risco do bebé nascer de forma prematura
Recomenda-se que durante a gravidez e amamentação seja interrompido o consumo de cannabis, uma vez que esta substância pode estar associada a restrições no crescimento do feto, aborto espontâneo e défices cognitivos na linguagem e atenção, e comportamentos delinquentes mais tarde na vida
O consumo de metanfetaminas pode provocar partos prematuros, doenças congénitas, e, a curto prazo após o parto, pequenos défices na função neurocomportamental e restrição do crescimento da criança, em comparação com a generalidade da população
Acredita-se ainda que o uso pré-natal de metanfetaminas possa ter efeitos a longo prazo no desenvolvimento cerebral.
A exposição intrauterina a toxinas ambientais tem o potencial de causar efeitos adversos no desenvolvimento pré-natal do embrião ou do feto e ainda de causar complicações da gravidez
Entre os potenciais efeitos das substâncias tóxicas e da poluição estão as malformações congénitas e incapacidade mental da criança mais tarde na vida
Entre as condições especialmente gravosas durante a gravidez estão a intoxicação por mercúrio e a intoxicação por chumbo
Algumas recomendações incluem verificar se a habitação foi pintada com tinta de chumbo, sobretudo em casas antigas, lavar todos os alimentos, tentar consumir alimentos biológicos e evitar o contacto com produtos com o rótulo "tóxico" ou qualquer produto com um rótulo de aviso
As fezes dos gatos apresentam um risco particularmente elevado de transmitir a toxoplasmose.
A prática regular de exercício aeróbico durante a gravidez aparenta melhorar ou manter a aptidão física da grávida e inclusive diminuir o risco de cesariana
No entanto, a qualidade das evidências é pouca e os dados são insuficientes para determinar riscos ou benefícios relevantes para a mãe e para o bebé
No passado, pensava-se que eventuais benefícios à mãe não compensavam os potenciais riscos para o feto
No entanto, as informações mais recentes sugerem que em gravidezes sem complicações é muito improvável que surgam lesões no feto, desde que o exercício seja adequado à gravidez
No entanto, há várias circunstâncias em que a grávida deve consultar um médico antes de continuar um programa de exercício: hemorragias vaginais, dispneia antes do esforço, tonturas, dores de cabeça, dores no peito, fraqueza muscular, risco de parto pré-termo, diminuição dos movimentos fetais, fuga de líquido amniótico e dores ou inflamação dos gémeos.
Embora não se tenha ainda determinado um limite seguro de intensidade, as mulheres que praticavam exercício físico regular antes da gravidez, e que não apresentam complicações na gravidez, estão aptas a praticar programas de exercício de alguma intensidade, como jogging ou aeróbica, desde que por períodos não superiores a 45 minutos, desde que estejam conscientes que pode ser necessário aumentar o consumo de energia e desde que tenham o cuidado de nunca sobreaquecer o corpo
Na ausência de outras complicações médicas ou obstétricas, recomenda-se que o tempo de exercício diário não exceda os 30 minutos
A participação em diversas atividades recreativas e desportos aparenta ser segura, desde que se evite aquelas nas quais existe um risco de queda, como esqui ou hipismo, ou atividades onde existe risco de trauma abdominal, como futebol ou hóquei.
Especialmente durante as primeiras semanas, o cansaço pode ser avassalador, pelo que é importante que a grávida descanse o suficiente e esteja relaxada
As técnicas de relaxamento ajudam a diminuir a pressão arterial e a aumentar o fornecimento de oxigénio ao bebé.
Durante as primeiras semanas de gravidez, o ritmo metabólico aumenta 20% e a pressão no útero provoca vontade de urinar frequente, o que diminui o tempo e qualidade do sono
No último trimestre, o volume da barriga torna difícil encontrar uma posição para dormir
Geralmente, recomenda-se que a grávida se deite sobre o lado esquerdo com uma almofada a apoiar a barriga e entre as pernas, que evite bebidas estimulantes como o chá ou café, que permaneça fresca e que realize exercícios ligeiros durante o dia
Tem sido sugerido que, pelo menos durante o último trimestre, se deve evitar o trabalho por turnos e a exposição a luz intensa durante noite, de modo a diminuir o risco de problemas psicológicos e comportamentais no recém-nascido
Tem sido proposto como mecanismo explicativo que o ritmo circadiano da mãe programa o ritmo em desenvolvimento do feto.
A maior parte das grávidas pode manter uma vida sexual ativa ao longo da gravidez
O sexo durante a gravidez é uma atividade de baixo risco, saudável e perfeitamente segura, que relaxa a mulher e ajuda a exercitar o soalho pélvico e os músculos do útero
O bebé está protegido dentro da placenta e o rolhão mucoso impede que o esperma passe para além da vagina
No entanto, há casos em que o profissional de saúde pode recomendar a abstinência sexual por motivos médicos, geralmente quando a grávida tem antecedentes de aborto espontâneo, parto prematuro, hemorragias durante a gravidez ou placenta prévia
É importante que o companheiro sexual nunca exerça pressão sobre o abdómen da grávida, pelo que se recomenda experimentar posições diferentes e descobrir aquelas que sejam mais confortáveis
A maior parte da investigação sugere que durante a gravidez se verifica uma diminuição do desejo sexual e da fequência das relações sexuais
No contexto desta diminuição geral do desejo sexual, alguns estudos indicam porém um aumento do desejo no segundo trimestre e novamente uma diminuição no terceiro trimestre.
Durante uma gravidez normal e sem complicações, são comuns vários incómodos ou desconfortos
Trata-se de manifestações e condições normais que resultam da gravidez, mas que não interferem com as atividades quotidianas nem são uma preocupação para a saúde da mãe e do bebé, ao contrário das complicações da gravidez
No entanto, a separação entre ambas nem sempre é clara e um incómodo com maior gravidade pode ser considerado uma complicação.
Praticamente todas as grávidas manifestam prurido na barriga, provocado pela pele esticada e consequente desidratação, que pode ser aliviado com um creme hidratante
No entanto, comichão frequente nas mãos e nos pés pode indicar colestase
É normal que as sardas e os sinais se tornem mais escuros devido à pigmentação da pele; no entanto, quaisquer alterações no tamanho, forma e cor dos sinais deve ser comunicada ao médico
Em 70% das grávidas aparece uma pigmentação no rosto denominada cloasma e, na parte inferior do abdómen, a linea nigra
São também comuns as erupções cutâneas devido ao calor e o aumento da sudação e do odor corporal
A pele seca é comum e resulta do aumento da quantidade de estrogénio, podendo ser minimizada com a ingestão de bastante água, evitando locais com ar condicionado e radiadores de calor e com a aplicação de creme hidratante
O acne durante a gravidez é perfeitamente normal
No entanto, existem alguns medicamentos para o tratamento de acne que podem provocar malformações graves no feto
Cerca de metade das mulheres desenvolvem estrias que, embora não tenham tratamento, podem ser minimizadas com um creme hidratante gordo.
As dores nas costas são comuns durante a gravidez, podendo ser bastante debilitantes
Manifestam-se entre 35 e 61% das grávidas e metade dos casos ocorre a partir do quinto mês
São causadas pela alteração na postura e podem-se agravar à noite
Entre as várias medidas de alívio comprovadas estão os exercícios na água, massagens e apoio de almofadas ao dormir
As cintas de maternidade não demonstram diminuir as dores nas costas na gravidez, e podem ter alguns efeitos adversos, incluindo dores e irritação na pele da mãe e potenciais efeitos no feto
As cãibras nas pernas ocorrem em metade das gravidezes e podem ser bastante dolorosas
Geralmente manifestam-se durante a noite e podem durar de segundos a minutos
Embora por vezes sejam usados alguns métodos de alívio, como meias de compressão e cálcio ou magnésio, não há evidências de que sejam eficazes a reduzir as cãibras ou que sejam seguros para o feto.
A síndrome do túnel cárpico é uma neuropatia compressiva muito comum durante a gravidez
Manifesta-se em até 62% das grávidas e geralmente ocorre no terceiro trimestre, embora também possa ocorrer no primeiro
Os sintomas são dormência e formigueiro nos dedos polegar, indicador, médio e parte do anelar
Também pode ocorrer dor no pulso e diminuição da força e destreza
Os sintomas são mais pronunciados à noite e podem ser agravados com a atividade física
O tratamento consiste em reduzir a atividade do pulso e a utilização de uma tala que o imobiliza numa posição neutra.
As náuseas e vómitos ocorrem principalmente de manhã, mas geralmente melhoram após o primeiro trimestre
O refluxo gástrico e a azia na gravidez são causados pelo relaxamento do esfíncter esofágico inferior e podem ser aliviadas fazendo múltiplas refeições ligeiras ao longo do dia, evitando comer nas três horas anteriores a dormir e mantendo uma postura direita durante a ingestão
Quando a dieta e as alterações ao estilo de vida não são suficientes, podem ser necessários antiácidos, alginatos ou ainda inibidores da bomba de protões.
A obstipação é um desconforto bastante comum, ocorrendo em 39% das gravidezes às 14 semanas de gestação
Pensa-se que seja causada pela diminuição da motilidade intestinal
Esta diminuição é normal durante a gravidez e deve-se ao aumento da quantidade de progesterona, que relaxa o intestino para que a mãe possa receber mais nutrientes e absorver mais água
Como efeito adverso, as fezes podem-se tornar extremamente desidratadas e de motilidade difícil
A obstipação pode também ser agravada pela suplementação de ferro
As hemorroidas resultam do esforço associado à obstipação ou da pressão intra-abdominal do fim da gravidez
Podem causar hemorragias, prurido, sujidade ou dor e os sintomas podem desaparecer espontaneamente depois da gravidez
O tratamento conservador inclui modificações na dieta, tratamentos locais e estimulantes ou depressores da motilidade intestinal.
Ao contrário dos incómodos e desconfortos, que são normais e não apresentam um risco para a saúde da mãe e do bebé, as complicações da gravidez são problemas de saúde causados pela gravidez
No entanto, a maioria destas complicações pode ser tratada e, mesmo após um aborto, uma mulher pode voltar a ter uma gravidez perfeitamente normal
Os fatores de risco mais comuns numa gravidez são uma idade superior a 35 anos, o consumo frequente de álcool, tabaco e drogas; historial familiar de malformações, síndroma de Down, atraso mental ou doenças congénitas; hipertensão arterial, diabetes, epilepsia, artrite reumatoide, problemas do coração, dos rins ou da tiroide; infecções como a rubéola ou a toxoplasmose, incluindo infeções de transmissão sexual como sífilis ou sida; e desnutrição ou excesso de peso
A grávida apresenta um risco acrescido de contrair determinadas infeções como, por exemplo, gripe, hepatite E, herpes e malária
Isto deve-se ao aumento da tolerância imunológica na gravidez, que impede a reação imunitária contra o feto, e a algumas das alterações fisiológicas maternas, entre as quais a diminuição do volume respiratório e a retenção urinária
A mastite, ou inflamação das mamas, ocorre em 20% das lactantes.
Anemias são doenças em que a quantidade de glóbulos vermelhos ou de hemoglobina é inferior aos valores normais
Durante a gravidez, o tipo de anemia mais comum é a anemia por deficiência de ferro, causada pela insuficiência de ferro ou ácido fólico na dieta
A maioria das gestantes são aconselhadas a tomar suplementos de ferro e ácido fólico para tratar ou prevenir eventuais anemias
Cerca de metade das gravidezes à escala mundial são acompanhadas de anemia
A prevalência varia entre 18% nos países desenvolvidos e 75% no sul da Ásia.
A hiperémese gravídica é a presença de vómitos severos e persistentes, ao ponto de causarem desidratação e perda de peso, o que pode provocar alterações perigosas nos valores de eletrólitos no sangue, lesões no fígado e hemorragias na retina
São mais graves do que os comuns enjoos matinais e estima-se que afetem entre 0,5 e 2% das grávidas
A causa é desconhecida, mas podem-se agravar ou desencadear por fatores psicológicos
O tratamento requer hospitalização.
Cerca de 10% das gravidezes são complicadas por doenças hipertensivas, nas quais se inclui pré-eclampsia, eclampsia, hipertensão gestacional e hipertensão crónica
A pré-eclampsia é uma doença caracterizada por tensão arterial elevada (>140/90 mmHg ou subida considerável da tensão) acompanhada por valores anormalmente elevados de proteínas na urina (>300 mg) e retenção de líquidos na cara e nas mãos
Afeta entre 5 e 8% das gravidezes e geralmente ocorre entre a 20.ª semana de gestação e uma semana após o parto
O risco mais significativo é o desprendimento prematuro da placenta
Geralmente recomenda-se a ingestão de líquidos e o repouso na cama virada sobre o lado esquerdo mas, se a condição não melhorar com rapidez, exige hospitalização
A eclampsia é uma forma mais grave da doença que surge em 0,5% das mulheres com pré-eclampsia, podendo provocar convulsões, coma e morte se não for tratada com rapidez
Um quarto dos casos de eclampsia ocorre após o parto
Ao contrário da hipertensão normal, ambas as doenças não respondem aos diuréticos nem à dieta sem sal
Uma das complicações da pré-eclampsia e eclampsia graves (>160/110 mmHg) é a síndrome HELLP, que é a combinação anemia hemolítica (destruição de glóbulos vermelhos), aumento das enzimas hepáticas (que indica lesões no fígado) e diminuição na contagem de plaquetas (que indica deficiência na coagulação do sangue)
Este síndrome ocorre entre 0,5 e 0,9% de todas as gravidezes.
A doença de Rhesus ocorre quando existe incompatibilidade do grupo Rh entre o sangue da mãe e do feto; ou seja, quando o sangue da mãe é Rh-negativo e o sangue do feto é Rh-positivo, herdado de um pai Rh-positivo
Se o sangue do feto entrar em contacto com o sangue da mãe através da placenta, o que acontece sobretudo durante o parto, o organismo da mãe pode considerar os glóbulos vermelhos do feto elementos estranhos e produzir anticorpos que os vão destruir (anticorpos antiRh)
Se estes anticorpos atravessarem a placenta, podem destruir parte dos glóbulos vermelhos do feto (eritroblastose fetal) ou do recém-nascido (eriotroblastose neonatal)
A destruição dos glóbulos vermelhos pode provocar anemia e aumentar a quantidade de bilirrubina no sangue
Se a bilirrubina for demasiado elevada, pode afetar o cérebro do feto
Nos países ocidentais, em 13% dos casais o homem é Rh-positivo e a mulher Rh-negativa
Um em cada 27 recém-nascidos destes casais desenvolve doença de Rhesus
Na primeira consulta fazem-se análises ao sangue da mãe; se for Rh-negativo confirma-se o sangue do pai e, se este for positivo, mede-se a quantidade de anticorpos antiRh na mãe
Ao longo da gravidez são monitorizados os valores de anticorpos
Se subirem demasiado, faz-se uma amniocentese para medir os valores de bilirrubina
Se ambos os valores forem altos, geralmente são feitas transfusões de sangue intra-uterinas, sendo o parto provocado entre a 32ª e 34ª semana de gravidez.
As dermatoses da gravidez são condições cutâneas que ocorrem apenas durante a gravidez
Entre as mais comuns estão as pápulas e placas urticariformes e pruriginosas da gravidez (PPUPG ou PUPPP) e o prurigo da gravidez
As PPUPG ocorrem numa em cada 160 gravidezes e geralmente manifestam-se no terceiro trimestre ou, mais raramente, após o parto
São caracterizadas por manchas de pápulas e placas eritematosas intensamente pruriginosas, que geralmente aparecem no abdómen superior e se estendem em poucos dias para os braços, coxas e mamas
São tratadas com corticosteroides tópicos e anti-histamínicos orais
O prurigo da gravidez afeta uma em cada 300 grávidas e ocorre com maior frequência entre as 20 e as 34 semanas de gestação
É uma erupção cutânea intensamente pruriginosa com pápulas por vezes foliculares ou lesões nodulares, com ou sem crosta, e que medem entre 0,5 e 1 cm
Geralmente aparece nas pernas e nos membros superiores.
Uma gravidez ectópica é uma gravidez em que o feto se desenvolve fora do útero
Geralmente, desenvolve-se numa das trompas de Falópio, embora em casos raros se possa desenvolver no canal cervical, na cavidade pélvica ou na cavidade abdominal
Durante o desenvolvimento fetal, ao deslocar-se em direção ao útero o óvulo fecundado pode ficar preso na trompa de Falópio e aí se implantar e desenvolver
Esta complicação afeta entre 0,5 e 1% de todas as gravidezes, tendo como fatores de risco uma gravidez ectópica anterior, uma laqueação de trompas mal sucedida ou exposição fetal ao dietilestilbestrol
O risco é elevado no caso da mulher ficar grávida com um dispositivo intra-uterino colocado
Uma gravidez ectópica coloca em risco a vida da mulher e deve ser removida cirurgicamente o mais cedo possível
Os sintomas de uma gravidez ectópica são pequenas perdas de sangue pela vagina e cãibras abdominais, juntamente com o atraso da menstruação
Quando o feto morre numa fase inicial, o organismo tenta expulsá-lo da mesma forma que o produto da menstruação e não se verificam lesões
Mas no caso de continuar a crescer é possível romper as paredes da trompa, causando uma hemorragia interna que provoca dores e sensação de pressão na parte inferior do abdómen
Entre as 6 e as 8 semanas é possível que ocorra uma dor aguda e intensa no baixo abdómen seguida por desmaio.
O desprendimento prematuro da placenta ocorre quando o revestimento da placenta se separa do útero entre as 20 semanas de gestação e o parto
Verifica-se entre 0,5 e 1 em cada 200 nascimentos, sendo uma urgência hospitalar e uma das complicações que mais contribui para a mortalidade materna no mundo
A placenta prévia é a inserção parcial ou total da placenta no colo do útero
É uma das principais causas de hemorragias pré-natais e afeta 1 em cada 200 partos
O sintoma inicial é uma hemorragia vaginal súbita e indolor no fim da gravidez, com sangue de cor vermelho vivo e necessita de cuidados hospitalares.
Aborto espontâneo é a perda de um feto por causas naturais e involuntárias antes das vinte semanas de gestação; a partir das vinte semanas passa a ser denominado feto morto
Aproximadamente 85% dos abortos espontâneos ocorrem durante as doze primeiras semanas de gestação e os restantes entre a 13.ª e 20.ª semanas
Durante as primeiras vinte semanas, 20 a 30% das grávidas manifestam hemorragias ou contrações, das quais metade resulta em abortos espontâneos
Geralmente, os abortos espontâneos devem-se a anomalias no feto
O primeiro sintoma é a perda de sangue pouco abundante o uma hemorragia juntamente com a secreção vaginal
Se o processo de aborto continuar, aumentam as dores, a hemorragia e a secreção, podendo no fim ser expulsa a totalidade ou parte do conteúdo do útero
Quando é expulso na totalidade, geralmente não há necessidade de tratamento; em caso de expulsão parcial geralmente realiza-se uma dilatação e sucção para remover o restante conteúdo
No entanto, quando apenas se verifica uma ameaça de aborto, geralmente aconselha-se repouso absoluto, uma vez que os sintomas costumam melhorar
A ameaça de aborto pode ser causada pela dilatação prematura do colo do útero devido à debilidade do tecido fibroso.
Denomina-se parto distócico o parto que decorre de forma difícil, demorada ou dolorosa
Esta situação acontece quando, apesar do útero estar a contrair normalmente, o bebé não consegue sair da pélvis devido a um bloqueio físico
Entre as complicações para o bebé estão o risco de asfixia, o que pode provocar a morte
Aumenta também o risco da mãe contrair uma infeção, de ter uma ruptura do útero ou de hemorragias pós-parto
Entre as complicações a longo prazo para a mãe estão a fístula obstétrica
Diz-se que o parto é prolongado quando esta fase dura mais do que doze horas.
Entre as principais causas de um parto distócico estão um bebé de grande dimensão, posicionamento do bebé fora do normal, uma pélvis pequena ou problemas com o canal de parto
O posicionamento fora do normal inclui a distócia de ombro, em que o ombro anterior não consegue passar com facilidade pelo osso público
Entre os fatores de risco de uma pélvis pequena estão a desnutrição, a falta de exposição à luz do sol, que provoca deficiência de vitamina D, e uma gravidez na adolescência, já que o osso pélvico pode ainda não estar completamente desenvolvido
Entre os problemas com o canal de parto estão uma vagina e períneo estreitos, os quais se podem dever a mutilação genital feminina ou a tumores
Os partos distócicos podem ser resolvidos com uma cesariana ou extração por ventosa.
A laceração perineal é a laceração não intencional da pele ou dos tecidos moles que se separam a vagina do ânus que geralmente ocorre durante o parto
São classificadas em primeiro grau (afetam a pele e mucosa), segundo grau (músculos perineais) ou terceiro grau (afetam o músculo esfíncter)
Se for uma intervenção cirúrgica provocada por necessidade médica denomina-se episiotomia
Num período de seis meses após qualquer tipo de parto, ocorre incontinência urinária em 3-7% das mulheres e incontinência fecal em 1-3%.
A depressão pós-parto é um episódio depressivo que pode ter início em qualquer momento da gravidez até quatro semanas após o parto
Ocorre em 4-20% das gravidezes, dependendo da definição
Em 28% dos casos de depressão pós-parto, a mulher ainda se encontra deprimida passado três anos
Em 0,2 % das gravidezes, a depressão pós parto leva a psicose
Nos mesmo período de seis meses, 13,6 % das mulheres sofre de stresse pós-traumático.
As doenças intercorrentes na gravidez são doenças ou condições que não são causadas diretamente pela gravidez, mas que durante a gravidez se podem agravar ou constituir um potencial risco para a gravidez
As infeções do trato urinário são mais frequentes durante a gravidez
As infeções agudas da bexiga e dos rins aumentam o risco de parto prematuro
As mulheres que já tiveram pielonefrite numa gravidez anterior têm maior risco de desenvolver infeções agudas noutra gravidez e de desenvolver infeções renais graves, como glomerulonefrite, que aumentam o risco de aborto espontâneo e parto prematuro
Se a mulher tiver tuberculose assintomática nos rins, a gravidez reativa a doença
As doenças gastrointestinais têm pouco ou nenhum efeito sobre a gravidez
No entanto, a gravidez tende a agravar estas doenças
As mulheres com colite ulcerosa são geralmente aconselhadas a evitar engravidar até à doença estar estável por dois anos
Durante a gravidez, o risco de trombose venosa profunda é cinco vezes superior devido a um maior estado de hipercoagulação so sangue, o que é provavelmente uma adaptação do organismo materno contra as hemorragias pós-parto
As mulheres com fatores de risco genéticos também apresentam um risco três a trinta vezes superior.
A gravidez geralmente agrava a diabetes e a doença pode-se tornar evidente durante a gravidez
Se não for tratada, a diabetes na gravidez está associada a uma maior incidência de malformações no feto, aborto espontâneo, natimortos, trabalho de parto prematuro e obesidade fetal
Mesmo com tratamento, mais de metade dos bebés de mães diabéticas têm sobrepeso ao nascer, o que também aumenta o risco de partos complicados
O risco de aborto espontâneo é maior caso a mãe seja diabética desde a infância, tenha diabetes há vários anos ou se tem doenças vasculares ou renais
As grávidas diabéticas apresentam maior risco de pré-eclampsia, eclampsia, infeções e poli-hidrâmnio
Uma tiroide demasiado ativa ou inativa, caso não seja tratada, pode estar associada a um maior risco de aborto espontâneo.
As doenças pulmonares podem constituir um risco para a gravidez no caso de diminuírem a quantidade de oxigénio fornecida ao feto, de causarem uma infeção sanguínea que é transmitida para a placenta e no caso de debilitarem a mãe de forma grave
As doenças do trato respiratório superior geralmente não interferem com a gravidez, a não ser que ocorram muito perto da data de parto, caso em que há a possibilidade de as transmitir para o bebé através dos órgãos genitais ou de contraírem uma infeção no sangue na sala hospitalar
A gripe durante a gravidez aumenta o risco de pneumonia, a qual apresenta um risco elevado de morte materna e fetal se a infeção for resistente a antibióticos
A gravidez tanto pode agravar como diminuir a gravidade da asma, enquanto algumas bronquites podem diminuir a quantidade de oxigénio inalada e fornecida ao feto.
As doenças neurológicas geralmente não têm efeitos sobre a gravidez e vice-versa
No entanto, algumas doenças neurológicas que se desenvolvam durante a gravidez podem ter efeito negativo
A gravidez pode agravar a epilepsia e as mulheres grávidas estão mais suscetíveis a poliomielite, embora não afete o curso da gravidez
A neuropatia periférica, resultante da insuficiência de vitamina B, pode complicar a gravidez, embora não afete a gestação
Perto do termo é comum a ocorrência de neuralgia que afeta principalmente o nervo ciático
Alguns distúrbios psiquiátricos em pessoas instáveis podem ser agravados pela gravidez
No entanto, raramente se manifestam problemas psiquiátricos sérios pela primeira vez durante a gravidez e as doenças psiquiátricas raramente têm influência na gestação.
Em 2012, ocorreram cerca de 213 milhões de gravidezes em todo o mundo, das quais 190 milhões em países em vias de desenvolvimento e 23 milhões nos países desenvolvidos
Isto corresponde a cerca de 133 gravidezes por cada 1000 mulheres entre os 15 e 44 anos de idade
Entre 10 e 15% do total de gravidezes terminam em aborto (espontâneo ou voluntário)
Cerca de 40% das gravidezes não foram planeadas
Cerca de metade das gravidezes não planeadas terminam em aborto
Em cada ano, estima-se que morram em todo o mundo cerca de 270 000 pessoas devido a complicações da gravidez.
A taxa de gravidez, assim como a idade a que ocorre, varia de país para país e de região para região e é influenciada por diversos fatores culturais, sociais e religiosos, pelo acesso à contraceção e pelo acesso à educação
Do total de gravidezes em 2012, 120 milhões ocorreram na Ásia, 54 milhões em África, 19 milhões na Europa, 18 milhões na América do Sul e Central, 7 milhões na América do Norte e 1 milhão na Oceania
No conjunto dos países em vias de desenvolvimento a taxa de gravidez é de 140 por cada 1000 mulheres em idade fértil, enquanto nos países desenvolvidos é de 94 por cada 1000
Em 2013, estimava-se que a maior taxa de fecundidade total pertencia ao Níger (7,03 crianças/mulher) e a menor a Singapura (0,79 crianças/mulher).
Em cada ano, cerca de 20 milhões de mulheres em todo o mundo são afetadas por complicações de uma gravidez
Em 2013, este tipo de complicações provocou a morte a 293 000 pessoas, uma diminuição em relação às 377 000 mortes em 1990
As causas de morte mais comuns são hemorragias obstétricas (44.000), complicações de abortos (44.000), pressão arterial elevada (29.000), sépsis neonatal (24000) e distócia (19.000).
Apesar de a reprodução ser um fenómeno essencialmente biológico, existem muitos fatores socioculturais influenciam o sucesso reprodutivo e o prognóstico da gravidez
Entre os fatores mais importantes estão a estrutura familiar e a situação conjugal
No entanto, esta estrutura familiar varia imenso consoante a época e a região
Em muitos países industrializados, a estrutura familiar tem-se alterado significativamente nas últimas décadas
Existe uma tendência para maior informalidade e instabilidade nas relações e para o aumento da idade do primeiro filho
O número de gravidezes de mães não casadas tem aumentado significativamente e é cada vez maior o número de crianças nascidas fora do casamento
Muitas religiões e cultos tradicionais associam à gravidez um significado espiritual profundo enquanto realização do mais elementar propósito do matrimónio
Neste processo de santificação, a gravidez é muitas vezes descrita como uma "bênção de Deus", "milagrosa" ou "divina"
A maior parte dos casais religiosos considera o casamento e a gravidez imbuídos de características sagradas.
Durante a gravidez começam-se a desenvolver os laços afetivos entre a mãe e o filho, principalmente após a observação da primeira ecografia e a sensação dos primeiros movimentos do bebé entre as 18 e as 25 semanas
Acredita-se que o feto em desenvolvimento é capaz de ouvir a voz e batimento cardíaco da mãe, podendo responder com pontapés ou movimentos voluntários
Ao sétimo mês de gravidez, dois terços das mães indicam possuir já uma forte ligação com o bebé
Nem todas as novas mães sentem um amor intenso e imediato pelo filho
Nestes casos, os laços afetivos vão-se fortalecendo ao longo do tempo
Os laços afetivos maternos são uma experiência que se vai desenvolvendo gradualmente e que pode demorar dias, semanas ou meses para se desenvolver.
O apoio do pai e a relação estreita com a mãe desempenham um papel significativo no bem-estar da gravidez, na saúde do feto, na paternidade, no ajustamento do casal e no desenvolvimento da criança
Apesar disso, o pai é frequentemente marginalizado da saúde reprodutiva e só muito recentemente é que o seu papel tem sido valorizado durante a gravidez e parto
O envolvimento paterno pode ter uma influência positiva durante a gravidez, podendo ser uma fonte de apoio
Em termos biológicos, os pais atravessam diversas alterações relacionadas com a gravidez ao nível da prolactina, cortisol e testosterona, que contribuem para o sentimento de fazer parte da gravidez
A presença, envolvimento e responsabilidade do pai tem impacto no desenvolvimento da cognição e linguagem da criança
Hoje em dia, em alguns países, os futuros pais são encorajados a acompanhar a mãe nas consultas pré-natais e a estarem presentes no parto e são propostas medidas que eliminem barreiras ao envolvimento paterno durante a gravidez e nascimento.
Na mulher, infertilidade é a incapacidade de engravidar ou de prosseguir uma gravidez até ao termo
No homem, é a incapacidade de fecundar o óvulo
Existem várias causas para infertilidade, incluindo algumas que podem ser tratadas através de reprodução medicamente assistida
Embora o intervalo de tempo para que se possa diagnosticar infertilidade possa variar entre países, a Organização Mundial de Saúde define infertilidade como a incapacidade de conceber uma gravidez clínica após doze ou mais meses de relações sexuais desprotegidas, sem que haja outros problemas de saúde
A infertilidade pode ter várias causas: infecções sexualmente transmissíveis que afetam o aparelho reprodutor como a clamídia, gonorreia, sífilis ou Mycoplasma genitalium; causas genéticas; e ambientais, como os danos ao ADN provocados pelo stress oxidativo ou pelo tabagismo.
Estima-se que um em cada sete casais tenha problemas de fertilidade
A infertilidade pode ter consequências psicológicas e sociais, como o aumento da ansiedade e dificuldades matrimoniais entre o casal, depressão, estigma social e disfunções sexuais
No entanto, os progressos na reprodução medicamente assistida oferecem uma esperança para muitos casais, embora existam barreiras em termos económicos e de disponibilidade em muitos países
O tratamento depende da causa de infertilidade, mas pode incluir aconselhamento profissional, medicação de fertilidade, cirurgia ou tratamentos de fertilidade, como a fertilização in vitro e a inseminação artificial
Os casais são geralmente aconselhados a procurar ajuda profissional ao fim de dois anos a tentar engravidar ou ao fim de um ano caso a mulher tenha mais de 30 anos de idade.
Embora as adolescentes grávidas enfrentem os mesmos desafios do que as restantes mulheres, existem riscos médicos acrescidos para as grávidas com idade inferior a 15 anos e riscos associados a fatores socioeconómicos para as mães entre os 15 e 19 anos de idade
Em países desenvolvidos, a gravidez na adolescência está muitas vezes associada a problemas sociais, incluindo menor nível de educação e maior pobreza, e ocorre geralmente fora do casamento, o que pode constituir um estigma social em muitas comunidades e culturas
A gravidez na adolescência é prevenida com educação sexual abrangente e acesso a métodos contracetivos
A educação sexual baseada apenas na abstinência sexual não aparenta ser eficaz.
Aborto é a interrupção da gravidez resultante da expulsão do feto ou do embrião do útero antes do momento de viabilidade fetal, ou do momento em que é capaz de sobreviver fora do útero
O aborto pode ocorrer de forma involuntária e espontânea, sendo denominado aborto espontâneo (ou interrupção involuntária da gravidez), ou pode ser induzido, sendo nesse caso denominado aborto induzido (ou interrupção voluntária da gravidez)
O uso do termo "aborto" geralmente refere-se a este último caso
Os métodos modernos recorrem a medicamentos abortivos ou cirurgia para induzir o aborto
Durante o primeiro trimestre, é comum a utilização de mifepristona e prostaglandina
Embora durante o segundo semestre os medicamentos sejam igualmente eficazes, a cirurgia apresenta menor risco de efeitos adversos
Uma vez realizado um aborto, os métodos contracetivos podem ser retomados de imediato
Quando permitido pela legislação, o aborto em países desenvolvidos é uma das intervenções médicas mais seguras que existem
Um aborto sem complicações não causa qualquer problema mental ou físico a longo prazo.
A Organização Mundial de Saúde recomenda que todas as mulheres tenham acesso a abortos legais e seguros
Todos os anos, os abortos feitos de forma insegura causam a morte a mais de 47 000 grávidas e são responsáveis por 5 milhões de entradas no hospital
No entanto, as perspetivas legais, culturais ou religiosas sobre o aborto são diferentes em todo o mundo
Enquanto em alguns países o aborto é legal, em outros é legal apenas em casos especiais como violação, malformações do feto, pobreza, risco para a saúde da mãe ou incesto
Existe um debate contínuo sobre os problemas morais, éticos e legais do aborto
As pessoas que se opõem ao aborto alegam que um embrião ou um feto é um ser humano com direito à vida
Por outro lado, os apoiantes mencionam os direitos humanos e o direito à mulher tomar as decisões sobre o seu próprio corpo.
A gravidez indesejada pode ter várias causas, incluindo a não utilização, utilização incorreta ou falha nos métodos contracetivos
Por sua vez, a não utilização ou utilização incorreta de contracetivos podem ser motivadas por falta de conhecimento sobre saúde reprodutiva, incluindo crenças erradas, a falta de disponibilidade, a crença equivocada de que a mulher é infértil
A gravidez indesejada pode também ser o resultado de coerção e violência contra a mulher, incluindo violação e gravidez forçada, que muitas vezes ocorre no contexto de violência doméstica.
A discriminação laboral na gravidez e na maternidade é uma situação frequente em vários locais no mundo
Entre algumas formas de discriminação estão a decisão de não contratar uma grávida apesar de ser a pessoa mais qualificada para determinado posto de trabalho, a decisão de não renovar um contrato por razões relacionadas com a gravidez ou perder o direito a bónus do emprego devido a complicações da gravidez ou à licença de maternidade
Também é comum algumas seguradoras terem um período de carência relativamente grande em situações de gravidez
Nos últimos vinte anos tem vindo a ser aprovada, principalmente na União Europeia, legislação e iniciativas de combate à discriminação da gravidez.
A licença parental é um direito no emprego existente em praticamente todos os países
A Convenção sobre a Eliminação de Todas as Formas de Discriminação contra as Mulheres determina que, após o parto, todas as mulheres têm direito a uma licença remunerada sem o risco de perder o posto de trabalho, a antiguidade no emprego ou prestações sociais
A Convenção da Proteção da Maternidade, adotada em 2000 pela Organização Internacional do Trabalho, determina uma duração mínima de 14 semanas para a licença de maternidade
A Carta dos Direitos Fundamentais da União Europeia afirma que a licença parental remunerada e a proteção do posto de trabalho a seguir à maternidade são direitos humanos.
Macrossomia fetal é uma doença que se caracteriza, principalmente, pelo excesso de peso de recém-nascidos
Foi definida de várias formas, incluindo o peso de nascimento de 4 kg - 4,5 kg
Fatores associados à macrossomia fetal incluem genética; duração da gestação, presença de diabetes gestacional, e classe A, B, C e diabetes mellitus
Genético, racial, étnica e de factores influenciam o peso ao nascer e ao risco de macrossomia.
A macrossomia está relacionado com a condição associada materna ou fetal que contabiliza o seu desenvolvimento
Em geral, a diabetes mal controlada, obesidade materna, e excessivo ganho de peso materno são todos associados com macrossomia e intermitentes períodos de hiperglicemia têm em comum
Hiperglicemia no feto resulta na estimulação da insulina, o hormônio do crescimento, e outros fatores de crescimento, o que, por sua vez, estimulam o crescimento fetal e deposição de gordura e glicogênio
Avançada idade gestacional resulta em um maior peso ao nascer na entrega possibilitando o crescimento pelo processo continue no útero.

Na literatura médica, sintoma é qualquer alteração da percepção normal que uma pessoa tem de seu próprio corpo, do seu metabolismo, de suas sensações, podendo ou não consistir-se em um início de doença
Em psicopatologia, sintoma é todo relato do paciente acerca de sensações ou sofrimento de cunho subjetivo apresentado durante a entrevista médica
Por ser subjetivo, relaciona-se com tudo que não pode ser mensurado ou objetivamente observado, mas, naturalmente, não pode ser desprezado, pois trata-se de uma queixa válida do paciente.
Sintomas são frequentemente confundidos com sinais, que são as alterações percebidas ou medidas por outra pessoa, geralmente um profissional de saúde
A diferença entre sintoma e sinal é que o sinal é aquilo que pode ser percebido por outra pessoa sem o relato ou comunicação do paciente e o sintoma é a queixa relatada pelo paciente mas que só ele consegue perceber.
Sintomas são subjetivos, sujeitos à interpretação do próprio paciente
A variabilidade descritiva dos sintomas varia enormemente em função da cultura do paciente, assim como da valorização que cada pessoa dá às suas próprias percepções.
Quando de um atendimento de alguém por um profissional de saúde, compete ao profissional saber colher as informações necessárias ao pleno conhecimento das características dos sintomas.


Sintoma também pode ser entendido como sinônimo de índice
Na Semiótica, a ciência geral dos signos, índices e sintomas são signos em que a relação entre significado e significante não é arbitrária, mas sim determinada pela experiência vivenciada pelo interpretador ou pela contiguidade de fato entre dois elementos.
A identificação dos Sintomas faz-se essencialmente, pelo interrogatório do paciente, pois, sem seu relato ou qualquer outra forma de comunicação lúcida, é impossível conhecê-los
Em poucas áreas do conhecimento da saúde, como a Neonatologia, por exemplo, não ocorre a identificação dos sintomas, uma vez que o seu paciente, recém nascido, não se comunica de modo lúcido
A etimologia da palavra (Sintoma) vem do grego
'Sin' = junção e 'Tomo' = pedaços
Ou seja, a palavra sintoma tem a ver com juntar as peças de várias sinalizações orgânicas ou psíquicas, mediante um doença; assim como num quebra-cabeças.
A caracterização dos sintomas baseia-se em sete princípios ou componentes dos sintomas, a saber:
Cronologia, Localização Corporal, Qualidade, Quantidade, Circunstâncias, Fatores Agravantes ou atenuantes e Manifestações Associadas.

Perda de peso, no contexto da medicina, é a redução do peso corporal total, que pode acontecer devido à perda de fluidos, massa muscular, massa óssea ou gordura
Nem sempre a perda de peso é algo desejado, sendo desta forma, sinal de alerta para algum problema de saúde.

A palavra fadiga é usada cotidianamente para descrever uma série de males subjetivos intrínsecos que vão desde um estado genérico de letargia até uma sensação específica de calor nos músculos provocada pelo trabalho intenso
Fisiologicamente, "fadiga" descreve a incapacidade de continuar funcionando ao nível normal da capacidade pessoal devido a uma percepção ampliada do esforço
Fadiga é onipresente na vida cotidiana, mas geralmente torna-se particularmente perceptível durante exercícios pesados
É o chamado esgotamento, na essência da palavra.
A fadiga possui duas formas; uma se manifesta como uma incapacidade muscular local para desenvolver um trabalho e a outra se manifesta como uma sensação abrangente de falta de energia, corporal ou sistêmica
Devido a estas duas facetas divergentes de sintomas de fadiga, tem sido proposto que as causas da fadiga sejam encaradas sob perspectivas "central" e "periférica".
A fadiga pode ser perigosa quando são realizadas tarefas que demandem concentração constante, tais como dirigir um veículo
Quando uma pessoa está suficientemente fatigada, ele ou ela pode experimentar períodos de microssono (perda de concentração)
Todavia, testes cognitivos objetivos deverão ser feitos para diferenciar os déficits neurocognitivos dos males cerebrais daqueles atribuíveis ao cansaço.
Acredita-se que a sensação de fadiga origina-se no sistema ativador reticular na base do cérebro
Estruturas musculo-esqueléticas podem ter co-evoluído com estruturas cerebrais apropriadas de modo que todo o conjunto funcione de forma construtiva e adaptativa
Os sistemas conjuntos de músculos, juntas e funções proprioceptivas e cinestésicas mais partes do cérebro evoluem e funcionam conjuntamente de forma unitária).


Existem dois tipos principais de fadiga: central e periférica
Estes tipos de fadiga são bastante importantes, no caso do desporto influenciam bastante o desempenho do atleta.
Catarata é uma opacificação do cristalino do olho que causa diminuição da capacidade visual
Pode afetar um ou ambos os olhos e é frequente desenvolver-se lentamente
Os sintomas podem incluir visão desfocada, diminuição de sensibilidade às cores, halos à volta das luzes, dificuldade em observar luzes brilhantes e dificuldade em ver durante a noite.Isto poderá afetar a condução, leitura, ou reconhecimento de rostos
A diminuição da capacidade visual pode também aumentar o risco de acidentes e depressão
As cataratas são a causa de metade dos casos de cegueira e de um terços dos casos de incapacidade visual em todo o mundo.
As cataratas são formadas por depósitos de proteínas ou pigmentos amarelados no cristalino, que diminuem a transmissão de luz para a retina na parte de trás do olho
A maior parte dos casos de cataratas deve-se ao envelhecimento da pessoa, mas a doença pode também ter origem em traumas ou exposição à radiação, estar presente desde o nascimento ou ocorrer na sequência de uma cirurgia ocular ou de outros problemas
Entre os fatores de risco estão a diabetes, fumar, a exposição prolongada à luz do sol e o consumo de bebidas alcoólicas
O diagnóstico é realizado através de um exame ocular.
As medidas de prevenção incluem o uso de óculos de sol e deixar de fumar
Na fase inicial os sintomas podem ser aliviados com o uso de óculos
Quando os óculos não resultam, o único tratamento eficaz é uma cirurgia para remover o cristalino opaco e substituí-lo por uma lente artificial
A cirurgia só é necessária nos casos em que as cataratas causam problemas
A cirurgia geralmente melhora a qualidade de vida
No entanto, em muitos países não é facilmente acessível, principalmente para mulheres, para pessoas que vivem no meio rural e para pessoas que não conseguem ler.
Em todo o mundo há cerca de 20 milhões de pessoas com cegueira provocada por cataratas
A doença é a causa de 5% dos casos de cegueira nos Estados Unidos e de cerca de 60% em partes de África e da América do Sul
A cegueira causada por cataratas afeta entre 10 a 40 em cada 100 000 crianças nos países em vias de desenvolvimento e entre 1 a 4 em cada 100 000 nos países desenvolvidos
As cataratas tornam-se mais comuns com a idade
Nos Estados Unidos, cerca de metade das pessoas com 80 anos apresenta cataratas.

pálpebra: inflamação (Hordéolo, Calázio, Blefarite) - Entrópio - Ectrópio - Lagoftalmo - Blefarocalásia - Ptose - Blefarofimose - Xantelasma - Triquíase
sistema lacrimal: Dacrioadenite - Epífora - Dacriocistite
Estrabismo paralítico: Oftalmoparesia - Oftalmoplegia externa progressiva - Paralisia (III, IV, VI) - Síndrome de Kearns-Sayre Outros estrabismos: Esotropia/Exotropia - Hipertropia - Heterophoria (Esophoria, Exoforia) - Síndrome de Brown - Síndrome de Duane
Outras binoculares: Paralisia do olhar conjugado - Insuficiência de convergência - Oftalmoplegia internuclear - Síndrome do um e meio
Glaucoma é uma designação genérica a um grupo de doenças oculares distintas que provocam danos ao nervo ótico e perda da visão
O tipo mais comum é o glaucoma de ângulo aberto, e os menos comuns são o glaucoma de ângulo fechado e glaucoma de pressão (ou tensão) normal
O primeiro tipo desenvolve-se lentamente e é assintomático durante a maior parte de sua evolução
Com o tempo, entretanto, a visão periférica do indivíduo acometido começa a ficar comprometida e ocorre um estreitamento progressivo do campo visual, evoluindo a visão tubular ou central e, se não houver tratamento, cegueira
Já o glaucoma de ângulo fechado pode cursar de forma crônica ou aguda
A apresentação aguda pode envolver dor ocular intensa, cefaleia, visão turva, halos coloridos, náusea e vômitos
A perda da visão pelo glaucoma, uma vez que tenha ocorrido, é permanente.
Os fatores de risco ao glaucoma incluem o aumento da pressão intraocular (PIO), histórico familiar, enxaqueca, hipertensão arterial e obesidade
Indivíduos com PIO superior a 21 mmHg ou 2,8 kPa são considerados hipertensos oculares e, portanto, com maior risco de desenvolver glaucoma
Entanto, alguns podem ter PIO aumentada durante anos sem desenvolver nenhum dano
Por outro lado, danos ao nervo ótico podem ocorrer com PIO dentro dos limites da normalidade, no chamado glaucoma de pressão normal
Crê-se que o mecanismo que desencadeia o glaucoma de ângulo aberto seja uma obstrução do escoamento do humor aquoso através da malha trabecular, enquanto que no glaucoma de ângulo fechado a dilatação da pupila bloqueia o fluxo do fluido através dela, levando à íris bloquear a malha trabecular
O diagnóstico é feito pelo exame de fundo de olho, que mostra um aumento da escavação do disco ótico, indicando dano ao nervo ótico.
Se tratado precocemente, é possível retardar ou frear a progressão da doença, utilizando-se terapia medicamentosa, tratamento a laser ou cirurgia com o objetivo de reduzir a PIO
Tratamentos a laser podem ser eficazes, tanto nos glaucomas de ângulo aberto, quanto nos de ângulo fechado
A intervenção cirúrgica somente é utilizada em indivíduos que não respondem adequadamente aos outros tratamentos
Os casos de glaucoma de ângulo fechado devem ser tratados como emergência médica.
Cerca de 11 a 67 milhões de pessoas sofrem de glaucoma em todo o mundo
Estima-se 2 milhões de pessoas afetadas pela doença nos Estados Unidos, 900 mil no Brasil e 100 mil em Portugal
É a segunda causa de cegueira em todo o mundo (a primeira é a catarata) e acomete principalmente indivíduos idosos, sendo que o glaucoma de ângulo fechado é mais comum nas mulheres
Como a perda da visão ocorre lentamente durante um longo período de tempo, o glaucoma também é chamado de "ladrão silencioso da visão"
A palavra "glaucoma" vem do grego antigo glaukos que significa azul, verde ou cinza
Em inglês, a palavra foi usada pela primeira vez em 1587, mas não era de uso corrente até depois de 1850, quando o desenvolvimento do oftalmoscópio passou a permitir o exame do nervo ótico.


Enquanto o glaucoma pode ou não ter sintomas distintos, uma complicação quase inevitável é a perda visual
A perda visual causada por glaucoma atinge primeiro a visão periférica
No começo a perda é sutil, e pode não ser percebida pelo paciente
Perdas moderadas a severas podem ser notadas pelo paciente através de exames atentos da sua visão periférica
Isso pode ser feito fechando um olho e examinando todos os quatro cantos do campo visual notando claridade e acuidade, e então repetindo o processo com o outro olho fechado.
Frequentemente, o paciente não nota a perda de visão até vivenciar a "visão tunelada"
Se a doença não for tratada, o campo visual se estreita cada vez mais, obscurecendo a visão central e finalmente progredindo à cegueira do olho afetado
Esperar pelos sintomas de perda visual não é o ideal
A perda visual causada pelo glaucoma é irreversível, mas pode ser prevenida ou atrasada por tratamento
Um oftalmologista deve ser consultado pelas pessoas com risco de desenvolver glaucoma, especialmente idosos e diabéticos.
É o tipo mais comum de glaucoma, representando cerca de 90% dos casos registrados, e frequentemente começando sem sintomas e demorando muitos anos para causar perda visual perceptível
Uma das causas pode ser uma obstrução da drenagem do humor aquoso do olho
O humor aquoso é produzido no corpo ciliar do olho, fluindo através da pupila para a câmera anterior
A malha trabecular então drena o líquido para o canal de Schlemm e finalmente para o sistema venoso.
Todos os olhos possuem alguma pressão intraocular que é causada pela presença de alguma resistência ao fluxo do humor aquoso através da malha trabecular e do canal de Schlemm
Se a pressão intraocular (PIO) for alta demais (maior do que 21,5 mm Hg), a pressão nas paredes do olho resultará na compressão das estruturas oculares
Entretanto, outros fatores, como perturbações no fluxo sanguíneo no nervo óptico podem interagir com a PIO e afetar o nervo óptico
Em um terço dos casos de glaucoma primário de ângulo aberto há PIO estatisticamente normal
Esses casos são chamados de glaucoma de pressão normal
Devido ao fato de exames do nervo óptico nem sempre serem realizados juntamente com medidas de PIO em pacientes de risco, o glaucoma de pressão normal é mais raramente diagnosticado até as condições se apresentarem adiantadas.
Caracterizado por um aumento súbitos da pressão intraocular
Isto ocorre em olhos susceptíveis quando a pupila dilata e bloqueia o fluxo do fluido através dela, levando à íris a bloquear a malha trabecular
Glaucoma de ângulo fechado pode causar dor e reduzir a acuidade visual (visão borrada) e pode levar à perda visual irreversível dentro de um curto período de tempo
É considerada uma situação de emergência oftalmológica e requer tratamento imediato
Muitas pessoas com esse glaucoma podem visualizar um halo (aro brilhante) em volta de pontos de luz brilhantes, além da perda de visão característica da doença.
É uma doença genética rara que atinge bebês
Recém nascidos com globos oculares aumentados e córneas embaçadas
Se considera que a causa da pressão intraocular elevada nesses casos é causada pela redução da permeabilidade trabecular
O tratamento é a cirurgia
Normalmente a criança já nasce com a doença, geralmente adquirida no período da gestação decorrente da má formação nos olhos.
Ocorre como uma complicação de várias condições médicas, como cirurgia ocular, catarata avançada, tumor, inflamações, lesões oculares, uveítes, diabetes ou pelo uso excessivo de medicamentos à base de corticoides.
Pessoas com histórico familiar de glaucoma têm cerca de 6% de chance de desenvolver a doença; Diabéticos e negros são mais propensos a desenvolverem glaucoma de ângulo aberto, e asiáticos têm maior tendência a desenvolver glaucoma de ângulo fechado
Idealmente, todas as pessoas devem verificar por glaucoma a partir dos 50 anos, com a frequência das checagens aumentando com a idade
Metade das pessoas que sofrem de glaucoma não sabem disso.
Verificação de glaucoma normalmente é parte do exame ocular padrão feito por um oftalmologista
A verificação de glaucoma deve incluir medida da pressão intraocular, além do exame do nervo óptico em busca de lesões
Se houver qualquer suspeita de lesão no nervo óptico deve ser feita uma campimetria
A oftalmoscopia a laser também pode ser realizada
Tomografia da cabeça também pode ser feita para buscar outras causas de pressão alta no crânio
Outros procedimentos para garantir o diagnóstico de glaucoma podem variar de acordo com os sintomas e histórico do paciente.
Diminuir a pressão intraocular elevada até o momento é o principal tratamento
A pressão intraocular pode ser diminuída com medicamentos,geralmente com colírios
Caso a pressão não diminua com o uso desses medicamentos, uma cirurgia poderá ser indicada, tanto a cirurgia a laser (trabeculoplastia),desobstrui a circulação do humor aquoso e costuma ser indolor, quanto a tradicional (trabeculectomia) ou mesmo uma cirurgia iridotomia (também a laser) que faz a abertura de um novo canal para a circulação do líquido ocular.
Para o glaucoma de ângulo fechado, na maioria das vezes, o paciente vai precisar de intervenções com medicamentos intravenosos
Algumas pessoas podem ser submetidas a cirurgias de emergência para diminuir instantaneamente a pressão ocular.
O glaucoma congênito, herdado pela mãe durante o período de gestação, sempre vai precisar de cirurgia para tratar os canais de circulação do líquido ocular.
Pressão intraocular pode ser diminuída com medicamentos, em geral, colírios
Há diversas classes diferentes de medicamentos para tratar glaucoma, com diversos medicamentos em cada classe
Antagonistas adrenérgico beta de uso tópico, como o timolol e o betaxolol diminuem a produção de humor aquoso
Medicamentos simpatomiméticos menos seletivos, como a epinefrina, aumentam o fluxo do humor aquoso através da malha trabecular e possivelmente através da via úveo-escleral
Agentes mióticos parassimpatomiméticos como a pilocarpina funcionam pela contração do músculo ciliar, estreitando a malha trabecular e permitindo o aumento do fluxo através das vias tradicionais
Inibidores da anidrase carbônica, como a dorzolamida, diminuem a secreção do humor aquoso pela inibição da anidrase carbônica no corpo ciliar
Análogas da prostaglandina, como o latanoproste, aumentam o escoamento do humor aquoso pela via úveo-escleral.
Efeitos Colaterais do fármacos antiglaucomatosos A maioria das medicações para o glaucoma é administrada topicamente
Como regra geral, o tratamento esta indicado sempre que houver a possibilidade de ocorrer lesão glaucomatosa
A decisão sobre qual medicamento prescrever depende não só do tipo de glaucoma, mas também do histórico medico do paciente (p.ex., presença de asma ou bradicardia), o que requer um conhecimento detalhado sobre os seus efeitos colaterais em potencial, sendo assim seguem os efeitos colaterais dos principais fármacos utilizados no glaucoma
Betabloqueadores 1 - Efeitos colaterais oculares incluem alergia ocasional, erosões epiteliais ponteadas da córnea e redução da secreção lacrimal
2 - Efeitos colaterais sistêmicos costumam ocorrer durante a primeira semana de tratamento
Apesar de incomuns, podem ser sérios
Bradicardia e hipotensão podem resultar do bloqueio dos receptores beta-1
É preciso palpar o pulso do paciente antes de prescrever um betabloqueador
Broncoespasmo pode ser induzido por bloqueio dos receptores beta-2, podendo ser fatal em asma preexistente ou doença pulmonar obstrutiva grave
Efeitos colaterais variados incluem distúrbios do sono, alucinações, confusão, depressão, fadiga, cefaleia, náusea, vertigem, redução da libido e possivelmente redução dos níveis séricos de lipoproteínas de alta densidade
3 – Redução da absorção sistêmica da droga pode ser conseguida com: oclusão lacrimal após instilação, obtida fechando-se os olhos e aplicando-se pressão digital sobre a região do saco lacrimal por 3 minutos
Além da redução da absorção sistêmica da droga, esta manobra também prolonga o tempo de contato da droga com o olho, aumentando sua eficácia terapêutica
Simplesmente fechar os olhos por 3 minutos, a absorção sistêmica ira reduzir-se em 50%
4 – As contraindicações para o uso de betabloqueadores incluem: insuficiência cardíaca congestiva, bloqueio cardíaco de segundo ou terceiro grau, bradicardia, asma e doença obstrutiva das vias aéreas
Os betabloqueadores não devem ser usados na hora de dormir porque podem causar uma queda profunda na pressão sanguínea enquanto o paciente esta dormindo, reduzindo, assim, a perfusão do disco óptico e podendo levar a deterioração da visão
Agonistas alfa-2 1 – Brimonidina: seu efeito colateral mais comum é a conjuntivite alérgica, que pode levar até um ano para se manifestar
Há relatos de uveíte anterior granulomatosa aguda
Efeitos colaterais sistêmicos incluem xerostomia, sonolência e fadiga
Análogos de prostaglandinas e prostamidas 1 - Efeitos colaterais Oculares Hiperemia conjuntival e uma sensação de corpo estranho são comuns; aumento, espessamento e hiperpigmentação de cílios; hiperpigmentação irreversível da íris em 11 a 23% dos pacientes após seis meses; edema macular cistoide; uveíte anterior; hiperpigmentação conjuntival 2 – Efeitos colaterais sistêmicos Podem estar presentes cefaleias ocasionais, precipitação de enxaqueca em indivíduos susceptíveis, rash cutâneo e sintomas leves do trato respiratório superior
Essas formulações não devem sem usadas em gestantes, pois estudos com modelos animais mostraram efeitos teratogênicos em potencial
Mióticos Os efeitos colaterais incluem miose, dor supraorbitária, miopia induzida e exacerbação dos sintomas de catarata
Defeitos de campo visual aparecem mais densos e maiores.
Inibidores sistêmicos da anidrase carbônica (IAC) O uso prolongado dos inibidores da anidrase carbônica é frequentemente limitado pelos efeitos colaterais sistêmicos para pacientes com alto risco de perda visual
O paciente deve ser sempre avisado sobre os possíveis efeitos colaterais, desta forma reduzindo a ansiedade e melhorando a adesão
1 – Parestesia é caracterizada por formigamento dos dedos das mãos e dos pés, ocasionalmente das junções mucocutâneas
É um achado universal e geralmente inócuo
Caso o paciente não relate este sintoma, questionamos sua adesão ao tratamento
2 – Síndrome de indisposição pe caracterizada por uma combinação de mal-estar, fadiga, depressão, perda de peso e redução da libido
Duas semanas de acetato de sódio suplementar podem ser úteis
3 – Síndrome gastrointestinal é caracterizada por irritação gástrica, cólicas abdominais, diarreia e náuseas
Pode ocorrer independente da síndrome de indisposição, e não esta relacionada com alterações especificas na química sanguínea 
4 - Formação de cálculos renais é incomum 5 - Síndrome de Stevens-Johnson pode ocorrer, pois os IACs são derivados das sulfonamidas
6 - Discrasias sanguíneas são raras e podem ser de dois tipos: Supressão da medula óssea relacionada com a dose, a qual geralmente reverte com a interrupção do tratamento
Anemia aplásica idiossincrásica não é dependente de dose e tem mortalidade de 50%
Pode ocorrer após uma única dose, mas geralmente se instala durante os 2-3 primeiros meses, e, muito raramente, após seis meses de tratamento
Agentes Osmóticos 1 – Sobrecarga cardíaca pode ocorrer como resultado do aumento do volume extracelular
Agentes osmóticos devem, portanto, se usados com cautela em pacientes com doença cardíaca ou renal
2 – Retenção urinaria pode afetar homens idosos após administração intravenosa
Cauterização pode ser necessária naqueles com prostatismo
3 – Efeitos colaterais variados incluem cefaleia, dor nas costas, náusea e confusão mental
"Fonte: KANSKI, Jack J
Oftalmologia Clínica: uma abordagem sistemática
6
Ed
Rio de Janeiro: Elsevier, 2008
P
372 – 440."
Todos os medicamentos usados para controlar o glaucoma provocam sérios efeitos colaterais
Uma importante pesquisa de R.S.Hepler e I.M
Frank revelou que apenas a cannabis não provoca tais efeitos
Eles observaram que trinta minutos depois de fumar cannabis a pressão intraocular reduzia em aproximadamente 25%, o fluxo lacrimal e a pressão ocular rítmica reduziam em 50%, sem desenvolvimento de tolerância (sem necessidade de aumento da dose para obter o mesmo efeito)
Extratos de cannabis administrados oralmente, por via endovenosa ou por aplicação tópica causavam o mesmo efeito.
Fonte: R.S.Hepler e I.M.Frank,1971
Apud Robinson, Rowan, O grande livro da cannabis: guia completo de seu uso industrial, medicinal e ambiental, Rio de Janeiro: Jorge Zahar Ed, 1999, p 33.
Tanto a cirurgia a laser quanto a tradicional podem ser realizadas para o tratamento de glaucoma
A trabeculoplastia laser pode ser utilizada para tratamento de glaucoma de ângulo aberto
Um ponto de laser de argônio é apontado à malha trabecular para estimular a abertura da malha e permitir um aumento no escoamento do humor aquoso.
A cirurgia convencional mais comum realizada para tratamento de glaucoma é a trabeculectomia
Nela, uma câmara (bolha) é feita na parede escleral do olho, e uma abertura é feita abaixo da bolha para remover a porção da malha trabecular
A bolha é então suturada frouxamente de volta
Isso permite o fluido escoar para fora do olho através desta abertura, resultando em diminuição da pressão intraocular.
Pacientes diagnosticados com glaucoma devem tomar os cuidados necessários para manter a qualidade de vida e prevenir a evolução da doença
Segundo um estudo da Evidências - Kantar Health, os portadores da doença costumam ter uma perda de 36% na produtividade do trabalho e 33% enfrentam limitações para a realização de atividades diárias
Os pacientes também costumam usar mais o sistema de saúde, com mais visitas ao pronto-socorro, maior taxa de consultas médias ambulatoriais e hospitalizações
Para conseguir manter a qualidade de vida apesar dos desafios da doença, é importante ter uma alimentação adequada, com vitaminas e nutrientes que ajudam na qualidade da visão
Além disso, manter exercícios físicos regulares ajudam a reduzir a pressão ocular, principalmente nos casos de glaucoma com ângulo aberto.Embora a doença não tenha cura, o tratamento pode ser muito favorável se levado com responsabilidade, obedecendo os horários dos medicamentos e orientações médicas.
Glaucomas atingem cerca de 1% das pessoas entre 43 e 54 anos, 2,1% entre 54 e 75 e 4,7% em maiores de 75 anos
Mais de 90% sendo do tipo ângulo aberto.

pálpebra: inflamação (Hordéolo, Calázio, Blefarite) - Entrópio - Ectrópio - Lagoftalmo - Blefarocalásia - Ptose - Blefarofimose - Xantelasma - Triquíase
sistema lacrimal: Dacrioadenite - Epífora - Dacriocistite
Estrabismo paralítico: Oftalmoparesia - Oftalmoplegia externa progressiva - Paralisia (III, IV, VI) - Síndrome de Kearns-Sayre Outros estrabismos: Esotropia/Exotropia - Hipertropia - Heterophoria (Esophoria, Exoforia) - Síndrome de Brown - Síndrome de Duane
Outras binoculares: Paralisia do olhar conjugado - Insuficiência de convergência - Oftalmoplegia internuclear - Síndrome do um e meio

Deficiência visual ou perda visual é a perda ou diminuição grave e irreversível da função visual que não é corrigível com lentes ou cirurgia e que interfere com as tarefas do dia-a-dia
A perda visual pode ser súbita e grave ou ser o resultado de uma deterioração gradual, em que objetos a grande distância se tornam cada vez mais difíceis de ver
A condição causa à pessoa dificuldades em realizar atividades do dia-a-dia, como conduzir veículos, ler, socializar ou deslocar-se a pé
A deficiência visual engloba todas as condições em que existe comprometimento da visão
A Organização Mundial de Saúde classifica a deficiência visual em seis graus de acordo com a acuidade visual (AV) da pessoa
Quando a perda de visão é parcial denomina-se visão subnormal
A visão subnormal pode ser ligeira, moderada ou grave
Quando a perda de visão é total ou quase total denomina-se cegueira
A cegueira divide-se em cegueira profunda, quase total e total
A maior parte dos cegos possui alguma função visual e percebe luzes, sombras e movimento
Só uma pequena percentagem é que não possui qualquer sensação visual.
As causas mais comuns de perda visual são erros refrativos não corrigidos em tempo útil (43%), cataratas (33%) e glaucoma (2%)
Os erros refrativos mais comuns são a miopia, hipermetropia, presbiopia e astigmatismo
As cataratas são a causa mais comum de cegueira
Entre outras possíveis doenças que causam perda visual estão a degeneração macular relacionada com a idade, retinopatia diabética, opacidade da córnea, cegueira infantil e diversas infeções
A perda visual pode ainda ser causada por problemas neurológicos na sequência de um acidente vascular cerebral, parto prematuro ou trauma, entre outros
Estes casos denominam-se deficiência visual cortical
O diagnóstico de perda visual baseia-se em exames oculares
O rastreio visual em crianças permite corrigir atempadamente os problemas de visão e inverter o insucesso escolar que daí resulta
No entanto, os benefícios do rastreio em adultos não são claros.
Estima-se que 80% dos casos de deficiência visual sejam evitáveis ou tratáveis
Nos casos evitáveis inclui-se a perda visual causada por cataratas, tracoma, oncocercose, glaucoma, retinipatia diabética e alguns casos de cegueira infantil
A muitas pessoas com perda visual profunda é recomendada a reabilitação funcional, alterações no ambiente e utilização de equipamentos auxiliares.
Em 2015 havia 940 milhões de pessoas em todo o mundo com algum grau de perda visual
Entre estas, havia 246 milhões com défice de visão e 39 milhões com cegueira
A maioria das pessoas com dificuldades de visão encontram-se nos países em vias de desenvolvimento e têm mais de 50 anos de idade
A prevalência de deficiência visual tem vindo a diminuir desde a década de 1990
A condição tem custos económicos elevados, derivdados não só do custo do tratamento em si, como também da incapacidade para o trabalho
Algumas definições incluem pessoas com dificuldades de visão por não terem acesso a óculos ou lentes de contacto.


Segundo a 10 ª Revisão da OMS de Classificação Estatística Internacional de Doenças, Lesões e Causas de Morte, a visão subnormal é definida como acuidade visual inferior a 20/60 (6/18), mas igual ou melhor que 20/200 (6/60), ou correspondente a perda de campo visual menor que 20 graus, no melhor olho com a melhor correção possível
A cegueira é definida como acuidade visual menor que 20/400 (6/120), ou correspondente a perda de campo visual menor que 10 graus, no melhor olho com a melhor correção possível.
Cegueira é a condição de falta de percepção visual, devido a fatores fisiológicos ou neurológicos
Várias escalas têm sido desenvolvidas para descrever a extensão da perda de visão e definir a cegueira
Cegueira total é a completa falta de percepção visual de forma e luz e é clinicamente registrado como NLP, uma abreviação para "no light perception" (sem percepção de luz)
Cegueira é frequentemente usada para descrever a deficiência visual grave, com visão residual
Aqueles descritos como tendo apenas percepção de luz têm apenas a capacidade de diferenciar o claro do escuro e a direção de uma fonte de luz.
A cegueira é definida pela Organização Mundial de Saúde como visão menor que 20/500 no melhor olho de um pessoa ou campo visual inferior a 10 graus
Esta definição foi criada em 1972 e há uma discussão em curso sobre se ela deve ser alterada.
Deficiência visual é uma categoria que abrange pessoas cegas e com visão reduzida
Na definição pedagógica, a pessoa é cega, mesmo possuindo visão subnormal, quando necessita da instrução em braile; a pessoa com visão subnormal pode ler tipos impressos ampliados ou com auxílio de potentes recursos ópticos.
A definição clínica define como cego o indivíduo que apresenta acuidade visual menor que 0,1 (com a melhor correção no melhor olho) ou campo visual abaixo de 20 graus; como visão reduzida quem possui acuidade visual de 6/60 e 18/60 (escala métrica) e/ou um campo visual entre 20 e 50 graus, e sua visão não pode ser corrigida por tratamento clínico nem com óculos convencionais.
Cegueira pode ocorrer diante de algumas condições tais como retardo mental, espectro autista, paralisia cerebral, surdez e epilepsia
Em um estudo com 228 crianças com deficiência visual na região metropolitana de Atlanta entre 1991 e 1993, 154 (68%) tinha uma deficiência adicional além da deficiência visual
Cegueira em combinação com a perda auditiva é conhecida como surdocegueira.
Deficiência visual grave possui uma variedade de causas:
De acordo com estimativas da OMS, as causas mais comuns de cegueira em todo o mundo em 2002 foram:
Em termos de prevalência mundial de cegueira, a um número muito maior de pessoas e maior probabilidade de serem afetadas em países em desenvolvimento, significa que as causas de cegueira nessas áreas são numericamente mais importantes
A catarata é responsável por mais de 22 milhões de casos de cegueira e glaucoma seis milhões, enquanto que a lepra e oncocercose cegam aproximadamente um milhão de indivíduos em todo o mundo
O número de indivíduos cegos por tracoma caiu drasticamente nos últimos 10 anos de seis para 1,3 milhões, colocando-o em sétimo lugar na lista de causas de cegueira no mundo
É estimado que a xeroftalmia afete cinco milhões de crianças a cada ano; 500 mil desenvolvem o envolvimento da córnea ativa, e metade destes tornam-se cegos
Ulceração da córnea central é também uma importante causa da cegueira monocular no mundo, o que representa uma estimativa de 850 mil casos de cegueira corneal todos os anos apenas na Índia
Como resultado, as cicatrizes corneanas por todas as causas agora são a quarta maior causa global da cegueira.
A degeneração macular relacionada à idade (DMRI) é uma doença degenerativa da retina que provoca uma perda progressiva da visão central e leva a cegueira
Atualmente é apontada como a causa mais comum de perda de visão nas pessoas acima de 55 anos
Segundo dados da Foundation Fighting Blindness, 10 milhões de pessoas nos EUA tem DMRI ou possuem risco considerável de desenvolver a doença
Estima-se que no ano de 2020, até 8 milhões de pessoas com 65 anos ou mais poderão apresentar DMRI
A taxa de acometimento pela DMRI aumenta com a idade.
Pessoas nos países em desenvolvimento são significativamente mais propensas a adquirir a deficiência visual como consequência de doenças tratáveis ou evitáveis do que suas contrapartes em países desenvolvidos
Enquanto a deficiência visual é mais comum em pessoas com mais de 60 anos de idade em todas as regiões, as crianças em comunidades mais pobres são mais propensas a serem afetadas do que seus pares mais ricos.
A ligação entre pobreza e deficiência visual tratável é mais evidente quando se realizam comparações regionais sobre a causa
A maioria dos adultos com deficiência visual na América do Norte e na Europa Ocidental tem como causa degeneração macular relacionada à idade e retinopatia diabética
Enquanto ambas as condições estão sujeitos a tratamento, nenhuma delas pode ser curada.
Nos países em desenvolvimento, onde as pessoas têm menor expectativa de vida, catarata e parasitas transmitidos pela água —ambas podem ser tratadas eficazmente— são na maioria das vezes os culpados
Em países desenvolvidos, onde doenças parasitárias são menos comuns e cirurgia de catarata é mais disponível, a degeneração macular relacionada à idade, glaucoma e retinopatia diabética são geralmente as principais causas da cegueira.
Cegueira infantil pode ser causada por condições relacionadas à gravidez, tais como a síndrome da rubéola congênita e retinopatia da prematuridade.
Lesões nos olhos, na maioria das vezes ocorrem em pessoas com menos de 30, são a principal causa de cegueira monocular (perda de visão em um olho) em todo o Estados Unidos
Lesões e cataratas afetam o olho em si, enquanto anormalidades tais como hipoplasia do nervo óptico afetam o feixe nervoso que envia sinais do olho para trás do cérebro, que pode levar à diminuição da acuidade visual.
Pessoas com lesões no lóbulo occipital do cérebro podem, apesar de terem os olhos e nervos ópticos danificados, ainda serem legalmente ou totalmente cegos.
Pessoas com albinismo têm frequentemente perda de visão e muitos são legalmente cegos, embora poucos deles realmente não possam ver
Neuropatia óptica hereditária de Leber pode causar cegueira total ou perda de visão grave desde o nascimento ou na infância.
Os recentes avanços no mapeamento do genoma humano identificaram outras causas genéticas de baixa visão ou cegueira
Um exemplo é a síndrome de Bardet-Biedl.
Raramente, a cegueira é causada pela ingestão de determinados produtos químicos
Um exemplo bem conhecido é o metanol, que é apenas levemente tóxico e minimamente intoxicante, mas não quando o etanol compete com o metabolismo, metanol decompõe-se em formaldeído e ácido fórmico substâncias que por sua vez pode causar cegueira, uma série de outras complicações de saúde e até a morte
O metanol é comumente encontrado em bebidas alcoólicas, o álcool etílico desnaturado, para evitar pagar impostos sobre a venda de etanol destinados ao consumo humano
Álcool etílico é por vezes usado por alcoólatras como um substituto desesperado e barato para bebidas alcoólicas.
Cegueira tem sido usada como um ato de vingança e tortura em alguns casos, para privar uma pessoa de um sentido importante pelo qual ela pode guiar-se ou interagir com o mundo, agir com total independência e estar ciente dos acontecimentos que os rodeiam
Um exemplo da esfera clássica é Édipo, que fura seus próprios olhos após perceber que cumpriu a terrível profecia sobre ele
Assassino de búlgaros, o imperador bizantino Basílio II Bulgaróctono cegou 15 mil prisioneiros, antes de libertá-los.
Em 2003, um tribunal antiterrorista paquistanês condenou um homem a ser cegado depois de ter realizado um ataque com ácido contra a sua noiva, que resultou em sua cegueira
A mesma sentença foi dada em 2009 para o homem que cegou Ameneh Bahrami.
Um estudo de 2008 publicado no New England Journal of Medicine testou o efeito do uso de terapia genética para ajudar a restaurar a visão de pacientes com uma forma rara de cegueira hereditária, conhecida como Neuropatia óptica de Leber ou NOL
A Neuropatia óptica de Leber danifica os receptores de luz na retina e normalmente começa a afetar a visão na infância, com piora da visão até a cegueira completa em torno da idade de 30 anos.
O estudo utilizou um vírus comum do resfriado para levar uma versão normal do gene chamado RPE65 diretamente nos olhos dos pacientes acometidos
Notavelmente todos os 3 pacientes com idades de 19, 22 e 25 responderam bem ao tratamento e relataram melhora da visão após o procedimento
Devido à idade dos pacientes e a natureza degenerativa do NOL a melhoria da visão dos pacientes em terapia genética é encorajadora para os investigadores
Espera-se que a terapia genética possa ser ainda mais eficaz em pacientes mais jovens que sofreram perda de visão limitada, bem como em outros indivíduos cegos ou parcialmente cegos.
Dois tratamentos experimentais para os problemas de retina incluem um substituto cibernética e transplante de células da retina fetal.
Muitas pessoas com sérias deficiências visuais podem se locomover de forma independente, usando uma ampla gama de ferramentas e técnicas
Especialistas em orientação e mobilidade são os profissionais que são treinados especificamente para ensinar as pessoas com deficiência visual como se locomover com segurança, confiança, e de forma independente em casa e na comunidade
Estes profissionais também podem ajudar as pessoas cegas na prática de locomoção em rotas específicas, que possam ser utilizadas, muitas vezes, como a rota da casa para uma loja.
Ferramentas como a bengala branca com uma ponta vermelha — o símbolo internacional da cegueira — também podem ser usadas para melhorar a mobilidade
A bengala cano-longo é usada para aumentar o alcance da sensação de toque do usuário
Geralmente é usada com ela para baixo em um movimento de balanço, através do caminho planejado, para detectar obstáculos
No entanto, as técnicas para manuseio da bengala podem variar dependendo do utilizador e/ou da situação
Algumas pessoas com deficiência visual não possuem esses tipos de bengalas, optando pela menor e mais leve bengala de identificação (ID)
Outros ainda necessitam de uma bengala de apoio
A escolha depende da visão do indivíduo, motivação e outros fatores.
Um pequeno número de pessoas utilizam cães-guia para ajudar em sua mobilidade
Estes cães são treinados para desviar de vários obstáculos, e indicar quando se torna necessário subir ou descer um degrau
No entanto, a utilidade dos cães-guia é limitado pela incapacidade de cães de entender os complexos caminhos
A metade humana da equipe traça o caminho, com base em habilidades adquiridas através da formação de mobilidade anterior
Neste sentido, o manipulador pode ser comparado ao navegador de uma aeronave, que deve saber como ir de um lugar para outro, e que o cão o piloto, que deve levá-los ao destino com segurança.
Algumas pessoas cegas usam GPS para deficientes visuais como ajuda em sua mobilidade
Esses softwares podem ajudar as pessoas cegas, com orientação e navegação, mas não é um substituto para ferramentas de mobilidade tradicionais, tais como bengalas brancas e cães-guia.
Tecnologia para permitir que pessoas cegas possam conduzir veículos motorizados começou a ser desenvolvida em 2011, por pesquisadores do Instituto Politécnico e Universidade Estadual da Virgínia, juntamente com a Federação Nacional dos Cegos dos Estados Unidos.
Ações do governo são algumas vezes tomadas para tornar lugares públicos mais acessíveis a pessoas cegas
O transporte público está disponível gratuitamente para os cegos em muitas cidades
Piso tátil e semáforos com autofalantes podem tornar mais fácil e mais seguro para os pedestres com deficiência visual atravessarem as ruas
Além de fazer regras sobre quem pode e não pode usar uma bengala, alguns governos obrigam que se de a preferência aos usuários de bengalas brancas ou cães-guia.
O tema da cegueira e da educação incluiu abordagens da evolução e percepção pública da melhor forma de abordar as necessidades especiais de alunos cegos
A prática de institucionalização em asilos dos cegos tem uma história que remonta mais de mil anos, mas só no século XVIII que as autoridades criaram escolas para eles, onde as crianças cegas, particularmente aqueles mais privilegiadas, geralmente eram educadas em tais ambientes especializados
Essas instituições fornecem desde a formação profissional e a simples adaptação, bem como aprofundamento em assuntos acadêmicos oferecidos através de formatos alternativos
Literatura, por exemplo, foi sendo disponibilizada para alunos cegos por meio de relevo nas letras romanas.
Os antigos egípcios foram a primeira civilização a mostrar interesse nas causas e curas para a deficiência e, durante alguns períodos as pessoas cegas foram registrados como representando uma porção substancial dos poetas e músicos na sociedade.
A primeira escola destinada a preparação de alunos com deficiência visual foi fundada por Valentin Haüy, em 1784, na cidade de Paris, a Instituição Real para Jovens Cegos em Paris (hoje o Instituto Nacional para Jovens Cegos, o INJA)
A primeira escola para cegos no Brasil foi o Imperial Instituto dos Meninos Cegos, fundado por Dom Pedro II no Rio de Janeiro, hoje o Instituto Benjamin Constant
Em Portugal a primeira instituição de ensino para cegos foi a Associação Promotora dos Ensino Cegos (APEC) que inaugurou sua primeira escola em 1888.
A maioria dos deficientes visuais que não são totalmente cegos leem impressões, sejam de um tamanho normal ou aumentado por dispositivos de ampliação
Muitos também leem impressões ampliadas que é mais fácil para se ler sem nenhum tipo de dispositivo
Uma variedade de lentes de aumento, algumas portáteis e outras não, podem tornar a leitura mais fácil para eles.
Outros leem Braille (ou o raramente usado alfabeto da lua) ou contam com livros falados e leitores ou máquinas de leitura, que convertem texto impresso em fala ou em Braille
Eles usam computadores com hardware especiais, tais como scanners e monitores Braille, bem como software que escrevem especificamente para os cegos, como aplicativos de reconhecimento óptico de caracteres e leitores de tela.
Algumas pessoas acessam estes materiais através de agências para os cegos, como Bibliotecas para Cegos.
Circuitos fechados de televisão são equipamentos que aumentam e contrastam os itens textual, são uma alternativa mais "high-tech" do que dispositivos de ampliação tradicional.
Há também mais de 100 serviços de rádio para se ler em todo o mundo que proporciona às pessoas com deficiência visual leituras periódicas através do rádio
A Associação Internacional de Serviços de Informação de Áudio fornece links para todas essas organizações.
Acesso a tecnologias, tais como leitores de tela, ampliadores de tela e monitores Braille permitem aos cegos a usar aplicações informáticas e telefones celulares
A disponibilidade de tecnologia assistiva está aumentando, acompanhada de esforços concertados para garantir a acessibilidade das tecnologias de informação a todos os potenciais utilizadores, incluindo os cegos
Versões mais recentes do Microsoft Windows incluem um Assistente de Acessibilidade e Lupa para aqueles com visão parcial, e Microsoft Narrator, um leitor de tela simples
Distribuição Linux (como CDs ao vivo) para cegos incluem Oralux e Knoppix, este último desenvolvido em parte por Adriane Knopper, que tem uma deficiência visual
Mac OS também vem com um leitor de tela embutido, chamado de VoiceOver.
O movimento em direção à maior acessibilidade da web está abrindo um número muito maior de sites para tecnologia adaptativa, tornando a web um lugar mais convidativo para deficientes visuais.
Modificações na produção visual que incluem letras grandes e/ou limpar gráficos simples pode ser um benefício para os usuários com alguma visão residual.
Pessoas cegas podem usar equipamentos que falam como termômetros, relógios, balanças, calculadoras, e bússolas
Eles também podem ampliar ou colocar marcadores em dispositivos tais como fornos e termostatos para torná-los utilizáveis
Outras técnicas usadas por pessoas cegas para auxiliá-los nas atividades diárias incluem:
A maioria das pessoas, uma vez que foram deficientes visuais por tempo suficiente, elaboram suas próprias estratégias de adaptação em todas as áreas de gestão pessoal e profissional.
A OMS estima que em 2002 havia 161 milhões de pessoas com deficiência visual no mundo (cerca de 2,6% da população total)
Deste número 124 milhões (cerca de 2%) tinham baixa visão e 37 milhões (cerca de 0,6%) estavam cegos
Em ordem de freqüência as principais causas foram catarata, erros refrativos não corrigidos (miopias, hipermetropias, ou astigmatismos), glaucoma e degeneração macular relacionada à idade
Em 2000, o número de pessoas cegas no Brasil foi estimado em 0,4 a 0,5% da população, ou seja, 4 a 5 por cada mil
Considerando-se na época a população brasileira de 160 milhões de habitantes, estima-se existirem 640.000 cegos no país
Em Portugal, no ano de 2008, existiam entre 130 e 140 mil cegos, 1% da população.
A fim de determinar quais as pessoas podem necessitar de assistência especial por causa de sua deficiência visual, várias jurisdições governamentais formularam definições mais complexas, conhecida como "cegueira legal".
No Brasil, "cegueira legal" é quando a acuidade visual é igual ou menor que 0,05 (20/400) no melhor olho, com a melhor correção óptica;
Em muitos lugares, as pessoas com acuidade média, que, no entanto têm um campo visual inferior a 20 graus (o normal é 180 graus) também são classificadas como sendo legalmente cegas
Cerca de dez por cento daqueles considerados legalmente cegos, por qualquer medida, não têm visão
O resto tem alguma visão, e percepção de luz, uma acuidade relativamente boa
Visão subnormal é por vezes utilizado para descrever acuidade visual de 20/70 a 20/200.
Diferentes culturas através da história têm retratado a cegueira de formas diferentes; para os gregos, por exemplo, era um castigo dos deuses, para o qual o indivíduo afligido muitas vezes recebia uma compensação na forma do gênio artístico
A literatura judaico-cristã trata a cegueira como um defeito; e só através do amor de Deus uma cura poderia o se manifestar, quando os olhos de um indivíduo afligido entrasse em contato com um homem santo ou relíquia
Quase sem exceção na literatura antiga as pessoas cegas poderiam trazer esta condição sobre si por causa de pecados ou ofensas contra os deuses, mas nunca foram os únicos instrumentos para sua reversão.
É impossível fazer uma generalização sobre como os cegos foram tratados na literatura,—eles foram maravilhosos, talentosos, maus, maliciosos, ignorantes, sábios, indefesos, inocentes, ou onerosos dependendo da história—mas sempre a cegueira foi dita como uma perda que deixa uma marca que não se apaga no caráter de uma pessoa.
Mesmo pioneiros no treinamento dos cegos, como Dorothy Harrison Eustis, abrigavam estereótipos negativos sobre eles
Pessoas cegas estavam, em sua opinião, tão acostumadas a esperar dos outros a ponto de serem passivas e melancólicas.
Father Thomas Carroll, que fundou o Carroll Centre for the Blind (Centro para cegos Carroll), escrveu o livro Blindness: What It Is, What It Does and How to Live with It (Cegueira: O Que É, O Que Ela Faz e Como Conviver com ela) em 1961
Nela, ele caracteriza a cegueira como sendo 20 perdas, e como a "morte" do indivíduo que enxergava.
No mito grego, Tirésias era um profeta famoso por sua clarividência
De acordo com um mito, ele foi cegado pelos deuses como castigo por ele ter revelado seus segredos, enquanto outro afirma que ele foi cegado como punição por ver Atena nua enquanto ela estava se banhando
Em a Odisseia, o ciclope Polifemo captura Ulisses, que cega-o, para poder escapar
Na mitologia nórdica, Loki engana o Deus cego Hoder fazendo-o matar seu irmão Balder, o Deus da felicidade.
No Novo Testamento contém numerosos exemplos de Jesus realizando milagres para curar os cegos
De acordo com os Evangelhos, Jesus curou os dois cegos da Galileia, o cego de Betsaida, o cego de Jericó e o homem que nasceu cego.
A parábola os cegos e um elefante cruzou entre muitas tradições religiosas e faz parte do Jainismo, Budismo, Sufismo e Hinduísmo
Em várias versões do conto, um grupo de cegos (ou homens no escuro) tocam em um elefante para aprenderem o que é
Cada um se sente uma parte diferente, mas apenas uma parte
Eles, então, comparam o que sentiram e descobrem que eles estão em completo desacordo.
"Three Blind Mice" (lit
"Três Ratos Cegos") é uma cantiga de roda medieval inglesa sobre três ratos cegos, cujas caudas são cortadas após perseguirem a mulher do fazendeiro
O trabalho é explicitamente incongruente, terminando com o comentário Você já viu tal visão em sua vida, Como três ratos cegos?
John Milton que se tornou cego na meia-idade, compôs On His Blindness (lit
Em Sua Cegueira), um soneto sobre como lidar com a cegueira
A obra postula que [aqueles] que conseguissem o urso mais manso [para Deus], seriam os melhores para servi-lo.
O pintor e gravador neerlandês Rembrandt muitas vezes mostravam cenas do apócrifo livro de Tobias, que conta a história de um patriarca cego que é curado por seu filho, Tobias, com a ajuda do arcanjo Rafael.
John Newton compôs o hino Amazing Grace sobre um infeliz que dizia "eu estava perdido, mas agora fui encontrado, estava cego, mas agora vejo." Cegueira, neste sentido, é usada tanto metaforicamente (para se referir a alguém que era ignorante, mas depois se tornou conhecedor) e, literalmente, como uma referência para aqueles curados na Bíblia
Nos últimos anos de sua vida, Newton se tornaria cego.
A música hino da luta pelos direitos civis "Blowin' in the Wind" de Bob Dylan duas vezes faz alusão à cegueira metafórica: Quantas vezes pode um homem virar sua cabeça / / e fingir que ele simplesmente não vê..
Quantas vezes precisará um homem olhar para cima / / Antes que ele possa ver o céu?
A ficção contém numerosos personagens cegos conhecidos
Alguns desses personagens podem "ver" por meio de dispositivos fictícios, como o super herói da Marvel Comics o Demolidor, que podem "ver" através de sua acuidade auditiva super-humana, ou Geordi La Forge de Star Trek que pode ver, com o auxílio de um VISOR, um dispositivo fictício que transmite sinais ópticos para seu cérebro.
Pessoas cegas e com visão parcial praticam esportes como natação, esqui na neve, e atletismo
Alguns esportes foram inventados ou adaptados para cegos, como golbol, futebol de cinco, críquete, judô e golfe
A autoridade mundial em esportes para cegos é a Federação Internacional de Desportos para Cegos (IBSA)
Pessoas com deficiência visual participam dos Jogos Paralímpicos desde o Jogos Paralímpicos de Verão de 1976 em Toronto.
A palavra "cego" (adjetivo e verbo) é frequentemente utilizada com o significado de falta de conhecimento de algo
Por exemplo, um encontro às cegas é uma data em que as pessoas envolvidas não foram previamente conhecidas; um experimento cego é aquele onde nem o examinado nem o examinador sabe o que está sendo utilizado como variável em um dado momento
A expressão "cego guiando cego" refere-se a pessoas incapazes de liderar outras pessoas incapazes, expressão que tem origem religiosa (vide O cego levando o cego)
Um "ponto cego" é uma área em que alguém não pode ver, por exemplo, onde um motorista de carro não pode ver porque parte de carroçaria do seu carro estão no caminho
A expressão "o amor é cego" diz que se deve olhar não só para a beleza exterior da pessoa.
Muitos ditados populares usam a cegueira tanto de forma metafórica quanto real
"Mais perdido do que cego em tiroteio" é um ditado popular atribuído a pessoas que não conseguem entender algo
"Em terra cego, quem tem um olho é rei" é outro dito, que refere-se a elevação de pessoas se comparadas a outras de pouco valor, por exemplo em uma área onde a procura por mão de obra qualificada é muita escassa, uma pessoa qualificada mesmo que minimamente já é muito boa
"O pior cego é aquele que não quer ver" fala sobre as pessoas que se recusam aceitar verdade
"Mais vale ser cego dos olhos do que do coração" é um provérbio árabe que enfatiza o amor.
Declarações de que certas espécies de mamíferos "nasceram cegas" refere-se a eles nascerem com os olhos fechados e as suas pálpebras se fundirem; os olhos ainda abrem
Um exemplo é o coelho
Nos seres humanos as pálpebras são fundidas no período que antecede o nascimento, mas são abertas novamente antes da hora do nascimento normal, mas os bebês muito prematuros, às vezes, nascem com os olhos fechados, que se abrem mais tarde
Outros animais como o rato-toupeira cego são realmente cegos e dependem de outros sentidos.
Animais cegos, em geral incluem animais noturnos e animais do subterrâneo, mas há outros como o peixe-cego, o grilo-cego, a salamandra do Texas , os platelmintos camarão sem olhos, peixe sem olhos, o besouro-cego, o lagostim-cego, e alguns artrópodes, isópodos, copépodes e troglóbios.
Animais cegos tem sido um tema poderoso na literatura
Equus peça de Peter Shaffer conta a história de um menino que cega seis cavalos
Romance clássico de Theodore Taylor, The Trouble With Tuck é sobre uma adolescente, Helen, que treina seu cão cego a seguir e confiar em um cão-guia.

pálpebra: inflamação (Hordéolo, Calázio, Blefarite) - Entrópio - Ectrópio - Lagoftalmo - Blefarocalásia - Ptose - Blefarofimose - Xantelasma - Triquíase
sistema lacrimal: Dacrioadenite - Epífora - Dacriocistite
Estrabismo paralítico: Oftalmoparesia - Oftalmoplegia externa progressiva - Paralisia (III, IV, VI) - Síndrome de Kearns-Sayre Outros estrabismos: Esotropia/Exotropia - Hipertropia - Heterophoria (Esophoria, Exoforia) - Síndrome de Brown - Síndrome de Duane
Outras binoculares: Paralisia do olhar conjugado - Insuficiência de convergência - Oftalmoplegia internuclear - Síndrome do um e meio
Os Pima são um povo nativo dos Estados Unidos da América que viviam às margens dos rios Gila e Sal, na parte sul do estado de Arizona.
Situados na área nevrálgica da cultura pré-histórica Hohokam, exerciam a agricultura intensiva, aproveitando os rios para irrigação
Usavam a caça como fonte suplementar de suas dietas
O primeiro contacto com os brancos ("caras pálidas") foi por intermédio do italiano Eusebio Francisco Kino, em 1697
A população naquela época era de cerca de quatro mil pessoas
Ainda hoje existem descendentes deles, embora obviamente com hábitos bastante distintos.
Coordenadas: 34° 17' N, 111° 39'W
O Arizona é um dos 50 estados dos Estados Unidos, localizado na região sudoeste do país
As taxas de crescimento populacional do Arizona são das mais altas de todo o país
Entre 1990 e 2000, a população do estado cresceu em cerca de 40%, de 3 677 985 habitantes em 1990 para 5 130 632 habitantes em 2000, mais do que qualquer outro estado norte-americano, com exceção de Nevada
Entre 1950, quando o Arizona tinha 749 587 habitantes, até 2000, a população cresceu sete vezes.
Grande parte do Arizona possui um clima árido ou semi-árido
Estas regiões recebem menos de 40 centímetros de chuva por ano, sendo muito quentes no verão e amenos no inverno
Regiões montanhosas de maior altitude, porém, possuem um clima mais úmido e frio
Grande parte do estado é escassamente habitada
A maior parte da população concentra-se ao redor de dois centros urbanos: Phoenix, a maior cidade e capital do estado, e Tucson.
O cognome de Arizona é The Grand Canyon State
O norte do estado abriga uma das atrações turísticas naturais mais conhecidas dos Estados Unidos e do mundo, o Grand Canyon
Outro cognome de Arizona é The Copper State (o estado do cobre)
O Arizona possui grandes reservas deste mineral, e já foi o maior produtor nacional de cobre
Até os dias atuais, a mineração de cobre é uma importante fonte de renda do Arizona.
Nativos norte-americanos viviam na região onde atualmente está localizado o Arizona milhares de anos antes da chegada dos primeiros europeus
Os nativos resistiram bravamente contra a colonização europeia na região
As últimas batalhas entre nativos e colonos de ascendência europeia foram realizados no Arizona
Atualmente, o estado, com uma população de 287 mil nativos, possui a segunda maior população nativa norte-americana dos Estados Unidos, estando atrás apenas da Califórnia.
O Arizona foi colonizado inicialmente pela Espanha, passando ao controle mexicano em 1821, quando o México tornou-se independente
Em 1848, com o fim da Guerra Mexicano-Americana, o Arizona passou a fazer parte dos Estados Unidos
Em 14 de fevereiro de 1912, o Arizona tornou-se o antepenúltimo território norte-americano a ser elevado à categoria de estado, e o último território norte-americano dentro dos Estados Unidos contíguos (localizado dentro do corpo principal de terra na América do Norte) a tornar-se um estado
Somente os territórios do Alasca e do Havaí seriam posteriormente elevados à categoria de estado.


Não se sabe ao certo a origem do nome do estado de Arizona
Existem três teorias que buscam explicar a origem deste nome , e segundo elas, a palavra Arizona seria derivada de:
Diversas tribos nativo norte-americanas viviam na região que atualmente constitui o estado do Arizona, cerca de 12 mil anos antes da chegada dos primeiros europeus à região
Estas tribos nativas perteciam a três classes distintas: os Na-Dene, os Uto-Astecas e os Yuman-Cochimi
Os Apaches e os Navajos, outra nação indígena, instalariam-se na região cerca de um século antes da chegada dos primeiros europeus na região.
A Espanha começou a colonizar a região que atualmente constitui o México e a região sudoeste dos Estados Unidos durante o início do século XVI
Embora as primeiras explorações na região onde atualmente localiza-se o estado de Arizona foram as explorações espanholas lideradas por Marcos de Niza e por Francisco Vásquez de Coronado, as mais influenciais
Estas explorações foram feitas por causa de rumores espalhados pelos primeiros exploradores espanhóis que exploraram o sudoeste do atual Estados Unidos, que afirmaram ter encontrado míticas cidades, tais como Cíbola, e grandes minas de cobre e prata
Nenhuma destas afirmações foi provada mas, no final, as explorações espanholas acabaram levando a grandes epidemias de catapora entre a população indígena da região.
Os primeiros assentamentos espanhóis permanentes fundados na região do atual estado foram fundados por jesuítas católicos, durante a década de 1620
Eles instalaram-se na região com o intuito de converter ao catolicismo os nativos que habitavam a região
Porém, nativos indígenas hopi rebelaram-se contra os colonos espanhóis da região em 1680
Vários colonos foram mortos, e os colonos espanhóis restantes foram obrigados a fugir
Em 1694, os espanhóis reconquistaram novamente a região
Nas próximas 13 décadas, os espanhóis controlariam o Arizona
Constantes ataques indígenas, especialmente por parte dos apaches, impediram uma forte colonização espanhola na região.
O primeiro assentamento branco permanente do Arizona foi fundado em 1752
Vários fortes protegiam os poucos assentamentos espanhóis instalados no Arizona
Certos acordos feitos entre os apaches e os espanhóis acabaram com os ataques por volta da década de 1790.
Em 1821, o México tornou-se independente da Espanha
A guerra mexicana de independência fez com que os tesouros nacionais mexicano e espanhol falissem por completo
Fundos espanhóis que anteriormente suportavam missões católicas, presídios, acordos de paz e fortes quase desapareceram, e os apaches voltaram a atacar novamente.
Durante a década de 1830, alguns norte-americanos começaram a explorar a região do Arizona em busca de peles de castor
Em 1846, a ideologia do destino manifesto fez com que os Estados Unidos entrassem em guerra contra o México
Em 1848, a guerra mexicano-americana já havia terminado, com derrota mexicana, que foram obrigados a ceder muito do norte do México aos Estados Unidos
Muito do atual Arizona passou então ao controle norte-americano
Porém, o extremo sul do Arizona ainda continuou sob controle mexicano
Em 1853, os norte-americanos compraram dos mexicanos a região que compreende o restante do atual Arizona, bem como o extremo sul do Novo México, na chamada Compra de Gadsden.
O Arizona, então, fazia parte do Território do Novo México
Gradualmente, o número de habitantes morando na região do Arizona começou a aumentar
Muitos destes habitantes pediram pela criação de um novo território, o Território do Arizona
Durante o início da guerra civil estadunidense, em 1862, tropas dos Estados Confederados da América ocuparam em parte o Novo México, porque muito dos habitantes morando no atual Arizona eram pró-confederação
Estas tropas foram forçadas a recuar por causa de contra-ataques por parte da União, em 1863
No mesmo ano, em um ato simbólico, os confederados, atendendo ao pedido da população da região, criaram o Território Confederado do Arizona
Em reação a este gesto dos confederados, o governo norte-americano, no final de 1863, criou oficialmente o Território do Arizona.
Entre a década de 1850 até a década de 1880, os nativos indígenas da região lutaram contra a presença norte-americana na região, através de constantes ataques contra fazendas e cidades
Os navajos renderam-se em 1864
As tribos indígenas do Arizona foram as últimas a renderem-se aos Estados Unidos.
Um ato do governo norte-americano, o Ato de Terra do Deserto de 1877, dava a quaisquer famílias interessadas em instalar-se no interior do sudoeste norte-americano 640 acres de terra
A população do Arizona começou a crescer rapidamente
Ao longo da década de 1890 e de 1900, a população do Arizona passou a pressionar cada vez mais o governo em elevar o território à categoria de estado
Em 14 de fevereiro de 1912, o Arizona tornou-se o 48º estado dos Estados Unidos.
A entrada dos Estados Unidos na primeira guerra mundial fez com que a economia do Arizona crescesse rapidamente
Grandes áreas de terra começaram a ser artificialmente irrigadas
Até então, a prática da agricultura estava restrita somente às regiões de maior altitude do Arizona, onde o clima é mais úmido
Várias represas foram construídas, e várias fábricas foram inauguradas
O Arizona foi afetado negativamente pela Grande Depressão, embora os efeitos negativos causados por ela tivessem sido estabilizados através da construção de grandes obras públicas, notavelmente a usina hidrelétrica Hoover, no rio Colorado
A segunda guerra mundial causou um novo boom econômico no estado
Várias bases militares foram construídas, notavelmente, bases aéreas - graças ao seu clima ensolarado.
Entre o final da década de 1910 até a década de 1940 - especialmente ao longo da segunda guerra - milhares de pessoas de outras regiões dos Estados Unidos migraram em direção ao Arizona, graças a prosperidade econômica do estado
Durante a segunda guerra, o medo de ataques aéreos por parte do Japão fez com que centenas de habitantes de estados costeiros do oeste norte-americano instalassem-se na região, em busca de maior proteção.
Durante o final da década de 1950, o imenso crescimento populacional fez com que a demanda por água potável na região subisse
Porém, devido à escassez de rios e lagos na região, a maior parte da água potável até então era obtida em reservas subterrâneas de água
Porém, por causa da crescente demanda, as águas das (escassas) chuvas da região não foram mais o suficiente para estabilizar os níveis destas reservas subterrâneas
Era preciso encontrar uma nova fonte de água, assim no início da década de 1960 o Arizona decidiu desviar água do rio Colorado, por meio de um plano chamado Projeto Central do Arizona
Porém, várias represas estavam instaladas no curso inferior do rio, na Califórnia
Esta processou o Arizona em 1960, e perdeu o processo, em 1963
Em 1968, o Projeto Central do Arizona foi finalizado.
Em 1988, o inglês tornou-se o idioma oficial do Arizona, através de uma emenda estadual, artigo 28 da constituição do estado
Porém, a Suprema Corte do Arizona considerou a emenda inconstitucional, o que proibiu o cumprimento em nível oficial da maior parte das provisões da emenda por parte do estado
Apesar de ser considerada inconstitucional pelo judiciário estadual, o artigo 28 continua na constituição do Arizona até os dias atuais
Atualmente, uma lei semelhante ao artigo 28 (que obrigará estabelecimentos comerciais e governamentais a utilizar apenas o inglês) está em estudo no legislativo, e que, se entrar em votação, através de um referendo estadual, provavelmente substituirá o artigo 28
A lei tem gerado controvérsia, devido à grande população hispânica e nativa norte-americana no estado.
Em 17 de agosto de 2005, os governadores do Arizona e do Novo México declararam em conjunto estado de emergência nos condados de ambos os estados que localizam-se ao longo da fronteira com o México
A implementação deste estado, segundo os governadores, foi feita por causa de crescente violência, imigração ilegal, tráfico de drogas e da falta de ação por parte de ambos os governos federais em resolver estes problemas
O governo do Arizona liberou um total de 1,5 milhão de dólares em fundos destinados à estes condados, e o Novo México liberou 1,75 milhão de dólares.
O Arizona limita-se ao sul e ao sudoeste com os estados mexicanos de Sonora e de Baja California, a oeste com os estados estadunidenses da Califórnia e de Nevada, ao norte com Utah, no extremo nordeste com o Colorado, e ao leste com o Novo México
Com um pouco mais de 295 mil km², é o sexto maior estado americano em área.
O Arizona possui poucos rios permanentes - embora possua vários rios temporários - em parte por causa do clima desértico que domina muito do estado
O rio mais importante é o rio Colorado, que é também o maior rio do estado
O rio Colorado é a principal fonte de água potável do estado, alimentando as áreas urbanas de Phoenix e de Tucson, bem como várias fazendas, através de longos canais
O rio Colorado corta 1 107 quilômetros do Arizona
A segunda maior fonte de água potável do estado são fontes de água subterrânea, que alimentam primariamente pequenas cidades e fazendas.
O Arizona pode ser dividido em três distintas regiões geográficas:
Devido à sua grande área e variações em altitude, o estado possui uma grande variedade de climas
No sudoeste do Arizona, região que possui as menores altitudes, o clima da região é primariamente desértico, com invernos amenos e verões muito quentes, e com grandes variações de temperatura entre o dia e a noite
No inverno, a temperatura média do sudoeste é de 2°C
A média das mínimas no extremo sudoeste no inverno é de 7 °C, e a média das máximas, é de 19 °C
No verão, a temperatura média do sudoeste do Estado é de 34 °C
A média das mínimas é de 25 °C e a média das máximas é de 39 °C, no extremo sudoeste
A temperatura mais alta já registrada no Arizona foi de 53 °C, registrada em Lake Havasu City, em 29 de junho de 1994.
A região central e o norte, regiões de maior altitude, possuem temperaturas mais baixas, com invernos frios e verões quentes
Temperaturas muito frias nesta região não são incomuns - frentes de ar frio vindos do norte dos Estados Unidos e do Canadá por vezes alcançam o estado, fazendo com que a temperatura caia para menos de -20 °C em certas áreas do norte do Arizona
No norte, a temperatura média no inverno é de -1 °C (as menores temperaturas são registradas no extremo nordeste do estado, onde estão localizadas as regiões de maior altitude do Arizona), e no verão, a temperatura média é de 25 °C
A menor temperatura já registrada foi de -40 °C, em Hawley Lake, em 7 de janeiro de 1971.
Em Phoenix, localizada no centro do estado, a temperatura média no inverno é de 13 °C, sendo a mínima de 7 °C e a máxima de 19 °C, e no verão, de 34 °C, sendo a mínima de 27 °C e a máxima de 42 °C
A capital do Arizona é também a mais quente capital dos Estados Unidos
As maiores taxas de precipitação média anual de chuva do Arizona estão localizadas ao longo da região central do estado, e as menores, no sudoeste
Nas regiões centrais, a precipitação média anual de chuva é superior a 50 centímetros, enquanto que no sudoeste, é inferior a 15 centímetros
As regiões de maior altitude do Arizona podem receber mais de 70 centímetros de neve todo ano
A estação úmida do Arizona começa no final de julho e estende-se até agosto.
A atual Constituição do Arizona foi adotada em 1911
Emendas à constituição são propostas pelo poder legislativo do Arizona, e para ser aprovada, precisa receber a aprovação de ao menos 51% do Senado e da Câmara dos Representantes do estado, e então dois terços dos votos da população eleitoral do Arizona, em um referendo
A população do Estado também pode propor emendas à constituição através da coleta de um certo número de abaixo-assinados
Quando este abaixo-assinado é aceito pelo governo, para ser aprovada a emenda, ela precisa receber aprovação de ao menos um quarto dos membros de ambas as câmeras do poder legislativo do Arizona, e então ao menos 51% dos votos da população eleitoral, em um referendo
Emendas também podem ser propostas e introduzidas por convenções constitucionais, que precisam receber ao menos 51% dos votos de ambas as câmeras do poder legislativo e dois terços dos votos da população eleitoral, em um referendo.
O principal oficial do poder executivo do Arizona é o governador
Este é eleito pelos eleitores do estado para mandatos de até quatro anos de duração
O estado não possui tenente-governador
Uma pessoa pode exercer o cargo de governador quantas vezes puder, embora não possa exercer o cargo duas vezes consecutivas
Outros quatro oficiais do alto escalão também são eleitos pela população eleitoral, o secretário de Estado do Arizona
É o secretário de Estado que substitui o governador caso este morra ou seja removido do ofício.
O poder legislativo do Arizona é constituído pelo Senado e pela Câmara dos Representantes
O Senado possui um total de 30 membros, enquanto que a Câmara dos Representantes possui um total de 60 membros
O Arizona está dividido em 30 distritos legislativos
Os eleitores de cada distrito elegem um senador e dois representantes, que irão representar tal distrito no Senado e na Câmara dos Representantes
O termo dos senadores e dos representantes é de dois anos de duração
Como o governador, não possuem limites de termos de ofício, mas não podem exercer o mesmo cargo duas vezes consecutivas.
A corte mais alta do poder judiciário do Arizona é a Suprema Corte do Arizona, composta por cinco juízes
Estes juízes são escolhidos por um órgão estadual do governo de Arizona para termos de cinco anos de duração
Ao final do termo, uma votação geral é realizada no estado, onde a população decide por aprovar este juiz ou não
Caso aprovados, estes juízes podem continuar em ofício por mais cinco anos - não podendo ser indicados novamente para o cargo.
O Arizona está dividido em 15 condados
Cerca de metade do orçamento do estado vêm de impostos estaduais
O restante vem de verbas recebidas do governo federal e de empréstimos
Em 2002, o governo do estado gastou 18,119 bilhões de dólares, tendo gerado 17,298 bilhões de dólares
A dívida governamental do Arizona é de 4,348 bilhões de dólares
A dívida per capita é de 799 dólares, o valor dos impostos estaduais per capita é de 1 558 dólares, e o valor dos gastos governamentais per capita é de 3 330 dólares
O Arizona possui a segunda menor dívida per capita - atrás somente do Tennessee - e o menor valor de gastos governamentais per capita, entre qualquer estado norte-americano.
Até a década de 1950, o partido político dominante no Arizona foi o Partido Democrata, especialmente quando em eleições realizadas em nível estadual ou regional
Desde então, o Partido Democrata tem-se fortalecido rapidamente no Arizona, primariamente nas principais cidades do estado
Nas últimas décadas, os republicanos tem sido maioria na região metropolitana de Phoenix, enquanto que os democratas ainda possuíam o domínio de áreas rurais e pequenas cidades
Os democratas ainda dominam politicamente a maioria dos condados do estado
Porém, o Condado de Maricopa, onde Phoenix e sua região metropolitana estão localizadas, concentra aproximadamente 60% da população do Arizona, fazendo com que ambos os partidos possuam grande força política
Nas eleições presidenciais norte-americanas, porém, o Arizona tende a favorecer candidatos republicanos, com os republicanos obtendo a maioria dos votos do colégio eleitoral do estado, em cerca de dois terços das eleições presidenciais realizadas desde a formação do Território do Arizona, em 1863.
De acordo com o censo nacional de 2000, a população do Arizona em 2000 era de 5 130 632 habitantes, um crescimento de 40% sobre a população do estado em 1990, de 3 677 985 habitantes, uma das taxas de crescimento populacional mais altas dos Estados Unidos
Uma estimativa realizada em 2005 estima a população em 5 939 292 habitantes, um crescimento de 61,4% em relação à população em 1990; de 15,7%, em relação à população em 2000; e de 3,5% em relação à população estimada em 2004
As altas taxas de crescimento populacional devem-se em grande parte à forte imigração (por vezes ilegal) de mexicanos no estado.
O crescimento populacional natural do Arizona entre 2000 e 2005 foi de 241 732 habitantes - 462 739 nascimentos menos 221 007 óbitos - o crescimento populacional causado pela imigração foi de 168 078 habitantes, enquanto que a migração interestadual resultou no ganho de 408 160 habitantes
Entre 2000 e 2005, a população do Arizona cresceu em 808 660 habitantes, e entre 2004 e 2005, em 199 413 habitantes.
Em 2004, 11,4% da população do estado (aproximadamente 400 mil habitantes) nasceram fora do país, com estimativas indicando que 10% destes são imigrantes ilegais (1,1% da população).
Composição racial da população do Arizona:
De acordo com estimativas de 2003, o Arizona possui o terceiro maior número de nativos norte-americanos dos Estados Unidos; apenas a Califórnia possui mais nativos
A percentagem de nativos em relação a população do estado é a sexta maior do país
Cerca de 286 680 nativos vivem no Arizona, representando cerca de 10% da população indígena norte-americana.
Os seis maiores grupos étnicos do Arizona são mexicanos (que compõem 21% da população do estado), alemães, britânicos, irlandeses e nativos norte-americanos
A população do sul e da região central são primariamente mexicanas, o centro-norte e o noroeste são habitados primariamente por britânicos, e o nordeste é habitado primariamente por nativos indígenas.
Atualmente, a maioria da população do estado é branca não-hispânica
Devido à grande imigração de hispânicos, e à maiores taxas de natalidade entre a população hispânica, prevê-se que nenhuma raça será majoritária no estado em torno de 2035
Em 2003, pela primeira vez na história do estado, foram registrados mais nascimentos de hispânicos do que nascimentos de brancos não-hispânicos.
Em 2000, 74,1% da população do Arizona com cinco anos ou mais de idade possuem o inglês como idioma materno, e 19,5% possuem o espanhol como idioma materno
O navajo é o terceiro idioma mais falado do estado; 1,9% da população do Arizona o possuem como idioma materno
Outros idiomas indígenas são falados por 0,6% da população
O alemão é o idioma materno de 0,5% da população do estado.
49,9% da população do Arizona são pessoas do sexo masculino, e 50,1% são pessoas do sexo feminino.
Percentagem da população do Arizona por afiliação religiosa:
Cerca de 87% da população do Arizona vive em cidades, e mais de 88% da população vive em regiões metropolitanas
Cerca de 60% da população vive na região metropolitana de Phoenix
Tucson é a segunda maior cidade do estado.
O produto interno bruto do Arizona foi de 182 bilhões de dólares
A renda per capita do estado, por sua vez, foi de 27 232 dólares, o trigésimo nono maior do país
A taxa de desemprego do Arizona é de 5%.
O setor primário responde por 2% do PIB do Arizona
O estado possui 7,4 mil fazendas, que ocupam cerca de 11% da área total
A agricultura e a pecuária respondem juntas por 2% do PIB, e empregam aproximadamente 68 mil pessoas
A maior parte das fazendas do Arizona, que são comumente chamadas de ranchos, são usadas para a criação de grandes rebanhos bovinos
Apenas 2,5% das terras são usadas para o cultivo de plantações
Apesar disso, são os vegetais (especialmente cenouras e ervilhas) as principais fontes de renda agropecuária do estado
Outros produtos cultivados são o algodão (o Arizona já foi o maior produtor nacional) e frutas cítricas
Leite e carne bovina são as principais fontes de renda da indústria pecuária do estado
Os efeitos da pesca e da silvicultura são negligíveis na economia.
O setor secundário responde por 23% do PIB do Arizona
O valor total dos produtos fabricados no estado é de 28 bilhões de dólares
Os principais produtos industrializados fabricados são computadores, produtos eletrônicos e alimentos industrialmente processados
A indústria de manufatura responde por 16% do PIB, empregando aproximadamente 227 mil pessoas
A indústria de alta tecnologia é facilmente o maior setor industrial do Arizona, empregando 161 166 pessoas
O Arizona é um grande produtor de eletrônicos em geral
Dos trabalhadores empregados na indústria de alta tecnologia, 34 314 estão trabalhando na produção de computadores e softwares, 30 358 na produção de componentes de computadores, 25 641 na indústria aeroespacial e 21 378 trabalhadores em serviços de arquitetura e engenharia, e 21 224 pessoas trabalhando na produção de produtos de telecomunicações
A indústria de construção responde por 6% do PIB e emprega aproximadamente 180 mil pessoas
A mineração responde por 1% do PIB do Arizona, empregando cerca de 16 mil pessoas
O estado é um dos maiores mineradores de cobre dos Estados Unidos, já tendo sido o maior produtor nacional, fato que lhe rendeu o cognome de The Copper State (O estado do cobre).
O setor terciário responde por 75% do PIB do Arizona
Serviços comunitários e pessoais respondem por 21% do PIB, empregando mais de 240 mil pessoas
Serviços financeiros e imobiliários respondem por cerca de 18% do PIB, empregando aproximadamente 350 mil pessoas
O comércio por atacado e varejo responde por 17% do PIB do Estado, e emprega aproximadamente 585 mil pessoas
O comércio do Arizona é muito auxiliado pelo turismo
O estado tem se destacado como um grande pólo turístico norte-americano, por causa de suas várias belezas naturais - em especial, o Grand Canyon - bem por causa de seu clima em geral quente e ensolarado, e seus invernos amenos.
O Wal Mart é o maior empregador privado do Arizona, tendo empregado 17 343 pessoas em 2003
Serviços governamentais respondem por 12% do PIB, empregando aproximadamente 345 mil pessoas
Transportes, telecomunicações e utilidades públicas empregam 118 mil pessoas, e respondem por 7% do PIB do estado
Sozinho, o setor de telecomunicações emprega 21 224 pessoas
45% da eletricidade gerada no estado é produzida em usinas termelétricas a carvão, 35% em usinas nucleares, e 20% em usinas hidrelétricas.
As primeiras escolas do Arizona foram fundadas por missionários espanhóis
Estas escolas, porém, ensinavam primariamente religião
Após a independência mexicana em 1821, os mexicanos expulsaram todos os missionários nascidos na Espanha
Estas escolas, voltadas primariamente para a conversão de nativos norte-americanos ao catolicismo, foram eventualmente abandonadas pelo governo mexicano
As primeiras escolas públicas foram fundadas em Tucson, em 1870
Na década de 1880, o governo do Arizona criou um sistema de fundos voltados à educação, e tornou obrigatória a educação a todas as crianças morando no estado
Até 1951, as escolas do Arizona eram segregadas.
Atualmente, todas as instituições educacionais no Arizona precisam seguir regras e padrões ditadas pelo Conselho Estadual de Educação do Arizona
Este conselho controla diretamente o sistema de escolas públicas do estado, que está dividido em diferentes distritos escolares
Cada cidade primária (city), diversas cidades secundárias (towns) e cada condado, é servida por um distrito escolar
Nas cidades, a responsabilidade de administrar as escolas é do distrito escolar municipal, enquanto que em regiões menos densamente habitadas, esta responsabilidade é dos distritos escolares operando em todo o condado em geral
Em regiões menos densamente habitadas, a responsabilidade de fornecer educação pública é dos condados
O Arizona permite a operação de escolas charter - escolas públicas independentes, que não são administradas por distritos escolares, mas que dependem de verbas públicas para operarem
Atendimento escolar é compulsório para todas as crianças e adolescentes com mais de seis anos de idade, até a conclusão do segundo grau ou até os quinze anos de idade.
Em 1999, as escolas públicas do estado atenderam cerca de 852,6 mil estudantes, empregando aproximadamente 43,9 mil professores
Escolas privadas atenderam cerca de 44,1 mil estudantes, empregando aproximadamente 3,3 mil professores
O sistema de escolas públicas do estado consumiu cerca de 3,963 bilhões de dólares, e o gasto das escolas públicas foi de aproximadamente 5,2 mil dólares por estudante
Cerca de 83,8% dos habitantes com mais de 25 anos de idade possuem um diploma de segundo grau.
As primeiras bibliotecas do Arizona foram fundadas por missionários espanhóis, no início do século XIX
Porém, estas bibliotecas foram eventualmente abandonadas após a independência do México em 1821
As primeiras bibliotecas públicas foram fundadas em Phoenix e em Tucson, na década de 1870
Atualmente, a grande maioria das cidades do Arizona possui ao menos uma biblioteca pública.
A instituição de educação superior mais antiga do Arizona é a Universidade do Estado do Arizona, que foi fundada em Tempe, em 1885
Atualmente, o Arizona possui 71 instituições de educação superior, dos quais 25 são públicas e 46 são privadas
Três destas instituições são universidades públicas, 10 são universidades privadas, sendo o restante faculdades
Phoenix e Tucson são os principais centros educacionais do Arizona.
Phoenix é o principal centro aeroportuário, ferroviário e rodoviário do Arizona
Em 2002, o estado possuía 2 860 quilômetros de ferrovias
Em 2003, o Arizona possuía 92 584 quilômetros de vias públicas, dos quais 1 878 quilômetros eram rodovias interestaduais, considerados parte do sistema rodoviário federal dos Estados Unidos.
O principal aeroporto do estado é o Aeroporto Internacional Sky Harbor, localizado em Phoenix
É o décimo aeroporto mais movimentado dos Estados Unidos e o décimo segundo mais movimentado do mundo em número de passageiros, e o mais movimentado do mundo, tratando-se de tonelagem de carga movimentada.
O primeiro jornal publicado no Arizona foi o Weekly Arizonian, em Tubac, em 1859
Atualmente são publicados no Arizona cerca de 100 jornais, dos quais 18 são diários
Muitos destes jornais são publicados em espanhol, graças à grande população hispânica do estado
Outros 95 periódicos são impressos no estado.
A primeira estação de rádio do Arizona foi fundada em 1922, em Phoenix, e a primeira estação de televisão foi fundada em 1953, também em Phoenix
Atualmente, o Arizona possui 125 estações de rádio - dos quais 58 são AM e 67 são FM - e 22 estações de televisão
Muitas destas estações possuem sua programação em espanhol.
Atrações turísticas · Bandeira · Listas · NHLs · NRHPs · Parques estaduais
Chandler · Flagstaff · Gilbert · Glendale · Kingman · Lake Havasu City · Mesa · Peoria · Phoenix · Prescott · Scottsdale · Sierra Vista · Tempe · Tucson · Yuma
Apache · Cochise · Coconino · Gila · Graham · Greenlee · La Paz · Maricopa · Mohave · Navajo · Pima · Pinal · Santa Cruz · Yavapai · Yuma
O pâncreas é uma glândula de aproximadamente 15 cm de extensão fazendo parte do sistema digestivo e endócrino dos seres humanos que se localiza atrás do estômago e entre o duodeno e o baço
Ele é tanto exócrino (secretando suco pancreático, que contém enzimas digestivas) quanto endócrino (produzindo muitos hormônios importantes, como insulina, glucagon e somatostatina)
Divide-se em cabeça, corpo e cauda
O pâncreas é um órgão produtor de enzimas, proteínas que aumentam a rapidez das transformações químicas.


Em humanos, geralmente o pâncreas é uma glândula longa com 15–25 cm que se localiza no abdômen
Sendo uma das glândulas retroperitoneais, ele é localizado posteriormente ao estômago e está em associação próxima ao duodeno.
É frequentemente descrito como tendo três regiões: a cabeça, corpo e a cauda.
O ducto pancreático (também chamado de ducto de Wirsung) percorre o comprimento do pâncreas e termina na segunda porção do duodeno, na ampola de Vater (hepatopancreática)
O ducto biliar comum geralmente se une ao ducto pancreático neste ponto ou próximo dele
Muitas pessoas também possuem um pequeno ducto acessório, o ducto de Santorini.
O pâncreas é suprido arterialmente pelas artérias pancreaticoduodenais: A artéria mesentérica superior que origina as artérias pancreaticoduodenais inferiores A artéria gastroduodenal que origina as artérias pancreaticoduodenais superiores A artéria esplênica que origina as artérias pancreáticas.
A drenagem venosa é feita através das veias pancreáticas que são tributárias das veias esplênica e mesentérica superior, no entanto a maioria delas terminam na veia esplênica
A veia porta hepática é formada pela união da veia mesentérica superior e veia esplênica posteriormente ao colo do pâncreas
Geralmente a veia mesentérica inferior se une à veia esplênica atrás do pâncreas (em outras pessoas ela simplesmente se une à veia mesentérica superior).
No microscópio, quando corado adequadamente, é fácil se distinguir os dois tipos diferentes de tecidos no pâncreas
Essas regiões correspondem às funções pancreáticas principais:
O pâncreas endócrino é composto de aglomerações de células especiais denominadas ilhotas de Langerhans
O "cansaço" crônico destas células leva ao aparecimento da diabetes no pâncreas.
Existem quatro tipos de células nas ilhotas de Langerhans
Elas são relativamente difíceis de se distinguir ao usar técnicas normais para corar o tecido, mas elas podem ser classificadas de acordo com sua secreção:
Porção que secreta, no duodeno, por meio de um ducto, o suco pancreático, contendo enzimas e bicarbonato.
Devido à sua importância na digestão e na produção de hormônios, as doenças do pâncreas possuem significativa relevância na prática clínica.
Ductos biliares: (bile canaliculus, ducto hepático comum, ducto cístico, ducto colédoco) | Ducto pancreático | Ampola hepatopancreática
Em biologia, um órgão (do latim organum, "instrumento, ferramenta", do grego όργανον (órganon), "órgão, instrumento, ferramenta") é um grupo de tecidos que desempenham uma função específica ou grupo de funções
Usualmente existem tecidos "principais" e "esporádicos"
O tecido principal é aquele que é único para um órgão específico
Por exemplo, o tecido principal no coração é o miocárdio, enquanto os esporádicos são os nervos, sangue, tecido conjuntivo, etc.
Em botânica e zoologia - principalmente na anatomia, um órgão é um conjunto de tecidos que evoluíram para executar determinada função vital
Alguns órgãos comuns aos vertebrados são o coração, o cérebro, o estômago, etc
Nas plantas "superiores", os órgãos principais são a raiz, o caule, as folhas, as flores e os frutos.
Um conjunto de órgãos com funções relacionadas chama-se um sistema
Por exemplo, o sistema respiratório dos animais ou o sistema radicular das plantas vasculares
Ei criança, assista o canal medicina é para saber mais


Os órgãos dos animais incluem o coração, pulmão, cérebro, olhos, estômago, baço, ossos, pâncreas, rim, fígado, intestinos, pele (o maior órgão), bexiga, e os órgãos sexuais
Os órgãos internos coletivamente são às vezes chamados de "vísceras".
Os órgãos das plantas podem se dividir em vegetativo e reprodutivo
Os órgãos vegetativos das plantas são raiz, caule e folha, enquanto os reprodutivos são a flor, semente e fruta.
Os órgãos vegetativos são essenciais para manter a vida de uma planta (eles formam as funções vitais, como a fotossíntese), enquanto os reprodutivos são essenciais na reprodução
Mas, se existe reprodução vegetativa assexual, os órgãos vegetativos são aqueles que criam a nova geração de plantas.
Um grupo de órgãos relacionados compõe um sistema orgânico
Órgãos possuindo um sistema podem ser relacionados em inúmeras formas, mas funções relacionadas são na maioria comumente usadas
Por exemplo o sistema urinário compreende órgãos que trabalham juntos para produzir, guardar e transportar a urina.
As funções dos sistemas orgânicos muitas vezes compartilham significantes justaposições
Por exemplo, os sistemas nervoso e endócrino operam através de uma partilha de ambos os órgãos, o hipotálamo
Por esta razão, os dois sistemas são combinados e estudados como o sistema neuroendócrino
O mesmo é verdade para o Sistema musculoesquelético, que envolve a relação entre o sistema muscular e o sistema esquelético.
São considerados tipicamente como sistemas orgânicos do corpo humano:
Hormona  ou hormônio  é uma substância química específica fabricada pelo sistema endócrino ou por neurónios altamente especializados e que funciona como um sinalizador celular
O termo provém do grego ormóni (ὁρμῶν) que significa evocar ou excitar.


O nome hormona foi primeiramente utilizado em 1905, pelo fisiologista inglês Ernest Starling durante uma palestra sobre o controle químico das funções corporais no Royal College of Physicians em Londres
Ele definiu hormonas como mensageiros químicos produzidos recorrentemente para atender necessidades fisiológicas do organismos e carregados do órgão em que são produzidos para o orgão de destino pela corrente sanguínea
Poucos anos antes, Starling e seu colega William Bayliss haviam identifcado o primeiro hormona, a secretina, durante experimentos sobre a digestão.
As hormonas ou hormônios são secretados em quantidades muito pequenas na corrente sanguínea
Assim sendo, podem ser produzidas por um órgão ou em determinadas células do órgão
São libertadas e transportadas diretamente pelo sangue
A sua função é exercer uma ação reguladora (indutora ou inibidora) em outros órgãos ou regiões do corpo
Em geral trabalham devagar e agem por muito tempo, regulando o crescimento, o desenvolvimento, a reprodução e as funções de muitos tecidos, bem como os processos metabólicos do organismo.
Os hormônios ligam-se aos receptores localizados sobre a superfície da célula ou no seu interior, sendo que a ligação de um hormona a um receptor acelera, reduz ou altera a função celular de uma outra maneira, controlando a função de órgãos inteiros
Alguns hormonas afetam somente um ou dois órgãos (eg
hormona estimulante da tireóide), enquanto outros afetam todo o organismo (eg
hormona tireoidiano).
Podemos também citar como exemplo a insulina, que controla a razão e a maneira pela qual a glicose é utilizada pelo corpo
Outras hormonas incluem as sexuais, os corticoesteroides, a adrenalina, a tiroxina, e a hormona do crescimento
Em plantas, as hormônios são conhecidas como factores de crescimento.
Nas mulheres, por volta dos 40 anos de idade, há uma queda brusca na produção de hormônios, que é chamada de menopausa; nos homens, essa queda é chamada de andropausa.
Algumas dos hormônios mais conhecidas são os que regulam as funções sexuais dos mamíferos (a testosterona e o estrogénio) e as que regulam o nível de glicose no sangue (como a insulina).
Alguns dos principais órgãos produtores de hormonas no homem são a hipófise, o hipotálamo, a tiroide, as paratiroides, as glândulas suprarrenais, o pâncreas e as gónadas.
Os hormonas podem ser classificados segundo as propriedades químicas:
Testículos: testosterona • AMH • inibina
Ovário: estradiol · progesterona · activin and inhibin · relaxina (gestação)

Insulina é uma hormona responsável pela redução da glicémia (taxa de glicose no sangue), ao promover a entrada de glicose nas células
Esta é também essencial no metabolismo de sacáridos (hidrato de carbono), na síntese de proteínas e no armazenamento de lípidos (gorduras).
É produzida nas células beta das ilhotas de Langerhans, do pâncreas endócrino
Atua numa grande parte das células do organismo, como nas células presentes no fígado, em músculos e no tecido adiposo, contudo não atua em células específicas cujos transportadores membranares não são sensíveis à insulina, como é o caso das células nervosas.
Quando a produção de insulina é deficiente, a glicose acumula-se no sangue e na urina, destruindo as células por falta de abastecimento: diabetes mellitus
Para doentes nessa condição, a insulina é providenciada através de injeções, ou bombas de insulina
Recentemente foi aprovado o uso de insulina inalada
Porém, ainda existem controvérsias acerca do uso do produto comercializado pela Pfizer
A agência de saúde britânica não recomenda o uso.
A insulina é um polipéptido de estrutura química plenamente conhecida, e pode ser sintetizada a partir de diversos animais
Mais recentemente, surgiram os medicamentos análogos de insulina, que constituem moléculas que, não sendo insulina, possuem as mesmas características químicas e portanto reactivas, são moléculas "de insulina" modificadas em laboratório.
O controlo da produção de insulina pelo corpo é um sistema muito complexo.


Em 1869, Paul Langerhans, um estudante de medicina em Berlim, estudava a estrutura do pâncreas através de um microscópio quando reparou em células, antes desconhecidas, espalhadas pelo tecido exócrino
A função da "pequena porção de células", mais tarde denominada como ilhotas de Langerhans, era desconhecida, mas Edouard Laguesse posteriormente sugeriu que tais células poderiam produzir algum tipo de secreção que participasse no processo de digestão.
Em 1889, o médico germano-polaco Oscar Minkowski em colaboração com Joseph von Mehring removeu o pâncreas de um cão saudável para demonstrar o papel do órgão na digestão de alimentos
Vários dias após a remoção do pâncreas, o guarda do cão reparou que existiam muitas moscas a alimentarem-se da urina do animal
Verificou-se com o teste da urina do cão que havia açúcar nesta, o que demonstrou pela primeira vez a relação entre o pâncreas e a diabetes
Em 1901, outro passo importante foi alcançado por Eugene Opie, quando este estabeleceu claramente a ligação entre as ilhotas de Langerhans e a diabetes: "Diabetes mellitus..
é causada pela destruição das ilhotas de Langerhans e ocorre apenas quando tais células são em parte ou totalmente destruídas".
Durante as duas décadas seguintes foram feitas várias tentativas de isolamento da secreção das ilhotas como um tratamento potencial de diabetes
Em 1906, Georg Ludwig Zuelzer foi parcialmente feliz no tratamento de cães com extrato pancreático, mas teve que interromper o seu trabalho
Entre 1911 e 1912, E
L
Scott da Universidade de Chicago usou extratos pancreáticos aquosos e notou uma leve diminuição da glicosúria, mas não conseguiu convencer o director da instituição com os resultados, e a pesquisa teve de ser encerrada
Israel Kleiner demonstrou efeitos semelhantes na Rockfeller University em 1919, mas o seu trabalho foi interrompido pela Primeira Guerra Mundial
Nicolae Paulescu, um professor de fisiologia da Escola Romena de Medicina, publicou um trabalho parecido em 1921 realizado na França e patenteado na Romênia, e discute-se desde então se Paulescu não tenha sido o verdadeiro descobridor da insulina.
Entretanto, o comitê do Prêmio Nobel em 1923 deu crédito pela extração prática da insulina a uma equipa da Universidade de Toronto
Em outubro de 1920, Frederick Banting lia um dos artigos de Minkowski e concluiu que Minkowski estava a estudar as secreções digestivas originalmente, e por isso não se conseguia extrair a insulina com sucesso
Ele redigiu uma nota para si mesmo: "Ligar duto pancreático do cão
Manter cães vivos até que acinos se degenerem, sobrando ilhotas
Tentar isolar secreção interna delas e aliviar glicosúria".
Ele viajou a Toronto para se encontrar com J
J
R
Macleod, que não se impressionou plenamente com a ideia
De qualquer forma, Macleod deixou à disposição de Banting um laboratório da universidade, e um assistente, Charles Best, e dez cães enquanto saía de férias no verão de 1921
O método de Banting e Best era amarrar uma ligadura ao redor do duto pancreático dos cães e, várias semanas depois, examinar que as células digestivas pancreáticas tinham morrido e sido absorvidas pelo sistema imunológico, deixando milhares de ilhotas
Isolava-se a proteína dessas ilhotas para produzir o que vinham chamando de isletina
Banting e Best mantiveram um cão pancreatectomizado vivo durante todo o verão.
Macleod viu o valor da pesquisa no seu regresso da Europa, mas pediu uma contraprova para saber se o método realmente funcionava
Várias semanas depois ficou claro que o segundo ensaio tinha sido um sucesso, e assim Macleod ajudou na publicação dos resultados em novembro daquele ano
Porém, precisavam de seis semanas para extrair a isletina, o que tornava o ensaio dramaticamente demoroso
Banting sugeriu que tentassem usar pâncreas de feto de bezerro, que ainda não teria desenvolvido glândulas digestivas, e ficou alivado pelo sucesso da empreitada.
Com a solução para a fonte de isletina, faltava agora purificar a proteína
Em dezembro de 1921, Macleod convidou o brilhante bioquímico James Collip para ajudar na tarefa, e num mês prepararam-se para um teste.
Em 11 de janeiro de 1922, Leonard Thompson, um diabético de quatorze anos, recebeu a primeira injeção de insulina
Infelizmente, o extrato estava tão impuro que ele acabou sofrendo uma reação alérgica severa, e injeções adicionais foram canceladas
Durante os doze dias seguintes, Collip trabalhou dia e noite para melhorar o extrato, e uma segunda dose foi injetada no dia 23
Desta vez foi um sucesso, não apenas em não apresentar efeitos colaterais, mas também por eliminar completamente os sintomas de diabetes
Entretanto, Banting e Best não se davam bem com Collip, porque aparentemente viam nele um intruso, e então Collip abandonou-os.
Durante a primavera de 1922, Best conseguiu melhorar as técnicas de preparo a ponto de poder extrair grandes quantidades de insulina, embora o extrato ainda permanecesse impuro
Contudo, receberam uma oferta de ajuda de Eli Lilly logo após as suas publicações em 1921, e aceitaram-na em abril
Em novembro, Lilly conseguiu a façanha de produzir grandes quantidades de insulina bastante pura
Depois disso, a insulina foi lançada no mercado.
Por esta descoberta marcante, Macleod e Banting foram premiados com o Prêmio Nobel em Fisiologia em 1923
Banting, aparentemente insultado porque Best não fora mencionado, dividiu seu prêmio com ele, e Macleod imediatamente dividiu o seu com Collip
A patente da insulina foi vendida à Universidade de Toronto por um dólar.
A sequência exata de aminoácidos contida na molécula de insulina, a chamada estrutura primária, foi determinada pelo biólogo britânico Frederick Sanger
Foi a primeira vez que a estrutura de uma proteína fora completamente determinada
Por isso, ele recebeu o Prêmio Nobel de Química em 1958
Em 1967, após décadas de trabalho, Dorothy Crowfoot Hodgkin determinou a conformação espacial da molécula mediante estudos de difração de raios X
Ela também recebeu um Prêmio Nobel.
A insulina é sintetizada nos humanos e em outros mamíferos dentro das células-beta das ilhotas de Langerhans, no pâncreas
Um a três milhões de ilhotas de Langerhans formam a parte endócrina do pâncreas, que é principalmente uma glândula exócrina
A parte endócrina totaliza apenas 2% da massa total do órgão
Dentro das ilhotas de Langerhans, as células-beta constituem 60-80% do todo.
A insulina é sintetizada a partir da molécula precursora proinsulina pela ação de enzimas proteolíticas conhecidas como prohormônio convertases (PC1 e PC2)
A insulina ativa tem 51 aminoácidos e é um polipeptídeo
A insulina bovina difere da humana em três resíduos de aminoácidos enquanto que a suína, em um resíduo
A insulina de peixes também é muito próxima à humana
Em humanos, a insulina tem um peso molecular de 5808
Ela é formada por duas cadeias de polipeptídeos ligadas por duas pontes dissulfídicas (veja a figura), com uma ligação dissulfídica adicional na cadeia A (não mostrada)
A cadeia A consiste de 21, e a cadeia B, de 30 aminoácidos
A insulina é produzida como uma molécula de prohormônio - proinsulina - que é mais tarde transformada, por ação proteolítica, em hormônio ativo.
A parte restante da molécula de proinsulina é chamada de peptídeo C
Este polipeptídeo é liberado no sangue em quantidades iguais à da insulina
Como insulinas exógenas não contêm peptídeo C, o nível em plasma desse peptídeo é um bom indicador de produção endógena de insulina
Recentemente, descobriu-se que esse peptídeo C também possui atividade biológica, que está aparentemente restrita a um efeito na camada muscular das artérias.
Pacientes com diabetes mellitus tipo 1 dependem de Insulinoterapia, ou seja da administração de insulina exógena (geralmente por via subcutânea), para a sua sobrevivência, pois a hormona não é produzida por seu organismo
Também certos pacientes com diabetes tipo 2 podem eventualmente necessitar de insulina se outras medicações não conseguirem controlar os níveis de glicose no sangue de forma adequada.
Inicialmente a insulina utilizada por diabéticos era extraída do pâncreas de bois e porcos, por ser parecida com a humana, mas esta insulina podia acarretar problemas, como reações alérgicas, ou não ser eficaz em alguns pacientes
Atualmente a insulina é produzida através da técnica de ADN recombinante, primeiro produto da moderna biotecnologia a ser comercializado mundialmente
A técnica surgiu no Brasil em 1990, em um projeto desenvolvido por Marcos Luís Mares Guia, bioquímicos da UFMG e pesquisadores da Biobrás e da Universidade de Brasília
A técnica consiste em introduzir na bactéria Escherichia coli, comum na flora intestinal humana, o gene da pró-insulina humana, para que ela passe a produzir o hormônio, um processo que dura 30 dias, um terço do tempo do método tradicional
Em 2001 somente quatro empresas no mundo, incluindo a Biobrás, tinham tecnologia de produção industrial da insulina recombinante
A Biobrás patenteou o processo nos Estados Unidos em 2000 e em 2002 foi comprada pela dinamarquesa Novo Nordisk
Comprada a Biobrás, a Novo Nordisk elevou rapidamente seus preços de fornecimento ao Ministério da Saúde combinando a importação e produção local, até acabarem fechando a produção dos cristais de insulina no Brasil para aqui fazer só envazamento.
Em 2013 o governo federal anunciou que o Brasil vai retomar a produção de insulina por meio do Laboratório Biomanguinhos, da Fundação Oswaldo Cruz, parte de um acordo firmado entre o governo e o laboratório ucraniano Indar, um dos três produtores remanescentes de insulina no mundo, que vai transferir a tecnologia para a produção nacional do medicamento.
Após o acordo de intenções com a Ucrânia, a Novo Nordisk, embora alegasse que a insulina ucraniana não tinha qualidade, fez proposta de compra do Indar ao governo
Um mês após a assinatura do contrato, em uma nova licitação governamental para aquisição de insulina, os preços da insulina oferecidos pelas empresas concorrentes baixaram quase à metade.
As ações nas células incluem:
Testículos: testosterona • AMH • inibina
Ovário: estradiol · progesterona · activin and inhibin · relaxina (gestação)
A glicemia é regulada, principalmente, por 2 hormônios produzidos no pâncreas: a insulina e o glucagon
A insulina favorece a absorção da glicose pelas células, enquanto que o glucagon promove a glicogenólise no fígado, quando ocorre baixa nos valores de glicemia.
A glicemia (do grego γλεῦκος, mosto, por extensão doce) é a concentração de glicose no sangue ou mais precisamente no plasma.
O nosso corpo transforma alguns dos hidratos de carbono ingeridos em glicose e a glicemia é o nível de glicose presente no nosso sangue
Ou seja, quando comemos muito, a glicemia aumenta, ao passo que quando comemos pouco, esta mantém-se baixa
O aumento da glicemia está intimamente relacionado ao consumo de carboidratos na dieta, sejam eles integrais (aumento glicêmico lento e seguro) ou refinados (aumento glicêmico rápido e perigoso), também levando em consideração para isso as combinações de alimentos numa refeição ou lanche.
Mede-se a glicemia através da confirmação dos sinais e sintomas clássicos da glicemia em jejum (exame de sangue onde são verificadas as taxas de glicose no sangue) e do teste padronizado de tolerância à glicose (TTG).
Estes critérios diagnosticados estão baseados nas recomendações da comunidade médico-científica atual:
Além da insulina, diabéticos podem controlar a glicemia através de dietas específicas e pratica de exercícios físicos, pois, a prática regular de exercício físico aumenta a ação da insulina, fazendo com que a glicose saia da corrente sanguínea, diminuindo, conseqüentemente, a glicemia
Actualmente tornou-se comum a "contagem de carboidratos" dos alimentos através do "indice glicêmico", um indicador de qualidade do carboidrato quanto à sua habilidade em aumentar e/ou influenciar a glicemia.
A manutenção da glicemia em valores fora do padrão normal, tanto para mais quanto para menos, acarreta uma série de complicações para a saúde, além do diabetes
Pesquisa publicada no respeitado periódico Neurology em setembro de 2012 comprovou que até mesmo valores de glicemia considerados um pouco acima do normal são um grave perigo para a saúde cerebral
De acordo com o estudo, idosos que mantiveram os valores de glicemia bem próximos ao valor considerado normal (110 mg/dL) apresentaram uma perda de 6-10% no volume cerebral ao longo de quatro anos, o que pode acarretar doenças neurológicas como Alzheimer e demência
O encolhimento cerebral exibido por eles foi consideravelmente maior em comparação a idosos que possuíam valores de glicemia menores.
146 °C 
α-D-glucose: 146 °C 
β-D-glucose: 150 °C 
A glicose, glucose ou dextrose, é um monossacarídeo e é um dos carboidratos mais importantes na biologia
As células a usam como fonte de energia e intermediário metabólico
A glicose é um dos principais produtos da fotossíntese e inicia a respiração celular em seres procariontes e eucariontes
É um cristal sólido de sabor adocicado, de formula molecular C6H12O6, encontrado na natureza na forma livre ou combinada
Juntamente com a frutose e a galactose, é o carboidrato fundamental de carboidratos maiores, como sacarose e maltose
Amido e celulose são polímeros de glucose.
No metabolismo, a glicose é uma das principais fontes de energia e fornece 4 calorias de energia por grama
A glicose hidratada (como no soro glicosado) fornece 3,4 calorias por grama
Sua degradação química durante o processo de respiração celular dá origem a energia química (armazenada em moléculas de ATP - 36 ou 38 moleculas (depende da celula) de ATP por moléculas de glicose), gás carbônico e água.
Por ter 6 átomos de carbono é classificada como uma hexose, uma subcategoria dos monossacarídeos
A D-Glicose é um dos 16 estereoisômeros da aldohexose, também conhecida como dextrose acontece abundantemente na natureza, diferente de seu isomero L-Glicose
No Brasil é comumente fabricada a partir da cana-de-açúcar.
No ano de 1747, Andreas Sigismund Marggraf foi o primeiro a isolar a glicose.
A glicose quando em soluçao com a substancia Benedict sob aquecimento muda sua cor de azul para laranja .
Apresenta fórmula mínima: CH2O
Fórmula estrutural:
A glicose (C6H12O6) contém seis átomos de carbono e um grupo aldeído e é consequentemente referida como uma aldo-hexose
A molécula de glicose pode existir em uma forma de cadeia aberta (acíclica) e anel (cíclica) (em equilíbrio), a última sendo o resultado de uma reação intramolecular entre o átomo C do aldeído e a grupo hidroxil C-5 para formar um hemiacetal intramolecular
Em solução aquosa as duas formas estão em equilíbrio, e em pH 7 a forma cíclica é predominante
Como o anel contém cinco átomos de carbono e um átomo de oxigênio, o que lembra a estrutura do pirano, a forma cíclica da glucose também é referida como glucopiranose
Neste anel, cada carbono está ligado a um grupo hidroxila lateral com exceção do quinto átomo, que se liga ao sexto átomo de carbono fora do anel, formando um grupo CH2OH.

O nome Glicose veio do grego (γλυκύς), que significa "doce", mais o sufixo -ose, indicativo de açúcar
Tem função de regulador de energia, participa das vias metabólicas, além de ser precursora de outras importantes moléculas.
A aerobiose refere-se a um processo bioquímico que representa a forma mais eficaz de obter energia a partir de nutrientes como a glicose, na presença obrigatória de oxigênio
Os seres vivos que procedem à aerobiose são os seres aerobióticos
A maioria dos seres vivos encontram-se nestas condições
Os seres vivos que sobrevivem sem oxigênio são anaeróbios.
As reacções aerobióticas são um tipo específico de um processo mais global, designado por respiração celular
Através destas reacções, a glicose é degradada em dióxido de carbono e água, libertando-se energia
É, assim, como que o processo inverso da fotossíntese, onde as plantas produzem glicose usando água, dióxido de carbono e energia solar.


A respiração aeróbia nos seres vivos é caracterizada fundamentalmente pela utilização do oxigênio para a quebra da molécula de glicose
Isso é feito em uma organela especial das células chamada mitocôndria
Para fins didáticos ela normalmente é dividida em três fases:
Esta fase acontece ainda no citoplasma (hialoplasma) da célula, fora da mitocôndria
Por ação de enzimas, a molécula de glicose (composta de seis carbonos, 12 hidrogênios e seis oxigênios) é quebrada em duas moléculas menores de ácido pirúvico (cada uma com três carbonos)
A partir delas, por ação também de enzimas ocorre a liberação de dióxido de carbono (CO2), transformando-as em ácido acético (cada uma com dois carbonos).
Nesta fase ocorre a formação de duas moléculas de ATP (responsáveis pelo armazenamento de energia).
Esta fase acontece dentro da mitocôndria, em suas matriz
A molécula de ácido pirúvico entra na mitocôndria, e então começa uma espécie de reconstituição da molécula, para torná-la novamente com seis carbonos
Essa molécula de ácido pirúvico é carregada por uma molécula chamada "acetil CoA" (que possui dois carbonos)
A molécula de acetil CoA faz com que o ácido pirúvico se una com uma molécula de ácido oxaloacético (composta de 4 carbonos)
Ao unirem-se, forma-se uma molécula composta de seis carbonos, 12 hidrogênios e seis oxigênios (mesma da glicose, porém com os hidrogênios em posição diferente), agora chamada de ácido cítrico
A molécula de acetil CoA sai da reação para voltar a carregar mais moléculas de ácido acético para completar o ciclo.
Nesta fase há formação de 4 ATP's e toda a glicose é quebrada nesta etapa.
Sendo a fase mais energética da respiração aeróbia, ela acontece na crista da mitocôndria
É a única fase em que há utilização de oxigênio para a quebra de moléculas, caracterizando a respiração Aeróbia
A molécula de ácido cítrico é quebrada por moléculas de oxigênio, fazendo com que, ao invés de separar em moléculas menores, como o ocorrido na primeira fase, as moléculas são quebradas perdendo um oxigênio por vez
Assim, o ácido cítrico de seis carbonos é quebrado por uma molécula de oxigênio em uma molécula de cinco carbonos, liberando gás carbônico, água e energia para a formação de ATP
Por sua vez, a molécula composta de cinco carbonos será quebrada em uma de quatro, e assim sucessivamente.
É a partir desta quebra, que se forma o ácido oxaloacético, utilizado para juntar-se com o ácido pirúvico na segunda fase.
Na maioria das células, o número de moléculas totais de ATP's produzidas são de 36
Entretanto há células como as do coracão, rins e fígado cujo toral é de 38 moléculas de ATP produzidas.
A morte por afogamento ou choque anafilático é consequência da não realização da etapa Cadeia Respiratória (ou transportadora de elétrons) da respiração celular.
Os produtos finais da respiração celular é o CO2 (gás carbônico), H2O (água) e ATP
O NAD e o FAD são receptores intermediários de hidrogênio; já o O2 (oxigênio) é o receptor final.
As células são as unidades estruturais e funcionais dos organismos vivos
Alguns organismos, tais como as bactérias, são unicelulares (consistem em uma única célula)
Outros, tais como os seres humanos, são pluricelulares (várias células).
O corpo humano é constituído por aproximadamente 10 trilhões (mais de 10) de células; A maioria das células vegetais e animais têm entre 1 e 100 µm e, portanto, são visíveis apenas sob o microscópio; a massa típica da célula é um nanograma.
A célula foi descoberta por Robert Hooke em 1663 / 1665
Em 1837, antes de a teoria final da célula estar desenvolvida, Jan Evangelista Purkyně observou "pequenos grãos" ao olhar um tecido vegetal através de um microscópio
A teoria da célula, desenvolvida primeiramente em 1838 por Matthias Jakob Schleiden e por Theodor Schwann, indica que todos os organismos são compostos de uma ou mais células
Todas as células vêm de células preexistentes
As funções vitais de um organismo ocorrem dentro das células, e todas elas contêm informação genética necessária para funções de regulamento da célula, e para transmitir a informação para a geração seguinte de células.
A palavra "célula" vem do latim: cellula (quarto pequeno)
O nome descrito para a menor estrutura viva foi escolhido por Robert Hooke
Em um livro que publicou em 1665, ele comparou as células da cortiça com os pequenos quartos onde os monges viviam.


As células foram descobertas entre 1663 e 1665 pelo inglês Robert Hooke
Ao examinar em um microscópio rudimentar, uma fatia de cortiça, verificou que ela era constituída por cavidades poliédricas, às quais chamou de células (do latim "cella", pequena cavidade)
Na realidade Hooke observou blocos hexagonais que eram as paredes de células vegetais mortas.
Enquanto isso, Antonie van Leeuwenhoek (1632–1723), um holandês que ganhava a vida vendendo roupas e botões, estava gastando seu tempo livre moendo lentes e construindo microscópios de qualidade notável
Ele desenhou protozoários, tais como o Vorticella da água da chuva, e bactérias de sua própria boca
Van Leeuwenhoek foi contemporâneo e amigo do pintor Johannes Vermeer (1632-1675) da cidade de Delft que foi pioneiro no uso da luz e da sombra na arte ao mesmo tempo em que van Leeuwenhoek estava explorando o uso da luz para descobrir o mundo microscópico.
Em 1838 Matthias Schleiden e Theodor Schwann, estabeleceram o que ficou conhecido como teoria celular: "todo o ser vivo é formado por células tronco".
As células são envolvidas pela membrana celular e preenchidas com uma solução aquosa concentrada de substâncias químicas e substâncias físicas, o citoplasma em que se encontram dispersos organelos (por vezes escrito organelas, organóides, orgânulos ou organitos).
As formas mais simples de vida são organismos unicelulares que se propagam por cissiparidade
As células podem também constituir arranjos ordenados, os tecidos.
De acordo com a organização estrutural, as células são divididas em: eucarióticas e procarióticas
As células procarióticas são geralmente independentes, enquanto que as células eucarióticas são frequentemente encontradas em organismos multicelulares.
As células procarióticas, também chamadas de protocélulas, são muito diferentes das eucariontes
Em geral, são bem menores e menos complexas estruturalmente do que as células eucarióticas.
A sua principal característica é a ausência da carioteca individualizando o núcleo celular ao qual chamamos de nucleoide., pela ausência de alguns organelos e pelo pequeno tamanho que se acredita que se deve ao fato de não possuírem compartimentos membranosos originados por evaginação ou invaginação
Também possuem DNA na forma de um anel associado a proteínas básicas e não a histonas (como acontece nas células eucarióticas, nas quais o DNA se dispõe em filamentos espiralados e associados a histonas).
Estas células são desprovidas de mitocôndrias, plastídeos, complexo de Golgi, retículo endoplasmático e sobretudo cariomembrana o que faz com que o DNA fique disperso no citoplasma
Como organela, só possuem ribossomos
A este grupo pertencem:
As bactérias dos grupos das Rickettsias e das clamídias são muito pequenas, sendo denominadas células incompletas por não apresentarem capacidade de auto-duplicação independente da colaboração de outras células, isto é, só proliferarem no interior de outras células completas, sendo, portanto, parasitas intracelulares obrigatórios.
Diversas doenças de importância médica tem sido descritas para organismos destes grupos, incluindo algumas vinculadas aos psitacídeos (papagaios e outras aves, a psitacose) e carrapatos (a febre maculosa, causada pela Rickettsia rickettsii).
Estas bactérias são diferente dos vírus por apresentarem:
1
Cloroplasto
2
Vacúolo
3
Núcleo
As células eucariontes ou eucarióticas, também chamadas de eucélulas, são mais complexas que as procariontes
Possuem membrana nuclear individualizada e vários tipos de organelas
Todos os animais e plantas são dotados deste tipo de células.
É altamente provável que estas células tenham surgido por um processo de aperfeiçoamento contínuo das células procariontes, o que chamamos de Endossimbiose.
Não é possível avaliar com precisão quanto tempo a célula "primitiva" levou para sofrer aperfeiçoamentos na sua estrutura até originar o modelo que hoje se repete na imensa maioria das células, mas é provável que tenha demorado milhões de anos
Acredita-se que a célula "primitiva" tivesse sido bem pequena e para que sua fisiologia estivesse melhor adequada à relação tamanho × funcionamento era necessário que crescesse.
Acredita-se que a membrana da célula "primitiva" tenha emitido internamente prolongamentos ou invaginações da sua superfície, os quais se multiplicaram, adquiriram complexidade crescente, conglomeraram-se ao redor do bloco inicial até o ponto de formarem a intrincada malha do retículo endoplasmático
Dali ela teria sofrido outros processos de dobramentos e originou outras estruturas intracelulares como o complexo de Golgi, vacúolos, lisossomos e outras.
Quanto aos cloroplastos (e outros plastídeos) e mitocôndrias, atualmente há uma corrente de cientistas que acreditam que a melhor teoria que explica a existência destes orgânulos é a Teoria da Endossimbiose, segundo a qual um ser com uma célula maior possuía dentro de sí uma célula menor mas com melhores características, fornecendo um refúgio à menor e esta a capacidade de fotossintetizar ou de sintetizar proteínas com interesse para a outra.
Nesse grupo encontram-se:
Todas as células, tanto procariontes quanto eucariontes, tem uma membrana que envolve a célula, que separa o interior de seu ambiente, regula o que se move dentro e para fora (seletivamente permeável), e mantém o potencial elétrico da célula
Dentro da membrana, um citoplasma salino ocupa a maior parte do volume da célula
Todas as células possuem DNA, o material hereditário dos genes, e RNA, contendo as informações necessárias para sintetizar várias proteínas como enzimas, as máquinas primária da célula
Existem também outros tipos de biomoléculas nas células
Esta seção lista estes componentes primários da célula, e em seguida, descreve brevemente a sua função.
O citoplasma de uma célula está rodeado por uma membrana celular ou membrana plasmática
A membrana plasmática em plantas e procariontes é normalmente coberta por uma parede celular
Esta membrana serve para separar e proteger uma célula do seu ambiente circundante e é feita principalmente a partir de uma camada dupla de lipídeos (hidrófoba semelhante as moléculas de gordura) e moléculas de fósforo hidrofílicas
Assim, a camada é chamada uma bicamada de fosfolípido
Pode também ser chamada de uma membrana mosaico fluido
Incorporadas dentro desta membrana há uma variedade de moléculas de proteínas que actuam como canais e bombas que movem diferentes moléculas para dentro e para fora da célula
A membrana é dita ser 'semi-permeável', na medida em que pode deixar uma substância (molécula ou íon) passar livremente, passar através de uma forma limitada ou não passar de jeito nenhum
As membranas da superfície celular também contém proteínas receptoras que permitem que as células detectem moléculas externas de sinalização, tais como hormonas.
O citoesqueleto atua para organizar e manter a forma da célula; âncorar organelas no lugar; ajuda durante a endocitose, a absorção de materiais externos por uma célula, e na citocinese, a separação de células filhas após a divisão celular; e move partes da célula em processos de crescimento e de mobilidade
Normalmente, 20-35% das proteínas de uma célula estão ligadas ao citoesqueleto embora esta quantidade possa variar sendo consideravelmente maior nas células musculares
O citoesqueleto eucariótico é composto por microfilamentos, filamentos intermediários e microtúbulos
Existe um grande número de proteínas associadas a eles, cada uma controlando uma estrutura da célula, orientando, agrupando, e alinhando os filamentos
O citoesqueleto procariótico é bem menos estudado, mas está envolvido na manutenção da forma da célula, na polaridade e na citocinese.
Dois tipos diferentes de material genético existem: ácido desoxirribonucleico (DNA) e ácido ribonucleico (RNA)
A maioria dos organismos usa o DNA para o seu armazenamento de informação de longo prazo, mas alguns vírus (por exemplo, os retrovírus) têm RNA como seu material genético
A informação biológica contida num organismo é codificado em seu DNA ou em sua sequência de RNA
O RNA é também utilizado para o transporte de informação (por exemplo, RNA mensageiro) e funções enzimáticas (por exemplo, o ARN ribossomal) em organismos que utilizam DNA para o código genético em si
Moléculas de RNA de transporte (RNA) são usadas para adicionar aminoácidos durante a tradução de proteínas.
O material genético procariótico é organizado em uma molécula de DNA circular simples (o cromossoma bacteriano) na região nucleoide do citoplasma
O material genético eucariótico é dividido em diferentes moléculas, lineares chamadas cromossomas dentro de um núcleo discreto, geralmente com material genético adicional, em algumas organelas como mitocôndrias e cloroplastos
(ver Teoria da endossimbiose).
O corpo humano contém muitos órgãos diferentes, tais como o coração, pulmão e rim, com cada órgão exercendo uma função diferente
As células também possuem um conjunto de "pequenos órgãos", chamado de organelas, que são adaptados e/ou especializados para a realização de uma ou mais funções vitais
Ambas as células eucarióticas e procarióticas têm organelas mas organelas em eucarioticas são geralmente mais complexa e pode ser envoltas em uma membrana.
Existem vários tipos de organelas em uma célula
Algumas (tais como o núcleo e o complexo de Golgi) são tipicamente solitárias, enquanto outras (tais como mitocôndrias, peroxissomas e lisossomas) podem ser numerosas (centenas a milhares)
O citosol é o fluido gelatinoso que preenche a célula e rodeia os organelos.
Em citologia, cílios são apêndices das células eucarióticas com movimento constante numa única direção
Este nome provém do latim, com o significado de pestana, pela sua similaridade aparente.
Uma cápsula gelatinosa está presente em algumas bactérias fora da parede celular
A cápsula pode ser de polissacárido como no pneumococos, meningococos ou de polipéptido como Bacillus anthracis ou ácido hialurónico como em estreptococos
As cápsulas não são marcadas por coloração comum e podem ser detectadas por coloração especial.
Flagelos são os organelos de mobilidade celular
Eles surgem a partir do citoplasma por extrusão através da parede celular
Eles são longos e grossos apêndices filamentados, proteínas em sua natureza
São mais comumente encontrados em células de bactérias, mas também são encontrados em algumas células animais
Alguns flagelos atuam como uma hélice rotativa em contraste aos cílios que agem mais como um remo.
Fímbrias são apêndices em forma de filamentos ou franjas presentes em bactérias
Este apêndices são menores, mais curtos e mais numerosos que os flagelos
Eles são filamentos curtos e finos como cabelos, formados de proteína chamada pilin (antigénico)
Fímbrias são responsáveis pela fixação das bactérias aos receptores específicos de células humanas (aderência).
O sangue é um tecido conjuntivo líquido que circula pelo sistema vascular em animais com sistemas circulatórios fechados; formado por uma porção celular de natureza diversificada - pelos "elementos figurados" do sangue - que circula em suspensão em meio fluido, o plasma
Em animais vertebrados o sangue, tipicamente vermelho, é geralmente produzido na medula óssea
Em animais invertebrados a coloração pode variar, mostrando-se em várias espécies, dada a presença de cobre e não ferro na estrutura das células responsáveis pelo transporte de oxigênio, azulado
O sangue tem como função a manutenção da vida do organismo no que tange ao transporte de nutrientes, excretas (metabólitos), oxigênio e gás carbônico, hormônios, anticorpos, e demais substâncias ou corpúsculos cujos transportes se façam essenciais entre os mais diversos e mesmo remotos tecidos e órgãos do organismo.
Popularmente também denomina-se por sangue o fluido com funções similares em animais não dotados de sistema circulatório fechados, a exemplo da hemolinfa nos insetos
A composição da hemolinfa é contudo diferente da composição do sangue propriamente dito.
O sangue é formado por diversos tipos de células, que constituem a parte "sólida" do sangue, cada tipo com anatomia e funções próprias; essas imersas em uma parte líquida chamada plasma
As células sanguíneas são classificadas em três grupos básicos: os leucócitos ou glóbulos brancos, que são células de defesa integrantes do sistema imunitário; os eritrócitos, glóbulos vermelhos ou hemácias, responsáveis pelo transporte de oxigênio; e plaquetas, responsáveis pela coagulação sanguínea.
Podemos encontrar os mesmos componentes básicos do sangue nos anfíbios, nos répteis, nas aves e nos mamíferos (incluindo o ser humano).


O sangue é composto basicamente por:
45% de elementos figurados (células): Hemácias, leucócitos e plaquetas.
55% de plasma (Matriz extracelular).
Função: realizar a respiração celular, ao transportar oxigênio e parte de gás carbônico pela hemoglobina
São estocadas no baço, que por sua vez tem duas funções: liberar hemácias sadias (por ex., ao se fazer esforço físico) e destruir hemácias velhas, reciclando a hemoglobina
Têm importante papel na regulação do PH sanguíneo, agindo como tampão
Em casos de redução do PH ela libera o íon de O² e absorve um íon de H, alcalinizando a solução
Caso o PH esteja elevado, a hemácia captura um íon de O² e libera um íon de H, acidificando o meio
Este mecanismo ocorre de forma fisiológica no organismo, onde, no músculo, normalmente há um PH levemente ácido, o O² é mobilizado e um íon de H é capturado
O inverso ocorre no pulmão, onde o meio encontra-se levemente básico, então a hemoglobina libera o íon de H e captura um íon de O².
As hemácias dos mamíferos são arredondadas, anucleadas, com formato bicôncavo, semelhante a balas soft
Nos humanos possuem um tempo médio de vida, de cerca de 120 dias.
As hemácias de aves, répteis e anfíbios são nucleicas, com formato oval, e bi convexas
O hematócrito serve para medir a porcentagem de células em relação ao plasma
Valores normais, em geral, variam de 25 a 55%
valores abaixo indicam uma anemia, valores aumentados indicam uma desidratação
As proteínas plasmáticas totais servem para indicar se a anemia é por perda de sangue total, onde seu valor estará reduzido, ou em deficiências de produção, onde o valor das proteínas estará normal.
Os leucócitos formam verdadeiros exércitos contra os micro-organismos causadores de doenças e qualquer partícula estranha que penetre no organismo: vírus, bactérias, parasitas ou proteínas diferentes das do corpo
Eles também "limpam" o corpo destruindo células mortas e restos de tecidos.
Função: imunológica ou de defesa do organismo.
São classificados em neutrófilos, monócitos, basófilos, eosinófilos, linfócitos
Cada qual tem uma função específica e um mecanismo diferente de combater um agente patogênico (bactérias, vírus etc)
Se uma pessoa tiver:
São fragmentos de células da medula óssea chamadas megacariócitos.
Função: realizar a coagulação sanguínea.
Se uma pessoa tiver:
Função: transporte de hemácias, leucócitos, plaquetas e outras substâncias dissolvidas, como proteínas (albumina, responsável pela manutenção da pressão osmótico sanguínea; anticorpos; fibrinogênio); nutrientes (glicose, aminoácidos, ácidos graxos); excretas (ureia, ácidos úricos, amônia); hormônios (testosterona, adrenalina); hemoglobinas (ou anticorpos); sais/íons (sódio, potássio); gases (na forma de ácido carbônico ou H2CO3)
O plasma transporta essas substâncias por todo organismo, permitindo às células a receber nutrientes e excretar e/ou secretar substâncias geradas no metabolismo.
Composição: cerca de 90% de água; 10% outras substâncias
Características da circulação sanguíneas
-Fechada: O sangue circula somente no interior dos vasos (artérias, veias e capilares).
-Completa: Não ocorre mistura do sangue arterial com o sangue venoso.
-Dupla: O sangue passa duas vezes pelo coração ( com sangue arterial e com sangue venoso)
Na tabela abaixo é possível ver a composição esperada para o sangue em seres humanos saudáveis:
(*) O número de leucócitos (linhas destacadas) é de 4 a 10 mil por mm e os valores indicados correspondem à porcentagem média de cada tipo
Dos leucócitos, 30% correspondem aos linfócitos e 70% aos diversos mieloides.
A doação de sangue é o processo pelo qual um doador voluntário tem seu sangue coletado para armazenamento em um banco de sangue ou hemocentro para um uso subsequente em uma transfusão de sangue
Trata-se de um processo de fundamental importância para o funcionamento de um hospital ou centro de saúde.
A transfusão sanguínea é realizada para repor a perda do fluido corpóreo devido a alguma doença ou trauma grave que venha a trazer perda substancial que não possa ser reposta pela própria pessoa.
Estimativas apontam que somente no Brasil, sejam consumidas diariamente mais de 5 mil bolsas de sangue que são, em sua maioria, aplicadas em centros hospitalares a pacientes enfermidade e/ou acidentados.
Todos os procedimentos médicos que demandam transfusão de sangue precisam dispor de um fornecimento regular e seguro deste elemento
Daí a importância de se manter sempre abastecidos os bancos de sangue por meio das doações, que não engrossam nem afinam o sangue do doador
É fácil e seguro, e não se pode mentir nem omitir informações, pois quem recebe o sangue pode ser contaminado.
Doar sangue é um procedimento simples, rápido, sigiloso, seguro e relativamente indolor
Para o doador em geral não há riscos, porém algumas complicações podem eventualmente aparecer:
O exame de sangue e de pressão sanguínea estão entre os mais comumente métodos de diagnóstico investigativo que envolve o sangue.
Problemas com a circulação sanguínea desempenham um papel importante em diversas doenças, por exemplo:
Leucemia :o aumento do número de glóbulos brancos no sangue de uma pessoa costuma indicar que ela tem uma infecção
Mas pode indicar também Leucemia, uma forma de câncer que ataca os leucócitos
Na leucemia não ha apenas aumento no número de glóbulos brancos, a medula óssea ou os tecidos linfáticos passam a produzir, em Grande número leucócitos anormais, incapazes de defender o corpo
Ha vários tipos de Leucemia que podem ser causados por fatores genéticos , certos tipos de vírus, radiações ou substâncias químicas
O tratamento dessa doença pode incluir medicamentos (quimioterapia) ou radiações (radioterapia), que destroem as células cancerosas
As vezes é necessário transplante de medula óssea de um doador, assim sendo substituído uma medula ruim com vírus, e uma Boa sem nenhum tipo de vírus 
Assim várias formas de leucemia podem ser totalmente curadas
O sangue é um importante fator de infecção para diversos patógenos, como:
A transfusão de sangue é o modo mais direto de uso terapêutico de sangue
Ele é obtido através da doação de sangue
Como existem diferentes tipos de sangue, e a transfusão de um tipo errado pode causar muitas complicações no receptor, são feitos exames de compatibilidade.
Outros produtos do sangue administrados intravenosamente são as plaquetas, plasma sanguíneo e concentrados de fator de coagulação específicos.
Muitas formas de medicação (dos antibióticos à quimioterapia) são administradas intravenosamente, já que elas não podem ser prontamente ou adequadamente absorvidas pelo trato digestivo.
Como dito acima, algumas doenças ainda são tratadas com a remoção de sangue da circulação.
Ao chegar ao baço e também ao fígado, as hemácias "velhas" são eliminadas e o organismo cria novas hemácias, assim ficando livre do que já não serve mais
O baço seria como a lixeira do sangue, onde as hemácias já envelhecidas e sem uso são descartadas do organismo.
As hemácias se desprendem facilmente das moléculas de oxigênio quando este chega aos pulmões
Só que, quando há a introdução de Monóxido de carbono no organismo, as hemácias se unem às moléculas desse gás tóxico que é inalado todos os dias por nós.
Aquando ligadas às moléculas de monóxido de carbono, as hemácias se unem a elas permanentemente, e não conseguem mais se desprender (a ponte molecular é muito forte), ficando impossibilitadas de servirem ao transporte do oxigênio
O oxigênio então fica solto no sangue e não consegue atingir as células que necessitam de sua energia para continuarem vivas
O monóxido de carbono, estando em excesso como está atualmente na atmosfera, é inalado, sendo um grande "capturador" de hemácias, faz com que o transporte de oxigênio fica prejudicado, no nível celular, em todo o corpo do indivíduo.
As hemácias presas ao monóxido de carbono tornam-se inúteis no organismo, e são transportadas para o baço e ao fígado, para serem eliminadas, pois o organismo passou a "entendê-las" como inimigas
Por serem em número maior do que poderiam ser eliminadas normalmente, esse excesso de hemácias mortas causa uma sobrecarga no baço e no fígado, provocando seu mal-funcionamento, pois que eles não conseguem eliminar esse número tão elevado de hemácias diariamente
E elas se acumulam, enquanto o fluxo de oxigênio no sangue é prejudicado pela escassez de hemácias "boas", livres do monóxido, ou mesmo hemácias novas, que não são produzidas com a rapidez e qualidade que o organismo exposto à alta concentração de monóxido de carbono necessita.
O excesso de "morte" de hemácias e a incapacidade de produção de um número tão grande para reposição de hemácias no corpo provocam uma forma de anemia crônica.
Ainda concomitante à escassez de oxigênio no corpo pelo fracasso no transporte para as células, e a sobrecarga no baço e no fígado pelas hemácias+CO eliminadas pelo órgão, o corpo sofre
Os rins têm que trabalhar excessivamente para garantir maior pureza no sangue e em todo o sistema; os pulmões se tornam sobrecarregados pelo trabalho excessivo do coração que tem que bater mais e mais rápido, para garantir um fluxo melhor de oxigênio e também para dominar a anemia.
O coração se torna maior com o excesso de trabalho, trazendo líquidos aos pulmões, que se tornam carregados, provocando má respiração, bronquites e prejudicando ainda mais a ventilação do organismo, com outros distúrbios também como gástricos e intestinais.
E, ao final, o cérebro, com pouca carga de oxigênio, fica falho e ocorrem problemas mais sérios, como falta de memória, distúrbios de sono, nervosismo, ansiedade - a chamada síndrome do pânico; e, ao final, o organismo pode se ver inteiramente colapsado.
Saiba mais sobre Sangue
nos projetos irmãos da Wikipedia:
Fibras reticulares: Colágeno

O glucagon  ou glicagina  é um hormônio (polipeptídeo) produzido no pâncreas e também nas células espalhadas pelo tracto gastrointestinal
São conhecidas inúmeras formas de glucagons, sendo que a biologicamente ativa tem 29 aminoácidos.
É um hormônio muito importante no metabolismo dos hidratos de carbono
O seu papel mais conhecido é aumentar a glicemia (nível de glicose no sangue), contrapondo-se aos efeitos da insulina
O glucagon atua na conversão da ATP (trifosfato de adenosina) a AMP-cíclico, composto importante na iniciação da glicogenólise, com imediata produção e libertação de glicose pelo fígado.
A palavra glucagon deriva de gluco, glucose (glicose) e agon, agonista, ou agonista para a glicose.


O hormônio é sintetizado e secretado a partir das células alfa (células-α) das ilhotas de Langerhans, que estão localizadas na porção endócrina do pâncreas
As células alfa estão localizadas na porção externa das ilhotas
exerce um efeito oposto ao da insulina
Sua secreção aumenta resposta a baixa concentração plasmática de glicose, na qual e monitorada pelas células alfa.
A secreção aumentada de glucagon é causada por (pelo):
A secreção diminuída de glucagon (inibição) é causada por (pela):
O glucagon ajuda a manter os níveis de glicose no sangue ao se ligar aos receptores do glucagon nos hepatócitos (células do fígado), fazendo com que o fígado libere glicose - armazenada na forma de glicogênio - através de um processo chamado glicogenólise
Assim que estas reservas acabam, o glucagon faz com que o fígado sintetize glicose adicional através da gliconeogênese
Esta glicose é então lançada na corrente sanguínea
Estes dois mecanismos levam à liberação de glicose pelo fígado, prevenindo o desenvolvimento de uma hipoglicemia.
Em condições normais, a ingestão de glicose suprime a secreção de glucagon
Há aumento dos níveis séricos de glucagon durante o jejum.
Níveis muito elevados (anormais) de glucagon podem ser causados por tumores pancreáticos como o glucagonoma, cujos sintomas incluem eritema migratório necrolítico (EMN ou NME), níveis elevados de aminoácidos e hiperglicemia.
Uma forma injetável de glucagon é um pronto-socorro essencial em diversos casos de hipoglicemia severa, geralmente em uma dose de 1 mg
O glucagon é administrado através de uma injeção intramuscular e rapidamente aumenta os níveis de glicose no sangue (glicemia).
Testículos: testosterona • AMH • inibina
Ovário: estradiol · progesterona · activin and inhibin · relaxina (gestação)
Carboidratos, glicídios, glícidos, glucídios, glúcides ou hidratos de carbono, são compostos de função mista do tipo poliálcool-aldeído ou poliálcool-cetona e outros compostos que, por hidrólise, dão poliálcoois-aldeídos e/ou poliálcoois-cetonas
São as biomoléculas mais abundantes na natureza, constituídas principalmente por carbono, hidrogênio e oxigênio, podendo apresentar nitrogênio, fósforo ou enxofre na sua composição.
Conforme o tamanho, os carboidratos podem ser classificados em monossacarídeos, oligossacarídeos e polissacarídeos.


Os carboidratos são compostos orgânicos constituídos por carbono, hidrogênio e oxigênio, que geralmente seguem a fórmula empírica [C(H2O)]n, sendo n ≥ 7
A proporção entre os átomos de carbono, hidrogênio e oxigênio é de 1:2:1
Contudo, alguns carboidratos não se ajustam a esta regra geral, como a fucose, por exemplo, cuja fórmula molecular é C6H12O5
Outros autores utilizam a fórmula empírica [Cx(H2O)y].
Podem ser poliidroxialdeídos ou poliidroxicetonas, isto é, possuem um grupo que pode ser aldeído ou cetona, respectivamente, e várias hidroxilas, geralmente uma em cada átomo de carbono que não faz parte do aldeído ou grupo funcional cetona
Além de carbono, hidrogênio e oxigênio, alguns carboidratos apresentam nitrogênio, fósforo ou enxofre em sua composição
Quando compostos por aldeídos são chamados de aldose, quando compostos por cetona são chamados de cetose.
Os monossacarídeos, também conhecidos como oses, são carboidratos com reduzido número de átomos de carbono em sua molécula
O "n" da fórmula geral (CnH2nOn) pode variar de 3 a 7 (trioses, tetroses, pentoses, hexoses e heptoses), sendo os mais importantes as pentoses e as hexoses (C6H12O6)
São relativamente pequenos, solúveis em água e não sofrem hidrólise
Devido à alta polaridade, os monossacarídeos são sólidos cristalinos em temperatura ambiente, e assim como os oligossacarídeos, são solúveis em água
São insolúveis em solventes não polares
Embora sejam comumente representados na forma de cadeia linear, as aldoses com quatro carbonos e todos os monossacarídeos com mais de cinco carbonos apresentam-se predominantemente em estruturas cíclicas quando em solução aquosas
A nomenclatura na cadeia cíclica da-se de acordo com a posição da hidroxila (OH)
Na glicose, por exemplo,se a OH que está ligada ao carbono um estiver abaixo do plano do anel irá se chamar de α-glicose, já se estiver acima do plano do anel irá s chamar β-glicose Com exceção da Di-hidroxicetona, todos os monossacarídeos apresentam pelo menos um carbono assimétrico, provocando a apresentação de formas isoméricas opticamente ativas

Os oligossacarídeos são carboidratos resultantes da união de duas a dez moléculas de monossacarídeos
A ligação entre os monossacarídeos ocorre por meio de ligação glicosídica, formada pela perda de uma molécula de água
O grupo mais importante dos oligossacarídeos são os dissacarídeos, formados pela união de apenas dois monossacarídeos
Quando são constituídos por três moléculas de monossacarídeos, recebem o nome de trissacarídeos.
Os oligossacarídeos são solúveis em água, mas como não são carboidratos simples como os monossacarídeos, necessitam ser quebrados na digestão para que sejam aproveitados pelos organismos como fonte de energia.
Os polissacarídeos são carboidratos grandes, às vezes ramificados, formados pela união de mais de dez monossacarídeos ligados em cadeia, constituindo, assim, um polímero de monossacarídeos, geralmente de hexoses
São insolúveis em água e portanto, não alteram o equilíbrio osmótico das células
Os polissacarídeos possuem duas funções biológicas principais, como forma armazenadora de combustível e como elementos estruturais.
Observação: existem outros tipos de polissacarídeos denominados hetropolissacarídeos que originam, por hidrólise, vários tipos diferentes de monossacarídeos
Como por exemplo o ácido hialurônico, condroitinsulfato e a heparina.
Carboidratos que ao contrário dos monossacarídeos se hidrolisam
São divididos em holosídeos e heterosídeos.
São os oligossacarídeos e polissacarídeos que, por hidrólise, produzem somente monossacarídeos
Tipo de açúcar encontrado nas plantas e vegetais.
Rafinose + 2 H2O → glicose + frutose + galactose Celulose + n H2O → n glicose.
São glicídios que sofrem hidrólise, produzindo oses (hidratos de carbono simples) e outros compostos.
Amidalina - Ácido glicônico - Ácido glicurônico - Ácido sacárico - Sorbitol - Trinitrato de celulose - Piroxilina - Acetato de celulose
Monossacarídeos são carboidratos não polimerizados, por isso, não sofrem hidrólise
Possuem em geral entre três e sete átomos de carbono
O termo inclui aldoses, cetoses, e vários derivados, por oxidação, desoxigenação, introdução de outros grupos substituintes, alquilação ou acilação das hidroxilas e ramificações.


Quando monossacarídeos se ciclizam sob a forma do anel "pirano" são conhecidos como piranosídicos e o nome do monossacarídeo é acompanhado pelo sufixo piranose, a fim de designar sua correta conformação espacial
Por exemplo, a glucose piranosídica é conhecida como glucopiranose
A mesma conjugação de substantivos também é válida para os monossacarídeos que se ciclizam na forma do anel furanosídico (nome oriundo da molécula furano)
A frutose, por exemplo, se ciclizada dessa forma, é conhecida como frutofuranose.
Em solução aquosa, as hexoses sofrem uma interação intramolecular formando uma estrutura cíclica, na forma de pentanel ( furano ) ou na forma de hexanel ( pirano ).
⇐>
⇐>
⇒
⇐>
100–104 °C
Frutose (pronúncia: /fɾuˈtɔzɨ/) ou levulose (/levuˈlɔzɨ/), também conhecida como açúcar das frutas, é um monossacarídeo (C6H12O6), com os carbonos dispostos em anel, muito encontrado em frutas.
O nome "frutose" foi inventado em 1857 pelo químico inglês William Miller
Pura, a frutose desidratada é muito doce, incolor, sem odor, sólida e cristalina
É o açúcar mais solúvel em água de todos.
É também conhecida como levulose, pois uma solução saturada é capaz de transformar luz linearmente polarizada em luz circularmente polarizada, com giro vetorial para esquerda.A frutose é um dos constituintes, junto a glicose, da sacarose (β-D-Frutofuranosil α-D-glicopiranosida), o açúcar refinado comum, e de outros polímeros denominados fructans ou inulina
Além de ser menos doce que a frutose, a sacarose é um dissacarídeo encontrado pricipalmente na cana-de-açúcar
Cerca de 240,000 toneladas de frutose cristalizada são produzidas anualmente.
A frutose também é encontrada em cereais, vegetais e no mel.
No organismo humano, a frutose é fosforilada a frutose-6-fosfato pela hexocínase, seguindo, posteriormente, para a glicólise onde é metabolizada a ATP
No fígado, contudo, a frutose é transformada em gliceraldeído-3-fosfato e só depois entra na via glicolítica
Desta forma, entra depois do maior ponto de regulação da actividade glicolítica, a reacção catalisada pela cínase da frutose fosforilada
Assim, um consumo excessivo de frutose leva a uma saturação da via glicolítica, o que leva à formação de elevadas quantidades de acetil-CoA o que aumenta a biossíntese de ácidos graxos, provocando acumulação de gorduras no tecido adiposo
O esperma humano é rico em frutose.
A frutose e a glicose estão fortemente presentes nas uvas, e são a base química do vinho
A ação de leveduras sobre esses açúcares (e nunca sobre sacarose) faz a transformação dos açúcares em álcool etílico e gás carbônico.
A maior parte da frutose vendida no Brasil é importada, tendo por esse e outros fatores um preço mais elevado.


Assim como a glucose, a frutose também se apresenta em duas formas: cadeias abertas (acíclicas) e cadeias fechadas (hemiacetal).
Em solução aquosa, a forma tautomérica predominante é a β-D-frutopiranose (73% a 20 °C), seguida da forma β-D-frutofuranose (20%) .
Em forma cristalina, a análise de raio X mostra que a forma adotada é a β-D-frutopiranose em conformação "chaise 2C5".
A posição dos grupos hidroxila e carbonila, após a hidrólise, na composição de um monossacarídio, composto por seis átomos de carbono unidos em ligações covalentes simples, determina se ele dará origem a uma cetona ou um aldeído
A glicose quando hidrolisada, dará origem a aldeído, sendo chamada de aldohexose
A frutose, por sua vez, por conter um grupo carbonila no final da cadeia, quando hidrolisada, fornecerá cetona, sendo denominada cetohexose.
A frutose pode ser anaerobicamente fermentada por fungos ou por bacterias
A enzimas de fungos convertem açúcar (glicose ou frutose) a etanol e dióxido de carbono
O dióxido de carbono liberado durante a fermentação permanecerá dissolvido na água, onde alcançará o equilibro com o ácido carbônico, a não ser que a câmara de fermentação seja deixada aberta
O dióxido de carbono e o ácido carbônico produzirão a carbonação em bebidas fermentadas engarrafadas.
A frutose sofre a reação de Maillard, a combinação não enzimática com aminoácidos
Por ocorrer mais frequentemente em cadeia aberta do que a glicose, os estágios iniciais da reação de Maillard ocorre mais rapidamente do que com a glicose
No entanto, a frutose tem potencial de contribuir com a mudança na palatícia de alimentos e também no brilho excessivo, volume e ternura na fermentação de bolos e na formação de compostos mutagênicos.
A frutose é facilmente desidratada para formar hidroximetilfurfural
Esse processo, no futuro, pode trazer um sistema de baixo custo de produção de substituintes do petróleo e do diesel de plantas.
A razão principal pela qual a frutose é usada comercialmente em bebidas e frutas industrializadas, além de seu baixo custo, é a sua elevada característica adocicada
É considerado o composto mais doce entre os carboidratos que ocorrem naturalmente
É cerca de 1,7 vezes mais que a sacarose
Contudo, a doçura provém do anel de 6 átomos de carbono da frutose; o anel de 5 átomos de carbonos, formado pelo aquecimento da frutose, possui o mesmo sabor que o açúcar refinado comum
Desta forma, pode-se dizer que a doçura diminui com o aumento da temperatura do composto
Em contraponto, observou-se que a doçura absoluta da frutose varia de 5 a 50 °C e, portanto, a característica adocicada da sacarose não é devido à distribuição anomérica, mas a sua diminuição em temperaturas mais baixas.
O doce da frutose é percebido mais cedo que o da sacarose e da glicose e a sensação do sabor atinge um pico superior à da sacarose e diminui mais rapidamente
A frutose também pode realçar outros sabores no sistema.
A frutose exibe um efeito de sinergia de doçura quando usado em combinação a outros adoçantes
A característica adocicada de frutose misturada a sacarose, aspartame ou sacarina é considerada maior que a doçura calculada a partir dos componentes vistos individualmente.
A frutose possui maior solubilidade que outros açúcares, assim como outros álcoois de açúcar
Portanto, é mais difícil de se cristalizar a partir de uma solução aquosa
As misturas de açúcar contendo frutose, como por exemplo os doces, são mais suaves que aquelas que contêm outros açúcares devido a sua maior solubilidade.
A frutose tem um efeito maior na depressão do ponto de solidificação que os dissacarídeos ou os oligossacarídeos, o que pode proteger a integridade das paredes celulares dos frutos, reduzindo a formação de cristais de gelo
Porém, essa característica pode ser inconveniente em sobremesas de produtos lácteos suaves ou congelados.
A frutose aumenta a viscosidade do amido mais rápido e diminui a temperatura necessária durante a sua gelatinização, causando uma viscosidade final mais elevada que a sacarose
Embora alguns adoçantes artificiais não sejam adequados para o cozimento doméstico, muitas receitas tradicionais usam frutose.
A frutose presente na dieta produz menor aumento na glicemia quando comparada a quantidades isocalóricas de sacarose e de amido, sendo essa uma vantagem da frutose como adoçante na dieta de diabéticos.
A frutose existe em alimentos tanto como monossacarídeo (frutose na forma livre) como dissacarídeo (sacarose)
A frutose na forma livre é absorvida diretamente pelo intestino
Quando a frutose é consumida na forma de sacarose, é digerida e então absorvida como frutose
Conforme a sacarose entra em contato com a membrana do delgado, a enzima sucrase catalisa a clivagem da sacarose para produzir uma unidade de glicose e uma unidade de frutose, cada uma delas absorvida
Após a absorção, ele entra na veia porta hepática e é direcionado para o fígado.
O mecanismo de absorção de frutose no intestino delgado não é completamente compreendido
Algumas evidências sugerem transporte ativo, porque a absorção de frutose ocorreu contra um gradiente de concentração
No entanto, a maioria das pesquisas apoia a afirmação de que a absorção de frutose ocorre na membrana mucosa através de transporte facilitado envolvendo proteínas de transporte GLUT5
Uma vez que a concentração de frutose é maior no lúmen, a frutose é capaz de escoar um gradiente de concentração nos enterócitos, auxiliados por proteínas de transporte
A frutose pode ser transportada para fora do enterócito através da membrana basolateral por GLUT2 ou GLUT5, embora o transportador GLUT2 tenha uma maior capacidade de transporte de frutose e, portanto, a maioria da frutose é transportada para fora do enterócito através do GLUT2.
A absorção de frutose ocorre no intestino delgado através do transportador GLUT-5 (somente frutose) e do transportador GLUT2, pelo qual concorre com glicose e galactose, as etapas no fígado ocorrem apenas quando o intestino delgado fica inundado
O excesso de consumo de frutose, a inibição de GLUT2 por outros fitoquímicos, como flavonóides, ou outros problemas podem resultar na entrega de frutose não absorvida no intestino grosso, o que causará maior quantidade de água no intestino grosso, por osmose, causando diarreia.
Além disso, o consumo excessivo de frutose é uma fonte de nutrientes para a flora intestinal e resulta em uma maior produção de ácidos gordos de cadeia curta, hidrogênio, dióxido de carbono e outros gases, devido à fermentação
Esse aumento de gás provoca efeitos colaterais gastrointestinais que são semelhantes à síndrome do intestino irritável.
Em uma meta-análise de ensaios clínicos com alimentação controlada em que os sujeitos de teste foram alimentados com uma quantidade fixa de energia em vez de serem autorizados a escolher a quantidade que eles comiam, a frutose não era um fator independente para o ganho de peso
No entanto, o consumo de frutose foi associado ao aumento de peso quando a frutose forneceu calorias em excesso.
A frutose é muitas vezes recomendada para diabéticos porque não desencadeia a produção de insulina por células β pancreáticas, provavelmente porque as células β têm níveis baixos de GLUT5, embora o efeito líquido para ambos os diabéticos e não-diabéticos ainda sejam debatidos
A frutose tem um índice glicêmico abaixo de 19 ± 2, em comparação com 100 para a glicose e 68 ± 5 para a sacarose
A frutose também é 73% mais doce que a sacarose à temperatura ambiente, de modo que os diabéticos podem usar menos
Estudos mostram que a frutose consumida antes de uma refeição pode até diminuir a resposta glicêmica da refeição
Os produtos de alimentos e bebidas adoçados com fructose causam menos aumento nos níveis de glicose no sangue do que aqueles fabricados com sacarose ou glicose.
Em comparação com o consumo de bebidas com alto teor de glicose, beber bebidas com alto teor de frutose nas refeições resulta em níveis mais baixos de circulação de insulina e leptina e maiores níveis de grelina após a refeição
Como a leptina e a insulina diminuem o apetite, e a grelina aumenta o apetite, alguns pesquisadores suspeitam que comer grandes quantidades de frutose aumenta a probabilidade de ganho de peso.
As células beta são células endócrinas nas ilhotas de Langerhans do pâncreas
Elas são responsáveis por sintetizar e secretar o hormônio insulina, que regula os níveis de glicose no sangue
Em roedores, as células-alfa estão localizadas na periferia das ilhotas, em humanos a arquitetura das ilhotas é geralmente menos organizada e as células alfa são frequentemente observadas dentro das ilhas.


270-280 °C 
O glicogénio  ou glicogênio  é um polissacarídeo e a principal reserva energética nas células animais e bactérias como as cianobactérias, antigamente chamadas de algas azuis, encontrado, principalmente, no fígado e nos músculos
Geralmente também é encontrado nos fungos, sendo neste caso, a principal substância de reserva.


Ocorre intracelularmente como grandes agregados ou grânulos, que são altamente hidratados por apresentar uma grande quantidade de grupos hidroxila expostos, sendo capazes de formar ligações de hidrogênio com a água
É uma molécula constituída por subunidades de glicose unidas por meio de ligações
Apresenta uma ramificação a cada oito a doze unidades.
O glicogênio é especialmente abundante no fígado, onde ele constitui até 7% do peso úmido deste órgão
Neste caso é denominado glicogênio hepático, sendo encontrado em grandes grânulos, eles mesmos agregados de grânulos menores compostos por moléculas de glicogênios unitárias altamente ramificadas e com uma massa molecular média de vários milhões
Esses grânulos apresentam em uma forma intimamente unida as enzimas responsáveis pela sua síntese e degradação
A principal função do glicogênio armazenado no fígado serve para alimentar a necessidade energética das células cerebrais
No caso de se verificar uma esteatose, este é armazenado dentro de vacúolos com limites pouco definidos.
O glicogênio muscular responde em casos de hiperglicemia, pegando o açúcar da corrente sanguínea e armazena para realizar a neoglicogênese
O glicogênio muscular não é usado em resposta á hipoglicemia pelos animais porque eles precisam desse glicogênio para realizar as atividades em busca da sua fonte de alimentos, exemplo: um leão precisa correr para pegar a sua presa, se ele tivesse usado o glicogênio muscular ele não conseguiria correr.
Cada ramificação do glicogênio termina com um açúcar não redutor, sendo assim ele tem tantos terminais não redutores quantas ramificações, porém com um único terminal redutor
Quando este é utilizado como fonte de energia, suas unidades de glicose são retiradas uma a uma, a partir dos terminais não redutores
As enzimas podem agir em muitos terminais, fazendo com que este polissacarídeo se reduza a um monossacarídeo.
O glicogênio é hidrolisado pelas α- e β-amilases
A α-amilase, presente no suco pancreático e na saliva, quebra o laço glicosídico α(1→4) ao acaso, produzindo tanto maltose quanto glicose
Já a β-amilase (que também quebra o laço glicosídico α(1→4)) cliva sucessivas unidades de maltose, iniciando a partir do terminal não reduzido.
A síntese de glicogênio é o processo pelo qual a glicose é polimerizada a glicogênio, que é acumulado nas células em quantidades variáveis de acordo com o tipo celular, funcionando aí como depósito de energia acessível à célula
Em determinadas células, como nas do fígado e músculo, este processo pode ser intenso e ocorrem extensos depósitos de glicogênio
O glicogênio hepático, que chega a 150 g, é degradado no intervalo das refeições mantendo constante o nível de glicose no sangue ao mesmo tempo em que fornecem este metabólito as outras células do organismo
O glicogênio muscular, ao contrário, só forma glicose para a contração muscular.
Anabolismo (do grego: ana = para cima; ballein = lançar) é a parte do metabolismo que conduz à síntese de moléculas complexas a partir de moléculas mais simples
Alguns exemplos são a produção de açúcares pelas plantas a partir da fotossíntese e a síntese proteica.
O anabolismo só ocorre em alta energética, caso esteja em baixa energética, acontece o catabolismo.
Esses processos não são espontâneos, já que há uma diminuição do caos das moléculas (variação da energia livre de Gibbs positiva ou ΔG>0), logo é necessária energia para que essa complexação aconteça
Em quase todas as vezes essa energia provém da quebra de ligações de compostos di e trifosfatados (os últimos principalmente), como ATP e GTP
Pode ser necessário também poder redutor, na forma de coenzimas transportadoras de elétrons, como NADH, NADPH e FADH2, como na biossíntese de ácidos graxos.
Nos humanos, o controle de processos anabólicos em escala celular são feitos principalmente por efetores alostéricos, assim como em células de outras espécies
Mas esse controle pode também ser feito por hormônios como a insulina.


Os hidratos de carbono são moléculas orgânicas que contêm um grupo carbonilo (aldeído ou cetona) e mais grupos hidroxilo (OH-
Sua síntese ocorre através de diversas vias:
As proteínas são polímeros de aminoácidos
São o produto da ligação de aminoácidos por ligações peptídicas.
Acidose refere-se ao processo de diminuição do pH sanguíneo para menos de 7,35 (aumento de H+) causando acidemia (Acidemia refere-se ao estado acídico do sangue; Acidose, por outro lado, corresponde ao processo que acidifica
Ou seja, uma acidose não tem, necessariamente de estar associada a uma acidemia uma vez que, por exemplo, num caso de existir uma acidose respiratória e uma alcalose metabólica, considerando que são as duas de 'intensidade' semelhante, o pH sanguíneo manter-se-ia constante
Neste caso estaríamos na presença de uma alcalose, de uma acidose, mas não de uma acidemia, nem de uma alcalémia)
Pode ser causado por excesso de CO2, por excesso de um ácido metabólico (como o ácido láctico), como resposta compensatória a uma alcalose, por doenças respiratórias, por envenenamento, por tumores ou por medicamentos.


Existem dois tipos de acidose:
Ocorre quando os pulmões não pode retirar suficiente dióxido de carbono (CO2) que o corpo produz fazendo com que os fluídos corporais, especialmente do sangue, se tornem muito ácidos
Pode ser causado por doenças respiratórias como asma, bronquite, DPOC (doença pulmonar obstrutiva crônica) ou enfisema, por medicamentos que diminuem a respiração como benzodiazepínicos (remédio para ansiedade e insônia), especialmente quando combinados com álcool, consumo prolongado de nicotina ou por obesidade mórbida.
Ocorre quando faltam íons de bicarbonato (HCO3) no sangue superando o sistema tampão do pH do corpo até provocar um desequilíbrio ácido-base
Pode ser causado por um aumento da produção de ácidos metabólicos, por incapacidade de excretar o ácido através dos rins ou por envenenamento.
Acidose renal geralmente está associada com a acumulação de ureia, creatinina e resíduos de ácidos metabólicos do catabolismo de proteína
Quando falta oxigênio e há excesso de ácido láctico no sangue é chamada de acidose láctica.
No feto, o intervalo normal de Ph na veia umbilical normalmente está entre 7,25-7,45 enquanto na artéria umbilical normalmente está entre 7,20-7,38
No feto, os pulmões ainda não são utilizados para a ventilação sendo as funções ventilatórias realizadas pela placenta
A acidose fetal ocorre quando como um vaso umbilical tem pH inferior a 7,20 e uma artéria umbilical tem PCO2 66 ou mais ou a veia umbilical tem PCO2 de 50 ou mais.
Quando estes dois mecanismos não conseguem estabelecer o equilíbrio e o corpo continua a produzir ácido em demasia, instala-se um quadro de acidose grave e, em última instância, o coma.
Acidose tubular renal (ATR) é um sintoma caracterizado pela acumulação de ácido no organismo devido a uma falha dos rins em eliminar esses ácidos apropriadamente ou pela eliminação excessiva de bicarbonato pela urina
Pode ser classificado em 4 tipos, dependendo da causa e área do túbulo renal envolvida.
Metabólica: Intervalo aniônico elevado (cetoacidose/cetoacidose diabética, láctica) · Intervalo aniônico normal (hiperclorêmica, tubular renal)
Metabólica: Alcalose de contração
Em anatomia renal, o túbulo proximal é o primeiro segmento dos túbulos renais, originando-se logo após o corpúsculo renal e terminando no ramo fino descendente do túbulo intermediário
É uma estrutura tubular microscópica que faz parte dos túbulos renais, um dos constituintes do nefrónio.
De acordo com a International Union of Physiological Sciences, o túbulo proximal é dividido em 2 partes: a porção inicial é uma estrutura tubular retorcida e por isso denominada de de parte convoluta ou pars convoluta ou túbulo contorcido proximal
A segunda parte tem a estrutura tubular mais retificada, portanto, denominada parte reta ou pars recta.
O túbulo proximal também é subdivido em três segmentos, de acordo com a estrutura de suas células: o segmento S1, S2 e S3
O segmento S1 estende-se por dois terços da parte convoluta
O segmento S2, estende-se pelo restante da parte convoluta e pela porção inicial da parte reta
O segmento S3 compreende a maior parte da parte reta.
O túbulo proximal é formado por um epitélio cúbico simples com inúmeras mitocôndrias, numerosos microvilos na superfície das suas células formando uma orla em escova, prolongamentos laterais que se interligam com as vizinhas, aumentando significativamente a superfície basal das células, onde estão localizadas as mitocôndrias
A presença de microvilos em redor da escova, prolongamentos laterais e muitas mitocôndrias, são características típicas de células transportadoras de iões.
Cápsula de Bowman ( Células parietais • Podócitos)
Glomérulo (Células endoteliais • Membrana basal glomerular)
Mesângio (Células mesangiais • Matriz mesangial)
Túbulo de conexão
Junção ureteropiélica • Junção ureterovesical
Úraco • Fundo • Ápice • Corpo • Trígono • Colo • Úvula
Esfíncter interno • Esfíncter externo
A glicosúria, é a presença de glicose na urina
É uma condição comum aos pacientes que apresentam diabetes (não-controlada)
Igualmente comum em grávidas, pela diminuição do limiar de excreção, podendo ser neste caso um processo fisiológico
A glicosúria pode ser devida à saturação da capacidade reabsortiva de glicose pelos túbulos proximais renais em situação de glicemia elevada (aumento na concentração plasmática de glicose) ou secundária a danos nos referidos túbulos (glicosúria de origem renal).
É muito importante para o diabético monitorar seus níveis de glicose no sangue
O exame de glicosúria é uma forma indireta de estimar um aumento de glicemia
Esta prática é mais adotada em decorrência de seu baixo custo, por ser menos invasiva e dolorosa se comparada à medição direta da glicemia que requer a perfuração, geralmente do dedo, para a obtenção do sangue a ser testado
Pode ser usado também quando não se tem acesso às formas mais eficazes de diagnóstico de elevação da glicemia
Fazer o automonitoramento reduz entre 25 e 40% o número de internações por complicações por diabetes.


Nas pessoas saudáveis os rins funcionam como um filtro do sangue, retirando as substâncias desnecessárias ao organismo, eliminando-as pela urina e reaproveitando as necessárias, como a glicose, que continuam no sangue
A glicosúria aparece em pessoas com problemas renais (glicosúria renal) ou excesso de açúcar (indicando diabetes).
Em situações normais, o organismo elimina a glicose pela urina quando a concentração no sangue é elevada
Na glicosúria renal, a concentração de glicose no sangue é normal ou baixa, mas é excretada pelos rins, devido ao mau funcionamento destes
Nesta situação a pessoa não tem sintomas e não necessita de tratamento
Deve ser vigiada porque pode vir a desenvolver diabetes
Esse transtorno tem importantes fatores hereditários.
Nos diabéticos com hiperglicemia (excesso de glicose no sangue), os rins não conseguem filtrar toda a glicose porque ultrapassa os limites de absorção destes e esse excesso é eliminado na urina.
Na gravidez pode ocorrer glicosúria devido ao stress ou pelo sangue passar mais rápido pelos rins, geralmente desaparece após o parto.
O teste da glicosúria pode ser feito num laboratório ou em casa
Se for realizado no laboratório, basta levar a urina num frasco que lhe é fornecido quando vai marcar a análise
Se for em casa, necessita de tiras próprias que se compram na farmácia
O frasco onde vêm as tiras tem uma escala com cores e valores para vários parâmetros que de avaliar na urina
Quando se utiliza o exame de glicosúria para estimar a glicemia é importante lembrar que DIB, Sergio Atala.:
Além do exame de glicosúria, outras opções mais eficazes para fazer o automonitoramento do tratamento da hiperglicemia dos pacientes diabéticos são a glicemia capilar e a glicohemoglobina
Existem aparelhos comercializados em farmácias para fazer esses exames.
Se quisermos interromper a osmose, basta exercer sobre o sistema formado por duas soluções ou uma solução e um solvente, separados por uma membrana semipermeável, uma pressão no sentido inverso ao da osmose no mínimo com a mesma intensidade daquela que o solvente faz para atravessar a membrana semipermeável.
A essa pressão, capaz de impedir o fenômeno da osmose, damos o nome de pressão osmótica
Ou seja, é definida como o equivalente à pressão necessária, aplicada sobre um recipiente contendo solvente puro de modo a impedir a osmose.
Osmose natural:a saida do meio menos concentrado para o meio mais concentrado
Osmose reversa:a saida do meio mais concentrado para o meio menos concentrado 




π
=
N
⋅
R
⋅
T
⋅
i


{\displaystyle \pi =N\cdot R\cdot T\cdot i}

.
Sendo:




π


{\displaystyle \pi }

 = pressão osmótica da solução




N


{\displaystyle N}

 = concentração do soluto em solução expressa em mol/L (molaridade)




R


{\displaystyle R}

 = constante universal dos gases perfeitos, cujo valores são 0,082 atm.L.K-1.mol-1 ou 62,3 mmHg.L.K-1.mol-1 ou 8,31 J/mol.K




T


{\displaystyle T}

 = temperatura em Kelvin




i


{\displaystyle i}

 = fator de correção de Van't Hoff
A equação mostra que a pressão de ebulição, a uma dada temperatura e pressão, é uma propriedade coligativa, pois depende somente do número de partículas do soluto por unidade de volume da solução.
Observação:

A osmose é o movimento de água através de uma membrana semipermeável ocasionado por diferenças na pressão osmótica; é um fator importante na vida das células
As membranas plasmáticas são mais permeáveis à água que a maioria das outras moléculas pequenas, íons e macromoléculas, por que os canais proteicos (aquaporinas) na membrana seletivamente permitem a passagem de água.
Soluções com osmolaridade igual à do citosol de uma célula são ditas isotônicas em relação àquela célula
Circundada por uma solução isotônica,uma célula nunca ganha ou perde água
Em soluções hipertônicas (com maior osmolaridade que o citosol),a célula encolhe assim que a água se transfere para fora
Em soluções hipotônicas (com menos osmolaridade que o citosol),a célula incha assim que a água entra
Nos seus ambientes naturais,as células geralmente contêm maior concentração de biomoléculas e íons que nas suas vizinhanças,logo a pressão osmótica tende a enviar a água para dentro das células
Se não estiver de alguma forma contrabalançada,essa invasão de água,para dentro das células pode distender a membrana plasmática e causar o rompimento da célula (osmólise).
Este tipo de transporte não apresenta gastos de energia por parte da célula, por isso é considerado um tipo de transporte passivo
Esse processo está relacionado com a pressão de vapor dos líquidos envolvidos que é regulada pela quantidade de soluto no solvente
Assim, a osmose pode ajudar a controlar o gradiente de concentração de sais nas células.
A osmose não é influenciada pela natureza do soluto, mas pelo número de partículas
Quando duas soluções contêm a mesma quantidade de partículas por unidade de volume, mesmo que não sejam do mesmo tipo, exercem a mesma pressão osmótica e são isotônicas
Caso sejam separadas por uma membrana, haverá fluxo de água nos dois sentidos de modo proporcional.
Quando se comparam soluções de concentrações diferentes, a que possui mais soluto e, portanto, maior pressão osmótica é chamada hipertônica, e a de menor concentração de soluto e menor pressão osmótica é hipotônica
Separadas por uma membrana, há maior fluxo de água da solução hipotônica para a hipertônica, até que as duas soluções se tornem isotônicas.
A osmose pode provocar alterações de volume celular
Uma hemácia humana é isotônica em relação a uma solução de cloreto de sódio a 0,9% (“solução fisiológica”)
Caso seja colocada em um meio com maior concentração, perde água e murcha
Se estiver em um meio mais diluído (hipotônico), absorve água por osmose e aumenta de volume, podendo romper (hemólise).


Energia
A osmose ocorre de um local onde o solvente tem um alto potencial químico para um local com solvente de baixo potencial químico
O potencial químico aumenta com a temperatura e com a pressão, diminuindo com a concentração do soluto.
Os conteúdos celulares também estão sob Pressão de Parede, que aumenta a energia livre da célula.
O potencial químico φ do solvente (ou potencial de água da célula) nos mostra a direção da difusão
A osmose sempre acontecerá no seguinte sentido:
φ A -> φ B -> Osmose
φ assume sempre um valor negativo, sendo o valo zero para a água pura e é o resultado da interação da Pressão de Parede (Pw) com o Potencial Osmótico (π), logo:
φ = π + Pw
O potencial osmótico está relacionado com a energia livre da célula.
Em animais, apesar da célula não possuir uma membrana plasmática dita "perfeita" em termos de permeabilidade (devido ao facto de nela passar, não só água mas também outras substâncias como íons de sódio e potássio) é possível a ocorrência de osmose por transporte passivo
Uma pequena quantidade de água (meio hipotónico), no entanto, pode resultar na ruptura da célula: o exemplo clássico para esse acontecimento é a ruptura das hemácias, conhecida como hemólise.Em oposto, no momento em que há uma grande saída de água (meio hipertónico), a célula enruga-se.
Em vegetais, apesar de grande similaridade com animais, a osmose tem suas particularidades
Primeiramente por não haver ruptura da célula devido à resistência que a parede celular proporciona e também pela presença do vacúolo que suporta certa quantidade de água
Quando uma célula vegetal está em meio hipotônico, absorve água
Ao contrário da célula animal, ela não se rompe, pois é revestida pela parede celular ou membrana celulósica, que é totalmente permeável, mas tem elasticidade limitada, restringindo o aumento do volume da célula
Assim, a entrada de água na célula não depende apenas da diferença de pressão osmótica entre o meio extracelular e o meio intracelular (principalmente a pressão osmótica do suco vacuolar, líquido presente no interior do vacúolo da célula vegetal)
Depende, também, da pressão contrária exercida pela parede celular
Essa pressão é conhecida por pressão de turgescência, ou resistência da membrana celulósica à entrada de água na célula.
Existem dois fatores que determinam a quantidade de água na célula
São eles:
Como a quantidade de água existente na célula depende diretamente da resultante desses dois fatores, convencionou-se utilizar a seguinte equação para mostrar a entrada de água na célula vegetal:




S
c
=
S
i
+
M


{\displaystyle Sc=Si+M}


Onde:
Por vezes, utiliza-se a seguinte fórmula:




D
.
P
.
D
.
=
P
.
O
.
−
P
.
T
.


{\displaystyle D.P.D.=P.O.-P.T.}


Onde:
Quando está em meio isotônico, a parede celular não oferece resistência à entrada de água, pois não está sendo distendida (PT = zero)
Mas, como as concentrações de partículas dentro e fora da célula são iguais, a diferença de pressão de difusão é nula a célula está flácida
A força de entrada (PO) de água é igual à força de saída (PT) de água da célula.
Como DPD = PO – PT DPD = zero.
Quando o meio é hipotônico, há diferença de pressão osmótica entre os meios intra e extra- celular
À medida que a célula absorve água, distende a membrana celulósica, que passa a oferecer resistência à entrada de água
Ao mesmo tempo, a entrada de água na célula dilui o suco vacuolar, cuja pressão osmótica diminui
Em certo instante, a pressão de turgescência(PT) se iguala à pressão osmótica(PO), tornando a entrada e a saída de água proporcionais.
PO = PT, portanto DPD = PO – PT DPD =zero A célula está túrgida.


Foi verificado que no interior das hemácias existe uma solução de NaCl, cuja concentração constante é de 0,9%
Quando as hemácias são colocadas num tubo de ensaio contendo uma solução de NaCl, de concentração 0,4% (portanto hipotônica), verifica-se que as hemácias incham devido à entrada de água e acabam arrebentando, sofrendo hemólise
Isso acontece porque as hemácias não possuem uma parede celular para suportar uma pressão interna maior
Quando colocadas em uma solução de NaCl a 1,5% (portanto hipertônica), elas perdem água, murcham e ficam enrugadas.Essa análise permite deduzir que no plasma sanguíneo existe uma solução, cuja concentração deve ser 0,9% (portanto isotônica), para manter intactas as hemácias.
É importante lembrar que a permeabilidade seletiva da membrana plasmática, auxilia na regulação da concentração interna da célula
Assim o controle de substâncias: íons e moléculas em translocação de um meio para outro, não ocorre aleatoriamente
Normalmente a seletividade da membrana garante proteção ao metabolismo celular.


Muitos mecanismos estão envolvidos na prevenção dessa catástrofe
Em bactérias e plantas,a membrana plasmática é envolvida por uma parede de célula não expansível com rigidez e força suficientes para resistir à pressão osmótica e prevenir a osmólise
Alguns protistas de água doce que vivem em meio altamente hipotônico têm uma organela (vacúolo contrátil) que bombeia a água para fora da célula
Em animais multicelulares,o plasma sanguíneo e os fluidos intersticiais (o fluido extracelular dos tecidos) são mantidos em osmolaridade semelhante à do citosol
A alta concentração de albumina e outras proteínas no plasma sanguíneo contribuem para sua osmolaridade
As células também bombeiam ativamente para fora Na+ (cátion positivo) e outros íons para o fluido intersticial para que permaneça o equilíbrio osmótico com o meio circundante
Como o efeito dos solutos na osmolaridade depende do número de partículas dissolvidas,e não de sua massa,as macromoléculas tem efeito menor na osmolaridade de uma solução que teria uma massa equivalente dos seus componentes monométricos.
A quantidade de soluto é igual dentro e fora da célula
A célula não ganha nem perde água,ou seja,sua forma fica inalterada.
A quantidade de soluto é maior fora da célula
A célula perde água e sofre crenação (murcha),isso quando se tratar de uma célula animal
No caso de uma célula vegetal ela irá sofrer plasmólise.
A quantidade de soluto é maior dentro da célula
A célula ganha água e sofre lise (estoura) se a mesma se tratar de uma célula animal,isso não ocorrerá no caso de uma célula vegetal por conta de sua parede celular.
A desidratação ocorre quando o corpo humano perde mais água que repõe, e com isso não tem água suficiente para realizar suas funções normais
Indivíduos desidratados apresentam um volume de sangue menor que o normal, o que força o coração a aumentar o ritmo de seus batimentos, quadro chamado pelos médicos de taquicardia
Outros sintomas podem ser fraqueza, tontura, dor de cabeça, fadiga e pode levar à morte.
Uma maneira de tratar a desidratação é o soro caseiro
Também existem soros industrializados contra a desidratação
Soros industrializados são especialmente indicados em casos de desidratação por apresentarem composição equilibrada de cloreto de sódio, cloreto de potássio monoidratado, citrato de sódio diidratado e glicose
A composição equilibrada desses ingredientes evita efeitos colaterais como convulsões.
A desidratação pode ocorrer em níveis diferentes, e com isso apresentar sintomas cada vez mais graves
Entre eles:
Metabólica: Intervalo aniônico elevado (cetoacidose/cetoacidose diabética, láctica) · Intervalo aniônico normal (hiperclorêmica, tubular renal)
Metabólica: Alcalose de contração
Retinopatia diabética é a lesão à retina causada pelas complicações do diabetes mellitus
É causa importante de cegueira.
Em pacientes com Diabetes mellitus tipo 1, sua progressão pode ser lentificada pelo uso de inibidores da enzima de conversão da angiotensina
O principal tratamento da Retinopatia Diabética é o controle clínico rigoroso das glicemias e pressão arterial.

pálpebra: inflamação (Hordéolo, Calázio, Blefarite) - Entrópio - Ectrópio - Lagoftalmo - Blefarocalásia - Ptose - Blefarofimose - Xantelasma - Triquíase
sistema lacrimal: Dacrioadenite - Epífora - Dacriocistite
Estrabismo paralítico: Oftalmoparesia - Oftalmoplegia externa progressiva - Paralisia (III, IV, VI) - Síndrome de Kearns-Sayre Outros estrabismos: Esotropia/Exotropia - Hipertropia - Heterophoria (Esophoria, Exoforia) - Síndrome de Brown - Síndrome de Duane
Outras binoculares: Paralisia do olhar conjugado - Insuficiência de convergência - Oftalmoplegia internuclear - Síndrome do um e meio

Cetoacidose diabética é uma complicação potencialmente mortal da diabetes mellitus
Os sinais e sintomas incluem vómitos, dor abdominal, respiração de Kussmaul, micção frequente, fadiga, confusão mental e, em algumas ocasiões, coma
A respiração da pessoa pode apresentar um odor característico
O aparecimento de sintomas é geralmente rápido
Em alguns casos, a pessoa pode não ter conhecimento de ter diabetes.
A cetoacidose diabética é mais comum entre pessoas com diabetes do tipo 1, embora em determinadas circunstâncias possa também ocorrer entre pessoa com outros tipos de diabetes
Entre os fatores desencadeantes estão infeções, não tomar a insulina de forma correta, um acidente vascular cerebral e determinados medicamentos como corticosteroides
A cetoacidose diabética é causada por não haver no corpo insulina em quantidade suficiente
Em resposta à falta de insulina, o corpo começa a queimar ácidos gordos, que produzem corpos cetónicos ácidos
A doença é geralmente diagnosticada quando as análises ao sangue ou à urina detectam elevados níveis de glicose e baixos níveis de pH.
O tratamento da cetoacidose diabética consiste na administração de insulina e fluidos intravenosos
Dependendo da gravidade, a insulina pode ser administrada por via intravenosa ou subcutânea
Geralmente também é necessário potássio para prevenir o desenvolvimento de hipocaliemia
Ao longo do tratamento é necessário avaliar periodicamente os níveis de glicose e potássio
Nos casos em que a doença tem origem numa infeção subjacente, podem ser necessários antibióticos
Em pessoas com pH extremamente baixo pode ser administrado bicarbonato de sódio, embora os benefícios sejam pouco claros, pelo que geralmente não está recomendado.
A prevalência da cetoacidose diabética difere entre as diferentes regiões do mundo
No Reino Unido, cerca de 4% das pessoas com diabetes do tipo 1 desenvolvem a doença em cada ano, enquanto na Malásia a proporção é de 25% por ano
A condição foi descrita pela primeira vez em 1886
Até à introdução da terapia de insulina na década de 1920, era quase sempre mortal
Com tratamento adequado e atempado, o risco de morte é atualmente de apenas 1–4%
Cerca de 1% das crianças com a doença desenvolvem uma complicação denominada edema cerebral.
Metabólica: Intervalo aniônico elevado (cetoacidose/cetoacidose diabética, láctica) · Intervalo aniônico normal (hiperclorêmica, tubular renal)
Metabólica: Alcalose de contração
Metabolismo (do grego metabolismos, μεταβολισμός, que significa "mudança", troca) é o conjunto de transformações que as substâncias químicas sofrem no interior dos organismos vivos
O termo "metabolismo celular" é usado em referência ao conjunto de todas as reações químicas que ocorrem nas células
Estas reacções são responsáveis pelos processos de síntese e degradação dos nutrientes na célula e constituem a base da vida, permitindo o crescimento e reprodução das células, mantendo as suas estruturas e adequando respostas aos seus ambientes.
As reações químicas do metabolismo estão organizadas em vias metabólicas, que são sequências de reacções em que o produto de uma reacção é utilizado como reagente na reacção seguinte
Diferentes enzimas catalisam diferentes passos de vias metabólicas, agindo de forma concertada de modo a não interromper o fluxo nessas vias
As enzimas são vitais para o metabolismo porque permitem a realização de reacções desejáveis mas termodinamicamente desfavoráveis, ao acoplá-las a reacções mais favoráveis
As enzimas regulam as vias metabólicas em resposta a mudanças no ambiente celular ou a sinais de outras células.
O metabolismo é normalmente dividido em dois grupos: anabolismo e catabolismo
Reacções anabólicas, ou reacções de síntese, são reacções químicas que produzem nova matéria orgânica nos seres vivos
Sintetizam-se novos compostos (moléculas mais complexas) a partir de moléculas simples (com consumo de energia sob a forma de ATP)
Reacções catabólicas, ou reacções de decomposição/degradação, são reacções químicas que produzem grandes quantidades de energia (ATP) a partir da decomposição ou degradação de moléculas mais complexas (matéria orgânica)
Quando o catabolismo supera em atividade o anabolismo, o organismo perde massa, o que acontece em períodos de jejum ou doença; mas se o anabolismo superar o catabolismo, o organismo cresce ou ganha massa
Se ambos os processos estão em equilíbrio, o organismo encontra-se em equilíbrio dinâmico ou homeostase
O metabolismo é fundamentalmente estudado pela Bioquímica, usando muitas vezes também técnicas ligadas à Biologia Molecular e à Genética.


O metabolismo de um organismo determina quais substâncias são nutricionais e quais são tóxicas
Por exemplo, alguns procariontes utilizam ácido sulfídrico como nutriente; este gás é no entanto venenoso para animais
A velocidade a que se processa o metabolismo, determinada pela taxa metabólica, também influencia a quantidade de alimento requerida por um organismo.
Uma característica do metabolismo é a semelhança de vias metabólicas básicas entre espécies muito diferentes
Por exemplo, o conjunto de intermediários reacionais encontrados no ciclo dos ácidos tricarboxílicos é encontrado de forma universal, em células tão diferentes como a bactéria Escherichia coli ou o elefante
Esta estrutura metabólica semelhante está provavelmente associada à grande eficiência dessas vias e na sua antiguidade na história da evolução.
A história do estudo científico do metabolismo estende-se por quatro séculos, tendo evoluído da observação de organismos animais inteiros até ao estudo de reacções metabólicas individuais na Bioquímica moderna
As primeiras experiências conduzidas de forma controlada foram publicadas por Santorio Santorio em 1614 no seu livro Ars de statica medecina
Neste, Santorio descreveu como determinou o seu próprio peso antes e depois de comer, beber, dormir, trabalhar, ter relações sexuais, jejuar e excretar
Ele descobriu que a maior parte da comida ingerida era perdida no que ele chamou de "perspiração insensível".
Nestes estudos iniciais, os mecanismos destes processos metabólicos não eram conhecidos; pensava-se que o tecido vivo era animado por uma "força vital".
No século XIX, enquanto estudava a fermentação do açúcar a álcool por leveduras, Louis Pasteur concluiu que a fermentação era catalisada por substâncias dentro das células de levedura, a que ele chamou de "fermentos"
Pasteur escreveu que "a fermentação alcoólica é um acto correlacionado com a vida e organização das células de levedura, não com a morte ou putrefacção das células."  Esta descoberta, junto com a publicação da síntese química da ureia por Friedrich Wöhler em 1828, provou que os compostos orgânicos e as reacções químicas existentes nas células partilham o mesmo princípio que qualquer outra área da Química.
A descoberta das enzimas no início do século XX, por Eduard Buchner, separou o estudo das reacções químicas do metabolismo do estudo biológico das células, marcando o início da Bioquímica como ciência independente
A quantidade de conhecimento bioquímico cresceu rapidamente durante o início do século XX
Um dos bioquímicos mais prolíficos dessa época foi Hans Krebs, que fez diversas contribuições no estudo do metabolismo
Ele descobriu o ciclo da ureia e, mais tarde, junto com Hans Kornberg, o ciclo dos ácidos tricarboxílicos (também conhecido por esta razão como ciclo de Krebs) e o ciclo do glioxilato.
A investigação bioquímica moderna tem sido ajudada com a invenção e desenvolvimento de diversas técnicas, como a cromatografia, a difracção de raios X, a espectroscopia de ressonância magnética nuclear, a marcação isotópica, a microscopia electrónica e simulações de dinâmica molecular
Estas técnicas permitiram a descoberta e análise detalhada de diversas moléculas e vias metabólicas nas células.
A maioria das estruturas que compõem os seres vivos é fabricada a partir de três classes básicas de moléculas: aminoácidos, glícidos e lípidos
Como estas moléculas são vitais, o metabolismo concentra-se na fabricação destas, na construção de células e tecidos ou na sua degradação para uso como fonte de energia
Muitos compostos bioquímicos podem ser ligados entre si formando polímeros, como o ADN e as proteínas
Estas macromoléculas são parte essencial de todos os organismos vivos.
Alguns dos polímeros mais comuns estão listados abaixo:
As proteínas são compostas por aminoácidos dispostos numa cadeia linear e ligados entre si por ligações peptídicas
Muitas proteínas são as enzimas que catalisam as reacções químicas no metabolismo
Outras proteínas têm funções estruturais ou mecânicas, como o sistema de armação celular usado para manter a forma da célula, o citoesqueleto.
As proteínas têm também papéis importantes na sinalização celular, resposta imunitária, adesão celular, transporte activo através de membranas e no ciclo celular.
Os lípidos são o grupo mais diversificado de compostos bioquímicos
Constituem grande parte das membranas biológicas, tais como a membrana celular; além desta função estrutural, também servem como fonte de energia
Os lípidos são normalmente definidos como moléculas biológicas hidrofóbicas ou anfipáticas solúveis em solventes orgânicos como o benzeno ou o clorofórmio.
As gorduras são um grupo alargado de compostos que inclui os ácidos gordos e o glicerol; uma molécula de glicerol ligada a três ácidos gordos por uma ligação éster é um triacilglicerol
Existem diversas variações desta estrutura básica, por exemplo a presença de esfingosina em esfingolípidos e grupos hidrofílicos como o fosfato nos fosfolípidos.
Os esteróides, como o colesterol, são outro grupo significativo de lípidos sintetizados em células.
Os glícidos são aldeídos ou cetonas contendo diversos grupos funcionais hidroxilo
Os glícidos simples podem existir numa forma linear ou numa forma cíclica
São as moléculas biológicas mais abundantes e possuem funções muito diversificadas, como o armazenamento e transporte de energia (sob a forma de amido e glicogénio) e construção de elementos estruturais (como a celulose em plantas e a quitina em animais).
Os glícidos mais simples são os monossacarídeos, que incluem a galactose, a frutose e a glicose
Os monossacarídeos podem formar polímeros designados polissacarídeos de formas muito diversas.
Os polímeros ADN e ARN são longas cadeias de nucleótidos
Estas macromoléculas são essenciais no armazenamento e uso da informação genética, através dos processos de transcrição e síntese proteica
Esta informação é protegida por mecanismos de reparação do ADN e propagada através da replicação do ADN
Alguns vírus têm um genoma constituído por ARN (por exemplo, o HIV), e usam transcrição reversa para sintetizar ADN a partir desse ARN.
O ARN de ribozimas (como o spliceossoma) apresenta actividade enzimática tal como as enzimas proteicas, pois pode catalisar reacções químicas.
Os nucleósidos são sintetizados a partir da ligação de uma base azotada a uma ribose
Estas bases são anéis heterocíclicos contendo azoto, classificados como purinas ou pirimidinas
Os nucleótidos também actuam como coenzimas em reacções de transferência de grupos químicos.
O metabolismo envolve um vasto conjunto de reacções químicas, mas a maioria cai dentro de alguns tipos básicos de transferências de grupos funcionais
Esta química comum permite às células usarem um conjunto relativamente pequeno de intermediários metabólicos no transporte de grupos químicos de uma reacção para a seguinte
Estes intermediários de transferência de grupos são as coenzimas
Cada classe de reacção de transferência de grupos corresponde a uma determinada coenzima, servindo de substrato para um conjunto de enzimas que a produz e que a consome
Assim, as coenzimas são continuamente produzidas, consumidas e então recicladas.
A coenzima mais central é o trifosfato de adenosina (ATP), a moeda de troca energética universal das células
O ATP é utilizado para transferir energia química entre diferentes reacções químicas
Existe uma pequena quantidade de ATP permanentemente presente nas células, mas como é constantemente regenerado, o corpo humano é capaz de utilizar o seu peso em ATP por dia
O ATP age como uma ponte entre catabolismo e anabolismo, tendo as reacções catabólicas como produtoras de ATP e as anabólicas como consumidoras
Também serve como um transportador de grupos fosfato em reacções de fosforilação.
As vitaminas são compostos orgânicos necessários em pequenas quantidades e que não podem ser sintetizados pelas células
Na nutrição humana, a maioria das vitaminas funciona como coenzimas após sofrerem uma modificação química; por exemplo, todas as vitaminas hidrossolúveis são fosforiladas ou ligadas a nucleótidos para a sua utilização intracelular
O dinucleótido de nicotinamida-adenina (NADH), um derivado da vitamina B3 (niacina), é uma coenzima importante que age como aceitador de hidrogénio
Centenas de diferentes tipos de desidrogenases retiram electrões dos seus substratos e reduzem NAD a NADH
Esta forma reduzida da coenzima é então substrato para redutases celulares que necessitem de reduzir os seus substratos
O dinucleótido de nicotinamida-adenina existe também sob uma forma fosfatada, NADPH
O par redox NAD/NADH é mais importante no catabolismo, enquanto que o par NADP/NADPH é mais usado no anabolismo.
Cerca de 99% da massa dos mamíferos é constituída pelos elementos carbono, azoto, hidrogénio, oxigénio, cálcio, magnésio, sódio, potássio, cloro e enxofre
Destes, são considerados "inorgânicos" os metais, o enxofre e o cloro
Enquanto que alguns dos elementos inorgânicos são abundantes em sistemas vivos (como o sódio e o potássio), outros encontram-se em quantidades vestigiais
Os compostos orgânicos (proteínas, lípidos, glícidos) contêm a maioria do carbono e azoto; a maioria do oxigénio e hidrogénio encontra-se sob a forma de água.
Os elementos inorgânicos mais abundantes actuam como electrólitos
Os iões mais importantes são o sódio, potássio, cálcio, magnésio, cloreto, fosfato e o ião orgânico bicarbonato
A existência de gradientes iónicos através de membranas celulares mantém a pressão osmótica e o pH
Os iões são também vitais para nervos e músculos, pois os potenciais de acção usados nestes tecidos são produzidos através da troca de electrólitos entre o fluido extracelular e o citoplasma
Os electrólitos entram e saem das células através de proteínas transmembranares denominadas canais iónicos
Por exemplo, a contracção muscular depende do movimento de cálcio, sódio e potássio através de canais iónicos na membrana celular e túbulos-T.
Os metais de transição são normalmente elementos vestigiais em organismos, sendo o zinco e o ferro os mais abundantes
Estes metais são usados por algumas proteínas como cofactores e são essenciais para a actividade de metaloenzimas como a catalase e proteínas de transporte de dioxigénio como a hemoglobina
Tais metais actuam como cofactores quer estando ligados directamente à cadeia polipeptídica, quer estejam integrados em moléculas orgânicas complexas que por sua vez se encontram ligadas à cadeia polipeptídica
Os cofactores sofrem modificações durante a catálise enzimática mas voltam sempre ao seu estado inicial no fim de um ciclo catalítico
Os metais de transição são absorvidos pelos organismos usando transportadores específicos e ligam-se a proteínas de armazenamento como a ferritina e a metalotioneína quando não é necessária a sua disponibilidade para intervir no metabolismo.
O catabolismo é o conjunto das reacções metabólicas que libertam energia
Tais reacções incluem a degradação e oxidação de moléculas encontradas em alimentos, assim como reacções que captam a energia luminosa da luz solar
As reacções catabólicas providenciam energia e componentes necessários às reacções anabólicas
A natureza exacta destas reacções catabólicas difere de organismo para organismo: organismos organotróficos usam moléculas orgânicas como fonte de energia, enquanto litotróficos usam substratos inorgânicos e fototróficos captam energia solar, transformando-a em energia química.
Todas estas diferentes formas de metabolismo dependem de reacções redox que envolvem a transferência de electrões de moléculas doadoras reduzidas, como moléculas orgânicas, água, amoníaco, ácido sulfídrico ous iões ferrosos (Fe), para moléculas aceitadoras, como o dioxigénio (O2), o nitrato (NO3) ou o sulfato (SO4)
Em animais, estas reacções envolvem a degradação de moléculas orgânicas complexas a moléculas mais simples, como dióxido de carbono (CO2) e água (H2O)
Em organismos fotossintéticos, como as plantas e cianobactérias, estas reacções de transferência electrónica não libertam energia, sendo antes utilizadas como forma de armazenar energia absorvida da luz solar.
O conjunto de reacções catabólicas mais comum em animais pode ser separado em três etapas diferentes
Na primeira etapa, moléculas orgânicas complexas como as proteínas, polissacarídeos ou lípidos são degradados nos seus componentes fora das células
Na etapa seguinte, estas moléculas de menor tamanho são importadas pelas células e convertidas a moléculas menores, normalmente o acetil-CoA, num processo que liberta energia
Na última etapa, o grupo acetilo do acetil-CoA é oxidado a água e dióxido de carbono, libertando energia que é armazenada através da redução da coenzima dinucleótido de nicotinamida-adenina, NAD, a NADH.
Macromoléculas como o amido ou as proteínas não podem ser rapidamente assimilados pelas células, tendo de ser degradados nos seus componentes de menor tamanho antes de poderem ser utilizados no metabolismo celular
A digestão destes polímeros é feita por diversas classes de enzimas
Estas enzimas digestivas incluem as proteases, que digerem proteínas a aminoácidos, e glicosídeo hidrolases, que digerem polissacarídeos a monossacarídeos.
Os microorganismos excretam enzimas digestivas para o ambiente ao seu redor, enquanto que os animais segregam estas enzimas em células especializadas do sistema digestivo
Os aminoácidos ou açúcares libertados por estas enzimas extracelulares são então assimiladas pelas células através de proteínas específicas usando transporte activo.
O catabolismo de glícidos consiste na degradação de glícidos complexos em unidades de menor tamanho
Os glícidos são normalmente assimilados pelas células após a sua digestão a monossacarídeos
Após entrada na célula, a principal via de degradação é a glicólise, em que açúcares como a glucose e a frutose são convertidos a piruvato, com formação em simultâneo de ATP
O piruvato é um intermediáro de diversas vias metabólicas, mas a maioria é convertida a acetil-CoA, que entra no ciclo dos ácidos tricarboxílicos (ciclo de Krebs)
Embora haja mais alguma formação de ATP neste ciclo, o produto principal deste é o NADH, resultante da redução do NAD quando o acetil-CoA é oxidado
Esta oxidação liberta dióxido de carbono (CO2)
Uma via alternativa de degradação da glicose é a Via das pentoses-fosfato, que reduz a coenzima NADPH e produz pentoses como a ribose, o açúcar componente dos ácidos nucleicos.
As gorduras são catabolizadas por hidrólise a ácidos gordos livres e glicerol
O glicerol entra na glicólise e os ácidos gordos são degradados por beta-oxidação a acetil-CoA, que entra então no ciclo dos ácidos tricarboxílicos
Devido à sua grande proporção de grupos metileno e pelo facto de os glícidos possuirem mais oxigénio nas suas estruturas químicas, os ácidos gordos libertam mais energia que os glícidos quando oxidados.
Os aminoácidos são utilizados na síntese de proteínas e outras biomoléculas, ou oxidados a ureia e dióxido de carbono para obtenção de energia
A via de oxidação começa com a remoção do grupo amina por uma transaminase, deixando um esqueleto de carbono sob a forma de um cetoácido; o grupo amina é então metabolizado no ciclo da ureia
Vários cetoácidos obtidos através da desaminação de aminoácidos são também intermediários no ciclo dos ácidos tricarboxílicos: por exemplo, a desaminação do glutamato forma α-cetoglutarato
Os aminoácidos glucogénicos também podem ser convertidos a glicose, através da gluconeogénese.
Na fosforilação oxidativa, os electrões obtidos na oxidação de moléculas em diversas vias metabólicas, como por exemplo o ciclo dos ácidos tricarboxílicos, são transferidos para o dioxigénio, e a energia libertada é usada na produção de ATP
Em eucariontes, este processo é feito por uma série de proteínas, a cadeia de transporte electrónico, que se encontram nas membranas mitocondriais
Em procariontes, estas proteínas encontram-se na membrana celular interna
Estas proteínas utilizam a energia obtida da oxidação de NADH para transportar protões através da membrana.
O transporte de protões para o exterior da mitocôndria cria uma diferença de concentração de protões entre os dois compartimentos, criando um gradiente electroquímico
A presença deste gradiente força os protões a regressarem ao interior da mitocôndria através da ATP sintase
O fluxo de protões provoca a rotação da subunidade inferior da ATP sintase, o que causa a fosforilação de difosfato de adenosina (ADP) a trifosfato de adenosina (ATP).
A quimiolitotrofia é um tipo de metabolismo encontrado em procariontes, em que a energia é obtida a partir da oxidação de compostos inorgânicos
Estes organismos podem usar hidrogénio, compostos reduzidos de enxofre (como sulfuretos, ácido sulfídrico e tiossulfato), óxidos de ferro (II), ou amoníaco como fontes de agentes redutores, ganhando energia a partir da oxidação destes compostos com aceitadores de electrões como o oxigénio ou o nitrito
Estes processos microbiológicos são importantes em ciclos biogeoquímicos como a acetogénese, a nitrificação e a desnitrificação e são de importância crítica para a fertilidade do solo.
A energia da luz solar é captada por plantas, cianobactérias, alguns tipos de bactérias e de protistas
Este processo está frequentemente associado à fixação de dióxido de carbono em compostos orgânicos, que é um processo integrante da fotossíntese
Os sistemas de captura de energia e de fixação de carbono podem trabalhar separadamente em procariontes, como acontece com as bactérias púrpura e as bactérias verdes sulfurosas
Estas bactérias usam a luz solar como fonte de energia mas alternam o seu metabolismo entre a fixação de carbono e a fermentação de compostos orgânicos.
A captação de energia solar é um processo semelhante à fosforilação oxidativa, pois ambos os processos envolvem o armazenamento de energia sob a forma de um gradiente de protões, que leva à síntese de ATP
No caso da fotossíntese, os electrões necessários para o funcionamento da cadeia de transporte electrónico provêm de proteínas colectoras de luz denominadas centros reaccionais fotossintéticos
Estas estruturas dividem-se em dois tipos dependendo do pigmento fotossintético presente; a maioria das bactéria fotossintéticas possui apenas um tipo de centro, enquanto as plantas e as cianobactérias possuem dois.
Em plantas, o fotossistema II usa energia luminosa para remover electrões da água, libertando oxigénio no processo
Os electrões movem-se então para o complexo do citocromo b6f, que usa a sua energia para transportar protões através das membranas dos tilacóides nos cloroplastos
Estes protões regressam ao interior dos tilacóides através da ATP sintase, num processo semelhante ao descrito nas mitocôndrias
Estes electrões podem então entrar no fotossistema I e ser utilizados na redução de NADP, no ciclo de Calvin ou reciclados para gerar ainda mais ATP.
O anabolismo é o conjunto de reacções metabólicas de síntese em que a energia libertada pelo catabolismo é utilizada para construir moléculas complexas
Em geral, as moléculas complexas que constituem estruturas celulares são construídas passo a passo a partir de precursores mais simples
O anabolismo divide-se em três etapas fundamentais:
Os organismos diferem entre si na quantidade de diferentes moléculas que conseguem sintetizar
Os seres autotróficos, como as plantas, podem construir moléculas complexas (polissacarídeos e proteínas) a partir de moléculas muito simples como o dióxido de carbono e a água
Os seres heterotróficos necessitam de fontes alimentares para providenciar monossacarídeos e aminoácidos, para poder produzir macromoléculas
Os organismos podem ainda ser classificados segundo a fonte primária da sua energia: fotoautotróficos e foto-heterotróficos obtém energia a partir da luz solar, enquanto que organismos quimioautotróficos e quimio-heterotróficos obtêm energia a partir de reacções de oxidação.
A fotossíntese é o processo em que ocorre síntese de glicose a partir da luz solar, dióxido de carbono e água, havendo produção de oxigénio
Este processo utiliza ATP e NADPH produzido pelos centros reaccionais fotossintéticos para converter CO2 em glicerol-3-fosfato, que pode ser então convertido a glicose
Esta reacção de fixação de carbono é catalisada pela enzima RuBisCO e é parte integrante do ciclo de Calvin
Ocorrem três tipos de fotossíntese em plantas: fixação de carbono em plantas C3, fixação de carbono em plantas C4 e fotossíntese CAM
Estes tipos de fotossíntese diferem na via que o CO2 toma até ao ciclo de Calvin: as plantas C3 fixam o CO2 directamente, enquanto que as C4 e CAM incorporam-no noutros compostos de forma a adaptar a condições de alta luminosidade e dessecação
Algas e plantas aquáticas usam organelas chamadas pirenóides.
Os mecanismos de fixação de carbono em procariontes fotossintéticos são mais diversificados
O CO2 pode ser fixado através do ciclo de Calvin, de um ciclo dos ácidos tricarboxílicos inverso ou através da carboxilação do acetil-CoA
Procariontes quimioautotróficos também utilizam o ciclo de Calvin para a fixação de carbono mas a energia usada nas reacções provém de compostos inorgânicos.
No anabolismo de glícidos, ácidos orgânicos simples podem ser convertidos a monossacarídeos como a glicose, sendo então usados para sintetizar polissacarídeos como o amido
A produção de glicose a partir de compostos como o piruvato, o lactato, o glicerol, o glicerol-3-fosfato e aminoácidos é chamada gluconeogénese
Na gluconeogénese, o piruvato é convertido a glicose-6-fosfato usando diversos intermediários, muitos deles comuns à glicólise
No entanto, esta via não se resume a uma inversão da glicólise, pois diversos passos são catalisados por enzimas não-glicolíticas
Este é um aspecto importante pois permite a regulação separada da formação e da degradação da glicose, evitando que ambas as vias funcionem em simultâneo num ciclo fútil.
Embora a gordura seja um modo comum de armazenamento de energia, em vertebrados, como os humanos, os ácidos gordos não podem ser convertidos a glicose através da gluconeogénese, pois estes organismos são incapazes de transformar acetil-CoA em piruvato
Por essa razão, após um longo jejum os vertebrados necessitam de produzir corpos cetónicos a partir de ácidos gordos para substituir a glicose em falta em tecidos e órgãos que não conseguem metabolizar ácidos gordos, como o cérebro
Noutros organismos, como plantas e bactérias, este problema metabólico é ultrapassado utilizando o ciclo do glioxilato, que evita o passo de descarboxilação no ciclo dos ácidos tricarboxílicos e permite a transformação de acetil-CoA a oxaloacetato, que pode ser então utilizado na produção de glicose.
Os polissacarídeos e os glicanos são sintetizados através da adição sequencial de monossacarídeos, catalisada por glicosiltransferases, de um doador de açúcar fosforilado como o difosfato de uridina-glicose (UDP-glicose) para um grupo hidroxilo aceitador no polissacarídeo nascente
Como qualquer um dos grupos hidroxilo da estrutura do substrato podem ser aceitadores, os polissacarídeos podem ter estruturas lineares ou ramificadas.
Os polissacarídeos podem desempenhar funções estruturais ou metabólicas, podendo também ser transferidos para lípidos e proteínas pelas enzimas oligossacariltransferases.
Os ácidos gordos são sintetizados pelas sintases de ácido gordo, que polimerizam e reduzem unidades de acetil-CoA
As cadeias acilo dos ácidos gordos são aumentadas através de um ciclo de reacções que adicionam o grupo acilo, reduzem-no à forma álcool, desidratam este a um grupo alceno, sendo este finalmente reduzido a um grupo alcano
As enzimas envolvidas na biossíntese de ácidos gordos encontram-se divididas em dois grupos: em animais e fungos todas estas reacções são catalisadas por uma proteína multifuncional (tipo I), enquanto que em plantas e bactérias diferentes enzimas catalisam as diversas reacções (tipo II).
Os terpenos e os isoprenóides são uma classe de lípidos, que inclui os carotenóides, sendo a maior classe de produtos naturais vegetais
Estes compostos são sintetizados através da montagem e modificação de unidades de isopreno doadas pelas moléculas precursoras pirofosfato de isopentenilo e pirofosfato de dimetilalilo
Estes precursores podem ser obtidos de diferentes formas
Em animais e arqueas, a via do mevalonato produz estes compostos a partir do acetil-CoA, enquanto que plantas e bactérias existe uma via alternativa (do não-mevalonato) que utiliza piruvato e 3-fosfato de gliceraldeído como substratos.
Uma reacção importante que utiliza estes doadores de isopreno é a síntese de esteróides
Nesta, as unidades de isopreno são unidas formando esqualeno; este é então convertido a lanosterol
O lanosterol pode ser então convertido a outros esteróides, como o colesterol e o ergosterol.
Diferentes organismos possuem diferentes capacidades de sintetizar os vinte aminoácidos mais comuns
A maioria das bactérias e plantas conseguem sintetizar todos os vinte aminoácidos; os mamíferos conseguem sintetizar apenas dez, denominados não-essenciais por esta razão
Assim, os aminoácidos essenciais têm de ser obtidos através da alimentação
Todos os aminoácidos são sintetizados a partir de intermediários da glicólise, do ciclo dos ácidos tricarboxílicos ou da via das pentoses-fosfato; o azoto não existente nestes intermediários é fornecido pelo glutamato ou pela glutamina
A síntese dos aminoácidos depende da formação do alfa-cetoácido apropriado, que sofre então transaminação para formar um aminoácido.
Os aminoácidos são utilizados na síntese de proteínas, ao serem ligados entre si por ligações peptídicas numa cadeia linear
Os aminoácidos podem ser ligados num número de combinações quase infinito, fazendo com que cada proteína tenha uma sequência única de aminoácidos, denominada estrutura primária
As proteínas são sintetizadas a partir de aminoácidos activados através de uma ligação éster a uma molécula de ARN de transferência (ARNt ou tRNA)
Estes aminoácidos activados, os aminoacil-tRNA, são sintetizados pela aminoacil-tRNA sintetase, numa reacção dependente da presença de ATP
Os ribossomas actuam então no aminoacil-tRNA, agregando-o à cadeia polipeptídica nascente, segundo a informação dada pelo ARN mensageiro.
Os nucleótidos são sintetizados a partir de aminoácidos, dióxido de carbono e ácido fórmico em vias metabólicas que necessitam de grandes quantidades de energia
As purinas são sintetizadas a partir de nucleósidos (bases ligadas à ribose)
Tanto a adenina como a guanina são sintetizadas a partir do monofosfato de inosina, que por sua vez é sintetizado usando átomos provenientes dos aminoácidos glicina, glutamina e aspartato, assim como de formato transferido pela coenzima tetra-hidrofolato
As pirimidinas são sintetizadas a partir da base orotato, formada a partir da glutamina e do aspartato.
Todos os organismos são constantemente expostos a compostos que não podem ser utilizados no metabolismo normal e que são potencialmente tóxicos se se acumularem nas células
Tais compostos são designados xenobióticos
Os xenobióticos, incluindo substâncias como drogas sintéticas, venenos e antibióticos, são desintoxicados usando um conjunto de enzimas específicas
Em humanos, estas enzimas incluem as citocromo P450 oxidases, as UDP-glucuronosiltransferases e as glutationo-S-transferases.
Este sistema de enzimas actua em três fases
Na fase I, o xenobiótico é oxidado; na fase II, existe conjugação de grupos hidrofílicos no xenobiótico oxidado, de modo a torná-lo mais hidrossolúvel; na fase III, o xenobiótico modificado é expulso das células, podendo sofrer mais algum metabolismo em organismos multicelulares antes da sua excreção
Estas reacções são bastante importantes em termos ecológicos, nomeadamente na biodegradação microbiana de agentes poluentes e biorremediação de terras contaminadas e derrames de combustíveis.
Muitas destas reacções microbianas são idênticas às existentes em organismos multicelulares
No entanto, e graças à sua enorme diversidade, os microorganismos conseguem desintoxicar uma variedade superior de xenobióticos que os organismos multicelulares, conseguindo inclusivamente degradar agentes poluentes orgânicos persistentes, como compostos organoclorados.
Um problema relacionado com o dos xenobióticos prende-se com a existência de stress oxidativo em organismos aeróbios
Os processos associados à vida em aerobiose, como a fosforilação oxidativa e a formação de ligações dissulfureto em proteínas, produzem espécies reactivas de oxigénio, como o peróxido de hidrogénio
Estas espécies danosas são removidas por antioxidantes, como a glutationa, e enzimas, como a catalase e outras peroxidases.
Os sistemas vivos têm de obedecer às leis da termodinâmica
A grande complexidade dos organismos aparentemente contradiz a segunda lei da termodinâmica, que enuncia que a entropia de um sistema fechado tende a aumentar; no entanto, os sistemas vivos são sistemas abertos que trocam energia e massa com o seu exterior
Assim, os organismos não se encontram em equilíbrio termodinâmico, sendo antes sistemas dissipativos, pois mantêm a sua ordem ao aumentar a entropia do seu ambiente
O metabolismo celular faz a ponte entre o processo espontâneo de catabolismo e o processo não espontâneo de anabolismo para obter este efeito
Em termos termodinâmicos, o metabolismo mantém a ordem ao criar desordem.
Em fungos, bactérias, plantas ou animais de sangue quente ou frio, vários processos interagem com a temperatura interna e externa aos organismos
As plantas e leveduras parecem ter um termostato biológico simples
Na planta Arabidopsis thaliana, uma única proteína (a histona H2A) desempenha o papel em variações de temperatura inferiores a 1° C
Esta proteína altera o enrolamento do DNA, controlando assim o acesso a determinadas moléculas de DNA, ou inibindo a ativação de genes
Este efeito de "bio-termostato" parece ser comum na natureza
Entender esses mecanismos também pode ajudar a compreender melhor alguns dos efeitos da mudança do clima
O ambiente da maioria dos organismos encontra-se em constante mudança, sendo necessária uma apertada regulação das reacções metabólicas de modo a manter um conjunto de condições mais ou menos constante nas células, chamado homeostase
A regulação metabólica permite aos organismos dar resposta a estímulos do exterior, permitindo a interacção com o seu ambiente
Existem dois conceitos relacionados que são importantes para a compreensão da forma como são reguladas vias metabólicas: em primeiro lugar, a regulação de uma enzima numa via refere-se ao aumento ou diminuição da sua actividade enzimática em resposta a estímulos; o segundo conceito é o controlo exercido por esta enzima na velocidade total da via por sofrer variações na sua actividade enzimática, ou seja, o controlo do fluxo da via metabólica
Por exemplo, uma enzima pode sofrer grandes alterações na sua actividade (ou seja, ser muito regulada) mas se estas mudanças não tiverem um efeito significativo no fluxo da via metabólica, então esta enzima não está envolvida no controlo da via.
Existem diversos níveis de regulação metabólica
Na regulação intrínseca, a via metabólica regula-se a si própria em resposta a mudanças nos níveis de substratos ou produtos; por exemplo, uma diminuição na quantidade de produto pode aumentar o fluxo da via para compensar essa diminuição
Este tipo de regulação envolve frequentemente o uso de regulação alostérica das diversas enzimas que participam na via metabólica
O controlo extrínseco corresponde à mudança do metabolismo de uma célula num organismo multicelular em resposta a sinais de outras células
Estes sinais são normalmente moléculas mensageiras solúveis, como hormonas e factores de crescimento, e são detectados por receptores específicos na superfície das células
Tais sinais são então transmitidos para o interior da célula por sistemas de mensageiros secundários que envolvem frequentemente a fosforilação de proteínas.
A regulação do metabolismo da glicose pela insulina é um exemplo bem conhecido de controlo extrínseco
A insulina é produzida em resposta a um aumento da glicemia
A ligação da hormona a receptores de insulina na superfície de células activa uma cascata de cinases que provoca a absorção de glicose pelas células e a sua conversão a moléculas de armazenamento, como o glicogénio e os ácidos gordos
O metabolismo do glicogénio é controlado pela actividade da glicogénio fosforilase, a enzima que hidrolisa o glicogénio, e pela glicogénio sintase, a enzima que o sintetiza
Estas enzimas são reguladas de forma recíproca, em que a fosforilação activa a fosforilase e inibe a sintase
A insulina provoca a síntese de glicogénio ao activar fosfatases, produzindo um decréscimo na fosforilação destas enzimas.
As vias metabólicas descritas acima são comuns aos três domínios da vida (Eukarya, Archaea e Bacteria), considerando-se por isso que estavam também presentes no mais recente antecessor comum aos três domínios
Este antecessor era procariótico e provavelmente metanogénico, possuindo um extenso metabolismo de lípidos, aminoácidos, nucleótidos e glícidos
A preservação destas vias durante a evolução que se seguiu poderá ter resultado de serem uma solução optimizada para os seus problemas metabólicos específicos: ocorre a produção de metabolitos de forma eficiente e com um número mínimo de passos reaccionais.
Diversos são os modelos propostos para a descrição da evolução de novas vias metabólicas, incluindo a adição sequencial de enzimas a curtas vias ancestrais, a duplicação e posterior divergência evolutiva de vias metabólicas inteiras e a inclusão de enzimas pré-existentes numa nova via reaccional
Não é clara a importância relativa destes mecanismos, mas diversos estudos genómicos sugerem que as enzimas de uma dada via metabólica possuem um antecessor comum
Esta ancestralidade comum implica que diversas vias terão evoluído passo a passo, com a criação de novas funções a partir de passos reaccionais pré-existentes
Existe também a possibilidade de que partes do metabolismo existam como "módulos" que podem ser reutilizados em diferentes vias e que desempenham funções semelhantes em diferentes moléculas.
A evolução de organismos pode levar também à perda de vias metabólicas
Por exemplo, em alguns parasitas, processos metabólicos que não são essenciais à sua sobrevivência são perdidos; o parasita absorve então aminoácidos, nucleótidos e glícidos do seu hospedeiro
Organismos endossimbióticos apresentam também capacidades metabólicas similarmente reduzidas.
O metabolismo é classicamente estudado usando uma aproximação reducionista, focando uma via metabólica isoladamente
A marcação isotópica de precursores é de grande utilidade em estudos com organismos inteiros, tecidos ou células, pois permite seguir o percurso dessas moléculas até serem transformadas no produto final, analisando intermediários e produtos marcados radioactivamente
As enzimas que catalisam estas reacções podem ser purificadas e analisadas do ponto de vista da sua actividade enzimática, medindo parâmetros cinéticos e respostas a inibidores
Outro tipo de investigação consiste na identificação de metabolitos numa célula ou tecido; o conjunto de metabolitos é por vezes designado metaboloma
De uma forma geral, este tipo de estudos é adequado para alcançar uma visão geral de uma via metabólica simples, mas é limitado quando aplicado a sistemas mais complexos, como o funcionamento de uma célula inteira.
É possível ter uma ideia da complexidade da rede metabólica existente nas células, que possuem tipicamente milhares de enzimas, analisando a figura ao lado, que representa apenas 43 proteínas e 40 metabolitos
A sequenciação de genomas mostra que poderão existir até 45000 genes (que corresponderão a tantos outros polipéptidos)
É, no entanto, possível usar esta informação genómica para reconstruir redes completas de reacções bioquímicas e produzir modelos matemáticos holísticos que expliquem e prevejam o seu comportamento
Tais modelos são particularmente úteis quando usados na integração de dados obtidos através de métodos laboratoriais de análise de expressão genética, como o uso de proteómica e microarrays.
Uma relevante aplicação tecnológica desta informação é a engenharia metabólica, em que organismos como leveduras, plantas ou bactérias são geneticamente modificados de modo a serem úteis em aplicações biotecnológicas, como a produção de medicamentos (por exemplo, antibióticos) ou reagentes químicos (como o propan-1,3-diol ou o ácido xiquímico).
Nível introdutório
Nível avançado

Informação geral
Glossários e dicionários
Metabolismo humano
Bases de dados
Vias metabólicas
Respiração de Kussmaul é um padrão respiratório profundo e trabalhoso associado com acidose metabólica grave, particularmente com a cetoacidose diabética, mas também com a insuficiência renal
É uma forma de hiperventilação, que é qualquer padrão respiratório que reduz o dióxido de carbono no sangue devido a uma frequência ou profundidade maior de respiração e divide-se em 4 fases.
Náusea ou enjoo é a sensação de desconforto no estômago com uma vontade urgente de vomitar.
A náusea também é uma defesa do organismo, já que é a preparação para o vômito e a expulsão de substâncias que podem estar causando problemas ao organismo
É o caso da náusea que ocorre após consumo de grande quantidade de bebidas alcoólicas
A náusea é um sintoma geral e inespecífico, que chama a atenção para um problema do organismo que nem sempre é facilmente detectável
As náuseas podem melhorar evitando-se a ingestão de alimentos sólidos e através da utilização de antieméticos.
Existe também a náusea de origem psicológica, como aquela que ocorre quando vemos alguma coisa repugnante, pode ser também tonturas repentinas
É a forma da consciência subjetiva de dizer que não aceita aquilo.
Deve-se diferenciar a náusea resultante da cinetose, comum em pessoas que passam mal em movimento, por ter tratamento distinto.
As causas de náuseas e vômitos são muito variadas
A maioria é causada por alterações que ocorrem diretamente no estômago ou intestino, mas certas situações envolvendo outros órgãos também causam esses sintomas
Por exemplo:
É importante diferenciar vômito de regurgitação
Esta última é o retorno não forçado de material do esôfago, estômago ou porção inicial do intestino, sem esforço ou contração de músculos da barriga ou tórax, e geralmente não associado à náusea
É o que frequentemente ocorre com bebês nos primeiros meses e em adultos com queixa de azia (refluxo gastroesofágico).
Vómito, émese  ou vômito, êmese  é a expulsão ativa do conteúdo gástrico pela boca
O vómito é ao mesmo tempo um sinal e um sintoma bastante desagradável que pode assustar muito a pessoa atingida
Pode ocorrer nas doenças do labirinto, nas intoxicações, nas obstruções intestinais e como resposta do organismo a dores muito intensas.


Os medicamentos que agem neste sintoma são chamados de antieméticos.
É uma área que faz com que a pessoa tenha vontade de vomitar
Está situada fora da barreira hematoencefálica, é estimulada de acordo com a presença de estimulantes na circulação
As principais substâncias estimulantes são: estrógenos,cisplatina, morfina, ergotamina, levodopa, estimulantes dos receptores da dopamina e da 5-hidroxitriptamina.
Na prática clínica, o reflexo do vómito (também designado de reflexo faríngeo) é um reflexo importante a ser testado
Este induz-se por toque nas paredes da faringe ou por toque no palato mole ou úvula e as fibras aferentes viscerais gerais do nervo glossofaríngeo vão ser estimuladas e, através dos ramos faríngeos deste nervo, vão atingir a porção caudal do núcleo do feixe solitário, onde vão sinaptizar
Este, por sua vez, envia fibras que vão para os núcleos ambíguo e motor dorsal do vago
O primeiro dá origem a fibras eferentes viscerais especiais para o nervo vago que vão, através do seu ramo laríngeo externo, ramo laríngeo recorrente e ramo faríngeo, induzir a contracção dos músculos faríngeos e laríngeos derivados do 4º e 6º arcos branquiais
O núcleo motor dorsal do vago dá origem a fibras eferentes viscerais gerais pré-ganglionares parassimpáticas que vão para o abdómen e vão induzir a contração dos músculos abdominais
Por isso, a via aferente do reflexo faríngeo é da responsabilidade do nervo glossofaríngeo, enquanto a via eferente é da responsabilidade do nervo vago
Os músculos induzidos neste reflexo são, por isso, os músculos da parede abdominal e a maior parte dos músculos laríngeos e faríngeos (os que são derivados dos arcos branquiais- 4º e 6º).
Fonte: Nolte, 4ª Edição
O ato de vomitar pode ser perigoso se o conteúdo gástrico entra no trato respiratório
Sob circunstâncias normais o reflexo do soluço e a tosse irão prevenir que isso ocorra, entretanto estes reflexos protetores estão comprometidos em pessoas sob influência de certas substâncias como álcool ou anestesia
Estes indivíduos podem se sufocar e se asfixiar ou sofrer uma pneumonia de aspiração.
Vómitos prolongados e excessivos irão depletar o corpo de água (desidratação) e podem alterar o balanço de eletrólitos do corpo
O vómito gástrico leva à perda de ácido (prótons) e cloro diretamente
Combinado com o ácido normalmente presente no estômago, este vómito leva a uma alcalose metabólica hipoclorêmica (baixo níveis de cloreto em associação com altos níveis de HCO3 e CO2 e pH sanguíneo aumentado) e frequentemente hipocalemia (depleção de potássio)
A hipocalemia é um resultado indireto do rim compensando pela perda de ácido
Com a perda da comida ingerida o indivíduo pode se tornar caquético
Menos frequente, o vômito do conteúdo intestinal, incluindo ácidos biliares e HCO3 pode levar à acidose metabólica.
O vômito repetido ou profuso pode causar erosões no esôfago ou pequenas lacerações na mucosa esofágica (laceração de Mallory-Weiss)
Isso pode se tornar aparente após diversos episódio se junto com os vômitos começa a surgir sangue fresco vermelho no conteúdo vomitado.
A síndrome de Boerhaave é a rotura espontânea do esôfago causada pelo esforço de vomitar
O quadro clínico típico é o sujeito vomitando e subitamente apresentando uma forte dor no peito ou região superior do abdomen
Caso não seja diagnosticado nas primeiras horas, leva o paciente a óbito por mediastinite.
Os vómitos repetidos, como observados na bulimia nervosa, podem levar a destruição do esmalte dentário devido à acidez do vômito
As enzimas digestivas também podem ter um efeito negativo na saúde oral, ao degradar o tecido das gengivas.
Um emético, como o xarope de ipeca, é uma substância que induz o vómito quando administrada oralmente ou por injeção
Um emético é usado medicamente quando uma substância tóxica foi ingerida e deve ser expelida do corpo imediatamente (por este motivo, muitos produtos tóxicos e facilmente digeríveis como veneno de rato possuem eméticos em sua composição)
A indução do vômito pode remover a substância antes dela ser absorvida pelo corpo
O abuso do xarope de ipeca pode causar danos à saúde.
O sulfato de cobre já foi usado no passado com um hemético
Hoje ele é considerado muito tóxico para este uso.
Um antiemético é uma medicação que é efetiva contra vômitos e náuseas
Os antieméticos são tipicamente usados para tratar a cinetose (enjoo dos movimentos em viagens) e os efeitos adversos de alguns analgésicos opioides e quimioterapia direcionada contra o câncer.
Os antieméticos atuam ao inibir os locais de receptores associados com a êmese
Desta maneira, são usados como antieméticos: anticolinérgicos, anti-histamínicos, antagonista da dopamina, antagonistas da serotonina e canabinoides.
Dor abdominal pode ser um sintoma associado a distúrbios transitórios ou a doenças mais graves
O diagnóstico definitivo da causa da dor pode ser difícil, pois muitas doenças podem apresentar sintomas semelhantes, incluindo doenças funcionais (como a síndrome do intestino irritável), que podem levar a dores crônicas de localização variada e até migratória, sem qualquer anormalidade em exames complementares.
Coma (do grego κῶμα, "sono profundo") é um estado de inconsciência do qual a pessoa não pode ser despertada.
A manutenção da consciência depende de dois componentes neurológicos importantes: o córtex, a matéria cinzenta cerebral da camada mais externa do cérebro, e o sistema de ativação reticular ascendente (SARA).


A consciência é o estado de alerta que permite ao indivíduo a percepção de si e do meio
Alterações da consciência são definidas como quantitativas e qualitativas
Alterações qualitativas modificam o conteúdo da consciência, como delírios, alucinações e perturbações que não afetam o estado de alerta.
Alterações quantitativas, também conhecidas como nível de consciência, variam em um continuum entre o coma e o estado de alerta normal
Neste continuum descrevem-se o alerta, letárgico, estuporoso e o comatoso
Alerta é o indivíduo no estado de despertar normal
Estuporoso é o indivíduo irresponsivo, que pode ser desperto por estímulo vigoroso, e o comatoso é o estado vegetativo do qual o indivíduo não pode ser desperto mediante estimulação externa
Letárgico é o estado de lentificação psicomotora intermediário entre o estupor e o alerta.
O diagnóstico de coma deve ser realizado por um profissional médico
Ele envolve causas reversíveis de perturbação da consciência (infecciosas, metabólicas, tóxicas, convulsivas)
O exame clínico, testes laboratoriais, eletrofisiológicos e de imagem são importantes e devem ser realizados conforme o julgamento médico
São importantes também na definição de morte encefálica: uma condição irreversível
A legislação brasileira permite a doação de órgãos de indivíduos nessa circunstância.
Nessa situação o indivíduo está acordado e alerta, porém quadriplégico (sem movimentos de braços e pernas) e com paralisia dos nervos cranianos inferiores (responsáveis pela fala e deglutição, por exemplo)
Subtipos de síndrome do locked-in são descritos na literatura médica.
Esses indivíduos preservam as funções vegetativas, embora não possuam consciência
As funções vegetativas compreendem: ciclo sono-vigília e variações autonômicas simpáticas e parassimpáticas, regidas pelo ciclo circadiano
O estado vegetativo persistente também é conhecido como síndrome apática, coma vígil cerebral cortical.
A abulia, também conhecida como mutismo acinético, compreende um complexo neurospsiquiátrico de ausência de iniciativa para o movimento e interação com o meio ambiente
Nessa condição o indivíduo está alerta e desperto, porém apático e indiferente ao ambiente, não movendo-se espontaneamente.
A catatonia é uma síndrome psiquiátrica composta por mutismo e acentuada redução da psicomotricidade
É uma condição normalmente psicogênica (sem lesão neurológica), porém é eventualmente causada por drogas ou mesmo lesão neurológica estrutural.

O Coma é causado pela perturbação grave do funcionamento cerebral devido a traumas crânio-encefálicos, acidentes vasculares cerebrais, tumores, distúrbios metabólicos, envenenamentos ou asfixia.
A avaliação do coma é de suma importância
Em situações de emergência ou de coma de instalação, a avaliação súbita permite ao médico basear suas medidas terapêuticas em protocolos de tratamento e saber da evolução do quadro pela piora ou melhora do estado de coma
A profundidade do coma pode ser classificada por diversas escalas onde o avaliador através de uma padronização de exame quantifica o grau do coma, desde uma leve confusão mental até o coma profundo
Uma das escalas mais utilizadas no mundo, conhecida como Escala de Coma de Glasgow, somando a pontuação pelos seguintes critérios:
Resultado:
O conhecimento médico atual não permite predizer de forma confiável o prognóstico de um indivíduo em coma, a não ser que esse indivíduo preencha critérios para morte encefálica
Certamente a causa (lesão estrutural e sua extensão, toxinas, hipoxemia e outros) e a duração do coma, bem como a idade e antecedentes patológicos do paciente influenciam na definição prognóstica do indivíduo.
A maioria das pessoas em coma permanecem assim entre duas a quatro semanas
Raramente um indivíduo pode permanecer nesse estado por mais tempo na ausência de drogas sedativas
Normalmente o paciente em coma evolui para melhora do nível de consciência ou para a morte encefálica.
Em um estudo com 34 pacientes em coma por falta de oxigenação, 79% dos pacientes nunca se recuperaram e 21% tiveram boa recuperação
Análise clínica, eletroencefalograma e dos potenciais somatossensoriais evocados (PSE) permitirem uma avaliação com 90% de acerto da possibilidade de recuperação do paciente a partir do terceiro dia na maior parte dos casos
Alguns, porém, levaram mais de uma semana antes de um prognóstico mais definitivo
 Em outro estudo com 131 casos de coma profundo, a análise dos potenciais somatossensoriais evocados e do córtex, permitiu acerto 100% do prognóstico
Nenhum paciente com redução do córtex e sem potenciais somatossensoriais evocados se recuperou
Estudo com pacientes com traumatismo encefálico tiveram resultados similares, no qual a avaliação dos potenciais somatossensoriais evocados foi o critério mais eficiente de prognóstico
Uma revisão de 25 estudos também chegou a conclusão de que os PSE são os melhores preditores de recuperação.
Uma pesquisa, que analisou 30 filmes feitos entre 1970 e 2004 que retratavam personagem em comas prolongados, concluiu que apenas dois deles retratavam com precisão o estado de uma vítima de coma e a agonia de esperar por um paciente a despertar: O Reverso da Fortuna (1990) e A Vida Sonhada dos Anjos (1998)
Os outros 28 foram criticados por retratar despertares milagrosos, sem efeitos colaterais duradouros, representações irrealistas de tratamentos com equipamentos desnecessários, sem perda muscular e até mesmo mantendo a pele bronzeada.
A escala de coma de Glasgow ou, na sua forma portuguesa, de Glásgua (ECG) é uma escala neurológica que parece constituir-se num método confiável e objetivo de registrar o nível de consciência de uma pessoa, para avaliação inicial e contínua após um traumatismo craniano
Seu valor também é utilizado no prognóstico do paciente e é de grande utilidade na previsão de eventuais seqüelas.
Inicialmente usado para avaliar o nível de consciência depois de trauma encefálico, a escala é atualmente aplicada a diferentes situações.
Uma escala similar, a Escala Rancho Los Amigos é usada para avaliar a recuperação e pacientes com ferimentos encefálicos.
Morte (do latim mors), óbito (do latim obitu), falecimento (falecer+mento), passamento (passar+mento), ou ainda desencarne (deixar a carne), são sinônimos usados para se referir ao processo irreversível de cessamento das atividades biológicas necessárias à caracterização e manutenção da vida em um sistema outrora classificado como vivo
Após o processo de morte o sistema não mais vive; e encontra-se morto
Os processos que seguem-se à morte (pós-mortem) geralmente são os que levam à decomposição dos sistemas
Sob condições ambientais específicas, processos distintos podem segui-la, a exemplo aqueles que levam à mumificação natural ou a fossilização de organismos.
A morte faz-se notória e ganha destaque especial ao ocorrer em seres humanos
Não há nenhuma evidência científica de que a consciência continue após a morte, no entanto existem várias crenças em diversas culturas e tempos históricos que acreditam em vida após a morte.
Com notórias consequências culturais e suscitando interesse recorrente na Filosofia, existem diversas concepções sobre o destino da consciência após a morte, como as crenças na ressurreição (religiões abraâmicas), na reencarnação (religiões orientais, Doutrina Espírita, etc) ou mesmo o eternal oblivion ("esquecimento eterno"), conceito esse o comum na neuropsicologia e atrelado à ideia de fim permanente da consciência após a morte.
As cerimônias de luto e práticas funerárias são variadas
Os restos mortais de uma pessoa, comumente chamado de cadáver ou corpo, são geralmente enterrados ou cremados
A forma de disposição mortuária pode contudo variar significativamente de cultura para cultura
Entre os fenômenos que induzem a morte, os mais comuns são: envelhecimento biológico (senescência), predação, desnutrição, doenças, suicídio, assassinato, acidentes e acontecimentos que causam traumatismo físico irrecuperável.


Biologicamente, a morte pode ocorrer para todo o organismo ou apenas para parte dele
É possível para células individuais, ou mesmo órgãos, morrerem e ainda assim o organismo continuar a viver
Muitas células individuais vivem por apenas pouco tempo e a maior parte das células de um organismo são continuamente substituídas por novas células.
A substituição de células, através da divisão celular, é definida pelo tamanho dos telômeros e ao fim de um certo número de divisões, cessa
Ao final deste ciclo de renovação celular, não há mais replicação, e o organismo terá de funcionar com cada vez menos células
Isso influenciará o desempenho dos órgãos num processo degenerativo até o ponto em que não haverá mais condições de propagação de sinais químicos para o funcionamento das funções vitais do organismo; implicando a chamada morte natural, por velhice.
Também é possível que um animal continue vivo, mas sem sinal de atividade cerebral (morte cerebral); nestas condições, tecidos e órgãos vivem e podem ser usados para transplantes
Porém, neste caso, os tecidos sobreviventes precisam ser removidos e transplantados rapidamente ou morrerão também
Em raros casos, algumas células podem sobreviver, como no caso de Henrietta Lacks, da qual células cancerígenas foram retiradas do seu corpo por um cientista, continuando a multiplicar-se indefinidamente.
A irreversibilidade é normalmente citada como um atributo da morte
Cientificamente, é impossível trazer de novo à vida um organismo morto, e se um organismo vive, é porque ainda não morreu anteriormente
Contudo existem casos que no mínimo chamam bastante a atenção e suscitam questionamentos quanto às definições de vida e morte
Um deles cerca um grupo de animais invertebrados denominados Rotiferas, que possuem uma capacidade denominada criptobiose, que consiste no "cessar" metabólico quando as condições ambientais não estão favoráveis
Eles podem manter-se assim por meses ou mesmo anos até que as condições se restabelecerem, e então "religarem" seus processos biológicos, retomando a sua vida normalmente
Se o conceito de morte for estendido a tais paralisações metabólicas, esses animais literalmente morrem e depois renascem
Igualmente, ovos de camarões (Shrimp Hatchery) desidratados são incluídos em quites de microscopia para laboratório didáticos, e assim podem permanecer por mais de cinco anos
Quando imersos em salmoura adequada, hidratam-se, desenvolvem-se plenamente e geram, em poucas semanas, camarões crescidos, implicando um literal processo de ressurreição de tais ovos
O caso limite é o do vírus, que até hoje permanece cientificamente exatamente sobre a fronteira que separa os seres vivos dos não vivos, e por tal traz muito trabalho aos taxonomistas.
Muitas pessoas não acreditam que a morte física é sempre e necessariamente irreversível, enquanto outras acreditam em ressurreição do espírito ou do corpo e outras ainda, têm esperança que futuros avanços científicos e tecnológicos possam trazê-las de volta à vida, utilizando técnicas ainda embrionárias, tais como a criogenia ou outros meios de ressuscitação ainda por descobrir.
Alguns biólogos acreditam que a função da morte é primariamente permitir a evolução.
Historicamente, tentativas de definir o momento exato da morte foram problemáticas
A identificação do momento exato da morte é importante, entre outros casos, no transplante de órgãos, porque tais órgãos precisam de ser transplantados, cirurgicamente, o mais rápido possível.
Morte já foi anteriormente definida como parada cardíaca e respiratória mas, com o desenvolvimento da ressuscitação cardiopulmonar e da desfibrilação, surgiu um dilema: ou a definição de morte estava errada, ou técnicas que realmente ressuscitavam uma pessoa foram descobertas: em vários e vários casos, respiração e pulso cardíaco são realmente restabelecidos após cessarem
Em vista da nova tecnologia, atualmente a definição médica de morte é conhecida como morte clínica, morte cerebral ou parada cardíaca irreversível.
A morte cerebral é definida pela cessão de atividade eléctrica no cérebro, mas mesmo aqui há correntes divergentes
Há aqueles que mantêm que apenas a atividade eléctrica do neo-córtex deve ser considerada a fim de se definir a morte
Por padrão, é usada contudo uma definição mais conservadora de morte: a interrupção da atividade elétrica no cérebro como um todo, incluso e sobretudo no tronco encefálico - responsável entre outros pelo controle de atividades vitais essenciais como batimentos cardíacos e respiração - e não apenas no neo-córtex, diretamente associado à consciência
Essa definição - a de morte cerebral - é a adotada, por exemplo, na "Definição Uniforme de Morte" nos Estados Unidos.
Mesmo frente a uma definição precisa de morte, a determinação da mesma ainda traz suas peculiaridades, e pode ser difícil
A exemplo, EEGs podem detectar pequenos impulsos elétricos onde nenhum existe, enquanto houve casos onde atividade cerebral em um dado cérebro mostrou-se baixa demais para que EEGs os detectassem
Por causa disso, vários hospitais possuem elaborados protocolos determinando morte envolvendo EEGs em intervalos separados, e não raro mediante os pareceres autônomos de no mínimo dois médicos.
A história médica contém muitas referências a pessoas que foram declaradas mortas por médicos, e durante os procedimentos para embalsamento eram encontradas vivas
Histórias de pessoas enterradas vivas levaram um inventor no começo do século XX a desenhar um sistema de alarme que poderia ser ativado dentro do caixão.
Por causa das dificuldades na definição de morte, na maioria dos protocolos de emergência, mais de uma confirmação de morte, tipicamente fornecida por médicos diferentes, é necessária
Alguns protocolos de treinamento, por exemplo, afirmam que uma pessoa não deve ser considerada morta a não ser que indicações óbvias que a morte ocorreu existam, como decapitação ou dano extremo ao corpo
Face a qualquer possibilidade de vida, e na ausência de uma ordem de não-ressuscitação, equipes de emergência devem proceder ao transporte o mais imediato possível até ao hospital, para que o paciente possa ser examinado por um médico
Isso leva à situação comum de um paciente ser dado como morto à chegada do hospital.
A questão de o que acontece, especialmente com os humanos, durante e após a morte, ou o que acontece "uma vez morto", se pensarmos na morte como um estado permanente, é uma interrogação frequente, literalmente uma questão latente na psique humana
Tais questões vêm de longa data, e a crença numa vida após a morte com uma posterior reencarnação ou mesmo a passagem para outros mundos embora muito antigas, são ainda muito difundidas socialmente (veja submundo)
Para muitos, a crença e informações sobre a vida após a morte resultam de uma mera busca por consolação ou mesmo de uma covardia em relação à morte de um ser amado ou à prospecção da inevitabilidade de sua própria morte
A crença em vida após a morte pode para esses trazer algum consolo, contudo crenças como o medo do Inferno ou de outras consequências negativas podem tornar a morte algo muito mais temido
A contemplação humana da morte é uma motivação importante para o desenvolvimento de sistemas de crenças e religiões organizadas
Por essa razão, palavra passamento quando dita por um espírita, significa a morte do corpo
A passagem da vida corpórea para a vida espiritual.
Apesar desse ser conceito comum a muitas crenças, ela normalmente segue padrões diferentes de definição de acordo com cada filosofia
Várias religiões creem que após a morte o ser vivo ficaria junto do seu criador, para os cristãos, Deus.
Muitos antropólogos sentem que os enterros fúnebres atribuídos ao Homem de Neanderthal / Homo neanderthalensis, onde corpos ornamentados estão em covas cuidadosamente escavadas, decoradas com flores e outros motivos simbólicos, é evidência de antiga crença na vida após a morte.
Do ponto de vista científico, não se confirma a idéia de uma vida após a morte
Embora grande parte da comunidade científica sustente que isso não é um assunto que caiba à ciência resolver, e que cientificamente não há evidências que corroborem a existência de espíritos ou algo com função similar que sobreviva após a morte, muitos pesquisadores tentaram e ainda tentam entrar nesse campo estudando por exemplo as chamadas "experiências de quase-morte"
Para eles, o conceito de "vida" se associa ao de "consciência", contudo consciência não atrela-se à matéria conhecida.
Ao fim, consideram-se em essência três hipóteses:
A morte como uma entidade sensível é um conceito que existe em muitas sociedades desde o início da história
A morte também é representada por uma figura mitológica em várias culturas
Na iconografia ocidental ela é usualmente representada como uma figura esquelética vestida de manta negra com capuz e portando uma foice/gadanha
É representada nas cartas do Tarot e frequentemente ilustrada na literatura e nas artes.
A associação da imagem com o ceifador está relacionada ao trigo, que na Bíblia simboliza a vida
Em inglês, é geralmente dado à morte o nome de "Grim Reaper"
Também é dado o nome de Anjo da Morte (em hebraico: מַלְאַךְ הַמָּוֶת Malach HaMavet), decorrente da Bíblia.
A morte também é uma figura mitológica que tem existido na mitologia e na cultura popular desde o surgimento dos contadores de histórias
Na mitologia grega, Tânato seria a divindade que personificava a morte, e Hades, o deus do mundo da morte.
O ceifador também aparece nas cartas de tarô e em vários trabalhos televisivos e cinematográficos
Uma das formas dessa personificação é um grande personagem da série Discworld de Terry Pratchett, com grande parte dos romances centrando-se nela como personagem principal.
Em alguns casos, essa personificação da morte é realmente capaz de causar a morte da vítima, gerando histórias de que ela pode ser subornada, enganada, ou iludida, a fim de manter uma vida
Outras crenças consideram que o espectro da morte é apenas um psicopompo e serve para cortar os laços antigos entre a alma e o corpo e para orientar o falecido ao outro mundo sem ter qualquer controle sobre o fato da morte da vítima.
Morte em muitas línguas é personificada na forma masculina (como no inglês), enquanto em outros ela é percebida como uma personagem feminina (por exemplo, em línguas eslavas e latinas)
A série Supernatural apresentou uma visão nova da morte, onde um dos cavaleiros do apocalipse, juntamente com a morte em sua personificação humana, discutem com o personagem principal sobre sua origem
Durante o diálogo ela afirma ser mais velha do que Deus, e que também acima dos céus e da terra, além de também existir em outros planetas, ela leva a vida para o abismo há muito tempo.
Os mexicanos personificam a morte na figura da Santa Muerte, uma deusa resultante do sincretismo entre as mitologias católica e mesoamericanas.
As Ordenações Filipinas - conjunto de leis que servia de base para o direito português na época do Brasil Colônia, previa a "morte natural" em duas versões: "natural cruel" e "natural atroz"
Na "morte cruel", o corpo do condenado era objeto de vingança e, por isso, devia ser torturado vivo
A finalidade era prolongar o sofrimento da vítima.
No caso da condenação por "morte natural atroz", a vítima teria ainda seus bens confiscados e a família seria atingida até a geração dos netos
Essa punição era considerada mais branda que a da "morte natural cruel" e o condenado podia ser esquartejado depois de morto
Em ambos os casos era ressaltado o "caráter pedagógico" da degradação do cadáver
Era a "pedagogia do domínio" pelo medo, "aprendida" por todos que presenciavam o "espetáculo".
Exemplo conhecido de sentenciado com a "morte natural cruel" é a de um dos inconfidentes
A essa pena Tiradentes foi condenado em 1792.
No final do século XVIII, o direito português previa a "morte natural para sempre": proibia o sepultamento do cadáver, que teria as partes do corpo expostas até a decomposição completa."
A morte, no ramo das ciências, é estudada pela tanatologia
Nesse sentido são estudados causas, circunstâncias, fenômenos e repercussões jurídico-sociais, sendo amplamente utilizados na medicina legal
No Brasil o diagnóstico da morte é regido pela resolução 1.480/97 do Conselho Federal de Medicina
A morte também é estudada em outros ramos da ciência, notadamente os relacionados a tratar doenças e traumatismos evitando que elas ocorram
No mesmo sentido uma das estatísticas mundialmente utilizadas para ações governamentais de prevenção são as taxas de mortalidade
Alguns estudos da ciência abordam as experiências de quase morte no sentido de entender os fenômenos correlacionados na quase morte.
Devido a dicotomia mente-corpo — monismo ou dualismo — muitos debates cercam a questão sobre o que acontece com a consciência quando o corpo morre
A crença na vida após a morte baseia-se em relatos, experiências, revelações divinas e exercícios lógicos, sendo um conceito primordial de praticamente todas as religiões
Para os que não acreditam que exista continuidade após a morte e rejeitam a veracidade dos indícios contrários (por não serem científicos), a consciência e personalidade é apenas o produto de um cérebro em funcionamento
Sendo assim, o cessamento da atividade cerebral significaria o final da existência do indivíduo, não havendo nada após isso
A visão monista é a cientificamente suportada em virtude primeiro da ausência factual científica necessária ao suporte da visão dualista; e em segundo devido a considerações levantadas quanto se busca definir de forma rigorosa o que é "consciência"; sobretudo diante da perspectiva dos avanços em biotecnologia, onde a possibilidade de se construir uma máquina com consciência não pode ser mais tratada como mera ficção científica.
Um dos ramos da ciência relatados através de vários casos de quase morte estuda os sentimentos declarados de pacientes que recuperaram suas funções vitais depois de uma intervenção médica
São comuns relatos de pessoas que dizem ter visto uma luz, um túnel iluminado e, às vezes, vendo-se a si mesmo, fora do próprio corpo, a exemplo durante uma cirurgia
Esses relatos dividem opiniões de especialistas que defendem as causas religiosas no sentido de que a "luz" vivenciada pelos pacientes de quase morte era a luz que indicava o caminho para o mundo pós-morte (visão dualista).
Até o momento a visão suportada cientificamente sobre esse fenômeno é a monista, a de que são alterações químicas e funcionais no cérebro - agravadas se há falta de oxigenação adequada aos tecidos, algo comum em cirurgias graves - que fazem o paciente ter alucinações durante a ocorrência das anormalidades
Os avanços das técnicas de mapeamento cerebral e de mecanismos excitatórios cerebrais contribuíram significativamente para a compreensão da experiência de quase-morte
A exemplo, o estímulo direto dos lobos temporais pode induzir a sensação de uma presença invisível ou "divina": um capacete construído pelo médico Michal Persinger e por ele denominado "capacete de Deus" induz experiências "espirituais" em 80% daqueles que o experimentam
Modificações induzidas no funcionamento dos lobos parietais simulam experiências extrassensoriais, entre elas corporificações e a sensação de se "sair do corpo".
Em experimentos realizados em aceleradores centrípetos, que visam a compreender as reações psicofisiológicas humanas em presença de enormes acelerações, após momentaneamente desmaiarem dada a incapacidade circulatória, as pessoas submetidas ao teste relatam quase sempre alucinações análogas às apresentadas pelas pessoas que passaram por experiências de quase-morte, incluso a experiência de se ver fora do corpo; muito embora, nesses experimentos controlados, as pessoas em testes sejam seguramente mantidas longe do limite entre a vida e a morte
A compreensão das reações humanas à bruscas acelerações mostra-se importante a exemplo na aviação militar, onde facilmente os pilotos encontrar-se-ão submetidos a enormes acelerações, usualmente medida via múltiplo da aceleração da gravidade, ou de seu próprio peso, mediante a chamada força G.
O psiquiatra e parapsicólogo Dr
Raymond Moody popularizou termo "experiência de quase-morte" com seu livro escrito em 1975, "Vida Depois da Vida"
O livro ganhou atenção do público em geral para o conceito de experiência de quase-morte
Entretanto, relatos dessas experiências sempre ocorreram na história
A obra "A República" (Livro X), de Platão, escrita no século IV a.C., contém a lenda de um soldado chamado Er que teve uma experiência semelhante depois de ter sido ferido em combate
Er descreveu sua alma deixando seu corpo e, do céu, viu-a sendo julgada junto com outras almas
As "experiências de quase-morte" caracterizam-se, em sua quase totalidade, pelas seguintes percepções:
Segundo Leite de Vasconcelos na noite de Todos os Santos, em Barqueiros, era tradição preparar, à meia-noite, uma mesa com castanhas para os mortos da família irem comer; e depois ninguém mais tocava nas castanhas porque se dizia que estavam “babada dos defuntos”
É também costume deixar um lugar vago à mesa para o morto ou deixar a mesa cheia de iguarias toda a noite da consoada para as "alminhas".
Leite de Vasconcelos também considerava o magusto, festa popular em que amigos e famílias se juntam para assar e comer castanhas, como o vestígio de um antigo sacrifício em honra dos mortos.
Outras manifestações do culto dos mortos são as alminhas e os cruzeiros, pequenos monumentos de devoção que se encontram frequentemente na beira dos caminhos, os Fiéis de Deus e a tradição de pedir o pão-por-deus.
Nas Viagens do Barão de Rozmital, de 1465 a 1467, encontram-se algumas referências aos clamores e brados e outras tradições fúnebres: « Ha também alli esta costumeira : morrendo alguém, levam para a egreja vinho, carne, pão e outras comidas ; os parentes do morto acompanham o funeral vestidos de roupas brancas próprias dos enterros com capuzes á maneira dos monges, com o qual vestuário se vestem de um modo admirável
Aquelles porém, que são assalariados para carpirem o defuncto vão vestidos com roupa preta, e fazem um pranto como o d'aquelles que entre nós pulam de contentes ou estão alegres por terem bebido. »
Algumas tribos de nativos do Novo Mundo acreditavam que havia algum tipo de vida após a morte
Outras consumiam a carne ou ossos de familiares mortos, pois pensavam que assim adquiririam as boas qualidades da pessoa morta.
Quando algum índio importante de tribos da Bahia falecia era enterrado com suas armas e objetos usados no dia a dia e para que pudesse se alimentar, alimentos e água eram disponibilizados
O pio do gavião caracará era temido pelos índios amazônicos uma vez que acreditam que era o anúncio de morte na aldeia.
Os Camacan da Bahia colocavam sobre a sepultura do índio morto pedaços de carnes e quando eles desapareciam (comidos por outros animais ou por outros motivos), evitava-se comer aquele tipo de caça
Entre os Maués da Amazônia a família da pessoa morta abstinha-se de comer banana, peixe pego em anzol ou com o emprego do timbó e alguns tipos de caça
Os Aruak de Roraima cremavam os mortos e as cinzas eram guardadas em pequenas urnas
Por ocasião da data de aniversário do falecido um punhado da cinza era misturado ao mingau de banana e consumido pelos parentes
Outras tribos misturavam as cinzas ao caxiri, uma bebida fermentada, e assim as ingeriam.
Os Tariana e os Tucano desenterravam seus mortos após um mês do funeral e os colocavam em uma grande panela até que as partes moles desaparecessem
Os ossos, após carbonizados, eram triturados e reduzidos a pó
Este era colocado em vários cochos cheios de caxirí
A mistura era bebida pelos presentes, que acreditavam que estavam ingerindo as boas qualidades do falecido
Entre os Kubewãna era costume desenterrar grandes líderes mortos há mais de quinze anos, triturar seus ossos e misturá-los a uma bebida grossa à base de milho e ingeri-los em grandes festas regadas a caxirí
Os Arapium, índios que viveram nos séculos XVII e XVIII a oeste do Rio Tapajós, também bebiam as cinzas dos seus mortos misturadas a bebidas.
Os Jumana da região dos rio Japurá e rio Solimões cremavam seus mortos e tomavam as cinzas misturadas com bebidas, uma vez que acreditavam que a alma da pessoa estava nas cinzas e voltava a viver no corpo de quem ingeria a bebida
Os Waiká da Amazônia adicionavam as cinzas à sopa de plátano e os Surara, também da Amazônia, ao mingau de banana
Entre os indígenas que habitavam no início do século XVII na região da serra da Ibiapaba, entre Ceará e Piauí, se o morto era do sexo masculino as mulheres comiam sua carne e moíam seus ossos, bebendo-o para não sentirem saudades do ente querido
As mulheres dos Tarairiu do Rio Grande do Norte repartiam o cadáver, moqueavam e lamentavam sua morte enquanto comiam a carne e roíam os ossos
Uma emergência médica é um machucado ou doença que necessita de atendimento médico imediato
É uma situação ou problema que põe em causa a sobrevivência do indivíduo a curto prazo, seja por doença súbita ou trauma, ou que lhe pode gerar incapacidade permanente grave e que necessita de ser abordado num intervalo curto de tempo, geralmente em poucos minutos.
A especialização em medicina de urgência inclui técnicas de manuseio efetivo e ressuscitação de pacientes.
A desidratação ocorre quando o corpo humano perde mais água que repõe, e com isso não tem água suficiente para realizar suas funções normais
Indivíduos desidratados apresentam um volume de sangue menor que o normal, o que força o coração a aumentar o ritmo de seus batimentos, quadro chamado pelos médicos de taquicardia
Outros sintomas podem ser fraqueza, tontura, dor de cabeça, fadiga e pode levar à morte.
Uma maneira de tratar a desidratação é o soro caseiro
Também existem soros industrializados contra a desidratação
Soros industrializados são especialmente indicados em casos de desidratação por apresentarem composição equilibrada de cloreto de sódio, cloreto de potássio monoidratado, citrato de sódio diidratado e glicose
A composição equilibrada desses ingredientes evita efeitos colaterais como convulsões.
A desidratação pode ocorrer em níveis diferentes, e com isso apresentar sintomas cada vez mais graves
Entre eles:
Metabólica: Intervalo aniônico elevado (cetoacidose/cetoacidose diabética, láctica) · Intervalo aniônico normal (hiperclorêmica, tubular renal)
Metabólica: Alcalose de contração
Hipoglicemia é uma condição em que a taxa de glicose no sangue diminui para valores inferiores ao normal
A condição causa vários sintomas, entre os quais desorientação, dificuldade em falar, estado de confusão, perda de consciência, convulsões ou morte
Podem ainda estar presentes sintomas como fome, sudação em excesso, tremores e fadiga
Geralmente os sintomas manifestam-se de forma súbita
A condição oposta é a hiperglicemia.
A causa mais comum de hipoglicemia são os medicamentos antidiabéticos usados no tratamento da diabetes, como a insulina e as sulfonilureias
O risco é maior em diabéticos que comeram menos do que é habitual ou que ingeriram bebidas alcoólicas
Entre outras possíveis causas estão a insuficiência renal, alguns tumores como o insulinoma, doenças hepáticas, hipotiroidismo, inanição, erro metabólico hereditário, infeções graves, hipoglicemia reativa e uma série de drogas, incluindo álcool
A hipoglicemia pode também ocorrer em bebés de outro modo saudáveis que não tenham comido durante várias horas.
A taxa de glicose no sangue que define a hipoglicemia varia
Em pessoas com diabetes, o diagnóstico corresponde a uma taxa inferior a 3,9 mmol/L (70 mg/dL)
Em adultos sem diabetes, o diagnóstico é confirmado quando se verifica simultaneamente sintomas relacionados com a hipoglicemia, baixa glicose no sangue durante os sintomas, e melhoria desses sintomas assim que a taxa regressa ao normal
Quando não se manifestam sintomas, pode ser usado um valor de referência inferior a 2,8 mmol/L (50 mg/dL) em jejum ou após a realização de exercício físico
Em recém-nascidos, uma taxa inferior a 2,2 mmol/L (40 mg/dL), ou inferior a 3,3 mmol/L (60 mg/dL) quando acompanhada de sintomas, indica a presença de hipoglicemia
Os valores de glicose são medidos com análises ao sangue
Entre outros exames que podem ser úteis para determinar a causa estão os valores de insulina e de peptídeos-C no sangue.
Nas pessoas com diabetes, a prevenção da hipoglicemia consiste em adequar a dieta à quantidade de exercício físico praticado e aos medicamentos usados
Quando as pessoas sentem que a taxa de glicose pode estar a diminuir, recomenda-se o uso de um medidor de glicemia portátil
Como algumas pessoas manifestam poucos sintomas iniciais quando a taxa de glicose diminui, recomenda-se a este grupo que monitorize frequentemente a taxa de glicose
O tratamento consiste em ingerir alimentos ricos em açúcares simples ou na toma de dextrose
Nos casos em que a pessoa não consegue ingerir alimentos pela boca, pode ser necessária uma injeção de glicagina
O tratamento da hipoglicemia sem relação com a diabetes consiste em tratar também o problema subjacente e numa dieta saudável.


Os sintomas hipoglicêmicos podem ser divididos naqueles produzidos pelos hormônios contra-regulatórios (adrenalina e glucagon), acionados pelo declínio da glicose, e naqueles produzidos pela redução de açúcar no cérebro.
Nem todas as manifestações anteriores ocorrem em casos de hipoglicemia
Não há ordem certa no aparecimento dos sintomas
Manifestações específicas variam de acordo com a idade e com a severidade da hipoglicemia
Em crianças jovens com hipoglicemia matinal, há vômito frequentemente acompanhado de cetose
Em crianças maiores e em adultos, a hipoglicemia moderadamente severa pode parecer mania, distúrbio mental, intoxicação por drogas ou embriaguez
Nos idosos, a hipoglicemia pode produzir efeitos parecidos com uma isquemia focal ou mal-estar sem explicação.
Em recém-nascidos, a hipoglicemia pode produzir irritabilidade, agitação, ataque mioclônico, cianose, dificuldade respiratória, episódios de apneia, sudorese, hipotermia, sonolência, hipotonia, recusa a se alimentar e convulsões
Também pode parecer asfixia, hipocalcemia, sepse ou falha cardíaca.
Em ambos, pacientes de longa data ou não, o cérebro pode se habituar a níveis baixos de glicose, com redução dos sintomas perceptíveis em momentos de neuroglicopenia
Diabéticos insulinodependentes chamam a neuroglicopenia incondicionalmente de hipoglicemia, e que é um problema clínico importante quando tenta-se melhorar o controle glicêmico desses pacientes
Outro aspecto desse fenômeno ocorre em glicogenose tipo I, onde a hipoglicemia crônica antes do diagnóstico pode ser mais bem tolerada do que episódios agudos após o início do tratamento.
Quase sempre a hipoglicemia severa a ponto de ocasionar convulsões ou inconsciência pode ser revertida sem danos ao cérebro
Os casos de morte ou dano neurológico permanente que ocorreram com um único episódio envolvem ocorrências conjuntas de inconsciência não tratada ou prolongada, ou interferência na respiração, ou doenças concorrentes severas ou outros tipos de vulnerabilidade
De qualquer maneira, hipoglicemias severas podem eventualmente resultar em morte ou dano cerebral.
Mais raramente, a hipoglicemia pode revelar:
Da mesma forma que a maioria das células de animais, o metabolismo cerebral depende primeiramente de glicose para trabalhar
Em casos de privação de glicose, pode-se conseguir uma quantidade limitada dela armazenada nos astrócitos, mas que é consumida em minutos
De qualquer forma, o cérebro é dependente de fornecimento contínuo de glicose, que difunde do sangue ao tecido intersticial dentro do sistema nervoso central, e aos próprios neurônios.
Por isso, se a quantidade de glicose suprida pelo sangue cai, o cérebro é um dos primeiros órgãos a percebê-lo
Na maioria das pessoas, a eficiência mental parece diminuir quando a glicemia cai abaixo de 65 mg/dL (3,6 mM)
Ocorre limitação de ações e de julgamento geralmente quando a glicemia cai abaixo de 40 mg/dL (2,2 mM)
Se cair ainda mais, podem ocorrer convulsões
Próxima ou abaixo de 10 mg/dL, a maior parte dos neurônios fica eletricamente desligada, resultando no coma.
A importância de um fornecimento adequado de glicose ao cérebro é clara pelo fato de ocorrerem inúmeras respostas nervosas, hormonais e metabólicas para combater uma hipoglicemia
A maior parte delas é defensiva ou adaptiva: ou tentando aumentar o açúcar no sangue via gliconeogênese e glicogenólise, ou providenciando formas de energia alternativas.
Embora se cite que 70 mg/dL (3.9 mmol/L) seja o limite inferior da glicemia normal, podem definir-se diferentes valores como baixos em diferentes populações, propósitos e circunstâncias
O nível preciso de glicemia considerado baixo o bastante para se definir uma hipoglicemia depende de: (1) método de medição; (2) idade da pessoa; (3) presença ou ausência de sintomas.
O nível de glicose neste artigo é o de plasma venoso ou em soro, medido por métodos-padrão de glicose oxidase usados em laboratórios
Para finalidades clínicas, tanto o nível no plasma quanto o no soro são similares o bastante para serem intercambiados
O plasma arterial ou em soro são levemente superiores do que os níveis venosos, e os níveis capilares estão entre os arteriais e os venosos
A diferença entre os níveis arterial e venoso é pequena sob jejum, mas é amplificada e pode ser até 20% maior em estado pós-prandial
Por outro lado, os níveis de glicemia totais (por exemplo os medidos por glicosímetros digitais) são cerca de 10-15% menores do que os níveis em plasma venoso
Além disso, os glicosímetros disponíveis garantem apenas exatidões de 15% em relação a valores de laboratórios clínicos.
Dois outros fatores afetam significantemente a medição da glicose
A disparidade entre a concentração venosa e a concentração total é maior quando o hematócrito é alto, como no caso de recém-nascidos
Em segundo, a menos que a amostra tenha sido colocada em um tubo de fluoreto ou processada imediatamente para separar o soro ou plasma das células, a glicose mensurável será gradualmente metabolizada in vitro.
Dados estatísticos de crianças e adultos saudáveis mostram que glicemias em jejum abaixo de 60 mg/dL (3,3 mM) ou acima de 100 mg/dL (5,6 mM) são encontradas em menos de 5% da população
Em até 10% dos recém-nascidos e crianças jovens, foram encontrados níveis abaixo de 60 mg/dL depois de jejum noturno
Em outras palavras, muitas pessoas saudáveis podem eventualmente ter níveis glicêmicos na faixa de hipoglicemia sem apresentar sintomas ou distúrbios.
A faixa glicêmica normal de recém-nascidos ainda é motivo de debate
As estatísticas e a experiência revelam níveis de açúcar frequentemente abaixo de 40 mg/dL (2,2 mM) e, mais raramente, abaixo de 30 mg/dL (1,7 mM) em bebês saudáveis de gravidez a termo nos primeiros dias de vida
Foi proposto que os cérebros de recém-nascidos são mais facilmente capazes de usar combustíveis alternativos quando os níveis glicêmicos estão baixos, em relação a adultos
Os especialistas continuam o debate quanto à significância e ao risco desses níveis glicêmicos, embora a tendência seja recomendar a manutenção dos níveis de glicose acima de 60–70 mg/dL (3,3-3,9 mM) após os primeiros dias de vida
Em bebês prematuros, adoecidos ou abaixo do peso é mais comum encontrar baixos níveis de glicose, mas há um consenso de que os açúcares devam ser mantidos ao menos acima de 50 mg/dL (2,8 mM) nestas circunstâncias
Alguns especialistas defendem 70 mg/dL (3,9mM) como um objetivo terapêutico, especialmente em circunstâncias tais como hiperinsulinismo, onde combustíveis alternativos podem ser mais escassos.
Pesquisas mostram que a eficiência mental diminui levemente mas de modo sensível quando a glicemia cai abaixo de 65 mg/dL (3,6 mM), em adultos saudáveis
Os mecanismos de defesa hormonal (adrenalina e glucagon) são ativados assim que a glicemia passa por limiares (cerca de 55 mg/dL ou 3,0 mM para a maioria das pessoas), produzindo tremores e disforia
Por outro lado, não ocorre com frequência um prejuízo de capacidade mental até que a glicemia caia abaixo de 40 mg/dL (2,2 mM), e até 10% da população pode eventualmente ter níveis de glicose abaixo de 65 (3,6) pela manhã sem efeitos aparentes
Os efeitos da hipoglicemia, chamados de neuroglicopenia, é que determinam quando um certo nível glicêmico é realmente um problema ao indivíduo.
É preferível que a pessoa com hipoglicemia use tanto os sintomas quanto os dados numéricos de seu glicosímetro para determinar as medidas a serem tomadas
É fácil notar hipoglicemia quando o valor lido é 50 mg/dL (2,8 mM); porém, um paciente que está com a diabetes descompensada e frequentemente lê valores acima de 200 mg/dL (11,1 mM) pode sentir sintomas de hipoglicemia quando o nível de glicose no sangue chegar a valores "normais" de 90 mg/dL (5,0 mM)
Neste caso, a pessoa não apresenta uma hipoglicemia clássica, mas terá alívio de sintomas com o tratamento rotineiro para hipoglicemias
Além disso, quando a glicemia diminui a uma taxa rápida, também podem surgir sintomas de hipoglicemia.
Este critério é por si só complicado de se admitir pelo fato de os sintomas da hipoglicemia serem vagos e poderem ser produzidos por outros motivos; além do que, quando a pessoa passa por níveis baixos de glicemia com recorrência, ela pode perder a sensação de limiar, de forma que pode haver agravamento de seus sintomas (por neuroglicopenia) sem que ela note
Para completar a dificuldade, os glicosímetros são inexatos para baixos valores, o que descredita a sua utilidade nessas horas.
Procure sempre encontrar a causa de uma baixa glicémia
A glicémia diária normal não deverá ser inferior a 90 mg/dl (5 mmol/l)
Utilize os testes à glicémia para evitar a hipoglicémia
É particularmente importante testar a glicémia ao deitar
Nenhuma criança diabética deverá deitar-se antes das refeições sem que lhe seja feito o teste da glicémia
Não injete insulina antes duma refeição se o valor for inferior a 90 mg/dl (5 mmol/l)
Espere que a criança acabe a refeição e só depois injete insulina
O açúcar sanguíneo pode subir ao valor normal em minutos da seguinte forma: consumindo (por conta própria) ou recebendo (por outrem) 10-20 g de carboidrato
Pode ser em forma de alimento ou bebida caso a pessoa esteja consciente e seja capaz de engolir
Essa quantidade de carboidrato está contida nos seguintes alimentos:
O amido é rapidamente transformado em glicose, mas a adição de gordura ou proteína retarda a digestão
Os sintomas começam a melhorar em 5 minutos, embora demore 10-20 min até a recuperação completa
O abuso de alimentos não acelera a recuperação e se a pessoa for diabética isto simplesmente causará uma hiperglicemia mais tarde.
Se a pessoa está sofrendo de efeitos severos de hipoglicemia de maneira que não possa (devido a combatividade) ou não deva (devido a convulsões ou inconsciência) ser alimentada, pode-se dar a ela uma infusão intravenosa de glicose ou uma injeção de glucagon..
A prevenção depende da causa da hipoglicemia
O risco de novos episódios pode ser frequentemente reduzida pelo abaixamento da dose de insulina ou medicamento, ou pela atenção maior à glicemia durante eventos inesperados, diminuição do ritmo de exercícios físicos ou de ingestão de álcool.
Muitos tipos de disfunções congêneres do metabolismo requerem evitar ou encurtar os intervalos de jejum, ou evitar carboidratos extras
Para distúrbios mais severos, como a glicogenose tipo I, isto pode ser feito pelo consumo de amido de milho de hora em hora ou por infusão gástrica contínua.
Vários tratamentos são usados em caso de hipoglicemia hiperinsulinêmica, dependendo da forma exata e do grau de severidade
Algumas formas de hiperinsulinismo congênito respondem bem ao diazóxido ou octreótido
A remoção cirúrgica da parte hiper-reativa do pâncreas é eficaz com risco mínimo quando o hiperinsulinismo é focal, ou devido a um tumor benigno produtor de insulina
Quando o hiperinsulinismo congênito é difuso ou imune às medicações, a pancreatectomia subtotal pode ser o tratamento de último caso, mas neste caso é menos efetivo e passível de várias complicações.
A hipoglicemia devida a deficiências hormonais como hipopituitarismo ou insuficiência adrenal geralmente cessa quando se administra o hormônio apropriado.
A hipoglicemia devida à síndrome do empachamento (ou Síndrome de dumping no português brasileiro) e outras condições pós-cirúrgicas é mais bem tratada com alteração da dieta
A inclusão de gordura e proteína com carboidratos pode retardar a digestão e reduzir a secreção antecipada de insulina
Alguns desses casos respondem a tratamento com um inibidor de glicosidase, que retarda a digestão de amido.
A hipoglicemia reativa com baixa glicose no açúcar é frequentemente um incômodo previsível, que pode ser evitado pelo consumo de gordura e proteína com carboidratos, pela adição de lanches pela manhã e à tarde e pela redução do consumo de álcool.
A síndrome pós-prandial idiopática sem níveis baixos de glicose no momento dos sintomas pode ser mesmo um desafio de conduta
Muitas pessoas encontram melhorias com a mudança no padrão de alimentação (refeições menores, evitando açúcar em demasia, refeições mistas em detrimento de carboidratos), ou fazendo mudanças no estilo de vida para evitar o estresse, ou diminuindo o consumo de estimulantes como cafeína.
Um acidente vascular cerebral (AVC) ocorre quando problemas na irrigação sanguínea do cérebro causam a morte das células, o que faz com que partes do cérebro deixem de funcionar devidamente
Existem dois tipos principais de AVC: isquémico, causado pela interrupção da irrigação sanguínea, e hemorrágico, causado por uma hemorragia
Entre os sinais e sintomas de um AVC estão a incapacidade de mover ou de sentir um dos lados do corpo, dificuldades em compreender ou em falar, sensação de que os objetos em volta se movimentam ou perda de um dos lados da visão
Na maior parte dos casos, os sinais e sintomas manifestam-se imediatamente após o AVC
Quando a duração dos sintomas é inferior a uma ou duas horas, o episódio denomina-se acidente isquémico transitório (AIT), ou mini-derrame
Uma hemorragia subaracnóidea pode também estar associada a dores de cabeça intensas
Os sintomas de um AVC podem ser permanentes
Entre as complicações a longo prazo estão a pneumonia ou incontinência urinária.
O principal fator de risco de um AVC é a hipertensão arterial
Entre outros fatores de risco estão fumar, a obesidade, colesterol elevado, diabetes, ter tido anteriormente um acidente isquémico transitório e fibrilação auricular
Um AVC isquémico é geralmente causado pelo bloqueio de um vaso sanguíneo, embora existam outras causas menos comuns
Um AVC hemorrágico é causado por um derrame, quer por uma hemorragia diretamente no cérebro quer por uma Hemorragia subaracnóidea no espaço entre as meninges
Estas hemorragias podem ocorrer devido à rutura de um aneurisma cerebral
O diagnóstico é geralmente feito com recurso a imagiologia médica, como uma TAC ou ressonância magnética, acompanhada por uma avaliação física da pessoa
Podem ser realizados outros exames, como análises ao sangue ou eletrocardiograma, para determinar fatores de risco e descartar outras possíveis causas
A hipoglicemia pode provocar sintomas semelhantes a um AVC.
A prevenção consiste em diminuir os fatores de risco, assim como na possibilidade de ser administrada aspirina ou estatinas
Em pessoas com estenose da carótida pode ser considerada uma Endarteriectomia para alargar as artérias do cérebro
Em pessoas fibrilação auricular pode ser administrada varfarina
Um AVC ou AIT geralmente necessita de assistência médica urgente
Quando um AVC isquémico é detectado nas primeiras três horas e meia a quatro horas, é possível ser tratado com medicação trombolítica que dissolve os coágulos sanguíneos e com aspirina
Em alguns AVC hemorrágicos pode ser considerada neurocirurgia
Algumas das funções perdidas durante o AVC podem ser recuperadas com tratamentos de reabilitação e recuperação
No entanto, em muitas regiões do mundo estes tratamentos não estão disponíveis.
Em 2013 cerca de 6,9 milhões de pessoas sofreram um AVC isquémico e 3,4 milhões um AVC hemorrágico
Em 2010, encontravam-se vivas cerca de 33 milhões de pessoas que no passado tinham sofrido um AVC
Entre 1990 e 2010 o número de AVC ocorrido em cada ano diminuiu cerca de 10% nos países desenvolvidos e aumentou cerca de 10% nos países em vias de desenvolvimento
Em 2013, os AVC foram a segunda principal causa de morte, a seguir à doença arterial coronária, tendo sido responsáveis por 6,4 milhões de mortes em todo o mundo, o que corresponde a 12% do total de mortes
Cerca de 3,3 milhões de mortes foram causadas por AVC isquémico e 3,2 milhões por AVC hemorrágico
Cerca de metade das pessoas que sofrem um AVC vivem menos de um ano
Dois terços dos AVC ocorrem em pessoas com mais de 65 anos de idade.


Os acidentes vasculares do cérebro podem ser basicamente decorrentes da obstrução de uma artéria que irriga o cérebro (ou seja, por isquemia) ou podem ser por vazamento de sangue de um vaso sanguíneo (ou seja, hemorrágico)
Cabe ressaltar que o termo "derrame" não é apropriado, visto que em apenas uma parte dos AVC's (na verdade a minoria deles) ocorre um derramamento de sangue no parênquima encefálico.
É o tipo de AVC mais comum, presente em cerca de 80% dos casos
Ocorre pela falta de fluxo sanguíneo cerebral, levando ao sofrimento e enfarte do parênquima do sistema nervoso
Essa queda no fluxo sanguíneo pode ser decorrente de:
Nos primeiros momentos do AVC isquêmico não há morte de tecido cerebral, mas a falta de suprimento sanguíneo provoca a rápida degeneração do tecido cerebral, um tecido metabolicamente muito ativo e que demanda muito oxigénio e glicose para manter seus neurónios vivos
A área central do acidente vascular morre em pouco tempo, pois está praticamente sem nenhum fluxo de sangue
Todavia, existe uma região ao redor do infarto central que possui um fluxo de sangue reduzido, que se mantém viável por mais tempo
A essa área dá-se o nome de penumbra
É na penumbra, uma área parcialmente perfundida, mas ainda viável, que deve-se concentrar os esforços terapêuticos
É por isso também que o tempo do início do ataque vascular cerebral até a reversão da obstrução de sangue é importante na evolução do AVC isquêmico.
O AIT ou ataque isquêmico transitório pode ser considerado um tipo de AVC isquêmico
Corresponde a uma isquemia (entupimento) passageira que não chega a constituir uma lesão neurológica definitiva e não deixa sequela
Ou seja, é um episódio súbito de déficit sanguíneo em uma região do cérebro com manifestações neurológicas que se revertem em minutos ou em até 24 horas sem deixar sequelas (se deixar sequelas por mais de 24 horas, passa a se chamar acidente isquêmico vascular por definição)
Constitui um fator de risco muito importante, visto que uma elevada porcentagem dos pacientes com AIT apresentam um AVC nos dias subsequentes
É possível que a definição de AIT venha a sofrer alterações, pois com exames mais acurados já é possível identificar lesões/sequelas cerebrais antes imperceptíveis em alguns AITs e, além disso, estudos clínicos mostram que a maioria dos AITs dura menos de 1 hora
Assim, o AIT que dura mais de uma hora provavelmente será um AVC e talvez possa provocar uma lesão cerebral, mesmo que imperceptível.
É o acidente vascular cerebral menos comum presente em cerca de 20% dos casos, mas não menos grave
Ocorre pela ruptura de um vaso sanguíneo intracraniano
O sangue em contato com o parênquima nervoso tem ação irritativa
Além disso, a inflamação e o efeito de massa ou pressão exercida pelo coágulo de sangue no tecido nervoso prejudica e degenera o cérebro e a função cerebral
Pode ser divido em dois tipos, O sangramento intraparenquimatoso ou a hemorragia subaracnóidea:
O diagnóstico do AVC é clínico, ou seja, é feito pela história e exame físico do paciente
Os principais sintomas são:
Durante um exame pode-se pedir ao paciente que sorria, levante os dois braços e repita uma frase (como "trinta e três")
Diante desses sintomas, quanto mais rápido o socorro, menor a probabilidade de sequelas, este teste é designado Escala de Cincinnati
Outros sintomas menos específicos, como queda do estado geral e coma, também elevam o risco de AVC.
Os médicos recomendam que a hipótese seja confirmada por um exame de imagem, tomografia computadorizada e ressonância magnética, que permitem ao médico identificar a área do cérebro afetada e o tipo de AVC.
A tomografia pode ser o exame inicial de escolha por sua disponibilidade e rapidez
Serve principalmente para diferenciar o AVC por entupimento/isquemia do hemorrágico, o que muda radicalmente a conduta médica
Uma tomografia normal dentro das primeiras 24 horas de um AVC isquêmico é algo esperado e confirma o diagnóstico, pois a maioria dos ataques isquêmicos não provoca lesões visíveis tão precoces nesse exame
Apenas lesões extensas ou mais antigas podem ser vistas na tomografia no AVC isquêmico ou, ainda, sinais indiretos de AVC como edema cerebral
Já o AVC hemorrágico costuma vir com imagem na tomografia indicando vazamento de sangue
Pode-se, ainda que menos comum, usar mão da retirada por punção lombar do líquor para o diagnóstico de AVC hemorrágico com tomografia normal.
Embora mais precisa que a tomografia, a ressonância magnética não costuma mudar a conduta médica e pode ainda atrasar o tratamento correto, o que pode ter impacto na recuperação do paciente
Contudo, é uma opção que pode ser útil em casos selecionados.
O processo de reabilitação pode ser longo, dependendo das características do próprio AVC, da região afetada, da rapidez de atuação para minimizar os riscos e do apoio que o doente tiver
O sistema nervoso central todo pode ser acometido por esta doença, o que inclui, além do cérebro, o tronco encefálico, o cerebelo e até a medula espinhal.
Assim o lobo frontal está mais ligado às decisões e movimentos; o lobo parietal com os movimentos do corpo, parte da fala e com a sensibilidade do pescoço até os pés; e o lobo occipital com a visão
Já o cerebelo está ligado com o equilíbrio e o tronco cerebral está ligado à respiração e aos movimentos e sensibilidade da cabeça
Claro que isto é uma explicação básica e deve-se ter em mente que todo sistema nervoso está interligado podendo uma lesão em uma mínima parte ter grandes repercussões no todo
A localização e as implicações da lesão podem ser difíceis de diagnosticar, devendo a pessoa acometida ser avaliada por um médico e equipe multidisciplinar, ou seja, com vários profissionais da saúde de diversas áreas.
No caso de um AIT ou acidente isquêmico transitório, não ocorre sequela
No entanto, a prevenção de outro AVC deve ser instituída devido ao alto risco de novo ataque dessas pessoas
No caso de um acidente encefálico associado a déficits motores, necessita-se de acompanhamento da equipe de fisioterapeutas, fonoaudiólogos e terapeutas ocupacionais para potencializar e fortalecer os músculos que ainda possuem a inervação funcionante para assim diminuir as deficiências que podem ter sido causadas; no caso de problemas na fala e/ou deglutição um fonoaudiólogo pode ser necessário.
Vale lembrar que o AVC é uma doença que merece muita atenção pela mudança que pode provocar na dinâmica da vida da vítima, da vida da sua família e das pessoas que dela cuidam
A vítima, antes totalmente funcional, pode se tornar totalmente dependente física e financeiramente de seus cuidadores
Pode, uma vez acamada, desencadear outras complicações, como escaras de decúbito, pneumonia e obstipação
Além disso, existe descrito o stress do cuidador - que, aliás, também deve ser abordado e ouvido no tratamento do paciente acamado, minimizando as sequelas familiares.
A melhor maneira de lidar com o AVC é preveni-lo controlando todos os fatores causais já citados, novamente mencionando que a principal é a hipertensão arterial sistêmica.
O AVC geralmente causa um impacto significativo na vida funcional, cognitiva e social do paciente, sendo comum que o paciente desenvolva transtornos psicológicos após o derrame
Entre 10 e 34% desenvolvem depressão maior, agravando ainda mais o prejuízo funcional, cognitivo e social do paciente
Quanto maior o prejuízo na qualidade de vida e dificuldade de adesão ao tratamento mais importante é o acompanhamento psicológico e psiquiátrico para a reabilitação da vítima do derrame.
Existem diversos fatores considerados de risco para a chance de ter um AVC, sendo o principal a hipertensão arterial sistêmica não controlada e, além dela, também aumentam a possibilidade o diabete melitus, doenças reumatológicas, trombose, uma arritmia cardíaca chamada fibrilação atrial, estenose da válvula mitral, entre outras.
Como todas as doenças vasculares, o melhor tratamento para o AVC é identificar e tratar os fatores de risco como a hipertensão, aterosclerose, o diabetes mellitus, o colesterol elevado, cessar o tabagismo e o etilismo, além de reconhecer e tratar problemas cardíacos
A essa prática se dá o nome de prevenção primária.
Se houver atendimento médico rápido, dentro de um determinado tempo, a área afetada poderá ser normalizada
A essa prática de prevenção que se baseia no atendimento médico eficiente se dá o nome de prevenção secundária.
Caso ocorram sequelas, deve ser iniciado um programa de reabilitação e cuidados com o paciente que inclui equipe multidisciplinar, ou seja, com vários profissionais de diferentes áreas da saúde - fisioterapia, fonoaudiologia, psicologia, técnicos em enfermagem, terapeutas ocupacionais, enfermeiros e médicos
A reabilitação é um tipo de prevenção terciária do paciente.
O manejo da pressão arterial no AVC isquêmico é altamente polêmico, uma vez que tanto pressões muito altas como muito baixas podem ser fatais
Ambas as situações podem apresentar um potencial de morbi-mortalidade, pois a hipertensão pode estar associada à transformação hemorrágica e recorrência do AVC, enquanto a hipotensão é suspeita de levar a uma baixa perfusão, provocando lesões definitivas da zona da penumbra isquêmica e levando a um pior prognóstico
O tratamento de redução da PA desses pacientes já foi associado a uma melhora de prognóstico e a um aumento da eficiência e segurança do tratamento trombolítico, mas outros estudos correlacionam a redução da PA, assim como a hipotensão do AVC com um pior prognóstico neurológico, com maior morbidade e mortalidade
Alguns especialistas chegam a sugerir o aumento induzido da pressão arterial em pacientes hipotensos com AVC
A causa desse aparente paradoxo não é bem esclarecida, e suspeita-se que diferentes modalidades e circunstâncias do AVC determinem um papel diferente para a pressão arterial no prognóstico do paciente.
A maioria dos neurologistas concorda que pressões excessivamente elevadas (PAS > 220 mmHg) estão associadas a um prognóstico pior, mas a hipotensão (PAS < 60 mmHg) parece ser igualmente deletéria
Vários estudos sugerem que uma redução moderada da pressão, se acompanhada por tratamento trombolítico (como o ativador do plasminogênio tecidual, que é um agente fibrinolítico), pode reduzir significantemente a morbi-mortalidade
Os mesmos estudos tendem a concordar que a redução da pressão, se não acompanhada por trombólise, pode não ser segura.
Em presença dessas incertezas, o protocolo de manejo da PA em pacientes com AVC isquêmico agudo se baseia essencialmente na opinião de especialistas, que recomendam reduzir a PA em casos nos quais esta se encontra excessivamente elevada (PAS>220 mmHg), ou quando a redução for associada ao tratamento trombolítico
Nos demais casos a redução da PA não é recomendada.
A gravidade das sequelas dependem de quanto tempo demorou para o paciente ser atendido, sendo que, quanto mais rápido o tratamento apropriado comece, menos sequelas o paciente provavelmente sofrerá.
Embora ainda existam pessoas usando a nomenclatura Acidente Vascular Encefálico (sigla: AVE) no ano de 1996, visando dirimir dúvidas e tentar unificar o termo a ser usado no Brasil, tal assunto foi colocado em discussão durante a Assembleia Geral da Sociedade Brasileira de Doenças Cerebrovasculares (Sigla:SBDCV), ocorrida na cidade de Curitiba, durante o Congresso Brasileiro de Neurologia
Foi aprovado que o termo que deveria ser empregado seria o de "Acidente Vascular Cerebral", quando se dirigir ao público médico e/ou especializado e "derrame" quando for voltado ao público leigo
Tal decisão foi ratificada em 2008, quando este assunto foi novamente discutido, em reunião extraordinária da SBDCV (Quando da elaboração do 2º Consenso do Tratamento da Fase Aguda do AVC) e os termos AVC e derrame foram novamente recomendados.
Em 2010 a Revista Neurociências publicou um artigo intitulado: Acidente Vascular Cerebral ou Acidente Vascular Encefálico? Qual a melhor nomenclatura? Tal artigo explica detalhadamente o porquê dos termos AVC e Derrame serem mantidos.
Um enfarte agudo do miocárdio  ou infarto agudo do miocárdio , vulgarmente denominado ataque cardíaco, ocorre quando a circulação de sangue para uma parte do coração é interrompida, causando lesões no músculo cardíaco
O sintoma mais comum é dor no peito ou desconforto que se pode espalhar para o ombro, costas, pescoço ou maxilar
É comum ter início no lado esquerdo do peito e durar alguns minutos
O desconforto pode por vezes ser semelhante à azia
Entre outros sintomas possíveis estão a falta de ar, náuseas, sensação de desmaio, suores frios ou fadiga
Cerca de 30% das pessoas manifestam sintomas atípicos, os quais são mais comuns entre mulheres
Entre as pessoas com mais de 75 anos de idade, cerca de 5% tiveram um enfarte do miocárdio com poucos ou nenhuns sintomas
Um enfarte do miocárdio pode causar insuficiência cardíaca, arritmia cardíaca ou paragem cardiorrespiratória.
A maior parte dos enfartes do miocárdio é causada por uma doença arterial coronária
Entre os fatores de risco estão, entre outros, a hipertensão arterial, tabagismo, diabetes, falta de exercício, obesidade, colesterol elevado, uma dieta pouco saudável e consumo excessivo de bebidas alcoólicas
O mecanismo de um enfarte do miocárdio muitas vezes envolve o bloqueio completo de uma artéria coronária, causado pela rutura de uma placa aterosclerótica
Ainda que de forma menos comum, pode também ser causado por espasmos da artéria coronária, que podem dever-se ao consumo de cocaína, estresse emocional significativo e frio extremo, entre outros
Alguns exames podem auxiliar o diagnóstico, incluindo eletrocardiogramas, análises ao sangue e angiografias coronárias
Os eletrocardiogramas permitem confirmar a presença de elevação do segmento ST, caso esteja presente
As análises ao sangue geralmente incluem a medição da troponina e, de forma menos comum, exame de CPK.
A aspirina é um tratamento imediato apropriado quando se suspeita de enfarte do miocárdio
As dores no peito podem ser aliviadas com nitroglicerina ou opiáceos, embora não melhorem o prognóstico
Em pessoas com baixos níveis de oxigénio pode ser administrado oxigénio suplementar
Nos enfartes do miocárdio com elevação do segmento ST são geralmente recomendados tratamentos para restaurar a corrente sanguínea para o coração
Estes tratamentos incluem angioplastia coronária, em que o bloqueio é removido com a introdução de um pequeno catéter na artéria, ou trombólise, em que o bloqueio é removido com recurso a medicamentos
As pessoas que apresentam um enfarte do miocárdio sem elevação do segmento ST são muitas vezes tratadas com o anticoagulante heparina, complementada por angioplastia em pessoas de risco elevado
Em pessoas com bloqueios em múltiplas artérias coronárias e diabetes, pode ser recomendada a realização de um cirurgia de bypass em vez de uma angioplastia
Na sequência de um enfarte do miocárdio são geralmente recomendadas alterações do estilo de vida e tratamento a longo prazo com aspirina, betabloqueadores e estatina.
Em 2013 ocorreram em todo o mundo 8,6 milhões de enfartes do miocárdio
Em mais de 3 milhões de casos verificou-se elevação do segmento ST
Os enfartes com elevação ST são duas vezes mais comuns em homens do que em mulheres
Nos países desenvolvidos o risco de morte em casos com elevação ST é de cerca de 10%
Entre 1990 e 2010 a prevalência da doença, quando corrigida pela idade, diminuiu em todo o mundo.
O sintoma mais importante e típico do IAM é a dor ou desconforto intenso retroesternal (atrás do osso esterno) que é muitas vezes referida como aperto, opressão, peso ou queimação, podendo irradiar-se para pescoço, mandíbula, membros superiores e dorso.
Frequentemente esses sintomas são acompanhados por náuseas, vômitos, sudorese, palidez e sensação de morte iminente
A duração é caracteristicamente superior a 20 minutos
Dor com as caraterísticas típicas, mas com duração inferior a 20 minutos sugere angina do peito, onde ainda não ocorreu a morte do músculo cardíaco.
Pacientes diabéticos, idosos e as mulheres têm maior probabilidade de apresentarem uma dor ou desconforto atípico, ou seja, com características e intensidade diferentes da descrição acima.
É possível a ocorrência de IAM sem dor
Este é o chamado infarto silencioso
Um infarto silencioso só será identificado na fase aguda se, por coincidência, um eletrocardiograma ou uma dosagem de enzimas cardíacas for feita enquanto ele ocorre.
Os achados dependerão da extensão do infarto
Na maioria das vezes os pacientes apresentam-se desconfortáveis, ansiosos, com sinais de liberação adrenérgica
Naqueles em que a área necrosada supera os 40% da massa ventricular esquerda têm alto risco de evoluírem com Insuficiência cardíaca, edema agudo de pulmão e choque cardiogênico.
O suprimento de sangue para o coração é feito através das artérias coronárias, que surgem diretamente da artéria aorta na valva aórtica, preferencialmente chamada de valva semilunar aórtica ou valva semilunar esquerda
São duas as principais artérias coronárias: a artéria coronária direita e a artéria coronária esquerda que logo se bifurca em duas grandes artérias, a artéria descendente anterior e artéria circunflexa.
A interrupção do suprimento ou fluxo sanguíneo para o músculo cardíaco é causada pela obstrução de uma artéria coronária ou de um de seus ramos.
A obstrução é causada mais frequentemente pela formação de um coágulo (ou trombo) sanguíneo sobre uma placa aterosclerótica no interior de uma das artérias coronárias.
Este trombo costuma ocorrer sobre uma placa aterosclerótica que sofreu alguma alteração, como a formação de uma úlcera ou a ruptura parcial da placa
Esta placa, antes da alteração que a instabilizou, pode ser suficientemente pequena para passar despercebida pelos métodos habituais de diagnóstico
Ou seja, um paciente com "exames normais" pode vir a ter um infarto do miocárdio por um processo muito breve, às vezes de poucos minutos.
Uma placa é considerada vulnerável (ou imatura) quando apresenta risco de ruptura
Quando a placa apresenta uma cápsula espessa (placa madura) torna-se menos propensa a ruptura
Não existe um método aceito para determinar qual placa é vulnerável e qual não, mas, após necrópsias, se verificou que as placas com propensão a romper costumam ter mais conteúdo de lipídeos e menos fibrose.
Quando ocorre a ruptura da placa, existe exposição de colágeno e fragmentos de tecido conjuntivo da região subendotelial
As plaquetas, células do sangue, se aderem e se agregam ao local da ruptura
As plaquetas liberam substâncias que desencadeiam o processo de coagulação, resultando na formação do trombo.
A falta de circulação impede a chegada de nutrientes e de oxigênio (isquemia) ao território arterial a jusante
A isquemia determina redução imediata e progressiva da contratilidade do miocárdio
A dinâmica da movimentação normal de íons, em especial potássio, cálcio e sódio, começa a se alterar
Isto gera uma instabilidade elétrica.
Como o ritmo cardíaco depende deste fluxo de íons e elétrons, podem ocorrer arritmias já precocemente no infarto
A morte nesta fase do infarto não costuma ser por que não existe força nos músculos, mas por que os músculos perdem a capacidade de trabalhar coordenados, tornando-se ineficientes
São músicos sem maestro.
A partir de 20 minutos de oclusão, parcelas progressivamente maiores do miocárdio entram irreversivelmente em necrose
Essa inicia-se na região subendocárdica, metabolicamente mais ativa, estendendo-se para a epicárdica sob a forma de uma "onda de necrose", completando-se em cerca de 6 horas.
Na ausência de adequada circulação colateral, 50% da massa miocárdica em risco sofre necrose na primeira hora e 70% em 3 a 4h.
O grau de disfunção ventricular esquerda é um dos fatores de risco mais importantes na sobrevida pós IAM
Cerca de 30% a 50% dos pacientes apresentam sinais de dilatação ventricular, dependendo do local e extensão do infarto, da perviabilidade ou não da artéria ocluída, da intensidade da circulação colateral e dos fatores que aumentam a tensão ventricular.
A remodelação começa dentro de horas e continua por vários meses, mesmo após a cicatrização histológica da área infartada, a qual dura de seis semanas a seis meses
No processo de remodelação observa-se a expansão da área infartada, fenômeno precursor de aneurisma ventricular
Essa remodelação dependerá do tamanho e da transmuralidade do infarto, do processo de cicatrização adequado, da intensidade das forças mecânicas que atuam sobre a parede ventricular.
Os fatores de risco para infarto agudo do miocárdio estão associados a arterioesclerose ou doença arterial coronariana
Os fatores de risco podem ser dividos em dois grupos:
A Organização Mundial de Saúde determina que para o diagnóstico de IAM é necessária a presença de critérios diagnósticos em três áreas:
Os sinais do IAM são:
Classificação baseada em dados clínicos que permite estudar a gravidade da insuficiência ventricular nos pacientes com IAM é bastante usada na avaliação da mortalidade em geral.
Achados eletrocardiográficos são fundamentais no diagnóstico de IAM.
A depender da região topográfica acometida, as alterações eletrocardiográficas aparecerão em derivações distintas:
Os marcadores de necrose miocárdica têm dupla função na avaliação do IAM, têm efeito diagnóstico e também na avaliação prognóstica
Em decorrência da isquemia prolongada a membrana celular perde sua integridade permitindo a saída para o meio extracelular de macromoléculas, possibilitando a dosagem sérica das mesmas
Dentre as mais importantes podemos citar:
Na prática clínica são utilizados as troponinas e a CK-MB nas 12 primeiras horas para diagnóstico e avaliação de pacientes com suspeita de síndromes coronariana agudas e o acompanhamento da curva de CK-MB nos paciente com diagnóstico de infarto.
A ecocardiografia frequentemente evidencia um compromisso miocárdico segmentar, ou seja um segmento do coração não se contrai devidamente
O ecocardiograma com Doppler é um exame de rotina de grande utilidade em centros que dispõem desta facilidade
Porém o método apesar de útil não se presta ao diagnóstico diferencial da dor torácica, só afastando a possibilidade de outras patologias concomitantes como estenose aórtica, hipertensão pulmonar aguda, pericardites com derrame, entre outras
O Ecocardiograma é relevante nos casos de IAM complicados com insuficiência cardíaca, por permitir identificar e avaliar quantitativamente esta insuficiência porém deverá ser efetuado com excelente material e a fiabilidade depende, como em todos os exames de ecografia, da experiência do examinador
Atualmente, como a revascularização do miocárdio é uma urgência, quando a enzimologia é sugestiva de enfarte do miocárdio passa-se directamente à coronariografia que permite a realização da angioplastia coronária e a recuperação da zona muscular isquémica
O ecocardiograma é assim, atualmente, um exame de "segundo plano" nesta patologia.
A angiografia é um exame bastante útil para visualização direta de vasos acometidos
Permite visualizar a artéria (ou as artérias) ocluída e o grau de oclusão
Este grau de oclusão é expresso por porcentagem de estenose, que é feito pela comparação do segmento mais estreitado com o segmento distal ou proximal de espessura normal.
Um estreitamento maior que 70% do diâmetro é considerado significante
Estreitamentos menores do que este grau não costumam provocar alterações importantes no fluxo coronário, não sendo prováveis causas do infarto
O procedimento costuma ser seguro, mas está sujeito a sérias complicações
É exame imprescindível quando se tentará restituir o fluxo de sangue a área de infarto, seja por Angioplastia, seja por Cirurgia
Não é feito apenas quando o risco de sua realização é maior que o possível benefício que traria.
A prevenção do infarto do coração passa pela promoção da saúde e pela prevenção de doenças relacionadas como a apneia do sono, a arterioesclerose, o diabetes, a dislipidemia, aterosclerose e a hipertensão arterial.
Devem-se levar em conta as características da dor, os antecedentes de doença cardiovascular, idade e fatores de risco na determinação da conduta inicial do paciente ao serviço médico
Com base nessa clínica, no ECG e nos marcadores séricos de necrose, obtém-se a estratificação inicial do risco para óbito ou IAM
Medidas básicas iniciais devem incluir: obtenção dos sinais vitais, oxigenação por cateter ou máscara, obtenção de acesso venoso, monitorização do risco cardíaco e saturação de O2, administração de 200 mg de aspirina por via oral, nitrato sublingual 5 mg, obtenção de ECG, administração endovenosa de morfina em situações de dor intensa sem melhora com nitrato
Pacientes candidatos a terapêutico para recanalização coronariana, farmacológica ou mecânica são aqueles em que o ECG mostra-se supradesnivelamento do segmento ST que não reverte após a administração de nitrato ou com bloqueio completo de ramo esquerdo novo
Paciente de alto risco para IAM, que devem ser encaminhado para Centros de Terapia Intensiva, são aqueles cujo ECG se mostra com um infradesnivelamento do segmento ST além de 1 mm ou ondas T invertidas com alta voltagem em múltiplas derivações
Alternativa para esses paciente é o uso de drogas endovenosas para estabilização de quadro clínico e o estudo cinecoronariográfico precoce em até 24 horas (imediatamente em casos refratário a medicação inicial)
O tratamento farmacológico se faz com várias drogas atuantes em diferentes mecanismos da doença
Dentre os antiplaquetários podemos destacar a Aspirina (ação por inibição da ciclo-oxigenase no metabolismo do ácido aracdônico), os derivados tienopiridínico (antagonistas da ativação plaquetária mediada pelo ADP, clopidrogel, ticlopidina) e os antagonista dos receptores glicoproteicos IIb-IIIa (abciximab)
Dezenas de estudos já comprovaram os efeitos benéficos da aspirina como conduta inicial, correlacionada com o menor grau de mortalidade, associada ou não a estreptoquinase.
Outra classe de medicamento útil no IAM são os antitrombínicos que têm ação sinérgica com os antiplaquetários
Podemos destacar as heparinas que atuam acelerando a ação da antitrombina circulantes, precipitando a inibição da trombina IIa e dos fatores IX e Xá
Medicamentos anti-isquêmicos têm função importantíssima no controle da sintomatologia do paciente
Os Nitratos têm seus efeitos benéficos através da redução da pré-carga e pós-carga, diminuindo o consumo de oxigênio, atuam também por diminuição do vasoespasmo coronariano e tem potencial inibição da agregação plaquetária
Os Betabloqueadores diminuem o consumo de oxigênio pelo miocárdio, controlando a frequência cardíaca e a pressão arterial, reduzindo a contratilidade
Podemos destacar metoprolol, propranolol
As contra indicações do seu uso é o broncoespasmo, hipotensão, bradiarritmias e insuficiência ventricular esquerda
Também são medicamentos bastante estudados em pesquisas multicêntrincas, que determinaram uma diminuição significativa em casos de infarto e óbito.
Antagonistas dos canais de cálcio atuam bloqueando a entrada de cálcio nas fibras miocárdicas, reduzindo a contratilidade e, consequentemente o consumo de oxigênio, atuam também nas paredes de vasos promovendo a vasodilatação e melhorando o fluxo coronariano para áreas isquêmicas
Inibidores da Enzima convertora da Angiotensina (iECA) têm se mostrado benéfico na prevenção de óbito, infarto e AVC em pacientes com doenças ateroscleróticas prévias com comprometimento coronariano
Também se beneficiam os portadores de cardiopatia isquêmica na medida em que controlam a hipertensão arterial, e são essenciais no tratamento da insuficiência cardíaca.4 Três estudos multicêntricos conseguiram demonstrar os benefícios dos iECA na prevenção da mortalidade a curto prazo.
É importante salientar que o tratamento do paciente com IAM já instalado baseia-se na reperfusão cardíaca precoce e restabelecimento da vitalidade das artérias coronarianas
Nesta etapa o tratamento é múltiplo e com abordagem farmacológica e cirúrgica.
Os trombolíticos devem ser usados precocemente, até 6 a 12 horas do início da sintomatologia, com cuidado para as contra-indicações absolutas: AVC hemorrágico prévio, neoplasia intracraniana conhecida, sangramento interno e suspeita de dissecção de aorta
Cuidado também para com os pacientes de idade acima de 75 anos pelo aumento de risco de AVC
Atualmente na prática clínica existem duas drogas trombolíticas para uso de rotina, a estreptoquinase e ativador tecidual de plasminogênio (t-PA).
Uma vantagem da estreptoquinase é seu baixo custo
Deve-se evitar nova administração desse trombolítico por pelo menos 2 anos devido a chance de alergia, não se associa a heparina de rotina devido ao risco aumentado de sangramentos.
Os t-PA devem ser usados em infusão acelerada e combinada com heparinização plena, é o trombolítico mais eficaz para recanalização coronária precoce, obtém-se maior patência do vaso em curto período de tempo
Seus custos ultrapassam bastante aos da estreptoquinase e com riscos ligeiramente maiores para hemorragia intracraniana.
Outra abordagem no paciente com IAM é a angioplastia primária, realizada entre 6 a 12 horas de início dos sintomas
Essa terapêutica é uma alternativa ao tratamento com trombolíticos para reperfusão imediata do miocárdio isquêmico
A taxa de abertura da artéria ocluída é significantemente maior com a angioplastia primária do que com trombolítico
No entanto, a tradução dessa vantagem em benefício clínico não tem mesma magnitude
Importantes estudos revelam que pacientes tratados com angioplastia primária têm menos incidência de morte, reinfarto e doença cerebrovascular agudas aos 30 dias do infarto, mas que em 6 meses a 1 ano essa vantagem desaparece.
Contudo, mesmo no pior quadro, a angioplastia primária é no mínimo equivalente à terapia trombolítica e pode ser indicada formalmente se o paciente tem contra-indicação a esta última.
A vantagem da angioplastia em relação a terapia trombolítica são:
A angioplastia de salvamento é recomendada nos casos de insucesso do tratamento trombolítico, caracterizado principalmente como persistência do supradesnivelamento de ST e/ou da dor precordial
O advento dos stents e o uso de potentes antiplaquetários têm contribuído para um sucesso ainda maior da angioplastia
Estudos comparativos demonstraram as vantagens do tratamento angioplástico em relação ao trombolíticos, em se tratando de morte por reinfarto, proporcionando melhor conforto e estabilidade ao paciente.
Tratamento que visam recuperar a circulação (reperfusão) até 6 horas após a oclusão permitem o salvamento das células sob risco que ainda não necrosaram
Como o processo é contínuo, quanto mais precoce a intervenção, mais músculo é salvo no final do processo.
Por outro lado, a reperfusão acelera a necrose daquelas células que apresentam lesões irreversíveis, porém não parece acrescentar riscos adicionais àquelas com lesões reversíveis.
A reperfusão instabiliza ainda mais o coração, mas suas complicações são tratáveis em Unidades de Terapia Intensiva especiais, as (Unidades coronarianas).
São riscos da reperfusão:
O prognóstico, ou seja, a previsão de evolução, será tanto mais favorável quanto menor a área de infarto e mais precoce o seu tratamento...
O infarto é um processo de necrose, morte celular
Imediatamente após sua ocorrência se inicia o processo de cicatrização local e readaptação do miocárdio restante as necessidades do corpo
Se não surgirem complicações, após alguns meses o processo cicatricial estará completo.
São complicações possíveis:
O enfarte agudo do miocárdio é a principal causa de morte nos países industrializados
Das mortes resultantes de enfarte, a maior parte é rápida, na primeira hora, em geral por uma arritmia severa denominada Fibrilação ventricular
Nos Estados Unidos, cerca de 25% das mortes são devidas a este problema, o que dá um número absoluto em torno de um milhão e quinhentas mil pessoas a cada ano
Um em cada 25 pacientes com alta hospitalar morre no primeiro ano pós enfarte
A mortalidade pós enfarte é diferente conforme a faixa etária, sendo maior nas faixas etárias mais avançadas.
Cerca de 60% dos óbitos acontecem na primeira hora após início dos sintomas
Miocardite (Doença de Chagas)
Cardiomiopatia: Dilatada (Alcoólica) · Hipertrófica · Restritiva (Endocardite de Loeffler, Amiloidose cardíaca, Fibroelastose endocardíaca)
Fibrose cardíaca · Cardiomegalia · Hipertrofia ventricular (Esquerdo, Direito/Corpulmonale)
Hipertensão arterial é uma doença crónica em que a pressão sanguínea nas artérias se encontra constantemente elevada
A doença geralmente não causa sintomas
No entanto, a longo prazo é um dos principais fatores de risco para uma série de doenças graves como a doença arterial coronária, acidente vascular cerebral, insuficiência cardíaca, doença arterial periférica, incapacidade visual, doença renal crónica e demência.
A hipertensão arterial pode ser classificada como primária ou secundária
Cerca de 90–95% dos casos são primários, tendo origem em fatores não específicos genéticos e de estilo de vida
Entre os fatores relacionados com o estilo de vida que aumentam o risco de hipertensão estão o excesso de sal na dieta, excesso de peso, tabagismo e consumo de álcool
Os restantes 5–10% dos casos são secundários, uma vez que têm origem em causas identificáveis, como doença renal crónica, estenose da artéria renal, doenças endócrinas ou uso de pílula contracetiva.
A pressão arterial é expressa em duas medidas: a pressão sistólica e pressão diastólica
A pressão sistólica é a pressão máxima, enquanto a diastólica é a pressão mínima
Na maior parte dos adultos, a pressão arterial normal em repouso sistólica é de 100 a 130 milímetros de mercúrio (mmHg) e a diastólica de 60 a 80 mmHg
Para a maior parte dos adultos, considera-se que a pessoa tem hipertensão arterial quando a pressão arterial em repouso é consistentemente igual ou superior a 130/90 ou 140/90 mmHg
Em crianças, os valores de referência são diferentes
A monitorização em ambulatório ao longo de 24 horas oferece uma medição mais rigorosa do que os medidores portáteis.
As alterações no estilo de vida e a medicação permitem diminuir a pressão arterial e o risco de complicações
Entre as alterações no estilo de vida estão perder peso, diminuir o consumo de sal, praticar exercício físico e manter uma dieta saudável
Quando as alterações no estilo de vida não são suficientes podem ser administrados medicamentos anti-hipertensivos
Existem três medicamentos que permitem controlar a pressão arterial em 90% das pessoas
O tratamento de pressão arterial de grau II (≥160/100 mmHg) com medicação está associado a um aumento da esperança de vida
O tratamento da pressão arterial entre 130/80 e 160/100 mmHg é menos claro, dado que algumas revisões da literatura observam benefícios enquanto outras não observam benefícios claros
A hipertensão arterial efata entre 16 e 37% de toda a população mundial
Estima-se que em 2010 a hipertensão tenha sido um fator em 18% de todas as mortes (9,4 milhões em todo o mundo).


A hipertensão foi definida como a pressão sanguínea de valor igual ou superior a 140/90 mmHg para um adulto jovem
Esta definição surgiu após 12 anos de experiência em 350 000 indivíduos de idades compreendidas entre os 18 e os 74 anos corroborados posteriormente pelo estudo JNC7
Levantou-se uma polémica acerca deste valor em virtude de a maioria dos médicos, cardiologistas ou não, considerar normal o valor de 140 mmHg
Após um longo consenso, a OMS (Organização Mundial de Saúde) juntamente com a Sociedade International de Hipertensão (ISH), tendo em conta a relação benefício/riscos do tratamento, fixou os limites em 140/90 mmHg sendo considerados normotensos  todos os indivíduos adultos com uma pressão arterial de 140/90 mmHg.
No adulto com mais de 74 anos, (faixa etária não englobada no estudo JNC7) pode-se aceitar um limite de 150/90 mmHg, tendo em conta a rigidez fisiológica da parede arterial
A pseudo-hipertensão entre os idosos é também um factor a considerar
Esta situação deve-se à calcificação das artérias, o que resulta em níveis de leitura anormalmente elevados no esfigmomanómetro enquanto que as medições intra-arteriais são normais
O processo de endurecimento das paredes arteriais com o envelhecimento é progressivo e o aumento de pressão arterial sistólica com a idade também será progressivo sem que isto signifique hipertensão arterial.
A classificação varia consoante estamos perante:
Existem várias classificações da hipertensão arterial, introduzindo cada uma delas, pequenas diferenças nos critérios de inclusão de um determinado valor no grupo hipertensivo.
Assim, segundo a classificação JNC7, em indivíduos de idade igual ou superior a 18 anos, a hipertensão define-se pela medição regular de valores de pressão sistólica e/ou diastólica mais altos do que os valores de referência (actualmente 139 mmHg para a sistólica e 89 mmHg para a diastólica: ver tabela)
No caso de monitorização constante, como a que possa ser feita em casa ou em ambulatório durante o prazo mínimo de 24 horas, são usados valores de referência mais baixos (135 mmHg para a sistólica ou 85 mmHg para a diastólica)
Ainda segundo o relatório JNC7, foram criadas categorias inferiores à hipertensão propriamente dita, chamadas de pré-hipertensão, de forma a melhorar a percepção da existência de um risco contínuo ao longo de qualquer valor acima do valor de 120 mmHg
A classificação JNC7, de 2003, uma revisão de JNC6 assim como de inúmeras publicações, recorre ao termo pré-hipertensão para valores de pressão sanguínea entre 120 e 139 mmHg para a sistólica e entre 80 e 89 para a diastólica
Se bem que os limites da pressão diastólica sejam incontestáveis, já os da pressão sistólica têm sido contestados e o interesse deste conceito de pré-hipertensão não tem sido provado, salvo em grupos com múltiplos factores de risco.
Estes trabalhos, com critérios muitos rígidos e englobando muitos indivíduos que na realidade se verificou serem normotensos, estiveram na base da tomada de posição da OMS para o estabelecimento dos valores acima dos quais se considera hipertensão num consenso de avaliação da relação benefício/risco
Por sua vez, as orientações da ESH-ESC de 2007 e da BHS IV de 2004, subdividem os valores de pressão inferiores a 140/90 nas categorias óptimo, normal e normal alta.
A própria hipertensão pode também ser dividida em várias classificações: a JNC7 distingue a hipertensão de estágio I, II e a hipertensão sistólica isolada
Esta refere-se à pressão sistólica elevada, mas com pressão diastólica normal, sendo comum entre os idosos
As orientações ESH-ESC de 2007 e a BHS IV de 2004 referem ainda um terceiro estágio (hipertensão de estágio III) para indivíduos com pressão sistólica acima dos 179 mmHg ou pressão diastólica acima dos 109 mmHg.
Para concluir, o próprio relatório JNC7 reconhece que a opinião do médico responsável pelo paciente é que é preponderante na determinação do valor normal de pressão arterial para esse doente
Existe unanimidade no que respeita os valores da pressão diastólica que deverão ser inferiores ou iguais a 90 mmHg em qualquer grupo etário (no idoso, por exemplo, se uma pressão sistólica de 149 mmHg pode ser considerada normal, já a diastólica terá que corresponder a um valor igual ou inferior a 90 mmHg).
A ocorrência de hipertensão em crianças e adolescentes ocorre entre 2 e 9% dos indivíduos, dependendo da idade, sexo e etnia, e obesidade
Está também associada ao risco de vir a padecer de complicações clínicas a longo prazo
Hoje em dia, recomenda-se que sejam feitas medições de rotina em crianças com idade superior a 3 anos, sempre que consultem um médico ou façam exames, mas os valores devem ser confirmados ao longo de várias consultas antes de se poder diagnosticar a presença de hipertensão numa criança
Durante a infância, a pressão sanguínea aumenta em proporção com a idade e, nas crianças, define-se como hipertensão a pressão sanguínea média sistólica ou diastólica que seja em três ou mais medições igual ou superior ao percentil 95 de acordo com o sexo, idade e altura da criança
Define-se como pré-hipertensão a pressão sanguínea média sistólica ou diastólica igual ou maior do que o percentil 90, mas menor que o percentil 95
Nos adolescentes, tem sido proposto que o diagnóstico de pré e hipertensão seja realizado com critérios iguais ao dos adultos.
A ocorrência de hipertensão em recém-nascidos é rara, ocorrendo apenas entre 0,2 a 3% dos indivíduos, e a medição da pressão arterial não faz parte dos exames de rotina
A hipertensão é mais comum em recém-nascidos de alto risco
Na determinação da pressão normal em recém-nascidos, devem ser levados em conta outros factores como a idade gestacional e o peso à nascença
Segundo a sua fisiopatologia, a hipertensão é classificada em dois tipos
O primeiro, a hipertensão arterial primária (essencial ou idiopática) que significa que a elevada pressão sanguínea não tem causa médica identificável, correspondendo a 90 a 95% dos casos
Neste tipo de hipertensão, existe uma tendência familiar acentuada mas, como em muitas outras doenças, ainda não se pode falar de hereditariedade
Os restantes cinco a dez por cento correspondem ao segundo tipo, a hipertensão arterial secundária, que é provocada por outros transtornos que afetam os rins, as artérias, o sistema endócrino ou ainda por iatrogenia.
A hipertensão raramente é acompanhada de outros sinais ou sintomas, e o seu diagnóstico usualmente acontece depois de um rastreio ou durante uma consulta médica por outros problemas
Uma parte significativa de hipertensos revela sofrer de dores de cabeça sobretudo na occipital (parte posterior da cabeça) e durante a manhã, assim como vertigens, zumbidos, distúrbios na visão ou mesmo episódios de desmaio.
Durante um exame físico, pode-se suspeitar de hipertensão caso se verifique retinopatia hipertensiva durante a observação do fundo do globo ocular através da oftalmoscopia
Normalmente, o grau de severidade da retinopatia hipertensiva é classificado numa escala de I a IV, embora possa ser difícil distinguir os graus intermédios entre si
O exame oftalmoscópico pode também indicar se um paciente sofre de hipertensão recente ou de longa data.
Outros sinais e sintomas podem sugerir a presença de hipertensão secundária, isto é, a hipertensão cuja causa possa ser identificada, como no caso de doenças renais ou endócrinas
Por exemplo, a obesidade de tipo andróide, a pouca tolerância à glicose e estrias azuladas sugerem a presença de uma síndrome de Cushing
As doenças da tiróide e a acromegalia podem também causar hipertensão e têm sintomas característicos
O sopro abdominal pode ser indicador de estenose da artéria renal, um estreitamento das artérias que irrigam os rins, enquanto a baixa pressão arterial nas extremidades inferiores e/ou pulsações ausentes ou fracas na artéria femoral podem indicar coarctação da aorta (estreitamento da aorta descendente)
Hipertensão instável ou paroxística acompanhada por dores de cabeça, palpitações, palidez e transpiração levantam suspeitas da presença de feocromocitoma.
A pressão arterial muito elevada (diastólica superior a 120 mmHg), de aparecimento súbito, é designada por "crise hipertensiva"
A pressão sanguínea acima destes níveis acarreta um risco elevado de complicações.
Urgência hipertensiva é a crise hipertensiva em que não se verifica lesão de órgãos alvo
A maior parte dos indivíduos com crise hipertensiva tem já antecedentes de pressão arterial elevada; no entanto, o aumento súbito pode dever-se a outros factores
Na maior parte dos casos verifica-se que houve controlo incorrecto da doença ou a interrupção na tomada da medicação
Contudo, estas crises aparecem só em 1% dos hipertensos
As causas mais frequentes são: a interrupção da tomada dos medicamentos, doenças vasculares, uso de algumas drogas como, por exemplo, cocaína e anfetaminas, traumatismo craniano, alguns tipos de tumores, glomerulonefrite aguda, eclampsia ou pre-eclampsia
Estes pacientes raramente são assintomáticos, sendo mais susceptíveis de relatar dores de cabeça (22% dos casos), um estado geral de confusão cognitiva, tonturas, distúrbios visuais tais como visão nublada, flashes de luz, diplopia, sensação de falta de ar devido a pré-edema pulmonar.
Emergência hipertensiva é o termo que se aplica à crise hipertensiva quando o aumento brusco da pressão arterial se acompanha de lesão dos órgãos alvo
Anteriormente designada por "hipertensão maligna", é uma crise hipertensiva mais grave, com compromisso de outros órgãos e pode ser diagnosticada mediante a observação de danos diretos nesses órgãos alvo
Raramente se verifica a lesão de órgãos em valores de pressão diastólica inferiores a 130 mmHg
Entre eles, é de referir a
Nestas situações, é imperativa a redução urgente da pressão arterial de modo a parar o processo de degradação dos órgãos alvo
Se as urgências hipertensivas podem ser tratadas com medicação oral, já as emergências hipertensivas necessitam de um tratamento rápido e eficaz usualmente por via endovenosa pois o paciente está sob um elevado risco de hemorragia cerebral e edema pulmonar mortal
No entanto esta redução deverá ser feita por "patamares" e nunca de uma maneira brusca e abusiva que pode pôr o paciente em estado de choque por hipotensão; esta é uma das razões da introdução de medicamentos por via endovenosa pois permite regular a velocidade de administração e subsequentemente e descida progressiva da pressão arterial.
A hipertensão manifesta-se em cerca de 8 a 10% dos casos de gravidez
Na maior parte casos de hipertensão durante a gravidez já existia uma hipertensão arterial primária prévia
A pressão arterial elevada durante a gravidez pode ser o primeiro sintoma de pré-eclampsia, um estado grave que pode ocorrer durante a segunda metade da gravidez e durante o período puerpério (período pós-parto que dura cerca de seis semanas, até o útero recuperar as suas dimensões normais)
A pré-eclampsia, primeira fase da toxémia gravídica conhecida de longa data, e de etiologia ainda desconhecida, caracteriza-se pela subida da pressão arterial, pela presença de proteínas na urina e edema
Ocorre em cerca de 5% das gravidezes e é responsável por cerca de 16% da mortalidade materna a nível mundial
Esta patologia duplica também o risco de mortalidade perinatal
Geralmente a doença, no início, não tem sintomas específicos e é detectada através de exames de rotina
Quando os sintomas se manifestam, verificam-se normalmente cefaleias (dores de cabeça), distúrbios da visão (frequentemente flashes de luz), vómitos, dores epigástrias e edemas
No que se refere ao edema é frequente o seu aparecimento na face e mãos, localização que é mais habitual nas doenças renais (sinal semiológico que faz o médico suspeitar de uma causa renal, em presença desta localização do edema)
Pode por vezes evoluir para a segunda fase da toxémia gravídica, um estado grave, com risco de vida, designado eclampsia, que constitui uma emergência hipertensiva e envolve várias complicações graves como perda de visão, edema cerebral, convulsões, insuficiência renal, edema pulmonar e coagulação intravascular disseminada (CIVD)
Esta última situação, também chamada de coagulopatia de consumo, caracteriza-se pela presença de tromboses principalmente dos pequenos vasos, hemorragias, petéquias (pequenas hemorragias cutâneas), e evolução rápida para o coma por falência de múltiplos órgãos como os rins, fígado e cérebro
A paciente nesta situação só se salva se for tratada muito precocemente antes de estabelecido o círculo vicioso trombose-hemólise-trombose
A descrição desta situação clínica, feita por Pritchard em 1954 difere um pouco da CIVD clássica e assemelha-se mais à anemia hemolítica microangiopática
Em 1982 Louis Weinstein denominou de síndrome HELLP, acrónimo que reúne as primeiras letras de cada um dos principais sinais laboratoriais em inglês, (Hemolysis, Elevated Liver enzymes, Low Platelet count) a tríade que descreve rapidamente a síndrome laboratorial que acompanha a eclâmpsia no auge da sua gravidade.
Em recém-nascidos e bebés, sintomas como a dificuldade de crescimento, convulsões, irritabilidade, fadiga e síndrome da angústia respiratória do recém-nascido podem estar associados à hipertensão
Mais tarde, em crianças, a hipertensão pode levar a dores de cabeça frequentes, irritabilidade sem causa aparente, fadiga, dificuldade de crescimento, visão turva, hemorragia nasal ou paralisia facial.
A hipertensão arterial primária, essencial, ou idiopática, é a forma mais comum de hipertensão, contabilizando 90 a 95% de todos os casos da doença
Em praticamente todas as sociedades contemporâneas a pressão arterial aumenta a par do envelhecimento, o que é fisiológico e relacionado com o aumento de rigidez da parede arterial.
A hipertensão essencial é consequência de uma interação complexa entre genes e fatores ambientais nomeadamente o consumo de sal
Entre os maus hábitos que contribuem para o aumento da pressão arterial estão o consumo de muito sal na dieta
Ainda não é conclusiva a possível influência de outros factores como o stress, o consumo de cafeína ou a insuficiência de vitamina D.
Pensa-se que a resistência à insulina, comum em casos de obesidade e um dos componentes da síndrome metabólica, contribua também para a hipertensão
Investigações recentes têm vindo a responsabilizar alguns acontecimentos ocorridos durante o início da vida, como o baixo peso à nascença, o tabagismo durante a gravidez e a ausência de amamentação considerando-os factores de risco para a hipertensão primária na idade adulta, embora os mecanismos exactos dessa relação continuem por esclarecer.
A hipertensão arterial secundária é consequência de uma causa identificável
As doenças renais são a causa mais comum de hipertensão secundária, ocupando lugar de destaque a estenose da artéria renal, a par de transtornos endócrinos como a síndrome de Cushing, o hipertiroidismo, o hipotiroidismo, a acromegalia, o hiperaldosteronismo primário ou síndrome de Conn, o hiperparatiroidismo e tumores como os para-gangliomas e os feocromocitomas
Na coartação da aorta a hipertensão arterial existe unicamente acima do nível da coartação, havendo hipotensão nos membros inferiores
Entre as outras possíveis causas encontra-se a obesidade, a apneia do sono, a gravidez, o consumo excessivo de alcaçuz e o uso de determinados medicamentos tais como:
A hipertensão hipercaliémica familiar, conhecida por síndrome de Gordon ou pseudo-hipoaldosteronismo do tipo II, é uma forma muito rara de hipertensão arterial, austosómica dominante, caracterizada por hipercaliémia, acidose metabólica com hiperclorémia e função renal normal, tendo servido de base aos os primeiros estudos genéticos da hipertensão arterial.
Na maior parte dos indivíduos com hipertensão primária, o aumento da resistência periférica total é o primum movens do aumento da pressão sanguínea mantendo-se o débito cardíaco normal.
Alguns jovens com pré-hipertensão têm débito cardíaco elevado, frequência cardíaca elevada e resistências periféricas normais, o que é denominado por "hipertensão periférica hipercinética"
Esta situação enquadra-se dentro da "síndrome hipercinético" cardiovascular e normalmente está relacionado com a ansiedade, sobretudo no adolescente
É ainda motivo de controvérsia se este padrão é comum ou não a todas as pessoas que vêm eventualmente a desenvolver hipertensão
O aumento da resistência periférica total em casos onde a hipertensão está já implementada é geralmente atribuído à vasoconstrição das pequenas e médias artérias e arteríolas.
A pressão de pulso (a diferença entre pressão sanguínea sistólica e diastólica) aumenta frequentemente em pessoas idosas com hipertensão
Isto significa que a pressão sistólica está elevada, enquanto a pressão diastólica se mantém normal ou baixa e é habitualmente designada por hipertensão sistólica
A pressão de pulso elevada nos idosos com hipertensão ou hipertensão sistólica isolada pode ser explicada pelo enrijecimento das artérias, que normalmente acompanha o processo de envelhecimento, mas deve ser sublinhado que um paciente com insuficiência aórtica tem uma diminuição da pressão diastólica o que leva a um aumento da pressão do pulso sem hipertensão.
De modo simplificado, a dinâmica do sangue dentro de um vaso segue exactamente os mesmos princípios da dinâmica dos fluidos
Assim o fluxo de sangue numa artéria reger-se-ia pela equação 



Q
=



(

P

1


−

P

2


)

R




{\displaystyle Q={\frac {(P_{1}-P_{2})}{R}}}

 sendo 




Q



{\displaystyle {Q}}

 o débito, 




R



{\displaystyle {R}}

 a resistência ao fluxo, 





P


1




{\displaystyle {P}_{1}}

 e 





P


2




{\displaystyle {P}_{2}}

 as pressões na origem e na extremidade da artéria, respectivamente.
Chamemos de 




△


P



{\displaystyle {\triangle }{P}}

 o valor 





P


1


−


P


2




{\displaystyle {P}_{1}-{P}_{2}}


O mesmo é dizer que 




△



{\displaystyle {\triangle }}






P



{\displaystyle {P}}

 = 




Q



{\displaystyle {Q}}

 



×


{\displaystyle \times }

 




R



{\displaystyle {R}}

 ou seja, o gradiente de pressão é directamente proporcional à resistência que, no caso da circulação sistémica, seria a resistência periférica total
Se forem introduzidas as variáveis viscosidade do sangue (




η



{\displaystyle {\eta }}

), raio (




r



{\displaystyle {r}}

) e comprimento do vaso (




l



{\displaystyle {l}}

), encontramos a lei de Poiseuille 



Q
=



P
π

r

4




8
l
η





{\displaystyle Q={\frac {P\pi r^{4}}{8l\eta }}}

 ou 



Δ
P
=



8
η
l
Q


π

r

4







{\displaystyle \Delta P={\frac {8\eta lQ}{\pi r^{4}}}}

.
Daqui se evidencia que a resistência é inversamente proporcional ao raio do vaso
Também é de salientar que a influência do raio do vaso é elevada à quarta potência (




r



{\displaystyle {r}}

) o que ajuda a compreender a facilidade com que qualquer influência sobre o raio faz aumentar ou diminuir a pressão
Por outro lado, o débito cardíaco 




Q



{\displaystyle {Q}}

 é o produto do volume de sangue ejectado ("stroke volume" no diagrama) a cada contração cardíaca pela frequência cardíaca
A resistência vascular depende directamente da estrutura vascular, isto é, do estado da parede arterial e das suas propriedades contráteis (noção importante quando se está a avaliar a pressão arterial de pessoas idosas).
Têm sido propostos vários mecanismos que explicam o aumento das resistências periféricas na hipertensão: A falência da atuação dos baroreceptores, as anomalias de funcionamento do sistema nervoso simpático, e a retenção de sódio e vasoconstrição pelo Sistema renina-angiotensina-aldosterona e as causas de origem genética.
Os baroreceptores são sensores do tipo mecanorreceptores, localizados nos vasos, que captam a pressão média no seu interior e enviam mensagens ao cérebro de modo a baixar ou aumentar a pressão mantendo-a nos níveis considerados habituais para o indivíduo em causa
O cérebro, mais precisamente o núcleo do trato solitário no bulbo raquidiano responde, via sistema nervoso autónomo, influenciando o débito cardíaco mas sobretudo as resistências periféricas
Atuam assim de imediato, como uma parte de um mecanismo de feedback negativo mais propriamente chamado baroreflexo
São um importante mecanismo de regulação rápida da pressão arterial
Por vezes esta regulação é "exagerada" como no exemplo clássico das crises hipotensivas
O paciente sofre uma brusca descida de tensão arterial, podendo mesmo desmaiar, o baroreflexo atua e uns minutos depois encontramos tensão arterial 160/110 por exemplo, o que pode induzir num erro diagnóstico de hipertensão
Outro exemplo da sua atuação é na hipotensão ortostática: quando passamos da posição de decúbito para o ortostatismo, a força da gravidade e a pressão ortostática fazem com que haja um afluxo súbito de sangue para as regiões de declive com diminuição secundária a nível cerebral
No adulto jovem o baroreflexo atua rapidamente quando o indivíduo passa da posição de decúbito para o ortostatismo e não há sintomatologia
Mas na pessoa idosa, o baroreflexo é mais lento e é frequente a sensação de tontura ou desequilíbrio com estas bruscas mudanças de posição
Quando a hipertensão se estabelece e fica um longo período sem ser diagnosticada e tratada, os baroreceptores estabelecem os novos valores como sendo os "normais", dificultando por vezes o início do tratamento e podendo estar relacionados com a crise hipertensiva quando o paciente suspende bruscamente a medicação
Pelo mesmo mecanismo, se a hipertensão for detectada no início, com o tratamento os baroreceptores fazem um "reset" e é frequente, passado algum tempo, o paciente necessitar de menos medicação e progressivamente suspendê-la.
Os efeitos reguladores da atividade simpática renal, sobre a produção de renina, a filtração glomerular e a reabsorção tubular do sódio, são hoje bem conhecidos
Mesmo os níveis que não são suficientes para provocar vasoconstrição, aumentam a secreção de renina e a retenção de sódio
O stress, que se acompanha de estimulação simpática, é um factor de peso para o aumento da pressão arterial sobretudo diastólica (reflexo do aumento das resistências periféricas)
Assim o sistema nervoso simpático tem um efeito desencadeador não só diretamente a nível vascular mas também, de modo indireto estimulando o sistema renina-angiotensina
Muito se tem discutido sobre a ação deste sistema
Todos os estudos apontam para a ação predominante do SNS na fisiopatologia da hipertensão por intermédio do sistema renina-angiotensina-aldosterona e não, exclusivamente, por uma ação direta isoloada.
A maior parte das evidências apontam para este mecanismo do Sistema renina-angiotensina-aldosterona como o responsável pelo aparecimento da hipertensão, via retenção de sódio e vasoconstrição
Este sistema é uma cascata hormonal, envolvendo péptidos, enzimas e recetores e cuja ação se manifesta no controlo da pressão arterial, do equilíbrio hidroeletrolítico e da volémia
A renina, primeiro interveniente nesta cascata, foi descoberta em 1898, por Robert Tigerstedt e Per Bergman
Desde então, a investigação não parou mas foram necessários cerca de 50 anos para que os outros intervenientes neste complexo sistema fossem descobertos e conduzissem ao conhecimento e às consequências terapêuticas.
Os principais intervenientes neste sistema são o angiotensinogénio, a renina, a angiotensina I, a enzima de conversão da angiotensina (ECA) e a angiotensina II
O angiotensinogénio é uma α-2 globulina produzida pelo fígado
A renina, produzida no aparelho justaglomerular do rim como uma pré-hormana (a pré-renina), é ativada pela perda do seu péptido N-terminal
Vai então atuar sobre o angiotensinogénio destacando o péptido terminal e originando assim a angiotensina I, que é inativa
Entra então em ação o enzima de conversão da angiotensina, produzida pelo epitélio vascular renal e pulmonar principalmente, que atua sobre a angiotensina I e a transforma em angiotensina II, péptido biologicamente ativo
Este péptido liga-se a pelo menos quatro tipos de recetores, sendo os melhor estudados os recetores de tipo 1: receptor AT1
Ao ligar-se ao recetor, a angiotensina I provoca vasoconstrição
Mas esta interligação não origina só vasoconstrição
Outros efeitos deletérios foram também referenciados como aumento da reabsorção do Na pelo rim, inflamação, stress oxidativo, efeitos sobre o coração com aumento do inotropismo, aumento da proliferação celular com hipertrofia ventricular esquerda, aumento da produção de aldosterona e de ADH por interferência no córtex suprarenal e no sistema nervoso central, respectivamente
Todo este complexo sistema é autorregulado com um sistema de feedback impressionante: assim a produção de renina é estimulada pela diminuição da concentração de cloreto de sódio, o aumento de atividade simpática, a diminuição da pressão arterial com diminuição da pressão de perfusão renal e estimulação dos baroreceptores
A presença de uma quantidade aumentada de angiotensina I junto do aparelho justaglomerular tem uma ação inibidora da formação de renina
Por sua vez, a produção de angiotensinogénio é estimulada por estrogénios, glicocorticóides e citocinas inflamatórias como a interleucina-1.
A alteração mais simples e mais frequente a nível do DNA é o polimorfismo de nucleotídeo único (SNP) que consiste na a troca de um par de bases do DNA
Isto pode originar a troca de um aminoácido na proteína codificada pelo gene, com possível alteração nos mecanismos de controle da pressão arterial
Este tipo de variação genética é considerada atualmente como uma das causas da predisposição individual para uma determinada doença
Os fatores ambientais, associados a este substrato genético polimórfico, vão conferir a predisposição de cada indivíduo a desenvolver ou não uma patologia de causa multifatorial como é o caso da hipertensão arterial
Foram identificados cerca de 150 genes, separados por classes funcionais, relacionados com a hipertensão
O SNP e outros tipos de alterações nestes genes estão sendo intensamente investigados
Pouco se sabe sobre os genes envolvidos na regulação da pressão arterial
As evidências sugerem que 30% dos casos são devidos a hereditariedade
Os genes que regulam o complexo sistema renina-angiotensina são alvo de estudos recentes
Segundo alguns trabalhos, o SNP do gene regulador da formação de angiotensinogénio (AGT) está associado com o aumento plasmático desta substância e com níveis tensionais mais altos nos pacientes portadores desta mutação, porém especula-se ainda sobre a ação destes e dos genes que regulam os receptores da angiotensina II de tipo 1 (AGT1R) e os receptores da angiotensina II do tipo 2 (AGT2R)
O gene da enzima de conversão da angiotensina está um pouco melhor estudado e o seu SNP está relacionado com os níveis plasmáticos da referida enzima.
Têm vindo a ser identificados outros genes comuns capazes de efectuar alterações na pressão sanguínea; os genes CYP3A5 e ABCB1 interatuam sobre a pressão arterial e o seu efeito é modificado pelo consumo de sal
Alguns trabalhos também sugerem que o efeito do gene ABCB1 no controlo da pressão arterial parece estar ligado à interacção do sistema renina-angiotensina com o sódio
Alguns estudos chegaram à conclusão que a glicoproteína-P (PGP em inglês) e o gene CYP3A5 interactuam um com o outro
A hipertensão é assim considerada como uma doença crónica, poligénica e multifactorial, em que as alterações genéticas ainda não estão estabelecidas mas tudo leva a crer que interatuem com os factores ambientais para que a patologia se manifeste ou não.
O diagnóstico de hipertensão faz-se na presença de pressão sanguínea elevada e persistente
Tradicionalmente, isto implica três medições com esfigmomanómetro efectuadas em consultório médico, depois de o doente estar em repouso pelo menos 10 minutos, efectuadas em posição sentada e repetidas com um intervalo a considerar consoante a gravidade do aumento de pressão arterial, se tal for o caso
No caso de se tratar de uma hipertensão limite, o intervalo poderá ser de um mês
Nos casos se hipertensão severa o doente deverá ser imediatamente medicado
De modo a evitar o "efeito bata branca" em que por ansiedade a pressão arterial aumenta em presença do médico, poderá ser facultada a medição da pressão arterial em casa, com medições a várias horas do dia, sempre após os 10 minutos de repouso
O paciente fará assim um mapping durante 3 a 7 dias que será avaliado pelo seu médico assistente
As medições deverão no primeiro dia ser efectuadas nos dois braços, e se houver uma diferença de mais de 20 mmHg na pressão sistólica, as medições seguintes serão sempre efectuadas no braço com pressão mais alta
Em caso contrário será sempre escolhido o braço direito, pois antes de chegar às artérias do lado esquerdo já foi alimentado o braço direito e o cérebro e a pressão será assim discretamente mais baixa do lado esquerdo
O diagnóstico inicial de hipertensão deve também considerar um exame físico e todo o historial médico do paciente
A pseudohipertensão entre os idosos pode também ser um factor a considerar no diagnóstico
Esta situação deve-se à calcificação das artérias, o que resulta em níveis de leitura anormalmente elevados no esfigmomanómetro enquanto que as medições intra-arteriais são normais
Não esquecer que o processo de endurecimento das paredes das artérias é progressivo com o envelhecimento e o aumento de pressão arterial sistólica com a idade também será progressivo sem que isto signifique hipertensão arterial
Estes dados desafiam o consenso actual, muito rígido nos critérios de hipertensão arterial acima dos 70 anos.
Uma vez completo o diagnóstico da hipertensão, o médico pode tentar identificar a causa com base em outros sintomas eventuais
A hipertensão secundária é mais comum na infância e adolescência, sendo na maior parte dos casos causada por doenças renais
A hipertensão primária é mais comum entre adultos e corresponde a múltiplos factores de risco, incluindo obesidade, hábitos alimentares em que predomina o excesso de sal, o consumo diário de águas ricas em cloreto de sódio e antecedentes familiares
Podem também ser realizados exames de laboratório de modo a identificar possíveis causas de hipertensão secundária, e determinar também se a hipertensão já causou danos no coração, olhos ou rins
Também são normalmente realizados exames complementares para a diabetes e colestrol elevado, uma vez que ambos são factores adicionais de risco para a eventualidade de uma doença cardiovascular e podem requerer tratamento complementar.
A creatinina no soro é medida com o intuito de despistar a eventual presença de doenças renais, que podem ser tanto causa como consequência da hipertensão
A creatinina do soro por si só pode sobrestimar a taxa de filtração glomerular (TFG), e orientações recentes têm indicado o uso de equações preditivas para avaliar correctamente a taxa
A TFG indica também uma medida base da função renal que pode ser usada para monitorizar efeitos secundários nos rins de determinados fármacos anti-hipertensivos
Para além disso, detecção de proteínas em amostras de urina é usada como indicador secundário de eventuais doenças renais
É feito também um electrocardiograma (ECG) de modo a revelar eventuais indícios de que o coração esteja a ser submetido a um esforço adicional devido à pressão arterial elevada
Pode também mostrar se existe ou não uma hipertrofia do ventrículo esquerdo ou se o coração foi já sujeito a um distúrbio menor, como por exemplo um enfarte silencioso
Pode ainda ser realizada uma radiografia torácica ou um ecocardiograma de modo a verificar sinais indicadores de um eventual aumento ou danos no coração.
A maior parte das complicações que a pressão arterial elevada acarreta é experienciada por indivíduos que não estão diagnosticados como hipertensos
Deste modo, torna-se necessária a adopção de estratégias de redução das consequências da pressão arterial elevada e reduzir a necessidade de terapias à base de fármacos anti-hipertensivos
Antes de se iniciar qualquer tratamento, recomenda-se alterações do estilo de vida de modo a reduzir a pressão arterial
Como meio de prevenção primária da hipertensão, as orientações de 2004 da Sociedade Britânica de Hipertensão, em consonância com as definidas já pelo Programa Educativo para a Alta Pressão Sanguínea dos Estados Unidos em 2002 recomendam as seguintes alterações ao estilo de vida:
As alterações dos hábitos e estilo de vida, quando feitas correctamente, podem baixar a pressão arterial para valores idênticos aos obtidos com medicação
A combinação de duas ou mais alterações pode produzir resultados ainda melhores.
Com a evolução da investigação sobre a genética da hipertensão arterial será possível no futuro estudar geneticamente a população, detetar os fatores de risco geneticamente relacionados com a doença e fazer a profilaxia desta.
A primeira forma do tratamento da hipertensão é idêntica às alterações no estilo de vida recomendadas na prevenção e incluem: alterações na dieta, exercício físico, e controle do peso
Todas estas medidas têm demonstrado reduzir de forma significativa a pressão arterial em indivíduos hipertensos
No entanto, se a pressão for tão elevada que justifique o uso imediato de medicamentos, as alterações dos hábitos de vida continuam a ser recomendadas em conjunto com a medicação
Tem-se publicitado vários programas de redução da hipertensão arterial através da redução do stress psicológico, como técnicas de relaxamento, meditação ou biofeedback
No entanto, as alegações de eficácia quase nunca são confirmadas por estudos científicos, e os poucos que existem são de qualidade e metodologia duvidosa.
A alteração dos hábitos alimentares, como a adopção de uma dieta de baixo teor de sal, é benéfica
Está demonstrado que uma dieta com pouco sal durante um período de apenas quatro semanas, oferece benefícios tanto em hipertensos como em pessoas com pressão arterial regular
De igual modo, está também demonstrado que uma dieta rica em frutos secos, cereais integrais, peixe, carne branca, frutas e vegetais, diminui de forma significativa a pressão arterial
Uma das principais vantagens da dieta é diminuir o consumo de sódio, embora seja rica em potássio, magnésio, cálcio e proteínas.
Estão disponíveis várias classes de fármacos para o tratamento da hipertensão, referidos em conjunto como anti-hipertensivos
A prescrição deve considerar sempre o risco cardiovascular do paciente (incluindo o risco de enfarte do miocárdio e acidente vascular cerebral) e os valores de pressão arterial medidos, de forma a obter um perfil cardiovascular preciso do paciente
Caso seja dado início ao tratamento com medicamentos, o JNC7 recomenda que o médico não só monitorize a resposta do paciente à medicação, como identifique os efeitos secundários que possam vir a ocorrer
Segundo o relatório JNC7, a redução da pressão arterial em apenas 5 mmHg pode reduzir o risco de um AVC em 34%, de cardiopatia isquémica em 21%, e a probabilidade de vir a sofrer de demência, insuficiência cardíaca e do risco de morte por doença cardiovascular
O objectivo do tratamento deve ser reduzir a pressão arterial para valores iguais ou inferiores a 140/90 mmHg na maior parte dos indivíduos (tendo em conta a idade e a rigidez ou mesmo calcificação da parede arterial) e inferiores nos que sofrem de diabetes ou de doenças renais (alguns profissionais recomendam a manutenção de valores inferiores a 120/80 mmHg) porém tendo sempre em conta cada caso em particular
Caso não se consiga atingir este objectivo, deve ser realizada uma alteração no tratamento, já que a inércia clínica é um claro impedimento do controlo da pressão arterial.
As orientações para a selecção de fármacos e a determinação da melhor forma de tratar vários subgrupos têm mudado ao longo dos anos e entre os próprios países
O melhor fármaco de primeira linha é ainda controverso
As orientações da Colaboração Cochrane, da Organização Mundial de Saúde, as Guideline americanas, as do Reino Unido, as VI Diretrizes Brasileiras de Hipertensão, variam muito sobre qual o medicamento de primeira linha a usar no tratamento da hipertensão, mas são unânimes na utilização dos inibidores da enzima de conversão da angiotensina (IECAs) e/ou dos antagonistas dos receptores da angiotensina II (ARAs)
No Japão e no Canadá é aceitável começar o tratamento com qualquer uma das seis classes de medicamentos, que incluem IECAs, Bloqueador dos canais de cálcio, diuréticos, bloqueadores beta e bloqueadores alfa, se bem que no Canadá os bloqueadores alfa estão excluídos
Vemos assim que as opiniões divergem muito e o médico assistente do paciente ou o cardiologista deverá avaliar cada caso de modo a decidir qual a melhor terapêutica para o seu paciente.
Os antagonistas dos receptores da angiotensina IIs, provaram ser excelentes medicamentos para um controlo inicial da hipertensão arterial e são muito eficazes quando associados aos IECAs, em muitas das hipertensões até então consideradas resistentes, em casos de insuficiência renal ou cardíaca
Os bloqueadores do cálcio provocam com muita frequência edemas dos membros inferiores que podem chegar ao estádio de eritromelalgia e são pouco aconselháveis nos idosos cuja mobilidade está diminuída e no adulto jovem em presença de insuficiência venosa dos membros inferiores
Os diuréticos têm um papel predominante assim como os beta-bloqueantes.
Recentemente, os inibidores diretos da renina, dos quais o alisquireno é o único disponível, são promissores, podem ser úteis quando outros bloqueadores falharam, porém estão ainda em fase experimental, não se conhecendo as suas contra-indicações nem os eventuais efeitos secundários
Estão obviamente contra-indicados na gravidez e não se conhecendo os efeitos colaterais também não se pode conhecer as interações medicamentosas
Há estudos que demonstram a potencialização do efeito quando administrados conjuntamente com os diuréticos, os IECAs e os antagonistas dos receptores da angiotensina IIs porém é ainda muito cedo para tirar conclusões e usá-los na clínica diária, sobretudo em pacientes com outras patologias tomando medicação diferente da anti-hipertensiva.
A maioria dos pacientes necessita de mais do que um fármaco para controlar a hipertensão
As orientações da JNC7 e ESH sugerem iniciar o tratamento com dois fármacos quando a pressão arterial for superior ao objectivo pretendido em 20 mmHg (160 mmHg)para a sistólica e 10 mmHg (99 mmHg) para a diastólica
As combinações sugeridas são inibidor do sistema renina-angiotensina-aldosterona com diuréticos ou inibidores do sistema renina-angiotensina com bloqueadores dos canais de cálcio
As combinações aceitáveis são antagonistas dos receptores da angiotensina IIs+IECAs, antagonistas dos receptores da angiotensina IIs ou IECAs+ Bloqueadores beta; se necessário juntar a estas duplas terapêuticas um diurético
As associações de bloqueadores dos canais de cálcio com diuréticos, bloqueadores de canais de cálcio à base de diidropiridina com bloqueadores beta, ou bloqueadores dos canais de cálcio à base de diidropiridina com diltiazem são menos eficazes e acompanham-se de efeitos colaterais já mencionados.
As combinações inaceitáveis são o triplo bloqueio, por exemplo, antagonistas dos receptores da angiotensina IIs + IECAs + beta bloqueadores.
Devido ao elevado risco de insuficiência renal aguda, deve ser evitada sempre que possível a combinação de um inibidor da enzima de conversão da angiotensina ou antagonista do receptor da angiotensina II com anti-inflamatórios não esteróides, sobretudo inibidores selectivos da COX-2 ou medicamentos de venda livre como o ibuprofeno
Estão disponíveis no mercado embalagens com combinações fixas de duas classes de fármacos que, embora possíveis de usar por qualquer pessoa, devem ser reservados para aqueles que já tenham sido sujeitos a uma terapêutica à base de um fármaco único.
Após exclusão de arteriopatia com calcificações da parede arterial, que falseiam a medição correcta da pressão arterial, a hipertensão classifica-se como "resistente" quando a medicação se mostra incapaz de a diminuir para níveis normais.
Se bem que a OMS (Organização Mundial de Saúde) considere idoso todo o indivíduo com mais de 60 anos, o termo "velho" está mais relacionado com o estado fisiológico do que com o cronológico e só a partir dos 65 anos, em termos de fisiologia, o adulto passa a ser englobado verdadeiramente na medicina geriátrica
Mas mesmo em geriatria, as particularidades de um paciente com setenta anos serão muito diferentes do paciente com 85 anos mesmo que ambos sejam saudáveis ou tenham a mesma patologia
Isto deve-se ao envelhecimento dos órgãos chave que manipulam os medicamentos (fígado e rins principalmente)
 O tratamento da hipertensão moderada ou grave em indivíduos com setenta anos ou mais contribui para a redução da mortalidade e da percentagem dessa mortalidade associada a doenças cardiovasculares
Existem poucos estudos que levam em conta indivíduos com idade superior a 80 anos, mas uma revisão recente concluiu que o tratamento da hipertensão diminui o número de indivíduos afectados e de mortes por doenças cardiovasculares, embora tal não reduza de forma significativa o número total de mortes.
O valor aceitável de pressão arterial em indivíduos com mais de 74 anos, é discretamente mais elevado, 150/90 mmHg, isto porque tem que se ter em atenção a rigidez da parede arterial (normal na pessoa idosa)
Vejamos porquê: quando medimos a pressão arterial máxima, o valor que obtemos é a pressão existente dentro da artéria (pressão do sangue) adicionado à pressão necessária para colapsar a parede arterial
Este último valor é desprezível quando se trata de um adulto jovem sem artériopatia
Já o mesmo não acontece na pessoa idosa onde a rigidez da parede arterial, própria da idade torna este valor significativo
Além disso, havendo um aumento das resistências cerebrais (fisiológico na pessoa idosa) é necessária uma pressão máxima um pouco mais elevada para que a irrigação cerebral seja feita correctamente
Se tratarmos uma pessoa idosa como a intenção de mantermos a sua pressão arterial sistólica a menos de 140 mmHg essa pessoa irá fazer hipotensão ortostática, hipotensão após as refeições, hipotensão com queda muito frequente ao levantar-se a meio da noite para urinar (como tantas vezes acontece)
Mais de 30% dos idosos caem cada ano e em cerca de 10% a intervenção cirúrgica é necessária
Nestes pacientes é fácil termos uma ideia do estado arterial pela palpação das artérias dos membros superiores sobretudo a nível da prega do cotovelo
A artéria humeral, de parede rija e muitas vezes calcificada, é sentida como um cordão duro debaixo dos dedos do médico
Os cuidados a ter no tratamento da pessoa idosa estão bem regulamentados em vários países, com base nos estudos que têm sido efetuados e publicados, sobretudo com base nos critérios de Beers.
O tratamento deve ser muito cauteloso: Segundo Chobanian, o melhor será começar com um IECA ou com um inibidor dos receptores da angiotensina, cujos efeitos colaterais são pequenos, salvo existência de patologias paralelas
Os diuréticos serão utilizados se necessário mas não deve ser esquecido que a pessoa idosa bebe pouca água e desidrata facilmente sobretudo durante o verão; além disso facilmente perdem potássio
Se excluirmos esta situação e se uma monitorização do potássio sérico for feita, os diuréticos da classe das tiazidas podem ser utilizados como drogas de primeira linha no tratamento da hipertensão arterial do idoso
Quanto aos bloqueadores dos canais de cálcio, o seu uso deverá ser ponderado na medida em que estes medicamentos provocam um "pooling" venoso importante com edema dos membros inferiores, com a agravante de que estes pacientes andam pouco e o trabalho dos músculos das pernas não contribui para a drenagem do sistema venoso
Além disso os bloqueadores dos canais de cálcio com mais efeito vasodilatador (Dihidropiridinas) podem provocar taquicardias, taquiarritmias e aumentam assim o consumo de oxigénio pelo miocárdio, podendo agravar uma doença coronária pré-existente.
Depois de excluir a hipótese de o doente ter as suas artérias calcificadas, como já tem sido presenciado em muitos serviços de cardiologia e nos quais a hipertensão sistólica a 300 mmHg pode ser documentada, define-se hipertensão resistente como a hipertensão que se mantém em valores superiores aos pretendidos apesar do uso combinado de pelo menos três fármacos anti-hipertensivos pertencentes a três classes diferentes de drogas anti-hipertensivas
Têm vindo a ser publicadas orientações para tratamento da hipertensão resistente no Reino Unido e nos Estados Unidos.
A hipertensão é o fator de risco mais importante e evitável nos casos de morte prematura à escala mundial
Aumenta significativamente o risco de cardiopatia isquémica, acidentes vasculares cerebrais, doença arterial periférica, e outras doenças cardiovasculares, incluindo insuficiência cardíaca, aneurisma da aorta, aterosclerose e embolia pulmonar
A hipertensão arterial constitui ainda um fator de risco para a insuficiência renal crónica e para o transtornos cognitivos como perturbações da memória e períodos de confusão e mesmo demência
Outras complicações podem ainda incluir retinopatia hipertensiva e nefropatia hipertensiva.
Numa análise bibliográfica efetuada entre 1998 e 2000, usando Medline, complementada por pesquisa manual, foi feito um estudo estatístico na Universidade de Tulane (Nova Orleães) que chegou à conclusão de que cerca de mil milhões de pessoas sofrem de hipertensão arterial, o que corresponde a 26% da população adulta mundial
No entanto, outros estudos mostram que a taxa varia de região para região, desde taxas de 0% nos Bushmen do deserto do Kalahari (a ausência de sal na alimentação tem sido considerada como uma das razões mas também a alimentação à base de carnes com pouca gordura, ausência de alimentos fritos, etc), 3,4% (homens) e 6,8% (mulheres) na Índia rural, até taxas alarmantes de 34% na população americana, apresentando os adultos afro-americanos as taxas de hipertensão mais altas do mundo (44%)
Seguindo as normas de JNC7, foi feito um estudo prospetivo Cortar sobre a taxa de incidência de hipertensão em Portugal, mais precisamente na região do Porto
300 000 indivíduos foram contactados por telefone no domicílio
A idade mínima de inclusão no estudo foi ≥ 18 anos e a máxima 80 anos, a pressão arterial considerada como hipertensão ≥140/90
Os valores encontrados são impressionantes pois cerca de 40% da população são hipertensos e há uma taxa de incidência de 47,3/1000-ano (cerca de duas vezes mais que na população espanhola)
A conclusão deste estudo é: Portugal tem uma taxa de incidência muito alta, a qual aumenta com a idade, a falta de escolaridade e a obesidade
A Polónia também apresenta muito taxas elevadas
A população estudada englobou indivíduos dos 18 aos 93 anos, considerando ≥140/90 como sendo hipertensão.
Em zonas de Portugal onde antigamente (há uns 40 anos) se conservava os alimentos no sal, o aparecimento dos congeladores reduziu a incidência da hipertensão nessas zonas
Porém o consumo de sal em algumas regiões é ainda exagerado
Portugal tem o pão mais salgado da Europa! Este estudo efetuado pelo Professor Mário Espiga Macedo reflete de modo excelente a prevalência da hipertensão em Portugal: apesar de a população estudada (5023 indivíduos)atingir idades compreendidas entre os 18 e os 90 anos, o estudo foi efetuado por grupos etários, dos 18 aos aos 34 anos, dos 35 aos 63 e acima de 64 anos
Os critérios utilizados foram os do Multiple Risk Factor Intervention Trial considerando hipertensos todos os indivíduos com valores de pressão arterial ≥140/90 mmHg
Assim, os hipertensos do estádio 2 segundo JNC7 (≥160 mmHg de pressão máxima) foram encontrados valores de prevalência de 2,4% antes dos 35 anos, 13,2% dos 35 aos 64 e 37,1% com mais de 65 anos (dos 65 aos 90 anos)
No que diz respeito à pressão arterial estádio 1 (≥140–159 mmHg) encontraram-se valores 16,3%, 27,7% e 32,2% respetivamente.
Fazendo uma análise da bibliografia é difícil avaliar a incidência de hipertensão no mundo na medida em que cada país, e em cada país cada região, tem os seus hábitos alimentares e estes condicionam fortemente a incidência da hipertensão arterial
A maioria destes estudos estatísticos utiliza os critérios de hipertensão emanados do estudo Multiple Risk Factor Intervention Trial (cuja população em estudo compreendeu indivíduos de 18 a 74 anos), que estabeleceu como hipertensão todo o valor de pressão arterial ≥140 mmHg para a sistólica, e englobam nas populações estudadas idosos até 80 e mesmo 90 anos (o estudo em Portugal) e 93 anos (caso da Polónia) cuja rigidez da parede arterial falseia o resultado
Estes critérios estão em desacordo com o valor de 140 mmHg considerado normal pela OMS e pela Sociedade Internacional de Hipertensão (ISH) e com as directivas emanadas pelas diferentes Sociedades de Geriatria
Num estudo de bibliografia efetuado no Brasil pelo Grupo de Pesquisa em Epidemiologia de Doenças Crónicas e Ocupacionais da Faculdade de Medicina da Universidade Federal de Minas Gerais, Belo Horizonte, com a colaboração de Secretaria de Vigilância em Saúde, Ministério da Saúde, Brasília, usando Medline e LILACS, e segundo os critérios JNC7, foram selecionados 13 trabalhos de prevalência com base populacional realizados desde 1990
Conclui-se haver uma elevada prevalência de 44,4%, 47,9 no sexo masculino e 41% no sexo feminino
Quando estes dados foram estudados segundo os critérios da OMS, sendo hipertensão arterial a pressão sistólica >140 mmHg e/ou pressão diastólica >90 mmHg e/ou uso corrente de anti-hipertensor, os estudos mostraram taxas de prevalência à volta de 20%, sem distinção de sexo, mas com a tendência de aumento com a idade
Estes mesmos valores são encontrados em outros países da América Latina
Estes resultados são importantíssimos em saúde pública e refletem a disparidade dos valores prevalência, do simples ao dobro, só pela inclusão no grupo de hipertensos de todos os indivíduos com pressão arterial igual a 140 mmHg.
A hipertensão infantil acompanha a subida da incidência da obesidade infantil
Normalmente está associada a uma história familiar de hipertensão e obesidade
A maior parte da hipertensão infantil, sobretudo entre pré-adolescentes, deve-se à presença de outro transtorno
Para além da obesidade, as doenças renais são a causa mais comum (60-70%) de hipertensão infantil
A investigação está a estudar as causas genéticas da hipertensão infantil e os estudos mais recentes apontam para um importância incontestável do fator genético
Porém os resultados ainda necessitam de maior precisão e confirmação.
Já na Antiguidade, a curiosidade pela circulação do sangue era uma realidade
Giovanni di Paolo (1403-83) no seu quadro, A decapitação de São João o Baptista, pintou como três jatos de sangue jorravam a diferentes velocidades do pescoço decapitado do santo
Em Itália, físicos e matemáticos sob a tutela de Galileu, entre eles Giovanni Borelli, interessavam-se pelo estudo da circulação
Borelli defendia as propriedades hidráulicas da circulação tendo o coração a função de bomba
Contudo ainda não existia um método de medida que pudesse validar os seus resultados
Em 1551, o Doutor Amato Lusitano (João Rodrigues de Castelo Branco, 1511-1568), médico português, descreveu a circulação do sangue na sua obra em sete volumes Curationum Medicinalium Centuriæ Septem e, pela primeira vez, afirmou que as veias tinham válvulas
77 anos depois, William Harvey (1578-1657), na obra Exercitatio Anatomica de Motu Cordis et Sanguinis in Animalibus, descreveu também a circulação sanguínea
Mas só em 1733, o Rev
Stephen Hales, Reitor de Farringdon em Hampshire e ministro em Teddington no Middlesex, publicou o primeiro método de medida da pressão arterial no segundo volume de "Statical Essays, Containing Haemastaticks"
Apesar do conhecimento já aprofundado de Hales sobre a circulação, foi Thomas Young, físico do St George's Hospital, autor da teoria ondulatória da luz e tradutor da Pedra de Roseta, que publicou um dos primeiros escritos sobre a pressão arterial
Porém a tentativa de quantificação da pressão sanguínea só começou após Jean Louis Marie Poiseuille ter inventado o manómetro de mercúrio.
O conhecimento da hipertensão deve-se aos estudos de Richard Bright iniciados por volta do ano 1820
Contemporâneo de Addison e Hodgkin, seus colegas, estudou por autópsia as consequências da hipertensão e deu um contributo incalculável para o conhecimento que se tem hoje
Em 1827, Bright publicou o seu livro "Reports of Medical Cases Selected with a view to Illustrating the Symptoms and Cure of Disease by a Reference to Morbid Anatomy"
Estava descrita a Doença de Bright
Em 1868, George Johnson descreveu pela primeira vez a hipertrofia da camada muscular da parede das pequenas artérias do rim, e subsequentemente em outros órgãos, dos doentes com doença de Bright
Em 1871, na Alemanha, Ludwig Traube e, em 1872, Sir William Gull, confirmam os achados de Johnson sobre a doença de Bright.
O manómetro de Poiseuille foi usado em membros que iam ser amputados pois a artéria ficava destruída após a sua utilização
A primeira medida indirecta da pressão arterial foi feita por Hérisson em 1834, com um esfigmomanómetro "artesanal" (um simples copo com um tubo graduado e coberto por uma membrana a qual era comprimida contra a artéria radial - lia-se depois o nível do mercúrio que subia no tubo graduado)
Foi o precursor dos manómetros de membrana que tornaram possível a medida indirecta da pressão sem destruição da artéria
O primeiro instrumento especificamente designado para medir a pressão arterial foi o de Vierordt em 1854, de técnica de utilização complicada
Em 1863, Étienne-Jules Marey de Paris inventou o primeiro esfigmomanómetro; Frederick Akbar Mahomed (1849–1884) o aperfeiçoou e este médico foi o primeiro a medir de modo sistemático a pressão arterial
Scipione Riva-Rocci inventou em 1896 um esfigmomanómetro com "cuff" (em português, braçadeira insuflável  ou manguito ), mas os instrumentos com braçadeiras mais largas devem-se a Recklinghausen, em 1901
Von Basch, em 1893, melhorou a técnica de medida da pressão arterial e estabeleceu pela primeira vez os valores normais entre 135 e 165 mmHg, mais tarde alterados para 135–150 mmHg
Allbut, professor de Física em Cambridge, descreveu a hipertensão sem lesão renal e classificou pela primeira vez três tipos de hipertensão, um dos quais é a hipertensão da pessoa idosa, com três publicações a este respeito "Diseases of the Arteries, Including Angina Pectoris (1915)", "Greek Medicine in Rome (1921)" e "A System of Medicine, 8 vol
(1896–99)"
Em 1895 e em 1889, Huchard, professor de medicina em Paris, chamou de "presclerosis" a hipertensão arterial que não se acompanha de lesão renal
Finalmente, em 1905, Nikolai Korotkov refinou a técnica de medição da pressão arterial ao descrever os "sons de Korotkov" que são ouvidos quando a artéria é auscultada com um estetoscópio, durante a fase de esvaziamento da braçadeira do esfigmomanómetro
Este modo de medida é o comummente utilizado atualmente.
Concomitantemente aos esforços de investigação para descobrir a circulação, a hipertensão arterial e como medi-la, muitas foram as diligências tomadas no sentido de tratar esta doença.
Durante séculos, o tratamento para aquilo que se designava por "doença do pulso rígido" consistia em reduzir a quantidade de sangue no organismo através de sangrias ou da aplicação de sanguessugas
Este método foi defendido por Aulo Cornélio Celso, Galeno e pelo próprio Hipócrates
Entre o final do século XIX e o início do século XX, antes de estarem disponíveis quaisquer fármacos para o tratamento da hipertensão, eram usadas três modalidades de tratamento, todas com vários efeitos secundários: uma restrição completa de sódio (por exemplo, uma dieta à base de arroz), a remoção de um gânglio simpático ou de outras partes do sistema nervoso simpático, e a terapia pirética, que consistia na injecção de substâncias que induziam febre, reduzindo de forma indirecta a pressão sanguínea
O primeiro elemento químico usado no tratamento da hipertensão, o tiocianato de sódio, começou a ser prescrito por volta de 1900, mas os inúmeros efeitos secundários tornaram-no bastante impopular
Após a II Guerra Mundial foram desenvolvidos vários fármacos, sendo os mais populares e relativamente eficazes, a hidralazina e a reserpina, esta extraída da planta medicinal rauwolfia serpentina
O maior avanço, no entanto, deu-se após a descoberta dos primeiros fármacos orais bem tolerados
O primeiro foi a hidroclorotiazida, a primeira tiazida diurética, desenvolvida a partir do antibiótico sulfanilamida, Robert Wilkins que a descobriu recebido o Prémio Lasker Especial Saúde de 1958.
A Organização Mundial de Saúde apontou a hipertensão, ou a pressão arterial elevada, como a principal causa de mortalidade cardiovascular
A Liga Mundial de Hipertensão, uma organização que congrega 85 ligas e institutos nacionais de hipertensão, divulgou que mais de 50% dos hipertensos no mundo não estão conscientes desse estado
De modo a aumentar a percepção pública do problema, a organização iniciou em 2005 uma campanha global de consciencialização e decretou o dia 17 de Maio como Dia Mundial da Hipertensão
Nos últimos anos o número de sociedades aderentes tem vindo a aumentar, sendo que em 2007 participaram no evento 47 países-membros
Durante a semana do Dia Mundial da Hipertensão todos os países – em associação com o governo local, profissionais de saúde, ONG e empresas privadas – promovem a consciencialização para o problema da hipertensão, recorrendo aos meios de comunicação social e a eventos públicos, alcançando um público-alvo de 250 milhões de pessoas.
A pressão arterial elevada é a doença crónica que dá origem ao maior número de consultas nos sistemas de cuidados de saúde nos Estados Unidos
A American Heart Association estima que os custos directos e indirectos da pressão arterial elevada tenham sido, em 2010, de 76,6 mil milhões de dólares
Oitenta por cento dos hipertensos norte-americanos estão conscientes do seu estado
Embora 71% tome medicação anti-hipertensiva, só 48% dos que estão conscientes que têm a doença é que são adequadamente controlados
A gestão correcta da hipertensão pode ser impedida por diagnósticos, medições ou tratamentos inadequados
Os prestadores de cuidados de saúde deparam-se com vários obstáculos no controlo da doença, entre os quais a renitência em tomar múltiplos medicamentos
Os próprios pacientes podem também ter dificuldade em se adaptar aos horários da medicação e às alterações dos hábitos de vida
Ainda assim, é perfeitamente possível atingir-se a pressão arterial pretendida e, sobretudo, a diminuição da pressão arterial reduz de forma significativa o risco de morte por doenças cardíacas e AVC, o desenvolvimento de outros estados debilitantes e os custos associados a cuidados médicos avançados.
Miocardite (Doença de Chagas)
Cardiomiopatia: Dilatada (Alcoólica) · Hipertrófica · Restritiva (Endocardite de Loeffler, Amiloidose cardíaca, Fibroelastose endocardíaca)
Fibrose cardíaca · Cardiomegalia · Hipertrofia ventricular (Esquerdo, Direito/Corpulmonale)
A lipoproteína de baixa densidade (em inglês: Low Density Lipoprotein - LDL) faz parte da família das lipoproteínas
É chamada de "colesterol ruim" ou "colesterol mau" porque em altas taxas ela está relacionada com a aterosclerose e, portanto, está também indiretamente relacionada ao infarto e AVC, por exemplo.
Em geral, o LDL transporta colesterol e triglicerídeos do fígado e intestino delgado às células e tecidos que estão necessitando destas substâncias.
A Associação Americana do Coração, NIH e NCEP relacionam os níveis de colesterol LDL em jejum aos riscos de doenças cardíacas:
Triacilglicerol, conhecido também como triglicerídeos, é o nome genérico de qualquer tri-éster oriundo da combinação do glicerol (um triálcool) com ácidos, especialmente ácidos graxos (ácidos carboxílicos de longa cadeia alquílica), no qual as três hidroxilas (do glicerol) sofreram condensação carboxílica com os ácidos, os quais não precisam ser necessariamente iguais
Triacilgliceróis são prontamente reconhecidos como óleos ou gorduras (ver óleo vegetal e gordura), produzidos e armazenados nos organismos vivos para fins de reserva alimentar.
De forma simplificada, um triacilglicerol é formado pela união de três ácidos graxos a uma molécula de glicerol, cujas três hidroxilas (grupos –OH) ligam-se aos radicais carboxílicos dos ácidos graxos.
Conquanto a forma preferível seja "Triacilglicerol", alternativamente usam-se também as variantes seguintes, todas com o mesmo significado:



Os triacilgliceróis são compostos essencialmente apolares (possuem longas cadeias de Carbono) além de que as regiões polares de seus precursores desapareceram na formação das ligações do tipo éster (Através da síntese por desidratação)
Por isso constituem moléculas muito hidrofóbicas
São insolúveis em água e solúveis em solventes orgânicos, como o álcool, benzina, éter e clorofórmio.
Os triacilgliceróis podem ser hidrolisados, liberando com isso ácidos graxos e glicerol
Se esta hidrólise é feita em meio alcalino, formam-se sais de ácidos graxos, os sabões, e o processo chamado de saponificação
Inclusive, sendo esse o processo de fabricação de sabão a partir de gordura animal, em um meio com NaOH ou KOH.
Alguns exemplos de triacilgliceróis, em que os três ácidos graxos que fazem parte das suas composições são iguais:
A mobilização do depósito de triacilgliceróis é obtida pela ação das lipases dos adipócitos, que são enzimas sujeitas a regulação hormonal, que hidrolisa os triacilgliceróis a ácidos graxos e glicerol
Sendo que estes produtos são oxidados por vias diferentes
O glicerol não pode ser reaproveitado pelos adipócitos, por esses não terem a glicerol quinase, e são por isso liberados na circulação
Já no fígado e outros tecidos, que tem essa quinase, o glicerol é convertido a glicerol-3-fosfato e depois transformado em diidroxiacetona fosfato, um intermediário da glicólise e neoglicogênese.
Já os ácidos graxos que são liberados dos adipócitos são transportados pelo sangue ligados à albumina e são utilizados por tecidos como fonte energética
O cérebro e as hemácias não os utilizam como fonte energética, porque só utilizam glicose.
Os triacilgliceróis vindos da dieta são hidrolisados por uma enzima diferente (lipase lipoproteica) e os produtos finais dessa hidrólise, glicerol e ácidos graxos, ficam disponíveis para as células.
A quantidade normal no organismo varia de 80-149 mg/dl
Em excesso (hipertrigliceridemia), participa do processo de aterosclerose, que obstrui os vasos sanguíneos
Outras complicações advindas do acúmulo de triglicerídios (taxas superiores a 400 mg/dl) são relacionadas à ausência de libido e, nos homens, ejaculação precoce e disfunção erétil.
Os triacilgliceróis são biologicamente úteis na alimentação dos cachalotes, uma determinada espécie de baleias
Esses mamíferos alimentam-se quase exclusivamente em águas muito profundas, o que lhes confere uma característica muito peculiar, o grande órgão do espermacete, uma massa oleosa que contém uma mistura de ceras e triacilgliceróis
Quando o cachalote mergulha em mar profundo para caçar, o óleo do espermacete solidifica deixando assim sua densidade com a mesma densidade da água ambiente
Durante o retorno á superfície para a respiração o espermacete congelado é aquecido e fundido de novo, diminuindo a sua densidade para atingir a mesma da superfície.
OBS: Variações nas dietas na atividade física, uso de bebidas alcoólicas e certos medicamentos são as causa mais frequentes de grandes variações dos níveis de triglicérides.
A lipoproteína de alta densidade (em inglês: High Density Lipoprotein - HDL) faz parte da família das lipoproteínas
É chamada de "colesterol bom", porque se acredita que ela seja capaz de retirar ateromas das artérias.
O HDL transporta colesterol dos tecidos do corpo humano ao fígado - o chamado transporte reverso do colesterol
Isso diminui a quantidade de colesterol no sangue ou aquele presente em células, diminuindo os riscos do surgimento de doenças que a hipercolesterolemia provoca, como doenças coronarianas, opacidades córneas e xantomas planares.
O HDL "recebe" parte do colesterol do LDL ao mesmo tempo em que "dá" apoproteínas para ele, facilitando assim a volta do LDL ao fígado e evitando que o mesmo fique na circulação sanguínea.
A Associação Americana do Coração, NIH e NCEP relacionam os níveis de HDL de um homem em jejum e o risco para doenças do coração:
O tabagismo é uma toxicomania caracterizada pela dependência física e psicológica do consumo de nicotina, substância presente no tabaco.
Segundo o Ministério da Saúde do Brasil, os cigarros contém cerca de 4720 substâncias tóxicas, sendo uma delas, a nicotina, responsável pela dependência.
De acordo com a Organização Pan-Americana da Saúde (OPAS), o tabagismo é o responsável por cerca de 30% das mortes por cancro (câncer no Brasil), 90% das mortes por cancro do pulmão, 25% das mortes por doença coronariana, 85% das mortes por doença pulmonar obstrutiva crónica e 25% das mortes por derrame cerebral
Ainda de acordo com a OPAS, não existem níveis seguros de consumo do tabaco.
As doenças ocasionadas pelo consumo de tabaco matam 4,9 milhões de pessoas por ano, o que significa cerca de 10 mil mortes por dia, com uma projeção estimada de óbitos em torno de 10 milhões até o ano 2030 - das quais 7 milhões ocorrerão nos países em desenvolvimento e metade dos afetados em idade ativa dos 35-70 anos
Vale a pena sublinhar que o tabagismo, hoje, mata mais que a soma das mortes por AIDS, cocaína, heroína, álcool, suicídios e acidentes de trânsito
As doenças causadas pelo tabaco são responsáveis por perdas econômicas de aproximadamente US$ 200 bilhões de dólares, no mundo.
O método de avaliação de Fagerström é, hoje, utilizado por especialistas, para ajudar a definir a melhor estratégia para quem quer largar o cigarro
Trata-se de um questionário utilizado por médicos a fim de determinar se uma pessoa está seriamente viciada na nicotina.


Em 15 de outubro de 1492 folhas secas de tabaco foram oferecidas a Cristovão Colombo pelos índios americanos.
Chegou a Europa como proposta curativa (o tabaco era mascado).
A relação entre o Tabagismo e Saúde é conhecida de forma geral pela maioria das pessoas
Sabe-se que "faz mal" mas o vício é de tal forma elevado que leva as pessoas a permanecer a sua atividade nociva com consequências variadas
O Tabagismo é responsável por:
No Brasil, estima-se que cerca de 290 mil mortes por ano são decorrentes do tabagismo
A proporção de fumantes no país é de 23,9% da população
Segundo dados da PNAD, em 2008, o Brasil tinha 24,6 milhões de fumantes habituais com idade a partir de 15 anos ou 17,2% da população de pessoas dessa faixa etária, sendo 15,1% fumantes diários.
Cerca de 90% dos fumantes tornam-se dependentes da nicotina entre os 5 e os 19 anos de idade
Há 2,8 milhões de fumantes nessa faixa etária, mas a maior concentração de fumantes está na faixa etária de 20 a 49 anos.
A região Sul do país é a que apresenta maior proporção de dependentes - 45% dos fumantes
Em 2008, a região Sul, com 19,3%, tinha o maior percentual de fumantes correntes.
No Nordeste, os fumantes dependentes são 31%
Os moradores da zona rural também fumam mais que os das zonas urbanas.
O fumo é responsável por 95% dos casos de câncer de boca; 90% das inflamações de mama; 80% da incidência de câncer no pulmão; por 97% dos casos de câncer da laringe; 50% dos casos de câncer de pele; 45% das mortes por doença coronariana (infarto do miocárdio) e também 25% das mortes por doença vascular-cerebral (derrames cerebrais).
O tabagismo, incluindo o passivo, é o fator de risco mais comum para a DPOC, Doença Pulmonar Obstrutiva Crônica
No Brasil, estima-se que a doença atinja cerca de 6 milhões de pessoas
Somente 12% dos pacientes são diagnosticados e, desses, apenas 18% recebem tratamento
Já no cenário mundial, a estimativa é de que aproximadamente 210 milhões de pessoas tenham DPOC e a previsão é que a doença se torne a terceira principal causa de morte por volta de 2020
Outros fatores que contribuem para o desenvolvimento da doença são a inalação de poeiras e produtos químicos em fábricas ou ambientes profissionais similares, poluição do ar, desenvolvimento pulmonar prejudicado e fatores genéticos.
Segundo uma pesquisa realizada em 20 países, o brasileiro, com 91%, é o que mais se arrepende de ter começado a fumar
Entre os fumantes brasileiros do estudo internacional, 63% apóiam campanhas e leis contra o fumo e 82% relatam que o fumo já lhes causou algum problema de saúde
Segundo os dados da Kantar Health, mesmo com restrições impostas, os fumantes parecem observar com razoável conforto as legislações que visam evitar que não fumantes sejam incomodados pela fumaça de cigarros, charutos e cachimbos
Dentre os respondentes do Reino Unido, França, EUA, China, Brasil e Espanha, a maioria alega não achar difícil restringir o consumo em locais restritos.
O Brasil é o maior exportador e quarto maior produtor mundial de tabaco - depois da China, EUA e Índia.
Deve-se ressaltar que o cultivo do tabaco expõe trabalhadores rurais a uma grande variedade de agrotóxicos aumentando o risco de manifestação de efeitos agudos e crônicos à saúde, como transtornos mentais e câncer
Durante a colheita das folhas de tabaco pode haver absorção dérmica da nicotina presente nas folhas úmidas, podendo ocasionar a denominada Doença da Folha Verde do Tabaco, cujos sintomas são muito semelhantes aos quadros de intoxicação por agrotóxicos e outras doenças.
Em 2015, um em cada quatro portugueses (25%) é fumador, mais dois pontos percentuais do que em 2012, 12% deixaram de fumar e quase dois terços (63%) nunca fumaram.
Na União Europeia (UE), a média de fumadores é de 26%, uma quebra de dois pontos na comparação com o inquérito de 2012.
Em Portugal, fumam mais os homens (34%) do que as mulheres (18%), em linha com a média da UE: 31% e 22%, respetivamente.
A maior prevalência é dada no grupo etário 25 a 34 anos (45,6% nos homens e 25,1% nas mulheres) e as mais baixas no grupo etário 65 a 74 anos (10,8% nos homens e 2,5% nas mulheres).
Obesidade é uma condição médica em que se verifica acumulação excessiva de tecido adiposo ao ponto de poder ter impacto negativo na saúde
Uma pessoa é considerada obesa quando o seu índice de massa corporal (IMC) é superior a 7002294199500000000♠30 kg/m, e com excesso de peso quando o seu IMC é superior a 7002245166250000000♠25–30 kg/m
O IMC é calculado dividindo o peso da pessoa pelo quadrado da sua altura
A obesidade aumenta a probabilidade de ocorrência de várias doenças, em particular de doenças cardiovasculares, diabetes do tipo 2, apneia do sono obstrutiva, alguns tipos de cancro, osteoartrite, e depressão.
A causa mais comum de obesidade é uma combinação de dieta hiperenergética, falta de exercício físico e suscetibilidade genética
Alguns casos são causados por genes, doenças endócrinas, medicamentos ou perturbações mentais
Não há evidências que apoiem um metabolismo lento como causa de obesidade em pessoas obesas que comem pouco
Em média, as pessoas obesas consomem mais energia do que as restantes, uma vez que quanto maior a massa corporal, maior a necessidade de energia.
A prevenção da obesidade consiste em alterações sociais e escolhas pessoais
O tratamento da obesidade baseia-se na dieta e no exercício físico
A qualidade da dieta pode ser melhorada reduzindo o consumo de alimentos ricos em energia, tais como os que têm grande quantidade de gordura e açúcar, e aumentando a ingestão de fibra dietética
Para acompanhar a dieta adequada pode ser administrada medicação anti-obesidade para reduzir o apetite ou diminuir a absorção de gordura pelo corpo
Quando a dieta, o exercício e a medicação não demonstram ser eficazes, pode ser considerada a aplicação de uma banda gástrica ou uma cirurgia bariátrica para reduzir o volume do estômago ou o comprimento do intestino, o que faz com que a pessoa se sinta cheia mais cedo e que haja menor capacidade de absorção de nutrientes dos alimentos.
A obesidade é uma das principais causas de morte evitáveis em todo o mundo, com taxas de prevalência cada vez maiores em dultos e crianças
Em 2015, 600 milhões de adultos (12% do total) e 100 milhões de crianças eram obesas
A obesidade é mais comum entre mulheres do que entre homens
As autoridades de saúde consideram a obesidade um dos mais graves problemas de saúde pública do século XXI
Em grande parte do mundo contemporâneo, particularmente na sociedade ocidental, a obesidade é alvo de estigma social, embora ao longo da História tenha sido vista como símbolo de riqueza e fertilidade, perspetiva que ainda se mentém em algumas partes do mundo.


A obesidade é uma condição médica na qual se verifica acumulação de tecido adiposo em excesso ao ponto de poder ter impacto negativo na saúde
É definida em função do índice de massa corporal (IMC) e avaliada em termos de distribuição de gordura pelo índice de cintura e quadris e pelos factores de risco cardiovascular
O IMC está intimamente relacionado com a taxa de gordura corporal e a quantidade total de gordura no corpo.
Calcula-se o IMC dividindo o peso do indivíduo pelo quadrado da sua altura, através da seguinte forma:
As definições mais amplamente usadas a nível mundial e em vigor nos países lusófonos, definidas pela Organização Mundial de Saúde (OMS) em 1997 e publicadas em 2000, indicam os valores de referência na tabela à direita
No entanto, alguns países asiáticos redefiniram os valores de obesidade da OMS, uma vez que as populações asiáticas desenvolvem consequências de saúde negativas a um IMC menor do que os caucasianos
Por exemplo, o Japão define obesidade como qualquer IMC superior a 25 kg/m, enquanto que a China usa um IMC superior a 28 kg/m
Algumas entidades de saúde também realizam alterações à definição da OMS
Por exemplo, a literatura cirúrgica divide a obesidade de classe III em mais categorias, cujos valores precisos ainda se encontram em discussão.
Em crianças, o peso considerado saudável varia em função da idade e do sexo
A obesidade em crianças e adolescentes não é definida em função de um número absoluto, mas sim por um percentil
Assim, uma criança com idade superior a dois anos é considerada obesa quando o seu IMC é igual ou superior ao percentil 95 para o seu sexo e idade
Da mesma forma, considera-se que uma criança tem excesso de peso (pré-obesidade) quando o seu IMC está entre o percentil 85 e 95
Os dados de referência nos quais estes percentis se baseiam correspondem ao período entre 1963 e 1994, os quais não foram afetados pelo aumento recente da média de peso.
O excesso de massa corporal está associado a várias doenças, em particular doenças cardiovasculares, diabetes do tipo 2, apneia do sono, alguns tipos de cancro, osteoartrite e asma Em consequência destes factores, determina-se que a obesidade contribui para a diminuição da esperança de vida.
A obesidade é uma das principais causas de morte evitáveis em todo o mundo.
Em cada ano, morrem 3,4 milhões de adultos em consequência da obesidade ou do sobrepeso
A doença está também na origem de 44% dos casos de diabetes, 23% dos casos de doença arterial coronariana e entre 7 e 41% de determinados tipos de cancro
Na Europa, 7,7% das mortes (cerca de um milhão de pessoas) são atribuídas ao excesso de peso
Em média, a obesidade reduz a esperança de vida entre seis a sete anos
Um IMC entre 30 e 35 kg/m reduz a esperança de vida entre dois e quatro anos, enquanto que a obesidade grave (IMC > 40 kg/m) reduz a esperança de vida em dez anos.
O risco de mortalidade é menor no intervalo de IMC de 20-25 kg/m em não fumadores, e 24–27 kg/m em fumadores
Existe uma associação entre valores de IMC superiores a 32 kg/m e a duplicação da taxa de mortalidade entre mulheres, ao longo de um período de 16 anos.
A obesidade aumenta o risco de diversas complicações físicas e psicológicas
Estas comorbidades estão frequentemente integradas numa condição denominada síndrome metabólica, um conjunto de transtornos clínicos que engloba: diabetes mellitus tipo 2, pressão arterial elevada, colesterol elevado e níveis elevados de triglicerídeos
As complicações podem ser causadas diretamente pela obesidade ou de forma indireta, através de mecanismos com causas em comum, como por exemplo uma dieta desequilibrada ou um estilo de vida sedentário
A intensidade da relação entre a obesidade e complicações específicas é variável
Uma das mais fortes é a ligação com a diabetes do tipo II
O excesso de gordura corporal está na origem de 64% dos casos de diabetes em homens e 77% dos casos em mulheres.
As consequências da obesidade a nível da saúde podem ser classificadas em duas categorias genéricas: as que podem ser atribuídas aos efeitos do aumento da massa adiposa (como a osteoartrite, a apneia de sono ou o estigma social) e as que podem ser atribuídas ao aumento do número e do volume de células adiposas, como a diabetes, cancro, doenças cardiovasculares ou a doença hepática gordurosa não alcoólica
O aumento de gordura corporal altera a reação do corpo à insulina, o que pode provocar resistência à insulina, e também cria um estado pró-inflamatório e pró-trombótico.
A nível individual, pensa-se que maior parte dos casos de obesidade se deva a uma conjugação da ingestão de alimentos energéticos em excesso com a ausência de exercício físico
Uma percentagem pequena de casos deve-se principalmente a condições genéticas, transtornos psiquiátricos ou razões médicas em geral
Por outro lado, o aumento generalizado da prevalência de obesidade na sociedade deve-se à facilidade no acesso à dieta hiperenergética, ao aumento da dependência de transportes automóveis e à mecanização do trabalho.
Existe uma relação entre o consumo de energia total e a obesidade
A maior parte da energia consumida em excesso tem origem no aumento do consumo de hidratos de carbono, e não no consumo de gordura
As principais fontes destes hidratos de carbono em excesso são as bebidas açucaradas e as batatas fritas, e acredita-se que o seu consumo excessivo esteja a contribuir para o aumento dos índices de obesidade
À medida que as sociedades se tornam cada vez mais consumidoras de dietas hipercalóricas, fast-food e refeições de grandes porções, a ligação entre o consumo de fast-food e a obesidade torna-se mais evidente.
A disponibilidade de energia dietética per capita varia de forma acentuada entre diferentes regiões e países, e foi-se alterando de forma significativa ao longo do tempo
Entre o início da década de 1970 e o fim da década de 1990, a energia alimentar disponível por pessoa e por dia (a quantidade de alimentos comprados) aumentou em todas as partes do mundo, exceto na Europa do Leste
A maior disponibilidade encontra-se nos Estados Unidos, com 3654 cal por pessoa em 1996, valor que aumentou para 3754 Cal em 2003
Em finais da década de 1990, os europeus tinham disponíveis em média 3394 Cal por pessoa, enquanto que nas regiões em desenvolvimento da Ásia a disponibilidade era de 2648 por pessoa e na África subsariana de 2176 Cal por pessoa
Apesar de estarem disponíveis recomendações de nutrição em diversos países, continuam a existir problemas derivados da ingestão excessiva de alimentos e de escolhas dietéticas pouco saudáveis.
As políticas a as técnicas agrícolas introduzidas na Europa e na América do Norte no pós-guerra proporcionaram a descida acentuada do preço dos alimentos
Entre estas políticas estão os subsídios à produção agrícola, como os que são provenientes da Política Agrícola Comum
No entanto, grande parte dos subsídios destinou-se à produção de milho, soja, trigo e arroz, o que fez com que estes alimentos se tornassem as principais fontes de comida processada
Assim, apesar dos custos de produção e tecnologia envolvidos, a comida processada com base neste alimentos tornou-se mais barata do que a própria fruta ou os vegetais
No fim da década de 2000, começou-se a questionar e a discutir a distribuição de subsídios agrícolas no sentido de melhor adequá-los às necessidades dietéticas, promovendo o cultivo de frutas e vegetais.
O estilo de vida sedentário desempenha um papel significativo na obesidade
A OMS sugere que entre a população mundial verifica-se um declínio das atividades recreativas ativas e que, atualmente, cerca de 30% da população mundial não realiza exercício físico suficiente
Isto deve-se à tendência de evolução para condições de trabalho que exigem cada vez menos esforço físico, ao aumento da utilização de transportes mecanizados e à maior prevalência de tecnologia residencial
No caso das crianças, o declínio na quantidade de atividade física deve-se também à diminuição na quantidade de percursos feitos a pé e à inexistência de educação física.
Tanto em adultos quanto em crianças existe uma correlação entre o tempo passado em frente à televisão e o risco de obesidade
Um estudo de revisão constatou que 63 entre 73 estudos (86%) demonstraram existir um aumento da taxa de obesos em função do aumento da exposição aos meios de comunicação, no qual a taxa aumenta de forma proporcional ao tempo de visualização.
Tal como muitas outras condições médicas, a obesidade é o resultado da interação entre fatores genéticos e ambientais
Perante fatores ambientais idênticos, o risco de obesidade é maior nas pessoas com predisposição genética para a doença
Esta predisposição genética tem origem nos polimorfismos de vários genes que controlam o apetite e o metabolismo
Existem mais de 40 sítios do genoma humano que estão associados ao desenvolvimento de obesidade quando existe comida em quantidade suficiente.
As pessoas com duas cópias do gene FTO pesam em média 3 a 4 quilos a mais e apresentam um risco 1,67 vezes superior de obesidade, em comparação com a restante população
A percentagem de obesidade que pode ser atribuída a factores genéticos varia entre 6 e 85%, dependendo da população examinada
Verifica-se que 7% das pessoas com obesidade grave precoce (obesidade antes dos 10 anos de idade e com IMC três vezes superior ao normal) possuem mutação pontual no ADN
Cerca de 80% dos filhos de dois progenitores obesos são também obesos, valor que contrasta com os menos de 10% entre os filhos de pais com peso normal
A obesidade é também uma das principais características de diversas síndromes genéticas, como a síndrome de Prader-Willi ou a síndrome de Bardet-Biedl.
Embora a influência genética seja importante para compreender a obesidade, ela por si só não explica o aumento dramático da incidência em determinados países ou em escala global
Existem diversas atitudes sociais que aparentam aumentar o risco de obesidade, como o stress, a discriminação, a classe socioeconómica, o tabagismo, o número de filhos e a urbanização.
A correlação entre a classe social e o IMC varia consoante a região do mundo
Em países desenvolvidos, o grupo com menor probabilidade de obesidade são as mulheres das classes superiores
Por outro lado, nos países em desenvolvimento os homens, mulheres e crianças das classes sociais superiores são os que apresentam as maiores taxas de obesidade
No entanto, devido aos efeitos da globalização, as diferenças têm-se vindo a atenuar
Em países desenvolvidos, o número de adultos obesos e crianças com sobrepeso está correlacionado com a desigualdade económica
Têm sido propostas diversas explicações para a relação entre o IMC e a classe social: em países desenvolvidos, as pessoas com maior poder de compra têm a possibilidade de escolher alimentação mais equilibrada e saudável, estão sob maior pressão social para manterem o peso ideal e têm a possibilidade de praticar programas de fitness; em países em vias de desenvolvimento, o padrão observado pode ser explicado pela diferença no acesso à alimentação, pela grande quantidade de energia dispendida no trabalho físico e por valores culturais que favorecem um corpo maior.
Fumar tem um efeito assinalável no peso individual
As pessoas que desistem de fumar aumentam em média entre 4,4 kg (homens) e 5,0 kg (mulheres) nos dez anos seguintes
No entanto, a diminuição do número de fumadores tem tido pouco efeito nas taxas de obesidade entre a população.
Na sociedade ocidental, o número de filhos tem também uma correlação com o aumento do risco de obesidade
O risco de uma mulher aumenta 7% por cada filho, enquanto o de um homem aumenta 4%
Isto pode ser explicado em parte pelo facto de que ter crianças dependentes diminui a atividade física dos pais
Nos países em desenvolvimento, a urbanização também desempenha um papel no aumento das taxas de obesidade
Por exemplo, na China a taxa nacional de obesidade é inferior a 5%, enquanto que nalgumas cidades é superior a 20%.
Algumas doenças físicas e mentais, e os fármacos usados no seu tratamento, podem aumentar o risco de obesidade
Entre as doenças que aumentam o risco de obesidade estão diversas síndromes genéticas raras e algumas condições congénitas ou adquiridas, como o hipotiroidismo, síndrome de Cushing ou deficiência de hormona do crescimento, e transtornos alimentares, como o transtorno da compulsão alimentar periódica
No entanto, a obesidade não é considerada nem classificada como transtorno psiquiátrico
O risco de sobrepeso e obesidade é maior em pessoas com transtornos psiquiátricos.
A desnutrição durante os primeiros anos de vida também aparenta desempenhar um papel no aumento da taxa de obesidade nos países em desenvolvimento
As alterações endócrinas que ocorrem durante períodos de desnutrição podem promover o armazenamento de gordura a partir do momento em que a comida esteja outra vez disponível
Diversos estudos confirmam também que a obesidade está também associada a défices cognitivos.
Alguns medicamentos podem provocar aumento de peso ou alterações na composição do corpo, como a insulina, sulfonilureias, tiazolidinedionas, antipsicóticos atípicos, antidepressivos, glicocorticoides, alguns anticonvulsivos (fenitoína e valproato), pizotifeno e algumas formas de contraceção hormonal.
Tem-se verificado que a flora intestinal difere entre pessoas magras e obesas, havendo uma indicação de que a flora pode afetar o potencial metabólico
Acredita-se que esta alteração no potencial metabólico faz com que o organismo tenha maior capacidade de recolher energia, contribuindo assim para a obesidade
No entanto, ainda não foi demonstrado de forma inequívoca se estas diferenças são causa ou consequência da obesidade
Verificou-se também uma associação entre vírus e obesidade em seres humanos e diversas outras espécies
No entanto, ainda está por determinar a contribuição desta associação para o aumento da taxa de obesidade.
Existem diversos mecanismos fisiopatológicos envolvidos no desenvolvimento e manutenção da obesidade e que participam na regulação do apetite e na ingestão de comida, no padrão de armazenagem do tecido adiposo e no desenvolvimento de resistência à insulina
Desde a descoberta da leptina, foram estudados diversos outros mediadores, como a grelina, insulina, orexina, colecistocinina e a adiponectina
As adipocinas são mediadores produzidos pelo tecido adiposo e supõe-se que sua acção modifique diversas doenças relacionadas à obesidade.
A leptina e a grelina são complementares ao nível da regulação do apetite
A grelina produzida pelo estômago regula o apetite a curto prazo, fazendo com que a pessoa sinta fome quando o estômago está vazio e indicando o momento em que o estômago está cheio
A leptina é produzida pelo tecido adiposo para sinalizar as reservas de gordura no corpo e mediar a regulação do apetite a longo prazo; isto é, comer mais quando as reservas são poucas, e pouco quando as reservas são muitas
Embora a administração de leptina possa ser eficaz num pequeno subgrupo de indivíduos obesos com deficiência de leptina, pensa-se que a maior parte seja resistente à leptina, apresentando inclusive níveis elevados da hormona, o que explica a ineficácia da administração de leptina para suprimir o apetite em grande parte da população.
Embora a leptina e a relina sejam produzidas perifericamente, elas regulam o apetite através de ações no sistema nervoso central
As diversas hormonas reguladoras do apetite atuam no hipotálamo, uma região do cérebro onde está concentrada a regulação da ingestão de alimentos e a gestão de energia
Existem diversos circuitos no hipotálamo que contribuem para a sua função reguladora do apetite, dos quais o sistema das melanocortinas é o mais bem compreendido
O circuito tem início no núcleo arqueado, uma região do hipotálamo com ligações ao hipotálamo lateral e ao hipotálamo ventromedial, os centros responsáveis pela alimentação e sacieção, respetivamente.
O núcleo arqueado contém dois grupos distintos de neurónios
O primeiro grupo coexpressa o neuropeptídeo Y (NPY) e o peptídeo Agouti (AgRP), ao mesmo tempo que estimula o hipotálamo lateral e inibe o hipotálamo ventromedial
O segundo grupo coexpressa pró-opiomelanocortina (POMC) e transcrito regulado por cocaína (CART), estimula o hipotálamo ventromedial e inibe o hipotálamo lateral
Desta forma, os neurónios NPY/AgRP estimulam a alimentação e inibem a saciação, enquanto que os neurónios POMC/CART estimulam a saciação e inibem a alimentação
Ambos os grupos do núcleo arqueado são regulados em parte pela leptina
A leptina inibe o grupo NPY/AgRP e estimula o grupo POMC/CART
Assim, a presença de uma deficiência na sinalização de leptina, causada tanto por insuficiência de leptina como por resistência à leptina, provoca sobrealimentação e pode ser responsável por algumas das formas genéticas e adquiridas de obesidade.
O principal tratamento para a obesidade é uma dieta apropriada e exercício físico
Os programas dietéticos proporcionam redução de peso a curto prazo, embora manter o peso pretendido seja difícil, pelo que geralmente essa redução necessita de ser acompanhada por alterações permanentes no estilo de vida da pessoa, como exercício físico regular e uma dieta menos calórica
A taxa de sucesso da manutenção a longo prazo da redução de peso com alterações no estilo de vida é de cerca de 20%
As alterações na dieta e no estilo de vida são eficazes na limitação do ganho de peso durante a gravidez e têm impacto positivo na saúde da mãe e da criança.
Estão disponíveis alguns fármacos para o tratamento de obesidade
Os mais comuns são o orlistato, a lorcaserina e a associação fentermina/topiramato
No entanto, a aprovação ou não de cada substância pode diferir bastante entre países
Embora o uso de lorcaserina tenha sido aprovado pela Food and Drug Administration norte-americana, o medicamento não foi aprovado pela Agência Europeia do Medicamento
A perda de peso com o orlistato é modesta, em média 2,9 kg entre 1 e 4 anos
O seu uso está associado a taxas elevadas de efeitos adversos gastrointestinais e têm sido levantadas preocupações acerca dos efeitos negativos nos rins
Os outros dois fármacos estão disponíveis nos Estados Unidos, mas não na Europa
A lorcaserina proporciona uma perda de peso média de 3,1 kg superior ao placebo ao longo de um ano
No entanto, pode aumentar os problemas relacionados com as válvulas do coração
A associação fenternina/topiramato apresenta alguma eficácia, embora possa estar associado a problemas no coração
Não existe ainda informação sobre a forma como estes fármacos afetam complicações a longo prazo da obesidade, tais como doenças cardiovasculares ou morte.
O tratamento mais eficaz para a obesidade é a cirurgia bariátrica, ou cirurgia de redução do estômago
O tratamento cirúrgico da obesidade está associado à perda de peso a longo prazo e à melhoria nas condições médicas relacionadas
Verificou-se num estudo uma perda de peso entre 14 e 25% ao longo de dez anos, dependendo do tipo de cirurgia, e uma redução de 29% na mortalidade, em comparação com as medidas convencionais para perder peso
No entanto, ocorrem complicações em 17% dos casos e em 7% é necessária uma segunda intervenção cirúrgica
Devido ao seu custo e riscos associados, atualmente procuram-se novos tratamentos eficazes, mas menos invasivos.
Antes do século XX a obesidade era rara
No entanto, em 1997 a OMS reconheceu formalmente a obesidade enquanto epidemia à escala global
Em 2008, a OMS estimou 500 milhões de adultos (10%) eram obesos e que a prevalência da doença era maior entre as mulheres
A incidência de obesidade também aumenta em função da idade até aproximadamente aos 50-60 anos
Em alguns países desenvolvidos o crescimento da obesidade grave é maior do que o crescimento da obesidade no geral.
Anteriormente considerada um problema restrito aos países industrializados, atualmente verifica-se que o aumento da obesidade se dá à escala global, afetando tanto os países desenvolvidos como os países em vias de desenvolvimento
Este aumento verifica-se de forma mais acentuada em contexto urbano, e a única região do mundo onde não é um problema comum é na África subsariana.
Em Portugal, a prevalência de pré-obesidade é de cerca de 34%, enquanto a prevalência de obesidade de 12%
Cerca de metade da população portuguesa não pratica qualquer atividade física regular, o que tem vindo a contribuir para o aumento acentuado da obesidade no país
A percentagem de sobrepeso é maior entre sexo masculino
Entre a população com idade superior a 55 anos, a prevalência de obesidade é 7,2 vezes superior à média
A maior prevalência de pré-obesidade regista-se no interior norte e centro, enquanto que a maior prevalência de obesidade se regista no Alentejo e em Setúbal
Verifica-se também que a prevalência de obesidade é maior em meio urbano do que em meio rural, e que diminui em função do grau de instrução dos pais
Segundo dados de 2004, 44,1% dos homens adultos apresentavam diagnóstico sobrepeso (IMC 25-29,9) e 14,5% apresentavam diagnóstico de obesidade (IMC ≥30)
Entre as mulheres adultas, 31,9% apresentavam diagnóstico de sobrepeso e 14,6% diagnóstico de obesidade
Nas crianças dos 7 aos 9 anos de idade, a prevalência da obesidade e da pré-obesidade é de 31,56%, sendo a prevalência maior em crianças do sexo feminino
Em 2009-2010, Portugal apresentava a segunda maior taxa de sobrepeso entre adolescentes europeus (32%).
No Brasil, segundo dados de 2008–2009, cerca de metade da população apresenta diagnóstico de sobrepeso
Verificou-se diagnóstico de obesidade em 12,5% dos homens e 16,9% das mulheres com mais de 20 anos, 4,0% dos homens e 5,9% das mulheres entre 10 e 19 anos e 16,6% das crianças do sexo masculino e 11,8% das crianças do sexo feminino entre 5 a 9 anos
Em homens, o excesso de peso e obesidade são mais prevalentes nas Regiões Sudeste, Sul e Centro-Oeste do que nas Regiões Norte e Nordeste, enquanto que nas mulheres a prevalência é maior na região Sul, embora de forma menos acentuada
O excesso de peso é maior em áreas urbanas em relação a áreas rurais
A prevalência de sobrepeso e obesidade no Brasil tem vindo a aumentar, particularmente a partir do final da década de 1990
Em 1974–1975, a prevalência média de sobrepeso em adultos do sexo masculino foi de 18,5%, enquanto que em 2008-2009 foi de 50,1%
Em mulheres adultas, a prevalência aumentou de 28,7% para 48%, respetivamente
Nas crianças entre os 5 e os 9 anos, o aumento é ainda mais acentuado
Em 1974-75, no sexo masculino a prevalência de sobrepeso foi de 10,9% e a prevalência de obesidade de 2,9%, em contraste com 34,8% de sobrepeso e 16,6% de obesidade em 2008-2009
No sexo feminino, a prevalência de sobrepeso aumentou de 8,6% para 32% e a prevalência de obesidade de 1,8% para 11,8%
Em 2008, apenas 10,2% dos brasileiros com 14 anos ou mais de idade praticava exercício físico regularmente
Entre 1970 e 2008, a percentagem da população envolvida no setor agrícola, que é aquele que possibilita maior gasto energético, diminuiu de 44% para 17,4%.
A Guiné-Bissau apresenta a taxa de obesidade mais elevada da África subsariana em ambos os sexos, tanto em adultos como em crianças
Entre os adultos, a taxa é de 16,8% nos homens e 24,2% nas mulheres e entre as crianças a taxa é de 8,1% no sexo masculino e 8,3% no sexo masculino
O país apresenta ainda taxas muito elevadas de sobrepeso (44% nos homens, 47,8% nas mulheres, 15,8% em crianças do sexo masculino e 20,4% no sexo feminino
Em Angola a taxa de obesidade engloba 12% dos homens, 18,7% das mulheres, 5,7% das crianças do sexo masculino e 6% do sexo feminino
No mesmo país, verifica-se sobrepeso em 42,9% dos homens, 49,1% das mulheres, 15,5% dos rapazes e 20,9% das raparigas.Em Moçambique, a taxa de sobrepeso afeta 14,1% dos homens, 26,5% das mulheres, 12,3% dos rapazes e 14,4% das raparigas
Em São Tomé e Príncipe 30,6% dos homens, 45,7% das mulheres, 12,3% dos rapazes e 18,9% das raparigas apresentam sobrepeso
Em Cabo Verde, o sobrepeso afeta 31,8% dos homens, 44% das mulheres, 11,5% dos rapazes e 18,3% das raparigas.
Em agosto de 2015, investigadores da Universidade de Harvard e do MIT descobriram que o gene FTO ativa dois outros genes que impedem a gordura de ser queimada na forma de calor - um processo chamado termogénese
Demonstraram também que é possível desativar estes genes através de uma técnica inovadora (CRISPR) que recorta código de ADN com erros e o substitui pela sequência correta.
"Obesidade" tem origem no latim obesitas, que significa gordo ou corpulento
Ēsus é o particípio passado de edere (comer), com o prefixo ob (sobre)
Os gregos foram a primeira civilização a reconhecer a obesidade enquanto transtorno de saúde
Hipócrates escreveu que "a corpulência não só é uma doença, como é o prenúncio de outras"
O cirurgião indiano Sushruta (século VI a.C.) associou a obesidade à diabetes e às doenças cardiovasculares, recomendando a cura através de exercício físico.
Ao longo de grande parte da História, a humanidade lutou continuamente contra a escassez de alimentos, pelo que a obesidade foi considerada em vários períodos um sinal de prosperidade e riqueza
Muitas culturas viam a obesidade enquanto resultado de defeitos de caráter
Na comédia grega, o obesus era um glutão e uma personagem ridicularizada
Durante a época paleocristã, a gula era vista como um sete pecados capitais.
A obesidade foi particularmente comum entre as elites europeias durante a Idade Média e o Renascimento e nas civilizações do oriente asiático
Durante a revolução industrial constatou-se que o poder económico e militar dos países está intimamente relacionado com a força e o tamanho do corpo dos seus trabalhadores e soldados
O crescimento do IMC médio entre a população, desde o que hoje se considera um peso inferior ao normal até ao que agora se considera peso normal, contribuiu de forma significativa para o desenvolvimento das sociedades industrializadas
Ao longo de todo o século XIX, a média de altura e de peso entre a população do mundo ocidental aumentou de forma significativa
No século XX, à medida que a população ia atingindo o seu potencial genético em termos de altura, o peso começou a aumentar de forma superior à altura, tendo como consequência o aumento da prevalência de obesidade
No pós-guerra, o aumento de prosperidade nos países desenvolvidos fez com que a taxa de mortalidade infantil diminuísse
No entanto, à medida que o índice de massa corporal aumentou, as doenças renais e cardiovasculares foram-se tornando cada vez mais comuns.
Na cultura ocidental contemporânea, o excesso de peso é muitas vezes visto como pouco atrativo e a obesidade está associada a diversos estereótipos negativos
Em qualquer idade, as pessoas obesas enfrentam estigma social e podem ser alvo de bullying, preconceito e discriminação
No entanto, em diversas regiões africanas a obesidade ainda é vista como sinal de riqueza e bem-estar, situação que se tornou ainda mais comum desde o início da epidemia de VIH.
A Organização Mundial de Saúde (OMS) antevê que a preocupação com o sobrepeso e a obesidade possa em breve sobrepôr-se a outras preocupações de saúde pública, como a subnutrição ou as doenças infecciosas, enquanto principal causa de problemas de saúde
A obesidade representa um problema de saúde pública devido à sua prevalência, custos e efeitos na saúde
As medidas de saúde pública procuram compreender e corrigir os fatores ambientais responsáveis pela prevalência cada vez maior de obesidade na população
As soluções apontadas procuram alterar os factores que provocam o consumo excessivo de energia e que inibem a atividade física, como por exemplo implementar refeições saudáveis nas escolas, restringir a publicidade a junk food dirigida a crianças, e diminuir o acesso a bebidas açucaradas na escolas
A nível do planeamento urbano têm sido realizados esforços no sentido de aumentar o acesso a parques e criar espaços pedestres.
No conjunto de todos os países europeus, a obesidade é a causa de 10 a 13% das mortes e estima-se que os custos diretos e indiretos com a doença correspondam a 2–8% da despesa em saúde
Os custos diretos e indiretos dos países União Europeia com a obesidade, em 2002, foram superiores a 32,8 mil milhões de euros
No mesmo ano, em Portugal, o custo direto da obesidade foi estimado em 297 milhões de euros (2,5% da despesa total em saúde), valor a que acrescem os custos indiretos de cerca de 200 milhões de euros.
Nos Estados Unidos, estima-se que em 2005 as despesas médicas devidas à obesidade tenham correspondido a 190,2 mil milhões de dólares, valor que representa 20,6% do total em despesas de saúde desse ano
enquanto que no Canadá o custo da obesidade foi estimado em 2 mil milhões de dólares canadianos em 1997 (2,4% dos custos totais)
Nos Estados Unidos, estima-se que a despesa anual em produtos dietéticos seja um valor entre 40 e 100 mil milhões de dólares.
Os programas de prevenção da obesidade reduzem o custo do tratamento de doenças relacionadas com a obesidade
No entanto, o aumento da esperança de vida leva a custos económicos com outras doenças, pelo que os investigadores concluem que embora a redução da obesidade possa melhorar a saúde pública, é pouco provável que haja redução na despesa total em saúde.
A obesidade pode levar ao estigma social e desvantagens no emprego
Alguns estudos verificaram que as pessoas obesas têm menos probabilidades de serem contratadas para um emprego ou de serem promovidas
As pessoas obesas também recebem, em média, ordenados inferiores às pessoas de peso normal para o mesmo posto de trabalho
As mulheres obesas ganham, em média, 6% menos e os homens 3%
Quando comparados com pessoas de peso normal, os trabalhadores obesos têm, em média, maiores taxas de absentismo do trabalho e maior número de baixas médicas, o que aumenta os custos para os empregadores e diminuiu a produtividade
Um estudo verificou que as pessoas com um IMC superior a 40 kg/m acionavam duas vezes mais seguros de trabalho e tinham doze vezes mais faltas ao trabalho em comparação com o grupo com IMC de 18,5–24,9 kg/m
As lesões mais comuns neste grupo deviam-se a quedas ou esforços, afetando principalmente os membros inferiores, pulsos, costas e mãos.
A obesidade também tem impacto económico em setores específicos
Por exemplo, devido ao crescimento da taxa de obesidade, as companhias de aviação têm encargos com combustível cada vez maiores e pressão para aumentar o tamanho dos bancos
Em 2000, o custo acrescido dos passageiros obesos foi estimado em 275 milhões de dólares
Os prestadores de cuidados de saúde também se vêm obrigados a investir em equipamento especial para pacientes com obesidade grave, como por exemplo equipamento elevatório específico ou âmbulâncias bariátricas
Com a classificação da obesidade como doença crónica, pensa-se que as companhias de seguros apresentem maior abertura para cobrir o tratamento, aconselhamento e cirurgia relacionados com a obesidade, e que diminuam os custos com a investigação e desenvolvimento de fármacos ou terapias genéticas caso sejam compartcipados
No entanto, esta classificação não é obrigatória em termos de legislação, pelo que as seguradoras têm o direito de rejeitar a cobertura para este tipo de tratamento.
Existem diversas organizações que promovem a aceitação da obesidade, as quais se tornaram mais proeminentes a partir da segunda metade do século XX
A principal causa do movimento pró-obesidade é diminuir a discriminação em relação às pessoas obesas ou com sobrepeso
Estes grupos muitas vezes defendem o reconhecimento da obesidade enquanto invalidez
No entanto, alguns setores dentro do movimento também tentam questionar a relação estabelecidade entre a obesidade e os efeitos nocivos que provoca na saúde.
As primeiras representações escultóricas do corpo humano, realizadas há 20 000–35 000 anos, representam mulheres obesas
Alguns historiadores atribuem estas estatuetas de Vénus à tendência para enfatizar a fertilidade, enquanto que outros alegam que possam representar a obesidade das pessoas na época
No entanto, este tipo de corpulência não se observa na arte grega ou romana, provavelmente em função dos ideais de moderação destas civilizações
Esta ausência verifica-se também ao longo de grande parte da arte cristã europeia, onde grande parte dos obesos representados correspondiam a pessoas de estratos socioeconómicos inferiores
Durante o Renascimento, alguns elementos da aristocracia europeia começam a ostentar a sua corpulência, como pode ser observado nos retratos de Henrique VIII
Rubens pintava com frequência retratos de corpo inteiro de mulheres obesas, facto que está na origem do termo "rubenesco"
Durante o século XIX a perspetiva ocidental sobre a obesidade alterou-se profundamente
Após vários séculos em que a obesidade era vista como sinónimo de riqueza e estatuto social, a norma social desejável passou a ser a magreza.
No século XXI, a obesidade infantil atingiu proporções epidémicas, com taxas em ascensão tanto nos países desenvolvidos como nos países em vias de desenvolvimento
Por exemplo, a taxa de obesidade entre crianças do sexo masculino no Canadá subiu de 11% na década de 1980 para mais de 30% na década de 1990
No Brasil, no mesmo período, a taxa de obesidade infantil aumentou de 4 para 14%.
Tal como no caso dos adultos, existem diversos factores que contribuem para o recente aumento da obesidade infantil
Acredita-se que as alterações dietéticas e a cada vez menor atividade física sejam as duas causas mais relevantes
Uma vez que em muitos casos a obesidade infantil persiste na fase adulta e está associada a diversas doenças crónicas, as crianças com obesidade são frequentemente examinadas com o intuito de diegnosticar hipertensão arterial, diabetes, hiperlipidemia e fígado gorduroso
O tratamento em crianças passa sobretudo por intervenções ao nível do estilo de vida e técnicas de comportamento, embora as tentativas de fazer aumentar a atividade física em crianças tenham geralmente pouco êxito
Não se encontra aprovada medicação para este grupo etário.
A obesidade em animais de estimação é relativamente comum em diversos países
Por exemplo, as taxas de sobrepeso e de obesidade em cães nos Estados Unidos variam entre 23 e 41%, sendo 5,1% obesos
No caso dos gatos, a taxa de obesidade era ligeiramente superior a 6,4%
O risco de obesidade em cães está relacionado com o facto dos seus donos serem ou não obesos, embora não se verifique esta relação no caso dos gatos.
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


Gravidez é o período de cerca de nove meses de gestação nos seres humanos, contado a partir da fecundação e implantação de um óvulo no útero até ao nascimento
Durante a gravidez, o organismo materno passa por diversas alterações fisiológicas que sustentam o bebé em crescimento e preparam o parto
A fecundação pode dar-se através de relações sexuais ou ser medicamente assistida
Após a fecundação, o óvulo fecundado desloca-se ao longo de uma das trompas de Falópio e implanta-se na parede do útero, onde forma o embrião e a placenta que o alimentará
O desenvolvimento do embrião tem início com a divisão do óvulo em múltiplas células e é nesta fase que se começam a formar a maior parte dos órgãos, muitos deles funcionais
A partir das oito semanas de idade gestacional, o embrião passa a ser designado feto e apresenta já a forma humana que se desenvolverá continuamente até ao nascimento
O parto ocorre em média cerca de 38 semanas após a fecundação, o que corresponde a aproximadamente 40 semanas após o início do último período menstrual
Uma gravidez múltipla é a gravidez em que existe mais do que um embrião ou feto, como é o caso dos gémeos.
Os primeiros sinais que indicam uma possível gravidez são a ausência de menstruação, sensibilidade nas mamas, náuseas, vómitos e aumento da frequência urinária
Uma gravidez pode ser confirmada com um teste de gravidez disponível em farmácias
A gravidez é convencionalmente dividida em três trimestres, de forma a simplificar a referência às diferentes fases do desenvolvimento pré-natal
O primeiro trimestre tem início com a fecundação e termina às doze semanas de idade gestacional, durante o qual existe risco acrescido de aborto espontâneo (morte natural do embrião ou do feto)
Durante o segundo trimestre, o risco de aborto espontâneo diminui acentuadamente, a mãe começa a sentir o bebé, são visíveis os primeiros sinais exteriores da gravidez e o seu desenvolvimento é mais facilmente monitorizado
O terceiro trimestre é marcado pelo desenvolvimento completo do feto até ao nascimento.
Os cuidados de saúde e os exames pré-natais apresentam uma série de benefícios para a saúde da grávida e do bebé
Entre os cuidados de saúde essenciais estão a suplementação com ácido fólico, a restrição do consumo de tabaco, álcool e drogas, a prática de exercício físico adequado à gravidez, a comparência às consultas de acompanhamento e a realização dos exames médicos e ecografias recomendados
Entre as complicações mais comuns estão a hipertensão, diabetes gestacional, anemia por deficiência de ferro e náuseas e vómitos graves
O termo da gravidez ocorre entre as 37 e as 41 semanas
Os bebés que nascem antes das 37 semanas são considerados pré-termo e depois das 41 semanas pós-termo
Os bebés prematuros apresentam risco acrescido de problemas de saúde
A indução de parto e cesariana não são recomendadas antes das 39 semanas, exceto por motivos médicos.
Em 2012 ocorreram 213 milhões de gravidezes, das quais 190 milhões em países em vias de desenvolvimento e 23 milhões em países desenvolvidos
Isto corresponde a 133 gravidezes por cada 1000 mulheres entre os 15 e 44 anos de idade
Cerca de 10 a 15% das gravidezes diagnosticadas terminam em aborto
Em 2013, as complicações da gravidez causaram a morte a 230 000 pessoas, uma diminuição em relação às 377 000 em 1990
Entre as causas mais comuns estão as hemorragias maternas, complicações de um aborto, hipertensão arterial, infeções, e complicações do parto
Cerca de 40% das gravidezes em todo o mundo não são planeadas, das quais metade resultam em aborto.
"Gestação" ou "gravidez" designa a condição de uma mulher ("gestante") que já concebeu e que na qual evolui o produto da concepção
"Gestação a termo" é a gestação com duração entre 37 semanas completas e 42 semanas
"Gestação pré-termo" é a gestação com duração inferior a 37 semanas, enquanto que "gestação pós-termo" corresponde à gestação de período igual ou superior a 42 semanas
A gestante pode ser classificada segundo o número de gestações: "primigesta" é a mulher que se encontra grávida pela primeira vez, "secundigesta" é a mulher grávida pela segunda vez, "tercigesta" pela terceira vez, "quadrigesta" pela quarta vez e assim sucessivamente
A gestante pode ainda ser classificada segundo o número de partos: "nulípara" é a mulher que nunca deu à luz; "primípara" é a mulher que deu uma única vez à luz um feto, com 20 ou mais semanas, vivo ou morto; "multípara" é a mulher que deu à luz duas ou mais vezes.
A "idade gestacional" é a duração da gestação a partir do primeiro dia do último período menstrual normal, sendo medida em dias ou semanas completas
A "fecundação" é a fase da reprodução em que o espermatozoide se funde com o óvulo
Durante as primeiras oito semanas, o produto da fecundação é denominado "embrião"; a partir da oitava semana e até ao parto passa a ser denominado "feto".
O parto pode ser classificado segundo a idade gestacional a que ocorre
Aborto designa a perda da gravidez antes da 20ª semana de gestação, podendo ser espontâneo ou induzido
O "parto pré-termo" é o parto ocorrido entre as 20ª e 37ª semanas de gravidez; o "parto a termo" é o parto ocorrido entre as 37 semanas completas e as 42 semanas incompletas; e o "parto pós-termo" é o parto que ocorre após as 42 semanas completas
O parto pode também ser classificado conforme a sua evolução e resolução
O "parto espontâneo" ou "parto natural" é o parto que ocorre espontaneamente sem qualquer intervenção
O "parto induzido" é o parto provocado por medicamentos ou outras técnicas
O "parto dirigido" é o parto assistido por ação médica
O "parto eutócito", "normal", "espontâneo" ou "fisiológico" denomina a expulsão espontânea do feto por vias normais, enquanto que o "parto distócito" é o parto que decorre de forma anormal
Uma cesariana é uma intervenção cirúrgica destinada a retirar o feto por via abdominal através de uma incisão no útero, quando não é possível ou desaconselhado o "parto vaginal"
Numa "cesariana segmentária" a abertura no útero é feita no segmento inferior, enquanto que na "cesariana corporal" a incisão é feita até ao fundo uterino
"Puérpera" é a mulher que se encontra no "puerpério", o período de 6 a 8 semanas desde o fim do parto até ao momento em que os órgãos voltam ao estado normal anterior à gestação
O "período neonatal" é o período entre o nascimento do bebé e os primeiros 28 dias de vida.
Os primeiros sinais e sintomas de uma gravidez são a ausência do período menstrual, náuseas, vómitos e dor ou sensibilidade nas mamas
Os testes de gravidez biológicos têm uma precisão de 95% e detectam a presença na urina ou no sangue de gonadotrofina coriónica humana, uma hormona produzida pela placenta durante a gravidez
A partir das 16-20 semanas é possível ouvir com um estetoscópio o batimento cardíaco fetal e confirmar em definitivo a gravidez
Ao longo da gestação, as ecografias permitem observar o feto em crescimento e por volta das 18-20 semanas é possível começar a sentir os movimentos fetais.
A maior parte das mulheres grávidas apresenta uma série de sinais e sintomas que podem ser indicadores de uma gravidez
O sinal inicial de gravidez mais confiável e perceptível é ausência de um período menstrual, ou um período muito ligeiro com pouca quantidade de sangue
Entre os sintomas iniciais mais comuns estão o cansaço e fadiga em excesso; náuseas, com ou sem vómitos (durante todo o dia mas principalmente de manhã); sensibilidade ou dor nas mamas (principalmente em mulheres jovens) e aumento da frequência urinária (principalmente durante a noite)
No início da gravidez são também comuns outros sintomas, embora nem sempre se manifestem, como a obstipação, aumento do corrimento vaginal ou ligeira hemorragia 10 a 14 dias após a fecundação, alteração do palato (sabor metálico na boca, desejo por determinados alimentos que não consome regularmente e rejeição de outros), aumento da sensibilidade olfativa (capaz de provocar náuseas), cólicas uterinas ligeiras, tonturas e alterações de humor
No entanto, todos estes sintomas não são exclusivos da gravidez, ao mesmo tempo que é possível estar grávida sem que nenhum destes sintomas se manifeste.
Existem também uma série de sinais associados à gravidez e que se manifestam logo a partir das primeiras semanas após a conceção
No entanto, estes sinais não são universais; isto é, em muitos casos as grávidas não apresentam alguns dos sinais e os sinais que apresentam podem ser diferentes de grávida para grávida
Nos casos em que estes sinais se manifestem isoladamente não é possível determinar um diagnóstico definitivo, mas caso se manifestem vários sinais em conjunto é possível assumir um diagnóstico de gravidez
Estes sinais incluem a presença de gonadotrofina coriónica humana (hCG) no sangue e na urina, hemorragia devido à nidação do embrião no útero na terceira ou quarta semana após o último período menstrual, aumento da temperatura corporal basal de forma sustentada duas semanas após a ovulação, sinal de Chadwick (escurecimento do colo do útero, vagina e vulva), sinal de Goodell (amolecimento da parte vaginal do útero), sinal de Hegar (amolecimento do istmo do útero) e presença da linea nigra (escurecimento da pele ao longo de uma linha no abdómen, provocado pela hiperpigmentação resultante das alterações hormonais, que geralmente se manifesta a meio da gravidez).
Existem, no entanto, uma série de condições médicas cujos sinais e sintomas se podem confundir com os de uma gravidez
A ausência do período menstrual pode ser causada por doença crónica, por distúrbios emocionais ou alimentares ou pela menopausa
As náuseas e os vómitos podem ter apenas origem gastrointestinal, enquanto a sensibilidade nas mamas se pode dever a distúrbios hormonais
As condições que causam congestão pélvica, como o cancro do colo do útero, podem provocar sintomas semelhantes a uma gravidez, e alguns tumores raros produzem falsos positivos nos testes de gravidez
Em alguns casos, mulheres com o forte desejo de engravidar acreditam vincadamente que estão grávidas, apesar de não o estarem, manifestando inclusive algumas das alterações físicas da gravidez, uma condição denominada pseudociese
Por outro lado, e apesar de terem presentes vários sinais, algumas mulheres só se apercebem da gravidez quando esta já está numa fase avançada
Em alguns casos extremos, a mulher só se apercebe da gravidez durante o trabalho de parto
Isto pode ser causado por diversos factores, entre os quais períodos irregulares, alguns medicamentos e mulheres obesas que não dão importância ao aumento de peso
Cerca de 1 em 475 mulheres às vinte semanas e 1 em 2500 mulheres na data do parto recusam reconhecer que estão grávidas.
Os testes de gravidez permitem detectar com bastante precisão uma gravidez a partir do 12º dia posterior à nidação
A maior parte dos testes de gravidez acusa a presença na urina ou no sangue da subunidade beta da gonadotrofina coriónica humana (hCG), uma hormona produzida pela placenta recém-formada
A hCG pode ser detectada após a nidação, que ocorre seis a doze dias após a fecundação
A presença de gonadotrofina coriónica no sangue significa apenas que a mulher alberga tecido placentário vivo, não permitindo determinar a condição do feto
Os testes ao sangue quantitativos têm maior sensibilidade do que os à urina, devido ao menor número de falsos negativos, sendo capazes de detectar quantidades de hCG a partir de 1 mIU/mL, enquanto que as tiras reagentes de urina só detectam a partir de 10 mIU/mL a 100 mIU/mL.
Os testes disponíveis nas farmácias para utilização em casa são testes à urina
Nestes testes, aplica-se uma pequena quantidade de urina numa tira química que, em caso de resultado positivo, muda de cor ou aparece um símbolo, conforme o fabricante
Têm, em média, uma precisão de 95% para uma utilização correta; valor muito idêntico aos testes profissionais em laboratório (97,4%)
A maior parte dos falsos negativos e falsos positivos, que pode atingir os 20% numa utilização típica, tem origem na utilização incorreta do dispositivo, devido aos utilizadores não seguirem corretamente as instruções da embalagem ou fazerem o exame demasiado cedo
A possibilidade de falsos negativos e de falsos positivos, ainda que ínfima numa utilização correta, faz com que o resultado apenas indique uma elevada probabilidade de estar ou não grávida, e não uma garantia absoluta
Os falsos positivos podem dever-se a uma série de razões, entre as quais a utilização incorreta do teste, o uso de fármacos com hCG, como a clorpromazina, fenotiazina ou metadona, e a ocorrência de doenças doenças hepáticas, cancro ou condições médicas que produzem quantidades elevadas de hCG
As mulheres que foram submetidas a uma injeção de hCG no contexto de um tratamento de fertilidade também apresentam sempre resultados positivos, independentemente de estarem ou não grávidas
Um resultado positivo num teste de farmácia pode ser confirmado com um teste de laboratório ou com um exame pélvico realizado por um médico
Por serem qualitativos, os exames de laboratório têm uma precisão ligeiramente superior.
O tempo médio de uma gravidez é de 268 dias (38 semanas e dois dias) contados a partir da ovulação, com um desvio padrão de 10 dias ou coeficiente de variação de 3,7%
A idade gestacional é calculada a partir do primeiro dia do último ciclo menstrual normal da mulher
Escolhe-se este momento porque não existe forma de determinar com precisão a data em que ocorreu a fecundação
A fecundação geralmente ocorre cerca de duas semanas antes do próximo ciclo menstrual, pelo é comum acrescentar 14 dias à idade embrionária para obter a idade gestacional e vice-versa
Assim, na 1ª e 2ª semanas de idade gestacional, a mulher ainda não está grávida
No entanto, o método mais preciso para determinar a idade gestacional é através de ecografia durante o primeiro trimestre de gravidez, o qual tem um intervalo de precisão de sete dias
Ao contrário do cálculo da idade gestacional, em que o evento inicial é o primeiro dia do último período menstrual, no cálculo da "idade fetal", "idade embrionária" ou "idade de fecundação" o evento inicial é a fecundação.
Os obstetras estimam a data prevista de parto (DPP) acrescentando sete dias ao primeiro dia do último período menstrual e mais nove meses de calendário
Por exemplo, se o último período menstrual teve início em 10 de janeiro, a data prevista de parto será 17 de outubro
No entanto, apenas 5% dos nascimentos é que ocorrem na data prevista de parto e em que se completam as 40 semanas de idade gestacional
50% dos nascimentos ocorre entre uma semana antes ou uma semana depois da data prevista
80% ocorre entre duas semanas antes ou depois
Na estimativa da data prevista de parto, as aplicações móveis oferecem estimativas consistentes entre si e corrigem os anos bissextos, enquanto que os discos gestacionais de papel podem apresentar variações até sete dias e geralmente não contabilizam anos bissextos
Uma vez estimada a data do parto, raramente é alterada, já que que a estimativa é mais precisa no início da gravidez.
Ao longo da gravidez, a mulher passa por diversas alterações fisiológicas perfeitamente normais, incluindo alterações cardiovasculares, hematológicas, metabólicas, renais e respiratórias, que asseguram a viabilidade do feto e têm um papel fundamental no caso de complicações
A gravidez é geralmente dividida em três trimestres, cada um com a duração aproximada de três meses
Os obstetras definem cada trimestre com a duração de 14 semanas, num total de 42
Embora não haja limites precisos entre eles, esta distinção é útil para descrever as diferentes alterações fisiológicas e anatómicas que ocorrem em cada um deles.
Uma gravidez tem início com a fecundação de um óvulo (gâmeta feminino) por um espermatozoide (gâmeta masculino)
Ao longo do ciclo menstrual que antecede a gravidez o corpo da mulher sofre alterações no sentido de se preparar para uma possível fecundação
Com a ovulação, o óvulo maduro liberta-se do seu folículo e deposita-se numa das trompas de falópio
Através da ejaculação de sémen durante uma relação sexual são depositados na vagina milhões de espermatozoides, que percorrem todo o útero e trompas de falópio até cercarem o óvulo
Ao entrar na trompa, o óvulo perde a camada exterior de células devido à ação de substâncias nos espermatozoides e no revestimento da parede das trompas
Ao perder a camada exterior, o óvulo permite que alguns espermatozoides penetrem na sua superfície; no entanto, geralmente só um dos espermatozoides é que realiza a fecundação
Depois de penetrar no óvulo, a cabeça do espermatozoide separa-se da cauda
Embora a cauda desapareça gradualmente, a cabeça e o respetivo núcleo sobrevivem
À medida que vai avançando em direção ao núcleo do óvulo, nesta fase designado pronúcleo feminino, a cabeça do espermatozoide aumenta de tamanho e torna-se o pronúcleo masculino
Os pronúcleos unem-se no centro do óvulo, onde a cromatina de ambos se organiza em cromossomas.
O núcleo feminino tem inicialmente 44 cromossomas não sexuais (autossomas) e dois cromossomas sexuais (X, X), num total de 46
Antes da fecundação, uma forma particular de divisão celular denominada meiose reduz para metade (23) o total de cromossomas no pronúcelo feminino, entre os quais apenas um cromossoma sexual X
O gâmeta masculino tem também 44 autossomas e dois cromossomas sexuais (X, Y)
Após a meiose, este número é igualmente reduzido para metade, entre os quais apenas um cromossoma sexual que pode ser X ou Y
Com a união dos pronúcleos feminino e masculino, os cromossomas de ambos unem-se através de um processo denominado mitose
Após a mitose, o óvulo fecundado, agora denominado zigoto, divide-se em duas células-filhas de igual tamanho
O sexo das células-filhas é determinado pelo cromossoma sexual masculino que resultou da meiose, conforme seja X ou Y.
A formação de gémeos depende de eventos ocorridos na fecundação
Os gémeos verdadeiros ocorrem quando, após ser fecundado por um espermatozoide, um óvulo se divide em dois
Os gémeos verdadeiros partilham a mesma informação genética, são do mesmo sexo e têm personalidades semelhantes
Só 2/3 dos gémeos verdadeiros é que partilham a mesma placenta no útero, embora tenham sacos amnióticos diferentes
Os gémeos falsos ocorrem quando a mulher produz dois óvulos distintos que são fecundados por dois espermatozoides diferentes
Os gémeos falsos são tão parecidos entre si como qualquer irmão, podendo ser de sexos diferentes, uma vez que só metade da sua informação genética é igual
Cada gémeo falso tem a sua própria placenta e saco amniótico
A probabilidade de ter gémeos aumenta no caso da mulher estar a ser submetida a tratamentos de fertilidade ou houver antecedentes familiares, especialmente da parte da mãe.
Nos seres humanos, a embriogénese, ou período embrionário, tem início com a fecundação e prolonga-se até ao início do período fetal
Após a fecundação, o zigoto desloca-se lentamente ao longo da trompa de Falópio em direção ao útero
Ao longo desta viagem de mais de uma semana, o zigoto divide-se em células idênticas
Esta divisão celular tem início aproximadamente entre 24 a 36 horas após a fecundação
Ao fim do 4º dia de divisão celular, o zigoto dá origem a uma esfera sólida de 16 ou 32 células denominada mórula
Ao chegar ao útero, cinco dias após a fecundação, esta esfera apresenta-se oca e tem entre 50 e 100 células
Nesta fase passa a ser denominada blastócito, demorando cerca de seis dias até nidificar na parede uterina
O revestimento de proteínas do blastócito dissolve-se, o que permite às suas células trofoblásticas entrar em contacto e aderir às células endometriais da parede uterina
O embrião une-se com o endométrio através de um processo denominado nidação, que ocorre oito a dez dias após a ovulação
Após alguns dias, forma-se o celoma extra-embrionário que se tornará na cavidade coriónica, a qual irá conter o embrião, o líquido amniótico e o cordão umbilical
Desenvolve-se também a cavidade amniótica entre o citotrofoblasto e a massa de células interna
Desenvolve-se também a placa pré-cordal, que indica o futuro local da boca e da região cranial
Nesta fase, o embrião cresce rapidamente e começam a tomar forma as principais características externas
Este processo, denominado diferenciação celular, produz os diferentes tipos de células do organismo.
Durante a quarta semana de idade gestacional (segunda semana de idade embrionária), as células trofoblásticas que envolvem as células embrionárias penetram profundamente no revestimento uterino, formando a placenta e as membranas embrionárias
Começa-se também a formar a vesícula vitelina, as células embrionárias formam um disco embrionário com duas células de espessura, desenvolve-se a linha primitiva e aparecem as vilosidades coriónicas
Na quinta semana de idade gestacional (terceira semana de idade embrionária) tem início a gastrulação, forma-se a corda dorsal no centro do disco embrionário, começa-se a formar o que virá a ser a medula espinal, com uma saliência que corresponderá ao cérebro, e aparecem os primeiros neurómeros
Já no final da semana, começam também a formar-se os vasos do coração primitivo e a desenvolver-se vascularização no disco embrionário.
Embora entre a 5ª e 6ª semana de gestação seja possível detectar atividade elétrica no cérebro, isto é apenas considerado atividade neural primitiva, e não ainda o início do pensamento consciente, algo que só se desenvolverá muito mais tarde
As sinapses só se começam a formar por volta das 17 semanas e, no início da 28ª semana, começam-se a multiplicar a um ritmo acentuado que se prolonga até 3 a 4 meses após o nascimento.
À sexta semana de idade gestacional (quarta semana de idade embrionária), o embrião mede cerca de 4 mm de comprimento e começa-se a curvar em forma de C
O coração desenvolve-se e começa a bater a um ritmo regular, aparece o septo primário e formam-se as cavidades que irão dar origem às estruturas da face e do pescoço, sendo já visível o início da formação dos braços e de uma cauda
O tubo neural encerra, aparecem os primeiros traços do pulmão e do fígado, aparecem ainda as estruturas que formarão o pâncreas e o baço e rompe-se a membrana bucofaríngea que formará boca
Na medula espinal, começa-se a diferenciar o corno anterior e posterior
Durante a sétima semana de idade gestacional (quinta semana de idade embrionária) o embrião mede cerca de 9 mm de comprimento
Nesta semana, começam-se a desenvolver as estruturas que formarão os olhos e o nariz e os brotos das pernas e das mãos
O cérebro divide-se em cinco vesículas, incluindo o telencéfalo primitivo e inicia-se a diferenciação do estômago
Existe já uma circulação sanguínea primitiva entre os vasos que ligam a vesícula vitelina e as vilosidades coriónicas
Inicia-se ainda o desenvolvimento do metanefro, precursor dos rins.
Durante a oitava semana de idade gestacional (sexta semana de idade embrionária) o embrião mede aproximadamente 13 mm de comprimento
Começam-se a formar os pulmões, o sistema linfático e os órgãos genitais externos, sendo também visível a crista gonadal
Os braços e as pernas aumentam de comprimento, sendo agora visíveis as áreas dos pés e das mãos, as quais já têm dedos mas que ainda estão unidos
Durante a nona semana de idade gestacional (sétima semana de idade embrionária) o embrião mede cerca de 18 mm de comprimento, estando já em processo de formação todos os órgãos essenciais
É possível ouvir o som do batimento cardíaco através de doppler e pode ser possível observar movimentos espontâneos dos membros através de ecografia
Começam-se a formar os folículos pilosos e os mamilos, são visíveis os cotovelos e os dedos dos pés e o ducto vitelino é geralmente encerrado
Ao fim da nona semana, decorreram 49 dias desde a fecundação e 63 dias desde o primeiro dia do último período menstrual
Ao longo da décima semana de gestação (oitava semana de idade embrionária), as pálpebras estão mais desenvolvidas e começam-se a fechar e as orelhas e as características faciais tornam-se mais distintas.
Ao fim da décima semana de idade gestacional, o embrião passa a ser denominado feto
Termina assim o período embrionário e inicia-se o período fetal
No início da fase fetal, o risco de aborto diminui acentuadamente
O feto tem agora cerca de 30 mm de comprimento e através de ecografia é possível observar o batimento cardíaco e a realização de vários movimentos involuntários
Entre as 11 e 14 semanas de idade gestacional, as pálpebras do feto estão cerradas e só se voltarão a abrir por volta da 28ª semana
A face está bastante desenvolvida, os membros apresentam-se longos e esguios e o fígado já produz glóbulos vermelhos
Neste intervalo aparecem as unhas nos pés e nas mãos, os órgãos genitais e os brotos para os futuros dentes
A cabeça é proporcionalmente muito grande, cerca de metade do tamanho do feto
Entre as 15 e 18 semanas de gestação o bebé começa-se a mexer e a esticar
A pele é praticamente transparente e surge um tipo de cabelo muito fino denominado lanugo
Desenvolvem-se os tecidos musculares, os ossos tornam-se mais fortes e o fígado e o pâncreas já produzem secreções.
Entre as 19 e as 21 semanas de gestação o bebé já consegue ouvir e é muito mais ativo em relação às semanas anteriores, sendo capaz de engolir
A mãe começa a ter uma sensação semelhante ao bater de asas de borboleta no baixo ventre, que corresponde aos primeiros movimentos do bebé
À 22ª semana, o bebé está mais ativo e algumas mães já conseguem sentir claramente o bebé a mover-se
O lanugo cobre a totalidade do corpo, aparecem as sobrancelhas e as pestanas, as unhas crescem até às extremidades dos dedos, o aparelho digestivo começa a produzir mecónio e é possível ouvir o batimento cardíaco apenas com um estetoscópio
Entre as 23 e 25 semanas, a medula óssea começa a produzir células sanguíneas, desenvolvem-se as vias respiratórias e o feto começa a armazenar gordura
À 26ª semana, as sobrancelhas e pestanas já se encontram formadas, os olhos estão plenamente desenvolvidos e as impressões digitais estão em formação
O feto sobressalta-se em resposta a ruídos altos e formam-se nos pulmões alvéolos, embora o feto não seja ainda capaz de respirar no exterior.
Entre as 27 e as 30 semanas de gestação o cérebro do feto cresce aceleradamente e o sistema nervoso encontra-se suficientemente desenvolvido para controlar algumas funções corporais
As pálpebras são capazes de abrir e fechar e o aparelho respiratório, embora imaturo, produz tensioativos que permitem encher os pulmões com ar
Entre as 31 e 34 semanas o feto cresce muito rapidamente e armazena uma quantidade assinalável de gordura, ferro, cálcio e fósforo
Os ossos encontram-se desenvolvidos, embora sejam ainda moles
O feto começa a respirar de forma ritmada, embora os pulmões não estejam completamente desenvolvidos
Entre as 35 e 37 semanas o feto pesa já cerca de 2,5 kg e continuará a ganhar mais peso, embora provavelmente o comprimento já não deva aumentar significativamente
Devido à gordura acumulada, a pele já não é tão rugosa
O feto tem padrões de sono definidos, o coração e os vasos sanguíneos estão completos e os músculos e ossos totalmente desenvolvidos
Entre as 38 e 40 semanas de gestação, o lanugo desaparece, exceto nos ombros, o cabelo é mais denso e espesso, as unhas crescem para além das extremidades dos dedos e estão presentes mamilos em ambos os sexos
À 40ª semana de idade gestacional decorreram 38 semanas desde a fecundação e o trabalho de parto pode começar a qualquer momento.
Durante a gravidez, o organismo materno passa por diversas adaptações e alterações fisiológicas fundamentais para sustentar o feto em crescimento e preparar o parto
Embora as alterações mais evidentes sejam as decorrentes do aumento do volume uterino, ocorre também um grande número de alterações hormonais, metabólicas, bioquímicas e anatómicas.
O corpo lúteo, que normalmente se desintegra no fim do ciclo menstrual e dá origem à menstruação, é, em caso de gravidez, preservado por hormonas segregadas pela recém-formada placenta
Isto acontece porque o corpo lúteo produz duas hormonas essenciais à gravidez, a progesterona e o estrogéneo, e só após algumas semanas é que a placenta é capaz de produzir estas hormonas de forma autónoma e sem colocar em risco a gravidez
Durante os primeiros meses, o ovário onde se situa o corpo lúteo em funcionamento é consideravelmente maior, normalmente regredindo no fim da gravidez
O papel das trompas de Falópio na gravidez restringe-se à alimentação do zigoto enquanto se desloca entre o ovário e o útero
Ao longo da gravidez, a cor geralmente rosada da vagina altera-se para um tom azulado devido à dilatação dos vasos sanguíneos e, mais tarde, para vermelho devido à maior afluência de sangue
O número e o tamanho das células da mucosa vaginal aumentam, produzindo maior quantidade secreções
A superfície torna-se mais macia, flexível e relaxada com o objetivo de preparar a passagem do feto durante o parto.
O útero é um órgão de forma semelhante a uma pêra, que compreende uma extremidade inferior, denominada colo do útero (ou cérvix), adjacente a uma parte bolbosa maior, denominada corpo do útero
Numa mulher não grávida com cerca de vinte anos, o útero mede aproximadamente sete centímetros de comprimento e pesa cerca de 30 gramas
No termo de uma gravidez, o útero mede cerca de 30 cm de comprimento, pesa cerca de 1200 g e tem uma capacidade líquida entre 4 e 5 litros
Este aumento significativo de tamanho durante a gravidez deve-se ao aumento da quantidade de fibras musculares, vasos sanguíneos, nervos e vasos linfáticos na parede uterina
A própria fibra muscular aumenta entre cinco a dez vezes de tamanho e o diâmetro dos vasos sanguíneos e capilares aumenta consideravelmente
Durante as primeiras semanas de gestação, a forma do útero mantém-se inalterada
Por volta da 14ª semana, o corpo do útero apresenta a forma de uma esfera achatada, enquanto o colo se apresenta muito mais macio e adquire um rolhão mucoso que o protege
À medida que o feto em crescimento vai exigindo mais espaço, o corpo do útero alonga-se e a parede torna-se mais fina
A determinado ponto, sobe para além da pélvis e preenche a cavidade abdominal, exercendo pressão no diafragma e nos outros órgãos
Com a aproximação da data de termo, a cabeça do feto começa a descer em direção à pélvis, fazendo com que todo o útero acompanhe o movimento, dando origem ao que popularmente se denomina "descida da barriga"
No entanto, este processo pode só ocorrer durante o parto ou não ocorrer caso o feto esteja numa posição fora do esperado
No termo da gravidez, o colo do útero vai-se tornando gradualmente mais fino e macio e, durante o parto, dilata para a passagem do bebé.
A placenta é uma estrutura em forma de disco que envolve e protege o feto e o líquido amniótico
No termo da gravidez, pesa entre 500 e 1000 gramas, mede 16 a 20 cm de diâmetro e 3 a 4 cm de espessura
Este órgão encontra-se unido às vilosidades coriónicas que revestem todo o útero, tem aparência lisa e brilhante e é constituída por diversos vasos sanguíneos que se unem no ponto onde começa o cordão umbilical
O sangue materno flui entre os vasos uterinos e o espaço interviloso, onde se acumula
Em cada vilosidade existe uma rede de vasos sanguíneos que fazem parte do sistema circulatório fetal e cuja circulação é impulsionada pelo coração do feto
Esta divisão entre a circulação materna e fetal denomina-se barreira placentária
À medida que a gravidez avança, a barreira torna-se mais fina
Esta barreira impede a passagem de células sanguíneas e de bactérias, embora permita a passagem de nutrientes, sal, vírus, hormonas e diversas substâncias, entre as quais drogas nocivas ao feto.
Na região pélvica, os vasos sanguíneos e linfáticos aumentam de tamanho e desenvolvem novas ramificações de modo a suportar o aumento de fluxo de sangue ao útero e restante órgãos
À medida que a gravidez avança, os músculos, ligamentos e outros tecidos da região tornam-se gradualmente mais pronunciados, elásticos e fortes de modo a permitir que o útero cresça para além da pélvis e que o bebé possa atravessar o canal de parto com maior facilidade
Os ossos pélvicos sofrem poucas alterações durante a gravidez
No entanto, a hormona relaxina relaxa a união entre os ossos frontais da bacia e entre a bacia e o sacro.
Durante o início da gravidez, uma das alterações mais percetíveis nas mamas é o agravamento da sensação de desconforto e saturação características do período pré-menstrual, que é de tal forma específica que pode ser um sinal da gravidez
À medida que a gravidez avança, os seios aumentam de tamanho, a pigmentação da aréola torna-se cada vez mais escura, e as artérias por baixo da pele e as glândulas de Montgomery tornam-se mais proeminentes
Estas alterações são causadas pelo aumento da quantidade de estrogéneo e progesterona no sangue, as quais também preparam o tecido mamário para a ação da hormona prolactina, responsável pela produção de leite após o parto
No final da gestação os ductos lactíferos começam a segregar colostro, um líquido leitoso que servirá para alimentar o bebé nos primeiros dias de vida
A produção de prolactina e a lactação continuam enquanto a mãe continuar a amamentar.
Um dos sinais mais visíveis da gravidez é o aparecimento de estrias nas mamas e nos abdómen, devido ao rompimento das fibras elásticas da pele e à deposição de gordura subcutânea
Após o parto, estas marcas podem-se tornar permanentes, embora não se manifestem em muitas mulheres
Outro sinal universal é o aumento da pigmentação da pele, sobretudo das aréolas e da vulva
Também comuns são a descoloração das palmas das mãos e o aparecimento de vasos sanguíneos avermelhados na pele dos braços e da cara
Durante a gravidez, aumenta também a produção de sebo e suor pela pele, o que pode acentuar o odor
Em alguns casos, o cabelo e as unhas tornam-se mais finos
No entanto, a maior parte destas alterações desaparece após o parto.
Durante a gravidez, a necessidade cada vez maior de sangue, oxigénio e nutrientes por parte do feto e dos tecidos coloca um esforço acrescido no coração da mãe
Entre as 9 e as 14 semanas de gestação, o débito cardíaco começa a aumentar significativamente, só voltando a diminuir perto da data do parto
Entre as 28 e 30 semanas, o esforço do coração é 25 a 30% superior ao período anterior à gravidez, embora o órgão não aumente de volume
No entanto, empurrado pelo diafragma e pelo útero em crescimento, o coração da grávida fica mais perto da parede torácica, o que pode distorcer os sons ouvidos ao estetoscópio
Uma gravidez normal não provoca o aumento da pressão arterial, verificando-se, pelo contrário, uma ligeira diminuição
Aliás, o aumento da pressão arterial é um sinal de alarme, geralmente indicando a possibilidade de pré-eclampsia
Por outro lado, a pulsação arterial é ligeiramente superior durante a gravidez, causada pelo aumento do débito cardíaco, necessário para deslocar o maior volume de sangue
O aumento da circulação de sangue na pele (circulação periférica) causa, em algumas mulheres, o aumento da temperatura da pele, tendência para suar e vermelhidão das palmas das mãos.
A alteração mais perceptível no sistema circulatório é o abrandamento da circulação sanguínea nos membros inferiores, o que leva ao aumento da pressão nas veias e estagnação do sangue nas pernas
Estas alterações são provocadas pela compressão da veia cava inferior pelo útero e pelo aumento da produção de hormonas
Embora sejam cada vez mais proeminentes ao longo da gravidez, podendo causar varizes e inchaço das pernas, estas alterações geralmente desaparecem após o parto
A pressão do útero em crescimento nos vasos linfáticos da pélvis provoca a diminuição da drenagem linfática das pernas, o que causa inchaço e dilatação das pernas e pés
O inchaço generalizado noutras partes do corpo é geralmente um sinal de alarme
O volume plasmático aumenta progressivamente a partir da sexta semana e o volume de hemácias aumenta depois da oitava semana
Ambos os volumes tornam-se estáveis nas últimas semanas, mas, como o aumento do volume plasmático é mais precoce e tende a ser mais acentuado do que o aumento do volume de hemácias, ocorre um efeito de diluição responsável pela chamada anemia fisiológica da gravidez
A alteração dos fatores de coagulação prepara o organismo da mulher para o momento do parto, permitindo controlar rapidamente eventuais hemorragias, embora durante a gestação e puerpério aumente o risco de trombose.
No termo da gravidez, a quantidade de sangue de uma mulher grávida é aproximadamente 25% superior em relação ao estado de não gravidez, de modo a preencher os vasos do útero, a transportar uma maior quantidade de oxigénio e nutrientes para o feto e servir de reserva em caso de hemorragias
Este aumento é consequência do aumento do número de glóbulos vermelhos (20%) produzidos na medula óssea e pelo aumento do volume do plasma (30%), causado pela retenção de líquidos
Esta diferença de valores faz diminuir a viscosidade do sangue e causa uma anemia aparente.
Durante a gravidez, o diâmetro da caixa torácica aumenta, fazendo com que também aumente o volume ocupado pelos pulmões
No primeiro trimestre, a quantidade de ar que é inspirada e expirada por minuto aumenta 40%
Isto deve-se à atuação da progesterona nos centros respiratórios do bulbo raquidiano, o que contribui para o aumento das trocas gasosas na placenta
Imediatamente antes do parto, o número de ciclos respiratórios por minuto é aproximadamente o dobro em relação ao período posterior ao parto.
A intolerância a alimentos gordos, indigestão, desconforto e azia na parte superior do abdómen que se manifestam na maior parte das grávidas são causados por distúrbios na função gástrica
Durante a gravidez, o estômago produz quantidades cada vez menores de ácido clorídrico e pepsina, os quais são necessários para uma digestão adequada e para a regulação da acidez no estômago
Devido ao efeito relaxante da progesterona sobre as fibras musculares lisas presentes em todo o sistema gastrointestinal, os músculos da parede do estômago perdem tensão, o que diminui a sua capacidade de contração e faz com que demore mais tempo a esvaziar o seu conteúdo
A diminuição da tensão muscular também no intestino provoca a diminuição dos movimentos peristálticos
Isto faz com que aumente quantidade de tempo que a comida demora a percorrer o trato intestinal, o que causa obstipação e, consequentemente, hemorroidas, embora o aparecimento destas também se deva à pressão do útero no soalho pélvico
A alteração do paladar e do olfato é relativamente comum durante os primeiros meses de gestação, podendo a grávida passar a achar desagradáveis odores ou alimentos que anteriormente considerava agradáveis e vice-versa
Muitas grávidas queixam-se de inflamações nas gengivas e na boca; no entanto, as causas são geralmente anemia, insuficiência de vitaminas e higiene oral inadequada, e não a própria gravidez.
As várias alterações na bexiga e na uretra são causadas pelo relaxamento dos músculos, por alterações na posição do órgão e pela pressão exercida pelo útero
Durante os primeiros meses, a pressão do útero provoca vontade de urinar frequente que diminui a partir do meio da gravidez, embora possa voltar a ocorrer perto do termo, quando o feto desce
Como consequência das alterações anatómicas, a parede da bexiga torna-se mais espessa com a dilatação dos vasos sanguíneos, retendo líquido, o que provoca inchaço ligeiro e inflamação mecânica da parede
No fim da gravidez, isto pode levar ao aparecimento de inflamações urinárias que se manifestam através de dor ao urinar e que, se não forem tratadas, podem dar origem a problemas urinários mais graves
Como consequência do relaxamento dos músculos que controlam a micção, é comum que a grávida perca alguma urina de forma involuntária ao tossir, espirrar ou rir
À medida que a gravidez avança, os uréteres e a pelve renal dilatam, perdendo capacidade de contração, o que faz com que a urina se acumule e escoe mais lentamente.
A função dos rins é filtrar égua, sódio, potássio, cloretos, proteínas e outras substâncias do sangue, mantendo o equilíbrio eletrolítico e químico do corpo, e recolher excedentes do sangue, expelindo-os através de urina
Durante a gravidez, o esforço que é solicitado aos rins aumenta consideravelmente devido à maior quantidade de água e sangue em circulação
Durante o início da gravidez, a secreção de grande quantidade de urina com pouca acidez, a par da pressão do útero na bexiga, provoca vontade de urinar constante
À medida que a gravidez avança, a acumulação de nitrogénio faz diminuir a excreção de ureia
A presença de proteínas na urina durante a gravidez é, geralmente, um sinal de alarme para a pré-eclampsia ou doenças renais
Durante a gravidez, a capacidade do rim de absorver glicose é menor e a sua presença na urina pode ser indicador de diabetes.
Durante a gravidez, a maior parte das glândulas endócrinas aumentam de tamanho e algumas sofrem modificações funcionais
No início da gravidez, o lobo anterior da hipófise aumenta de tamanho, segregando as hormonas que vão estimular as restantes glândulas endócrinas e, no fim da gravidez, a hormona prolactina que vai estimular a produção de leite
Embora a tiroide aumente de tamanho, não há alterações significativas na sua função
Ao longo da gravidez, aumenta também a produção da hormona aldosterona, responsável pela retenção de sal e água pelo corpo
As ilhotas de Langerhans no pâncreas, responsáveis pela produção de insulina, aumentam de tamanho, de modo a dar resposta à maior necessidade do corpo de produtos resultantes do metabolismo dos hidratos de carbono
A progesterona, em conjunto com a prolactina, induz a maturação das mamas durante a gravidez, o que vai permitir a produção de leite e amamentação após o parto, ao mesmo tempo que inibe a produção até ao momento do parto.
O fígado é responsável por muitos dos processos metabólicos vitais, incluindo a eliminação das substâncias nocivas produzidas pelos processos metabólicos do feto
Durante a gravidez, aumenta de tamanho e peso e os seus vasos sanguíneos dilatam, ajustando-se à maior quantidade de hormonas e glóbulos vermelhos em circulação no sangue
A taxa metabólica basal começa a aumentar a partir do terceiro mês, de modo a responder às necessidades conjuntas da mãe e do feto
O corpo da grávida necessita de maior quantidade de nitrogénio, obtido a partir do metabolismo das proteínas ingeridas e fundamental para o crescimento do feto e dos tecidos
Ao longo da gravidez, a quantidade de lípidos no sangue aumenta de 600–700 mg/dL para 900–1000 mg/dL
Embora os rins processem maior quantidade de sangue, são incapazes de reabsorver a maior quantidade de glicose, pelo que a grávida tolera uma menor quantidade de açúcar no sangue.
A quantidade de água no corpo também aumenta, sendo acrescentados mais 3500-4000 mL de líquido ao já existente nos tecidos
Este acréscimo é retido principalmente pelo útero, pelo líquido amniótico, pelo feto e também pelos músculos, tecidos moles da pélvis e mamas
Entre um a dois meses antes da data de termo, acumula-se nas extremidades inferiores da grávida uma quantidade significativa de líquido, o que causa inchaço das pernas
Esta retenção de líquidos é acompanhada pela retenção de eletrólitos, sobretudo sódio
Quando a retenção de água e sódio é excessiva, verifica-se inchaço generalizado do corpo.
O parto é o processo pelo qual nasce o bebé
Considera-se que a mulher está em trabalho de parto quando começa a sentir contrações uterinas em intervalos regulares e progressivas que gradualmente fazem descer o feto pelo colo do útero e pela vagina (canal de parto) até à sua expulsão para o exterior
Estas contrações são acompanhadas por alterações no colo do útero, o qual dilata e se torna cada vez mais fino até desaparecer
Embora a maior parte dos nascimentos ocorra por parto vaginal, podem surgir determinadas complicações que obriguem à realização de uma cesariana.
 A maioria dos partos tem início num intervalo de duas semanas antes ou depois da data prevista de parto
Na situação mais desejável, o trabalho de parto ocorre de forma espontânea e quando a mulher se encontra na data de termo
A gravidez é considerada a termo quando a gestação durou entre 37 e 42 semanas
Os eventos ocorridos antes das 37 semanas completas são considerados pré-termo e os eventos ocorridos após as 42 semanas são considerados pós-termo
Os bebés nascidos entre as 39 e as 41 semanas de gestação são os que apresentam o melhor prognóstico de saúde possível, em comparação com aqueles que nascem antes ou depois deste intervalo
A não ser que exista uma recomendação médica em contrário, o parto planeado não deve acontecer antes das 39 semanas completas, a apenas com indicação médica e no caso do colo do útero ser favorável.
O parto pré-termo, ou prematuro, está associado a uma série de riscos e problemas, pelo que é evitado sempre que possível até a gravidez se encontrar a termo
No entanto, existem situações em que o parto prematuro é inevitável, como no caso de contrações uterinas ou rotura prematura das membranas antes das 39 semanas
Quando uma gravidez excede as 42 semanas, o risco de complicações para a mulher e para o feto aumenta significativamente
Neste casos, e quando não existam outras complicações, os obstetras geralmente optam por induzir o parto entre as 41 e 42 semanas.
Os primeiros sinais que indicam o início de trabalho de parto são a expulsão do rolhão mucoso, a rotura da bolsa de águas e contrações uterinas em intervalos regulares
A expulsão do rolhão mucoso consiste na expulsão pela vagina de um muco gelatinoso, o qual pode ser rosado ou acastanhado
Esta expulsão pode ocorrer horas ou até mesmo dias antes do parto, significando que o nascimento poderá ocorrer em breve
A rotura da bolsa de águas é a saída do líquido amniótico pela vagina, causada pela rotura das membranas que envolvem o bebé
O líquido amniótico é normalmente claro e transparente e a sua saída pode ocorrer de forma lenta e gradual ou bruscamente e em grande quantidade
No início do trabalho de parto as contrações são irregulares e pouco frequentes e, gradualmente, vão-se tornando mais regulares, intensas e próximas
As contrações do trabalho de parto, regulares e dolorosas, não devem ser confundidas com as contrações de Braxton Hicks, que são contrações irregulares e indolores comuns nas últimas semanas de estação.
Na grande maioria das gravidezes (80-90%), o trabalho de parto começa nas 24 horas a seguir à rotura da bolsa de águas
Geralmente recomenda-se a deslocação para a instituição de saúde onde irá ocorrer o parto quando rompem as águas ou quando as contrações são regulares, dolorosas e com intervalos de dez minutos entre cada uma delas
Na primeira gravidez, o trabalho de parto geralmente não demora mais do que 12-14 horas
Em gravidezes posteriores é mais curto, demorando em média 6-8 horas
Pensa-se que o parto seja provocado pela ação da ocitocina, uma hormona que causa a contração do útero
O trabalho de parto vaginal divide-se em 3 etapas: dilatação, expulsão e dequitadura
Geralmente, as 4 horas posteriores à expulsão da placenta são também denominadas quarta etapa do trabalho de parto.
O período de dilatação é o intervalo de tempo desde o início do trabalho de parto até à dilatação completa do colo do útero (cerca de 10 cm)
Esta etapa é a mais longa do trabalho de parto, podendo ultrapassar as 12 horas no primeiro filho
A etapa de dilatação pode ser dividida em duas fases: a fase latente e a fase ativa
Na fase latente, que dura em média 8,5 horas na primeira gravidez, as contrações do útero tornam-se gradualmente mais intensas e ritmadas, o colo do útero contrai-se e dilata até cerca de 4 cm e a sensação de desconforto ainda é mínima
Na fase ativa, o colo do útero dilata entre 4 e 10 cm e a parte com que o bebé se apresenta (geralmente a cabeça) começa a descer pelo canal de parto, pelo que a mãe começa a sentir a necessidade de fazer força
A fase ativa dura em média 5 horas na primeira gravidez e 2 nas gravidezes seguintes.
Se, ao fim de 24 horas após a rotura das membranas, o trabalho de parto ainda não tiver começado, geralmente é necessária a indução do parto para reduzir o risco de infeção causado pela entrada das bactérias da vagina no útero
O parto é geralmente induzido com a administração de ocitocina
Ao dar entrada no hospital, geralmente com contrações fortes de 5 em 5 minutos e uma dilatação superior a 4 cm, são feitos vários exames e análises de sangue e urina, controla-se o ritmo cardíaco da mãe e do feto e é avaliada a apresentação do feto
Se, durante a rotura das membranas, o líquido amniótico se apresentar com uma coloração esverdeada, significa que o feto defecou mecónio para o líquido e pode ser um indicador de sofrimento fetal.
A fase expulsiva é o intervalo de tempo desde a dilatação completa do colo uterino até à expulsão completa do bebé pela vagina
Esta etapa pode durar até 60 minutos na primeira gravidez e cerca de 15-30 minutos nas gravidezes seguintes
A posição e apresentação do feto determinam como vai passar pela vagina
Nas semanas anteriores ao parto, normalmente o bebé dá a volta para que a cabeça se apresente de frente para a vagina (apresentação cefálica)
Esta é a apresentação mais segura e frequente
A apresentação de nádegas (podálica) e de ombros (transversal) fazem com que o parto seja mais complicado, ao tornarem mais difícil a passagem do feto no canal vaginal
É durante esta etapa que é pedido à mãe que faça força em cada contração, de modo a deslocar o feto pela vagina, descontraindo entre as contrações
Em algumas situações é necessário realizar um pequeno corte cirúrgico do períneo (episiotomia) para evitar rompimentos dos tecidos.
A dequitadura é o intervalo de tempo entre a expulsão do bebé e a expulsão da placenta e normalmente dura poucos minutos
A expulsão da placenta tem início com o desprendimento fisiológico da placenta da parede do útero
Mais de metade das mortes maternas acontece nas 24 horas posteriores ao parto e são causadas principalmente por hemorragias pós-parto
A Organização Mundial de Saúde recomenda que seja feita a gestão ativa da terceira etapa do parto, de modo a diminuir o risco de hemorragias pós-parto
A gestão ativa consiste na administração de uterotónicos durante ou após a expulsão do feto, na remoção controlada do cordão umbilical e da placenta e em massagem uterina.
O puerpério, ou período pós-natal, tem início imediatamente a seguir ao nascimento e prolonga-se por seis semanas
Durante este intervalo, o corpo da mãe regressa ao estado anterior à gravidez, incluindo a alteração na quantidade de hormonas e no tamanho do útero
No período imediatamente a seguir ao nascimento, a libertação de hormonas faz com que a mãe e o bebé criem uma ligação única
A mãe liberta ocitocina, a qual também é libertada durante a amamentação
O contacto entre a pele da mãe e do recém-nascido imediatamente a seguir ao parto apresenta benefícios para ambos: diminui o choro, melhora a interação mãe-filho e ajuda a mãe a conseguir amamentar
A Organização Mundial de Saúde recomenda que se promova o contacto entre a pele da mãe e do recém-nascido nas duas horas imediatamente a seguir ao parto, uma vez que é neste intervalo de tempo que estão mais alertas, em comparação com as horas seguintes.
Uma cesariana é um procedimento cirúrgico em que é feita uma ou mais incisões no abdómen e útero da grávida para fazer nascer o bebé
Este procedimento é geralmente realizado quando um parto vaginal coloca em risco a saúde da mãe ou do bebé
Antes da incisão são administrados antibióticos
É feita uma incisão no útero, a qual é alargada ao longo do eixo céfalo-caudal, sendo depois extraído o bebé e, por fim, a placenta
É usada anestesia local em 95% das cesarianas, sendo as mais comuns a anestesia espinhal e a combinação de anestesia espinhal com anestesia epidural
Em ambas a grávida permanece acordada.
Entre as razões médicas mais comuns que justificam a realização de uma cesariana estão a placenta prévia, infeção por VIH, pélvis contraída, apresentação do feto difícil ou uma cesariana anterior
Entre os potenciais benefícios são citados a maior segurança para o bebé, menor trauma no soalho pélvico para a mulher, conveniência e ausência das dores do trabalho de parto
No entanto, as cesarianas também estão associadas ao aumento do risco de morbilidade ou mortalidade para a mãe, sequelas psicológicas adversas, infeções pós parto e problemas nas gravidezes futuras, incluindo rotura do útero e um risco acrescido de morbilidade neonatal
Pensa-se também que as diferenças fisiológicas da cesariana para o parto vaginal possam ter implicações no bebé, uma vez que a cesariana pode aumentar o risco de problemas de saúde a curto e a longo prazo.
No entanto, e apesar dos riscos, algumas cesarianas são realizadas a pedido da mãe e sem uma razão médica que a justifique
A Organização Mundial de Saúde e as recomendações internacionais alertam para que não sejam realizadas cesarianas antes das 39 semanas e que não sejam realizadas cesarianas sem que exista uma justificação médica
Em muitos países, recorre-se a cesarianas com maior frequência daquilo que é necessário (idealmente entre 10 e 15%), pelo que muitos governos e instituições promovem programas para diminuir a prevalência de cesarianas em relação ao parto vaginal.
Ao longo da gravidez, são realizados de forma periódica vários exames e consultas
Os exames de rastreio destinam-se a avaliar o grau de risco da gravidez e incluem análises ao sangue, análises à urina e ecografias Alguns são exames de rotina realizados em todas as grávidas, enquanto que outros são realizados apenas em determinado grupo de risco
Quando um exame de rastreio indica risco acrescido para determinada doença, geralmente é seguido por um exame de diagnóstico que confirma a presença dessa doença.
A primeira consulta médica durante a gravidez é geralmente realizada entre as seis e oito semanas de gestação, ou entre duas e quatro semanas de atraso do período menstrual
Nesta primeira consulta exaustiva são calculadas a idade gestacional e a data prevista de parto e realizados diversos exames e análises para determinar o estado de saúde da grávida e potenciais riscos à gravidez
Determina-se o peso, altura e a pressão arterial e são examinados o pescoço, tiroide, mamas, abdómen, membros, coração, pulmões e os olhos
São também pedidas análises sanguíneas para a contagem de células, determinação do grupo sanguíneo, antiRH e deteção de doenças sexualmente transmissíveis como a sífilis, hepatite, gonorreia, VIH, rubéola e clamídia
É também realizado um exame ginecológico que determina o tamanho e posição do útero e eventuais anomalias
Pode ser realizado um teste de Papanicolau para a presença de cancro do colo do útero e exames genéticos em mulheres em grupos de risco para o desenvolvimento de fetos com malformações genéticas
Em mulheres negras e de origem mediterrânica podem ser feitos testes à drepanocitose.
As consultas de acompanhamento são geralmente agendadas de quatro em quatro semanas até às 32 semanas de gestação, sendo a partir daí de 2 em 2 semanas até às 36 semanas, e uma vez por semana até ao parto
Nestas consultas são anotados o peso, tensão arterial e tamanho e forma do útero
Em cada consulta é recolhida e analisada uma amostra de urina para detectar a presença de açúcar, que pode ser um sinal de diabetes, e de proteínas, que podem ser um sinal de pré-eclampsia.
Na primeira consulta são geralmente realizadas análises ao sangue de rotina a todas as grávidas
Se a grávida fizer parte de um grupo de risco, podem ser adicionalmente realizadas análises a biomarcadores específicos
Nas situações em que a grávida apresenta um risco acrescido de síndroma de Down, por volta das dez semanas são realizadas análises para determinar o nível das hormonas fetais, da proteína plasmática associada à gravidez (PAPP-A) e da gonadotrofina coriónica humana (HCG)
Por volta das dezasseis semanas, algumas instituições de saúde realizam análises adicionais
Dependendo da instituição e do risco da gravidez, podem ser requisitadas análises para medição da alfafetoproteína (AFP), uma análise tripla (AFP, HCG e estriol) ou uma análise quádrupla (que também analisa a inibina-A)
Quando o fator Rh do sangue da mãe é negativo e existe a possibilidade de doença de Rhesus, geralmente confirma-se a presença de anticorpos antiRh no sangue.
Um valor elevado de alfafetoproteína no sangue da grávida indica uma maior probabilidade de doenças do tubo neural como espinha bífida, anencefalia e outras anomalias no feto
Por outro lado, um valor baixo de alfafetoproteína no sangue em conjunto com um valor elevado de gonadotrofina coriónica humana e um valor baixo de estriol indicam uma maior probabilidade de síndrome de Down
No entanto, existem outras causas que explicam valores elevados: erro no cálculo da idade gestacional, a existência de mais do que um feto, ameaça de aborto ou morte do feto
Em caso de valores elevados, geralmente é recomendada a realização de uma ecografia
No entanto, em 2% dos casos a ecografia não revela a causa do aumento dos valores, situação em que se recomenda a realização de uma amniocentese para medir os valores de alfaproteína no líquido amniótico.
A ecografia é um exame seguro que não implica nenhum risco para a grávida ou para o feto e que permite detectar algumas doenças congénitas durante a fase inicial da gravidez, estimar com maior precisão a idade gestacional e a data prevista de parto e detetar uma gravidez múltipla
A partir das cinco semanas e meia de gestação já é possível observar o embrião
Quando este atinge 5mm é possível observar o batimento cardíaco por ecografia pélvica, embora em alguns casos só seja visível quando atinge os 7mm, o que acontece por volta da 7ª semana
As recomendações internacionais de saúde pública recomendam que seja realizada pelo menos uma ecografia de rotina a todas as grávidas entre as 18 e as 22 semanas de gestação (ecografia do segundo trimestre) e, em países com recursos, que seja também realizada uma ecografia de rotina entre as 11 semanas e as 13 semanas e seis dias de idade gestacional (ecografia do primeiro trimestre)
Em alguns países realiza-se ainda uma ecografia de rotina entre as 30 e as 32 semanas (ecografia do terceiro trimestre)
Em todas as ecografias de rotina de uma gravidez de baixo risco são avaliados o número de fetos e placentas, a atividade cardíaca, os movimentos fetais, a localização da placenta, a quantidade de líquido amniótico e os valores biométricos
Para além destes parâmetros gerais, em cada trimestre são também avaliados parâmetros específicos.
Na ecografia do primeiro trimestre são geralmente avaliados o comprimento crânio-caudal, a frequência cardíaca do feto, a medida da translucência da nuca, se gémeos partilham ou não a placenta (corionicidade) e a anatomia do feto (pólo cefálico, coluna vertebral, estômago, parede abdominal e membros)
O comprimento crânio-caudal permite determinar a idade gestacional com uma precisão ligeiramente superior aos cálculos com base no último período menstrual
Uma vez determinada a idade gestacional por ecografia, não será alterada até ao fim da gravidez
Durante a ecografia do primeiro trimestre é também calculado o risco de trissomia 21
Este risco é calculado através da ponderação conjunta do valor de translucência da nuca medido por ecografia, da idade da mãe e, sempre que possível, do rastreio por análises clínicas da fração livre da gonadotrofina coriónica humana e da proteína plasmática associada à gravidez
Este rastreio combinado identifica 90% dos casos de trissomia 21 e outras principais doenças congénitas.
A ecografia do segundo semestre, ou ecografia morfológica, para além de confirmar alguns dados do primeiro trimestre, destina-se principalmente a identificar malformações do feto
São avaliados o contorno craniano e cérebro, face e pescoço, coração, pulmões, abdómen, coluna vertebral, membros, cordão umbilical e genitais externos
É possível distinguir o sexo do feto por ecografia a partir das 11 semanas de gestação
No entanto, só a partir das 13 semanas é que é possível fazê-lo com uma precisão entre 99% e 100%
Na ecografia do terceiro trimestre são avaliados a apresentação fetal, o perímetro cefálico, perímetro abdominal, comprimento do fémur e vários parâmetros biofísicos.
Os exames de diagnóstico são geralmente propostos a grávidas que apresentem um risco acrescido de doenças cromossómicas
Os fatores de risco mais comuns são a idade superior a 35 anos, antecedentes familiares de doenças cromossómicas, como a síndrome de Down, ou de doenças genéticas, como a fibrose cística, um problema detectado na ecografia ou um risco elevado detectado nos exames de rastreio ou em função de um valor de translucência nucal elevado.
A amniocentese é um exame de diagnóstico utilizado para confirmar a presença de defeitos na espinal medula, de diversas anomalias cromossómicas, como a síndrome de Down, e de doenças autossómicas recessivas como a fibrose cística e a doença de Tay-Sachs
Este exame também permite determinar com 100% de certeza o sexo do bebé
No entanto, nem todas as malformações podem ser detectadas através de amniocentese
O exame consiste na inserção de uma agulha no abdómen para recolha de uma amostra de líquido amniótico
Como este exame apresenta um risco de aborto espontâneo, embora muito baixo (0,06% ou 1:1600), não é um procedimento de rotina e é apenas apresentado como opção a mulheres com idade superior a 35 anos, a mulheres com resultados fora do normal nas análises triplas do primeiro trimestre e a mulheres com historial familiar de determinadas doenças ou malformações
A amniocentese é geralmente realizada a partir das 16 semanas de gestação e os resultados demoram, no mínimo, duas semanas a ser obtidos.
A biópsia das vilosidades coriónicas é um exame de diagnóstico que consiste na recolha de uma amostra das vilosidades coriónicas do útero, as membranas embriónicas exteriores
Embora semelhante à amniocentese, este exame pode ser realizado bastante mais cedo, geralmente entre as oito e doze semanas de gestação, o que em caso de resultados desfavoráveis permite optar pela interrupção da gravidez numa fase precoce
Por ser realizado mais cedo, apresenta um risco de aborto espontâneo significativamente superior ao da amniocentese (1-2%).
Existem diversas medidas que a grávida pode tomar para promover a saúde e o bem-estar dela e do bebé em crescimento
Por outro lado, é também importante que conheça os comportamentos de risco que colocam em risco a saúde do feto
Entre os cuidados de saúde essenciais estão a suplementação com ácido fólico, a abstenção do consumo de tabaco, álcool e drogas, a prática de exercício físico adequado à gravidez, a comparência às consultas de acompanhamento e exames médicos e ecografias recomendados.
Durante a gravidez, é de especial importância seguir uma dieta equilibrada, aumentando a qualidade nutricional dos alimentos de modo a responder às exigências do bebé em crescimento
As necessidades diárias de uma grávida incluem 2-3 doses de proteínas, 2-3 doses de lacticínios e 5 doses de fruta e legumes
Do total de calorias ingeridas por dia, pelo menos um terço devem ser hidratos de carbono complexos; no máximo um terço devem ser lípidos (gorduras); enquanto que o consumo de hidratos de carbono simples (açúcares) deve ser mínimo
No último trimestre, a grávida necessita de aumentar a ingestão diária de calorias de 2000 para 2200.
As proteínas podem ser obtidas de alimentos como o peixe, carne, lacticínios, feijão, leguminosas, lentilhas, nozes e derivados de soja, e o seu consumo durante a gravidez deve aumentar 13%
É importante separar o excesso de gordura da carne e a pele das aves
Devem ser incluídos na dieta uma variedade de lacticínios, especialmente durante o fim da gravidez
Os hidratos de carbono complexos, como o pão, os cereais ou as batatas, que são a base de qualquer dieta, assumem particular importância durante a gravidez, já que devem constituir a principal fonte de energia, em vez das gorduras
Há maiores benefícios no pão escuro ou integral, arroz e massas integrais, batatas, cuscuz e cereais como a aveia, cevada e centeio
As frutas e legumes fornecem vitaminas, sais minerais e fibras
Os citrinos, pêssegos, mangas e quivis fornecem vitamina C que ajuda à absorção de ferro
Entre os alimentos ricos em ácido fólico estão os espinafres (frescos, congelados ou enlatados), legumes verdes (alface, bróculos, espargos), citrinos, melão, grão-de-bico, e ovos.
O ómega-3 DHA é um ácido gordo essencial para o desenvolvimento do cérebro, nervos e retina, estando naturalmente presente no leite materno
É importante que a mulher consuma uma quantidade adequada de ómega-3 durante a gravidez e amamentação, uma vez que os bebés ainda em desenvolvimento não o conseguem produzir de forma eficaz e necessitam de receber este nutriente vital através da mãe
Pode ser obtido a partir dos peixes gordos, como a cavala, arenque, sardinha, salmão, truta, atum fresco, avelãs e nos óleos de colza e de linhaça
Deve-se evitar as gorduras da comida processada e e substituir as gorduras saturadas (como a manteiga, natas ou banha de porco) por gorduras monoinsaturadas (como o azeite) e poliinsaturadas (como o óleo de girassol)
Devem-se evitar os açúcares.
A ingestão adequada de suplementos de ácido fólico (também denominado Vitamina B9) no período periconcecional diminui o risco de malformações fetais graves, principalmente defeitos do tubo neural como a espinha bífida, uma doença congénita grave
O tubo neural desenvolve-se durante os primeiros 28 dias da gravidez, pelo que é importante que a toma de ácido fólico seja iniciada ainda antes da concepção
Alguns micronutrientes são importantes para a saúde do feto em desenvolvimento, principalmente em regiões onde a subnutrição é prevalente
Em países desenvolvidos, como na Europa ocidental e na América do Norte, pode ser necessária a suplementação com determinados nutrientes como a vitamina D e o cálcio, necessários para o desenvolvimento ósseo.
Durante a gravidez, o sistema imunitário da mulher encontra-se diminuído para que o corpo não rejeite o ADN do bebé em crescimento
No entanto, Isto faz com que o corpo esteja também mais susceptível a intoxicações alimentares, pelo que a grávida deve ter cuidados acrescidos com a higiene dos alimentos e evitar o consumo de determinados alimentos
Os alimentos podem ser contaminados por algumas bactérias ou parasitas perigosos para a gravidez, como a Listeria e a Toxoplasma gondii
A lavagem criteriosa da fruta e dos vegetais crus pode remover alguns destes patógenos
A carne crua, a carne processada e todas as sobras de comida devem ser sempre cozinhadas e sempre bem passadas
As mulheres grávidas estão também mais suscetíveis a infeções por salmonelas a partir de ovos ou carne de aves, os quais devem também ser plenamente cozinhados e nunca ingeridos crus.
É seguro comer queijos curados e alguns moles, desde que pasteurizados
No entanto, devido ao risco de listeriose e salmonelose devem ser evitados todos os queijos moles que são amadurecidos na forma, como o brie e o camembert, e todos os queijos que não forem pasteurizados
Só deve ser consumido leite ultrapasteurizado
Devem ser evitados gelados e sorvetes caseiros ou de quiosques
Não se deve consumir qualquer alimento que contenha ovos crus ou mal passados, como a maionese caseira, mousses, ovos cozidos moles, omeletas, ovos mexidos ou escalfados e pratos com ovos pouco cozinhados como o tiramisu, leite-creme e merengues
Devido ao risco de toxoplasmose e listeriose, devem ser evitados todos os legumes e fruta não lavados
Podem ser consumidos desde que sejam cozinhados ou crus, desde que bem lavados em água corrente ou descascados.
Devido ao risco de toxoplasmose e E
coli, não deve ser comida carne crua, mal passada ou pré-cozinhada; carnes fumadas e curadas não cozinhadas, como toucinho, fiambre, presunto e enchidos como o chouriço, salame ou mortadela
Também não deve ser consumido fígado e produtos derivados, devido à elevada quantidade de retinol, nocivo para o bebé em gestação
No entanto, é seguro consumir carne bem cozinhada e carnes curadas, desde que cozinhadas
Pode ser consumido frango cozinhado pré-embalado, desde que aquecido por completo
Devido ao risco de toxoplasmose, não deve ser comido peixe cru, mal passado ou fumado não cozinhado, como sushi ou sashimi
O peixe deve ser bem cozinhado, sendo também seguro consumir peixe enlatado
O tubarão, peixe-espada e o espadarte contêm níveis excessivos de mercúrio
Devido ao risco de salmonelose e campilobactéria deve ser evitado o consumo de marisco cru, como as ostras, e qualquer marisco à venda sem data de validade, embora possa ser consumido marisco bem cozinhado quente
Devem também ser evitados alimentos pré-cozinhados frios, como quiches, devendo ser aquecidos na totalidade para poderem ser consumidos.
A quantidade de peso adquirida durante a gravidez varia de mulher para mulher
Em pessoas com peso normal (IMC de 18,5–24,9), o valor de referência para o ganho total de peso numa gravidez com um único feto é entre 11,3 e e 15,9 kg
Em mulheres com baixo peso (IMC < 18,5), o aumento de peso deve ser entre 12,7 e 18 kg; as mulheres com pré-obesidade (IMC 25–29,9) são aconselhadas a ganhar entre 6,8 e 11,3 kg; e mulheres obesas (IMC ≥30) devem aumentar apenas entre 5 e 9 kg
Um aumento excessivo de peso durante a gravidez potencia o risco de complicações para a mãe e para o bebé, incluindo a necessidade de uma cesariana, hipertensão gestacional, pré-eclampsia, macrossomia fetal e distócia de ombro, enquanto que o aumento insuficiente de peso coloca em risco o fornecimento adequado de nutrientes
A dieta é a forma mais eficaz de diminuir o aumento excessivo de peso durante a gravidez e os riscos associados
No entanto, ainda não é clara qual é a melhor intervenção para ganhar peso em mulheres que não adquirem peso suficiente.
A maior parte do peso é adquirida numa fase avançada da gravidez, e só uma parte desse peso é que se deve ao bebé
Numa gravidez média, o feto, a placenta e os líquidos no útero pesam cerca de 4,5 kg; o aumento de tamanho do útero e das mamas corresponde a cerca de 2,25 kg; e o aumento de líquidos e gordura no corpo a 2,25 kg
Durante o parto, a mulher perde 7 kg e os restantes 2,25 kg de líquidos são eliminados à medida que o útero encolhe
No entanto, caso a mulher não limite a ingestão de calorias após o parto, pode não perder o restante peso.
Muitos medicamentos de venda livre para tratar doenças comuns, como tosse, constipações ou gripe, são nocivos durante a gravidez
O uso recreativo de drogas e o consumo de tabaco e álcool durante a gravidez podem causar diversas complicações graves na saúde do feto.
O uso de determinados fármacos durante a gravidez pode causar efeitos temporários ou permanentes no feto
Muitos médicos optam por não prescrever medicamentos a mulheres grávidas, devido sobretudo ao risco de teratogenicidade desses fármacos
Do ponto de vista da segurança de uso na gravidez, as categorias farmacológicas na gravidez classificam os medicamentos nas categorias A, B, C, D e X
Isto baseia-se no sistema de classificação da Food and Drug Administration norte-americana, o qual tem por base os potenciais benefícios e riscos para o feto
Os medicamentos, incluindo suplementos vitamínicos, que não tenham demonstrado riscos para o feto em estudos controlados em seres humanos são classificados na categoria A
Por outro lado, medicamentos como a talidomida, com riscos que superam todos os benefícios, são classificados na categoria X.
Entre os medicamentos mais comuns, a aspirina deve ser evitada, já que pode afetar a circulação sanguínea
A codeína está associada a algumas deficiências congénitas
O ibuprofeno está associado a problemas no crescimento do coração e do feto
O paracetamol é seguro em pequenas doses, embora a sobredosagem possa causar problemas nos rins e no fígado do bebé
A maior parte dos medicamentos para a tosse, constipação e gripe contêm codeína, aspirina, ibuprofeno ou paracetamol
Os medicamentos para enxaquecas geralmente têm codeína
Os medicamentos para a diarreia não são seguros porque atrasam o funcionamento do estômago e do intestino, já de si lento devido à gravidez
Os laxantes que contêm sene, cáscara ou bisacodil não são seguros, uma vez que estes fármacos podem atravessar a placenta e impedir os intestino de funcionar corretamente, impedindo o bebé de receber nutrientes
Alguns antibióticos são seguros
Os cremes vaporizantes também são seguros
A isotretinoína, usada em alguns medicamentos para o tratamento de acne, é teratogénica, havendo o risco elevado de causar malformações no feto se tomada durante a gravidez.
O consumo de etanol pode provocar síndrome alcoólica fetal
Vários estudos demonstraram que, embora o consumo ocasional de bebidas alcoólicas possa não apresentar riscos imediatos para o feto, não é possível garantir a total segurança do consumo de álcool, mesmo que seja ingerido em quantidades pequenas
Beber sete ou mais bebidas por semana pode ser prejudicial e pode causar restrições de crescimento no feto
O consumo excessivo pode causar dificuldades de aprendizagem, problemas de comportamento e deficiências físicas na criança
As políticas de saúde pública geralmente reconhecem que é pouco provável que o consumo ocasional possa causar problemas, mas que só a abstinência total é que elimina todos os possíveis riscos.
O consumo de tabaco durante a gravidez pode provocar uma série de dificuldades neurológicas, físicas e comportamentais
Fumar durante a gravidez duplica o risco de ruptura prematura de membranas, descolamento prematuro da placenta e placenta prévia
Aumenta também em 30% o risco do bebé nascer de forma prematura
Recomenda-se que durante a gravidez e amamentação seja interrompido o consumo de cannabis, uma vez que esta substância pode estar associada a restrições no crescimento do feto, aborto espontâneo e défices cognitivos na linguagem e atenção, e comportamentos delinquentes mais tarde na vida
O consumo de metanfetaminas pode provocar partos prematuros, doenças congénitas, e, a curto prazo após o parto, pequenos défices na função neurocomportamental e restrição do crescimento da criança, em comparação com a generalidade da população
Acredita-se ainda que o uso pré-natal de metanfetaminas possa ter efeitos a longo prazo no desenvolvimento cerebral.
A exposição intrauterina a toxinas ambientais tem o potencial de causar efeitos adversos no desenvolvimento pré-natal do embrião ou do feto e ainda de causar complicações da gravidez
Entre os potenciais efeitos das substâncias tóxicas e da poluição estão as malformações congénitas e incapacidade mental da criança mais tarde na vida
Entre as condições especialmente gravosas durante a gravidez estão a intoxicação por mercúrio e a intoxicação por chumbo
Algumas recomendações incluem verificar se a habitação foi pintada com tinta de chumbo, sobretudo em casas antigas, lavar todos os alimentos, tentar consumir alimentos biológicos e evitar o contacto com produtos com o rótulo "tóxico" ou qualquer produto com um rótulo de aviso
As fezes dos gatos apresentam um risco particularmente elevado de transmitir a toxoplasmose.
A prática regular de exercício aeróbico durante a gravidez aparenta melhorar ou manter a aptidão física da grávida e inclusive diminuir o risco de cesariana
No entanto, a qualidade das evidências é pouca e os dados são insuficientes para determinar riscos ou benefícios relevantes para a mãe e para o bebé
No passado, pensava-se que eventuais benefícios à mãe não compensavam os potenciais riscos para o feto
No entanto, as informações mais recentes sugerem que em gravidezes sem complicações é muito improvável que surgam lesões no feto, desde que o exercício seja adequado à gravidez
No entanto, há várias circunstâncias em que a grávida deve consultar um médico antes de continuar um programa de exercício: hemorragias vaginais, dispneia antes do esforço, tonturas, dores de cabeça, dores no peito, fraqueza muscular, risco de parto pré-termo, diminuição dos movimentos fetais, fuga de líquido amniótico e dores ou inflamação dos gémeos.
Embora não se tenha ainda determinado um limite seguro de intensidade, as mulheres que praticavam exercício físico regular antes da gravidez, e que não apresentam complicações na gravidez, estão aptas a praticar programas de exercício de alguma intensidade, como jogging ou aeróbica, desde que por períodos não superiores a 45 minutos, desde que estejam conscientes que pode ser necessário aumentar o consumo de energia e desde que tenham o cuidado de nunca sobreaquecer o corpo
Na ausência de outras complicações médicas ou obstétricas, recomenda-se que o tempo de exercício diário não exceda os 30 minutos
A participação em diversas atividades recreativas e desportos aparenta ser segura, desde que se evite aquelas nas quais existe um risco de queda, como esqui ou hipismo, ou atividades onde existe risco de trauma abdominal, como futebol ou hóquei.
Especialmente durante as primeiras semanas, o cansaço pode ser avassalador, pelo que é importante que a grávida descanse o suficiente e esteja relaxada
As técnicas de relaxamento ajudam a diminuir a pressão arterial e a aumentar o fornecimento de oxigénio ao bebé.
Durante as primeiras semanas de gravidez, o ritmo metabólico aumenta 20% e a pressão no útero provoca vontade de urinar frequente, o que diminui o tempo e qualidade do sono
No último trimestre, o volume da barriga torna difícil encontrar uma posição para dormir
Geralmente, recomenda-se que a grávida se deite sobre o lado esquerdo com uma almofada a apoiar a barriga e entre as pernas, que evite bebidas estimulantes como o chá ou café, que permaneça fresca e que realize exercícios ligeiros durante o dia
Tem sido sugerido que, pelo menos durante o último trimestre, se deve evitar o trabalho por turnos e a exposição a luz intensa durante noite, de modo a diminuir o risco de problemas psicológicos e comportamentais no recém-nascido
Tem sido proposto como mecanismo explicativo que o ritmo circadiano da mãe programa o ritmo em desenvolvimento do feto.
A maior parte das grávidas pode manter uma vida sexual ativa ao longo da gravidez
O sexo durante a gravidez é uma atividade de baixo risco, saudável e perfeitamente segura, que relaxa a mulher e ajuda a exercitar o soalho pélvico e os músculos do útero
O bebé está protegido dentro da placenta e o rolhão mucoso impede que o esperma passe para além da vagina
No entanto, há casos em que o profissional de saúde pode recomendar a abstinência sexual por motivos médicos, geralmente quando a grávida tem antecedentes de aborto espontâneo, parto prematuro, hemorragias durante a gravidez ou placenta prévia
É importante que o companheiro sexual nunca exerça pressão sobre o abdómen da grávida, pelo que se recomenda experimentar posições diferentes e descobrir aquelas que sejam mais confortáveis
A maior parte da investigação sugere que durante a gravidez se verifica uma diminuição do desejo sexual e da fequência das relações sexuais
No contexto desta diminuição geral do desejo sexual, alguns estudos indicam porém um aumento do desejo no segundo trimestre e novamente uma diminuição no terceiro trimestre.
Durante uma gravidez normal e sem complicações, são comuns vários incómodos ou desconfortos
Trata-se de manifestações e condições normais que resultam da gravidez, mas que não interferem com as atividades quotidianas nem são uma preocupação para a saúde da mãe e do bebé, ao contrário das complicações da gravidez
No entanto, a separação entre ambas nem sempre é clara e um incómodo com maior gravidade pode ser considerado uma complicação.
Praticamente todas as grávidas manifestam prurido na barriga, provocado pela pele esticada e consequente desidratação, que pode ser aliviado com um creme hidratante
No entanto, comichão frequente nas mãos e nos pés pode indicar colestase
É normal que as sardas e os sinais se tornem mais escuros devido à pigmentação da pele; no entanto, quaisquer alterações no tamanho, forma e cor dos sinais deve ser comunicada ao médico
Em 70% das grávidas aparece uma pigmentação no rosto denominada cloasma e, na parte inferior do abdómen, a linea nigra
São também comuns as erupções cutâneas devido ao calor e o aumento da sudação e do odor corporal
A pele seca é comum e resulta do aumento da quantidade de estrogénio, podendo ser minimizada com a ingestão de bastante água, evitando locais com ar condicionado e radiadores de calor e com a aplicação de creme hidratante
O acne durante a gravidez é perfeitamente normal
No entanto, existem alguns medicamentos para o tratamento de acne que podem provocar malformações graves no feto
Cerca de metade das mulheres desenvolvem estrias que, embora não tenham tratamento, podem ser minimizadas com um creme hidratante gordo.
As dores nas costas são comuns durante a gravidez, podendo ser bastante debilitantes
Manifestam-se entre 35 e 61% das grávidas e metade dos casos ocorre a partir do quinto mês
São causadas pela alteração na postura e podem-se agravar à noite
Entre as várias medidas de alívio comprovadas estão os exercícios na água, massagens e apoio de almofadas ao dormir
As cintas de maternidade não demonstram diminuir as dores nas costas na gravidez, e podem ter alguns efeitos adversos, incluindo dores e irritação na pele da mãe e potenciais efeitos no feto
As cãibras nas pernas ocorrem em metade das gravidezes e podem ser bastante dolorosas
Geralmente manifestam-se durante a noite e podem durar de segundos a minutos
Embora por vezes sejam usados alguns métodos de alívio, como meias de compressão e cálcio ou magnésio, não há evidências de que sejam eficazes a reduzir as cãibras ou que sejam seguros para o feto.
A síndrome do túnel cárpico é uma neuropatia compressiva muito comum durante a gravidez
Manifesta-se em até 62% das grávidas e geralmente ocorre no terceiro trimestre, embora também possa ocorrer no primeiro
Os sintomas são dormência e formigueiro nos dedos polegar, indicador, médio e parte do anelar
Também pode ocorrer dor no pulso e diminuição da força e destreza
Os sintomas são mais pronunciados à noite e podem ser agravados com a atividade física
O tratamento consiste em reduzir a atividade do pulso e a utilização de uma tala que o imobiliza numa posição neutra.
As náuseas e vómitos ocorrem principalmente de manhã, mas geralmente melhoram após o primeiro trimestre
O refluxo gástrico e a azia na gravidez são causados pelo relaxamento do esfíncter esofágico inferior e podem ser aliviadas fazendo múltiplas refeições ligeiras ao longo do dia, evitando comer nas três horas anteriores a dormir e mantendo uma postura direita durante a ingestão
Quando a dieta e as alterações ao estilo de vida não são suficientes, podem ser necessários antiácidos, alginatos ou ainda inibidores da bomba de protões.
A obstipação é um desconforto bastante comum, ocorrendo em 39% das gravidezes às 14 semanas de gestação
Pensa-se que seja causada pela diminuição da motilidade intestinal
Esta diminuição é normal durante a gravidez e deve-se ao aumento da quantidade de progesterona, que relaxa o intestino para que a mãe possa receber mais nutrientes e absorver mais água
Como efeito adverso, as fezes podem-se tornar extremamente desidratadas e de motilidade difícil
A obstipação pode também ser agravada pela suplementação de ferro
As hemorroidas resultam do esforço associado à obstipação ou da pressão intra-abdominal do fim da gravidez
Podem causar hemorragias, prurido, sujidade ou dor e os sintomas podem desaparecer espontaneamente depois da gravidez
O tratamento conservador inclui modificações na dieta, tratamentos locais e estimulantes ou depressores da motilidade intestinal.
Ao contrário dos incómodos e desconfortos, que são normais e não apresentam um risco para a saúde da mãe e do bebé, as complicações da gravidez são problemas de saúde causados pela gravidez
No entanto, a maioria destas complicações pode ser tratada e, mesmo após um aborto, uma mulher pode voltar a ter uma gravidez perfeitamente normal
Os fatores de risco mais comuns numa gravidez são uma idade superior a 35 anos, o consumo frequente de álcool, tabaco e drogas; historial familiar de malformações, síndroma de Down, atraso mental ou doenças congénitas; hipertensão arterial, diabetes, epilepsia, artrite reumatoide, problemas do coração, dos rins ou da tiroide; infecções como a rubéola ou a toxoplasmose, incluindo infeções de transmissão sexual como sífilis ou sida; e desnutrição ou excesso de peso
A grávida apresenta um risco acrescido de contrair determinadas infeções como, por exemplo, gripe, hepatite E, herpes e malária
Isto deve-se ao aumento da tolerância imunológica na gravidez, que impede a reação imunitária contra o feto, e a algumas das alterações fisiológicas maternas, entre as quais a diminuição do volume respiratório e a retenção urinária
A mastite, ou inflamação das mamas, ocorre em 20% das lactantes.
Anemias são doenças em que a quantidade de glóbulos vermelhos ou de hemoglobina é inferior aos valores normais
Durante a gravidez, o tipo de anemia mais comum é a anemia por deficiência de ferro, causada pela insuficiência de ferro ou ácido fólico na dieta
A maioria das gestantes são aconselhadas a tomar suplementos de ferro e ácido fólico para tratar ou prevenir eventuais anemias
Cerca de metade das gravidezes à escala mundial são acompanhadas de anemia
A prevalência varia entre 18% nos países desenvolvidos e 75% no sul da Ásia.
A hiperémese gravídica é a presença de vómitos severos e persistentes, ao ponto de causarem desidratação e perda de peso, o que pode provocar alterações perigosas nos valores de eletrólitos no sangue, lesões no fígado e hemorragias na retina
São mais graves do que os comuns enjoos matinais e estima-se que afetem entre 0,5 e 2% das grávidas
A causa é desconhecida, mas podem-se agravar ou desencadear por fatores psicológicos
O tratamento requer hospitalização.
Cerca de 10% das gravidezes são complicadas por doenças hipertensivas, nas quais se inclui pré-eclampsia, eclampsia, hipertensão gestacional e hipertensão crónica
A pré-eclampsia é uma doença caracterizada por tensão arterial elevada (>140/90 mmHg ou subida considerável da tensão) acompanhada por valores anormalmente elevados de proteínas na urina (>300 mg) e retenção de líquidos na cara e nas mãos
Afeta entre 5 e 8% das gravidezes e geralmente ocorre entre a 20.ª semana de gestação e uma semana após o parto
O risco mais significativo é o desprendimento prematuro da placenta
Geralmente recomenda-se a ingestão de líquidos e o repouso na cama virada sobre o lado esquerdo mas, se a condição não melhorar com rapidez, exige hospitalização
A eclampsia é uma forma mais grave da doença que surge em 0,5% das mulheres com pré-eclampsia, podendo provocar convulsões, coma e morte se não for tratada com rapidez
Um quarto dos casos de eclampsia ocorre após o parto
Ao contrário da hipertensão normal, ambas as doenças não respondem aos diuréticos nem à dieta sem sal
Uma das complicações da pré-eclampsia e eclampsia graves (>160/110 mmHg) é a síndrome HELLP, que é a combinação anemia hemolítica (destruição de glóbulos vermelhos), aumento das enzimas hepáticas (que indica lesões no fígado) e diminuição na contagem de plaquetas (que indica deficiência na coagulação do sangue)
Este síndrome ocorre entre 0,5 e 0,9% de todas as gravidezes.
A doença de Rhesus ocorre quando existe incompatibilidade do grupo Rh entre o sangue da mãe e do feto; ou seja, quando o sangue da mãe é Rh-negativo e o sangue do feto é Rh-positivo, herdado de um pai Rh-positivo
Se o sangue do feto entrar em contacto com o sangue da mãe através da placenta, o que acontece sobretudo durante o parto, o organismo da mãe pode considerar os glóbulos vermelhos do feto elementos estranhos e produzir anticorpos que os vão destruir (anticorpos antiRh)
Se estes anticorpos atravessarem a placenta, podem destruir parte dos glóbulos vermelhos do feto (eritroblastose fetal) ou do recém-nascido (eriotroblastose neonatal)
A destruição dos glóbulos vermelhos pode provocar anemia e aumentar a quantidade de bilirrubina no sangue
Se a bilirrubina for demasiado elevada, pode afetar o cérebro do feto
Nos países ocidentais, em 13% dos casais o homem é Rh-positivo e a mulher Rh-negativa
Um em cada 27 recém-nascidos destes casais desenvolve doença de Rhesus
Na primeira consulta fazem-se análises ao sangue da mãe; se for Rh-negativo confirma-se o sangue do pai e, se este for positivo, mede-se a quantidade de anticorpos antiRh na mãe
Ao longo da gravidez são monitorizados os valores de anticorpos
Se subirem demasiado, faz-se uma amniocentese para medir os valores de bilirrubina
Se ambos os valores forem altos, geralmente são feitas transfusões de sangue intra-uterinas, sendo o parto provocado entre a 32ª e 34ª semana de gravidez.
As dermatoses da gravidez são condições cutâneas que ocorrem apenas durante a gravidez
Entre as mais comuns estão as pápulas e placas urticariformes e pruriginosas da gravidez (PPUPG ou PUPPP) e o prurigo da gravidez
As PPUPG ocorrem numa em cada 160 gravidezes e geralmente manifestam-se no terceiro trimestre ou, mais raramente, após o parto
São caracterizadas por manchas de pápulas e placas eritematosas intensamente pruriginosas, que geralmente aparecem no abdómen superior e se estendem em poucos dias para os braços, coxas e mamas
São tratadas com corticosteroides tópicos e anti-histamínicos orais
O prurigo da gravidez afeta uma em cada 300 grávidas e ocorre com maior frequência entre as 20 e as 34 semanas de gestação
É uma erupção cutânea intensamente pruriginosa com pápulas por vezes foliculares ou lesões nodulares, com ou sem crosta, e que medem entre 0,5 e 1 cm
Geralmente aparece nas pernas e nos membros superiores.
Uma gravidez ectópica é uma gravidez em que o feto se desenvolve fora do útero
Geralmente, desenvolve-se numa das trompas de Falópio, embora em casos raros se possa desenvolver no canal cervical, na cavidade pélvica ou na cavidade abdominal
Durante o desenvolvimento fetal, ao deslocar-se em direção ao útero o óvulo fecundado pode ficar preso na trompa de Falópio e aí se implantar e desenvolver
Esta complicação afeta entre 0,5 e 1% de todas as gravidezes, tendo como fatores de risco uma gravidez ectópica anterior, uma laqueação de trompas mal sucedida ou exposição fetal ao dietilestilbestrol
O risco é elevado no caso da mulher ficar grávida com um dispositivo intra-uterino colocado
Uma gravidez ectópica coloca em risco a vida da mulher e deve ser removida cirurgicamente o mais cedo possível
Os sintomas de uma gravidez ectópica são pequenas perdas de sangue pela vagina e cãibras abdominais, juntamente com o atraso da menstruação
Quando o feto morre numa fase inicial, o organismo tenta expulsá-lo da mesma forma que o produto da menstruação e não se verificam lesões
Mas no caso de continuar a crescer é possível romper as paredes da trompa, causando uma hemorragia interna que provoca dores e sensação de pressão na parte inferior do abdómen
Entre as 6 e as 8 semanas é possível que ocorra uma dor aguda e intensa no baixo abdómen seguida por desmaio.
O desprendimento prematuro da placenta ocorre quando o revestimento da placenta se separa do útero entre as 20 semanas de gestação e o parto
Verifica-se entre 0,5 e 1 em cada 200 nascimentos, sendo uma urgência hospitalar e uma das complicações que mais contribui para a mortalidade materna no mundo
A placenta prévia é a inserção parcial ou total da placenta no colo do útero
É uma das principais causas de hemorragias pré-natais e afeta 1 em cada 200 partos
O sintoma inicial é uma hemorragia vaginal súbita e indolor no fim da gravidez, com sangue de cor vermelho vivo e necessita de cuidados hospitalares.
Aborto espontâneo é a perda de um feto por causas naturais e involuntárias antes das vinte semanas de gestação; a partir das vinte semanas passa a ser denominado feto morto
Aproximadamente 85% dos abortos espontâneos ocorrem durante as doze primeiras semanas de gestação e os restantes entre a 13.ª e 20.ª semanas
Durante as primeiras vinte semanas, 20 a 30% das grávidas manifestam hemorragias ou contrações, das quais metade resulta em abortos espontâneos
Geralmente, os abortos espontâneos devem-se a anomalias no feto
O primeiro sintoma é a perda de sangue pouco abundante o uma hemorragia juntamente com a secreção vaginal
Se o processo de aborto continuar, aumentam as dores, a hemorragia e a secreção, podendo no fim ser expulsa a totalidade ou parte do conteúdo do útero
Quando é expulso na totalidade, geralmente não há necessidade de tratamento; em caso de expulsão parcial geralmente realiza-se uma dilatação e sucção para remover o restante conteúdo
No entanto, quando apenas se verifica uma ameaça de aborto, geralmente aconselha-se repouso absoluto, uma vez que os sintomas costumam melhorar
A ameaça de aborto pode ser causada pela dilatação prematura do colo do útero devido à debilidade do tecido fibroso.
Denomina-se parto distócico o parto que decorre de forma difícil, demorada ou dolorosa
Esta situação acontece quando, apesar do útero estar a contrair normalmente, o bebé não consegue sair da pélvis devido a um bloqueio físico
Entre as complicações para o bebé estão o risco de asfixia, o que pode provocar a morte
Aumenta também o risco da mãe contrair uma infeção, de ter uma ruptura do útero ou de hemorragias pós-parto
Entre as complicações a longo prazo para a mãe estão a fístula obstétrica
Diz-se que o parto é prolongado quando esta fase dura mais do que doze horas.
Entre as principais causas de um parto distócico estão um bebé de grande dimensão, posicionamento do bebé fora do normal, uma pélvis pequena ou problemas com o canal de parto
O posicionamento fora do normal inclui a distócia de ombro, em que o ombro anterior não consegue passar com facilidade pelo osso público
Entre os fatores de risco de uma pélvis pequena estão a desnutrição, a falta de exposição à luz do sol, que provoca deficiência de vitamina D, e uma gravidez na adolescência, já que o osso pélvico pode ainda não estar completamente desenvolvido
Entre os problemas com o canal de parto estão uma vagina e períneo estreitos, os quais se podem dever a mutilação genital feminina ou a tumores
Os partos distócicos podem ser resolvidos com uma cesariana ou extração por ventosa.
A laceração perineal é a laceração não intencional da pele ou dos tecidos moles que se separam a vagina do ânus que geralmente ocorre durante o parto
São classificadas em primeiro grau (afetam a pele e mucosa), segundo grau (músculos perineais) ou terceiro grau (afetam o músculo esfíncter)
Se for uma intervenção cirúrgica provocada por necessidade médica denomina-se episiotomia
Num período de seis meses após qualquer tipo de parto, ocorre incontinência urinária em 3-7% das mulheres e incontinência fecal em 1-3%.
A depressão pós-parto é um episódio depressivo que pode ter início em qualquer momento da gravidez até quatro semanas após o parto
Ocorre em 4-20% das gravidezes, dependendo da definição
Em 28% dos casos de depressão pós-parto, a mulher ainda se encontra deprimida passado três anos
Em 0,2 % das gravidezes, a depressão pós parto leva a psicose
Nos mesmo período de seis meses, 13,6 % das mulheres sofre de stresse pós-traumático.
As doenças intercorrentes na gravidez são doenças ou condições que não são causadas diretamente pela gravidez, mas que durante a gravidez se podem agravar ou constituir um potencial risco para a gravidez
As infeções do trato urinário são mais frequentes durante a gravidez
As infeções agudas da bexiga e dos rins aumentam o risco de parto prematuro
As mulheres que já tiveram pielonefrite numa gravidez anterior têm maior risco de desenvolver infeções agudas noutra gravidez e de desenvolver infeções renais graves, como glomerulonefrite, que aumentam o risco de aborto espontâneo e parto prematuro
Se a mulher tiver tuberculose assintomática nos rins, a gravidez reativa a doença
As doenças gastrointestinais têm pouco ou nenhum efeito sobre a gravidez
No entanto, a gravidez tende a agravar estas doenças
As mulheres com colite ulcerosa são geralmente aconselhadas a evitar engravidar até à doença estar estável por dois anos
Durante a gravidez, o risco de trombose venosa profunda é cinco vezes superior devido a um maior estado de hipercoagulação so sangue, o que é provavelmente uma adaptação do organismo materno contra as hemorragias pós-parto
As mulheres com fatores de risco genéticos também apresentam um risco três a trinta vezes superior.
A gravidez geralmente agrava a diabetes e a doença pode-se tornar evidente durante a gravidez
Se não for tratada, a diabetes na gravidez está associada a uma maior incidência de malformações no feto, aborto espontâneo, natimortos, trabalho de parto prematuro e obesidade fetal
Mesmo com tratamento, mais de metade dos bebés de mães diabéticas têm sobrepeso ao nascer, o que também aumenta o risco de partos complicados
O risco de aborto espontâneo é maior caso a mãe seja diabética desde a infância, tenha diabetes há vários anos ou se tem doenças vasculares ou renais
As grávidas diabéticas apresentam maior risco de pré-eclampsia, eclampsia, infeções e poli-hidrâmnio
Uma tiroide demasiado ativa ou inativa, caso não seja tratada, pode estar associada a um maior risco de aborto espontâneo.
As doenças pulmonares podem constituir um risco para a gravidez no caso de diminuírem a quantidade de oxigénio fornecida ao feto, de causarem uma infeção sanguínea que é transmitida para a placenta e no caso de debilitarem a mãe de forma grave
As doenças do trato respiratório superior geralmente não interferem com a gravidez, a não ser que ocorram muito perto da data de parto, caso em que há a possibilidade de as transmitir para o bebé através dos órgãos genitais ou de contraírem uma infeção no sangue na sala hospitalar
A gripe durante a gravidez aumenta o risco de pneumonia, a qual apresenta um risco elevado de morte materna e fetal se a infeção for resistente a antibióticos
A gravidez tanto pode agravar como diminuir a gravidade da asma, enquanto algumas bronquites podem diminuir a quantidade de oxigénio inalada e fornecida ao feto.
As doenças neurológicas geralmente não têm efeitos sobre a gravidez e vice-versa
No entanto, algumas doenças neurológicas que se desenvolvam durante a gravidez podem ter efeito negativo
A gravidez pode agravar a epilepsia e as mulheres grávidas estão mais suscetíveis a poliomielite, embora não afete o curso da gravidez
A neuropatia periférica, resultante da insuficiência de vitamina B, pode complicar a gravidez, embora não afete a gestação
Perto do termo é comum a ocorrência de neuralgia que afeta principalmente o nervo ciático
Alguns distúrbios psiquiátricos em pessoas instáveis podem ser agravados pela gravidez
No entanto, raramente se manifestam problemas psiquiátricos sérios pela primeira vez durante a gravidez e as doenças psiquiátricas raramente têm influência na gestação.
Em 2012, ocorreram cerca de 213 milhões de gravidezes em todo o mundo, das quais 190 milhões em países em vias de desenvolvimento e 23 milhões nos países desenvolvidos
Isto corresponde a cerca de 133 gravidezes por cada 1000 mulheres entre os 15 e 44 anos de idade
Entre 10 e 15% do total de gravidezes terminam em aborto (espontâneo ou voluntário)
Cerca de 40% das gravidezes não foram planeadas
Cerca de metade das gravidezes não planeadas terminam em aborto
Em cada ano, estima-se que morram em todo o mundo cerca de 270 000 pessoas devido a complicações da gravidez.
A taxa de gravidez, assim como a idade a que ocorre, varia de país para país e de região para região e é influenciada por diversos fatores culturais, sociais e religiosos, pelo acesso à contraceção e pelo acesso à educação
Do total de gravidezes em 2012, 120 milhões ocorreram na Ásia, 54 milhões em África, 19 milhões na Europa, 18 milhões na América do Sul e Central, 7 milhões na América do Norte e 1 milhão na Oceania
No conjunto dos países em vias de desenvolvimento a taxa de gravidez é de 140 por cada 1000 mulheres em idade fértil, enquanto nos países desenvolvidos é de 94 por cada 1000
Em 2013, estimava-se que a maior taxa de fecundidade total pertencia ao Níger (7,03 crianças/mulher) e a menor a Singapura (0,79 crianças/mulher).
Em cada ano, cerca de 20 milhões de mulheres em todo o mundo são afetadas por complicações de uma gravidez
Em 2013, este tipo de complicações provocou a morte a 293 000 pessoas, uma diminuição em relação às 377 000 mortes em 1990
As causas de morte mais comuns são hemorragias obstétricas (44.000), complicações de abortos (44.000), pressão arterial elevada (29.000), sépsis neonatal (24000) e distócia (19.000).
Apesar de a reprodução ser um fenómeno essencialmente biológico, existem muitos fatores socioculturais influenciam o sucesso reprodutivo e o prognóstico da gravidez
Entre os fatores mais importantes estão a estrutura familiar e a situação conjugal
No entanto, esta estrutura familiar varia imenso consoante a época e a região
Em muitos países industrializados, a estrutura familiar tem-se alterado significativamente nas últimas décadas
Existe uma tendência para maior informalidade e instabilidade nas relações e para o aumento da idade do primeiro filho
O número de gravidezes de mães não casadas tem aumentado significativamente e é cada vez maior o número de crianças nascidas fora do casamento
Muitas religiões e cultos tradicionais associam à gravidez um significado espiritual profundo enquanto realização do mais elementar propósito do matrimónio
Neste processo de santificação, a gravidez é muitas vezes descrita como uma "bênção de Deus", "milagrosa" ou "divina"
A maior parte dos casais religiosos considera o casamento e a gravidez imbuídos de características sagradas.
Durante a gravidez começam-se a desenvolver os laços afetivos entre a mãe e o filho, principalmente após a observação da primeira ecografia e a sensação dos primeiros movimentos do bebé entre as 18 e as 25 semanas
Acredita-se que o feto em desenvolvimento é capaz de ouvir a voz e batimento cardíaco da mãe, podendo responder com pontapés ou movimentos voluntários
Ao sétimo mês de gravidez, dois terços das mães indicam possuir já uma forte ligação com o bebé
Nem todas as novas mães sentem um amor intenso e imediato pelo filho
Nestes casos, os laços afetivos vão-se fortalecendo ao longo do tempo
Os laços afetivos maternos são uma experiência que se vai desenvolvendo gradualmente e que pode demorar dias, semanas ou meses para se desenvolver.
O apoio do pai e a relação estreita com a mãe desempenham um papel significativo no bem-estar da gravidez, na saúde do feto, na paternidade, no ajustamento do casal e no desenvolvimento da criança
Apesar disso, o pai é frequentemente marginalizado da saúde reprodutiva e só muito recentemente é que o seu papel tem sido valorizado durante a gravidez e parto
O envolvimento paterno pode ter uma influência positiva durante a gravidez, podendo ser uma fonte de apoio
Em termos biológicos, os pais atravessam diversas alterações relacionadas com a gravidez ao nível da prolactina, cortisol e testosterona, que contribuem para o sentimento de fazer parte da gravidez
A presença, envolvimento e responsabilidade do pai tem impacto no desenvolvimento da cognição e linguagem da criança
Hoje em dia, em alguns países, os futuros pais são encorajados a acompanhar a mãe nas consultas pré-natais e a estarem presentes no parto e são propostas medidas que eliminem barreiras ao envolvimento paterno durante a gravidez e nascimento.
Na mulher, infertilidade é a incapacidade de engravidar ou de prosseguir uma gravidez até ao termo
No homem, é a incapacidade de fecundar o óvulo
Existem várias causas para infertilidade, incluindo algumas que podem ser tratadas através de reprodução medicamente assistida
Embora o intervalo de tempo para que se possa diagnosticar infertilidade possa variar entre países, a Organização Mundial de Saúde define infertilidade como a incapacidade de conceber uma gravidez clínica após doze ou mais meses de relações sexuais desprotegidas, sem que haja outros problemas de saúde
A infertilidade pode ter várias causas: infecções sexualmente transmissíveis que afetam o aparelho reprodutor como a clamídia, gonorreia, sífilis ou Mycoplasma genitalium; causas genéticas; e ambientais, como os danos ao ADN provocados pelo stress oxidativo ou pelo tabagismo.
Estima-se que um em cada sete casais tenha problemas de fertilidade
A infertilidade pode ter consequências psicológicas e sociais, como o aumento da ansiedade e dificuldades matrimoniais entre o casal, depressão, estigma social e disfunções sexuais
No entanto, os progressos na reprodução medicamente assistida oferecem uma esperança para muitos casais, embora existam barreiras em termos económicos e de disponibilidade em muitos países
O tratamento depende da causa de infertilidade, mas pode incluir aconselhamento profissional, medicação de fertilidade, cirurgia ou tratamentos de fertilidade, como a fertilização in vitro e a inseminação artificial
Os casais são geralmente aconselhados a procurar ajuda profissional ao fim de dois anos a tentar engravidar ou ao fim de um ano caso a mulher tenha mais de 30 anos de idade.
Embora as adolescentes grávidas enfrentem os mesmos desafios do que as restantes mulheres, existem riscos médicos acrescidos para as grávidas com idade inferior a 15 anos e riscos associados a fatores socioeconómicos para as mães entre os 15 e 19 anos de idade
Em países desenvolvidos, a gravidez na adolescência está muitas vezes associada a problemas sociais, incluindo menor nível de educação e maior pobreza, e ocorre geralmente fora do casamento, o que pode constituir um estigma social em muitas comunidades e culturas
A gravidez na adolescência é prevenida com educação sexual abrangente e acesso a métodos contracetivos
A educação sexual baseada apenas na abstinência sexual não aparenta ser eficaz.
Aborto é a interrupção da gravidez resultante da expulsão do feto ou do embrião do útero antes do momento de viabilidade fetal, ou do momento em que é capaz de sobreviver fora do útero
O aborto pode ocorrer de forma involuntária e espontânea, sendo denominado aborto espontâneo (ou interrupção involuntária da gravidez), ou pode ser induzido, sendo nesse caso denominado aborto induzido (ou interrupção voluntária da gravidez)
O uso do termo "aborto" geralmente refere-se a este último caso
Os métodos modernos recorrem a medicamentos abortivos ou cirurgia para induzir o aborto
Durante o primeiro trimestre, é comum a utilização de mifepristona e prostaglandina
Embora durante o segundo semestre os medicamentos sejam igualmente eficazes, a cirurgia apresenta menor risco de efeitos adversos
Uma vez realizado um aborto, os métodos contracetivos podem ser retomados de imediato
Quando permitido pela legislação, o aborto em países desenvolvidos é uma das intervenções médicas mais seguras que existem
Um aborto sem complicações não causa qualquer problema mental ou físico a longo prazo.
A Organização Mundial de Saúde recomenda que todas as mulheres tenham acesso a abortos legais e seguros
Todos os anos, os abortos feitos de forma insegura causam a morte a mais de 47 000 grávidas e são responsáveis por 5 milhões de entradas no hospital
No entanto, as perspetivas legais, culturais ou religiosas sobre o aborto são diferentes em todo o mundo
Enquanto em alguns países o aborto é legal, em outros é legal apenas em casos especiais como violação, malformações do feto, pobreza, risco para a saúde da mãe ou incesto
Existe um debate contínuo sobre os problemas morais, éticos e legais do aborto
As pessoas que se opõem ao aborto alegam que um embrião ou um feto é um ser humano com direito à vida
Por outro lado, os apoiantes mencionam os direitos humanos e o direito à mulher tomar as decisões sobre o seu próprio corpo.
A gravidez indesejada pode ter várias causas, incluindo a não utilização, utilização incorreta ou falha nos métodos contracetivos
Por sua vez, a não utilização ou utilização incorreta de contracetivos podem ser motivadas por falta de conhecimento sobre saúde reprodutiva, incluindo crenças erradas, a falta de disponibilidade, a crença equivocada de que a mulher é infértil
A gravidez indesejada pode também ser o resultado de coerção e violência contra a mulher, incluindo violação e gravidez forçada, que muitas vezes ocorre no contexto de violência doméstica.
A discriminação laboral na gravidez e na maternidade é uma situação frequente em vários locais no mundo
Entre algumas formas de discriminação estão a decisão de não contratar uma grávida apesar de ser a pessoa mais qualificada para determinado posto de trabalho, a decisão de não renovar um contrato por razões relacionadas com a gravidez ou perder o direito a bónus do emprego devido a complicações da gravidez ou à licença de maternidade
Também é comum algumas seguradoras terem um período de carência relativamente grande em situações de gravidez
Nos últimos vinte anos tem vindo a ser aprovada, principalmente na União Europeia, legislação e iniciativas de combate à discriminação da gravidez.
A licença parental é um direito no emprego existente em praticamente todos os países
A Convenção sobre a Eliminação de Todas as Formas de Discriminação contra as Mulheres determina que, após o parto, todas as mulheres têm direito a uma licença remunerada sem o risco de perder o posto de trabalho, a antiguidade no emprego ou prestações sociais
A Convenção da Proteção da Maternidade, adotada em 2000 pela Organização Internacional do Trabalho, determina uma duração mínima de 14 semanas para a licença de maternidade
A Carta dos Direitos Fundamentais da União Europeia afirma que a licença parental remunerada e a proteção do posto de trabalho a seguir à maternidade são direitos humanos.
A anomalia da tolerância à glicose (ATG) ou tolerância diminuída à glicose (TDG) existe quando os valores da glicemia em jejum são superiores a 6,1 mmol L (110 mg/ dL) e e inferior 7,0 mmol L (126 mg/ dL)
Assim, quando a glicemia do paciente se encontra entre esses valores, é necessário realizar uma prova de tolerância à glicose oral para confirmar o diagnóstico de diabetes mellitus.
A anomalia da tolerância à glicose (ATG) ou tolerância diminuída à glicose (TDG) existe quando os valores da glicemia em jejum são superiores a 6,1 mmol L (110 mg/ dL) e e inferior 7,0 mmol L (126 mg/ dL)
Assim, quando a glicemia do paciente se encontra entre esses valores, é necessário realizar uma prova de tolerância à glicose oral para confirmar o diagnóstico de diabetes mellitus.
Rosiglitazona (maleato) é um fármaco da classe dos antidiabéticos
Teve sua venda proibida na Europa pela EMEA e nos Estados Unidos a venda foi restrita, pelos riscos cardiovasculares que apresenta
No Brasil a Anvisa determinou a retirada do medicamento das farmácias e drogarias, cancelando seu registro em 29 de setembro de 2010.


O fármaco pertence a classe química das tiazolidinedionas
Provoca redução dos níveis de glicose circulante e torna as células (hepática, muscular e adiposas) mais sensíveis a insulina Atua nos receptores da insulina e também reduz a gliconeogênese hepática.
Na gravidez foi detectado que o fármaco possui risco de toxicidade para o feto
Em testes com animais, foram encontrados concentrações de rosiglitazona no leite.

POM (UK) ℞-only (US)
A metformina (DCI; comercializada como Glifage, Dimefor, Glucoformin, Glucophage, entre outras marcas, e como medicamento genérico) é um antidiabético oral da classe das biguanidas
É um dos medicamentos de escolha no tratamento do diabetes mellitus tipo 2 especialmente em pessoas obesas ou com sobrepeso
É o antidiabético mais usado no Brasil e nos Estados Unidos (onde foi prescrita quase 35 milhões de vezes em 2006 como genérico)
A metformina e a glibenclamida (uma sulfoniluréia) são os únicos antidiabéticos orais constantes da Lista de Medicamentos Essenciais da Organização Mundial de Saúde
No Brasil, faz parte do programa Farmácia Popular do Ministério da Saúde.
Os efeitos colaterais comuns da metformina são poucos e de gravidade quase zero, pode surgir no inicio do tratamento : cólicas, diarreia, às vezes enjoo e vômitos, e geralmente restringem-se ao início do tratamento
A metformina é um dos poucos antidiabéticos que não provocam hipoglicemia (motivo pelo qual é às vezes classificada como normoglicemiante e não hipoglicemiante) e não provoca aumento de peso
O cloridrato de Metformina pode também ser usado em casos de gordura no figado (esteatose hepática) mas os estudos científicos ainda não mostraram benefício definitivo nesta condição
Muito se fala sobre um possível efeito redutor de peso da metformina mas isso não corresponde a realidade sendo considerada uma droga de efeito neutro no peso corporal
Também não é verdade que a metformina promoveria uma perda de gordura corporal.
A metformina parece agir de três maneiras distintas:
Ela diminuiria a absorção dos carboidratos a nível intestinal
Reduz a produção de glicose pelo fígado
O fígado utiliza parte da sua alimentação para fazer uma reserva de glicose
Assim, quando seu organismo passar por uma situação de estresse, o fígado vai liberar esta reserva de glicose, como uma fonte extra de energia, para o cérebro e os músculos trazendo a queima acelerada da gordura abdominal.
Aumenta a captação da glicose periférica, melhorando a ligação da insulina aos seus receptores
Aumentaria a sensibilidade das células à insulina
A insulina é o hormônio responsável pela colocação da glicose do sangue dentro das células do organismo para que seja gasta como combustível ou estocada
Resistência à insulina é uma disfunção onde quantidades excessivas de insulina são necessárias para colocar a glicose dentro das células.
A circulação de grandes quantidades de insulina no organismo pode levar à obesidade, a certos tipos de câncer e problemas cardiovasculares
Além disto, a situação sobrecarrega o pâncreas que pode, assim, envelhecer mais cedo e cessar a produção de insulina, tornando o indivíduo diabético.


O desenvolvimento da classe das biguanidas foi derivado do estudo dos efeitos da planta Galega officinalis, amplamente usada na Europa desde a Idade Média como um tratamento popular para a poliúria do diabetes
Mais tarde, descobriu-se o composto químico responsável pelo efeito hipoglicemiante da planta – denominado galegina –, um derivado da guanidina
A guanidina por si só é tóxica demais para ser usada como medicamento, mas o desenvolvimento de agentes derivados persistiu, e em 1957 foi publicada a primeira descrição científica da metformina
A metformina entrou em uso clínico pela primeira vez na França, em 1979; nos Estados Unidos, foi aprovada somente no final de 1994, devido a preocupações de longa data a respeito da segurança das biguanidas.
A principal indicação para a metformina é o diabetes mellitus tipo 2, principalmente em pessoas obesas e quando acompanhado de resistência à insulina
A metformina reduz a ocorrência de todas as complicações do diabetes, inclusive as complicações cardiovasculares, e parece ter a melhor relação risco-benefício dentre todos os antidiabéticos, mesmo os de desenvolvimento mais recente (carece de referência)
Ao contrário das sulfoniluréias, a outra classe de medicamentos mais utilizada contra o diabetes, a metformina por si só é incapaz de provocar hipoglicemia, pois não aumenta e não estimula a secreção de insulina (embora raríssimos casos de hipoglicemia após exercício físico intenso tenham sido relatados); portanto, é às vezes considerada um "normoglicemiante"
A metformina não causa aumento de peso, e pode mesmo provocar discreto emagrecimento
Também reduz os níveis de ácidos graxos livres, e pode reduzir discretamente os níveis de LDL e triglicérides.
A metformina também está indicada e é eficaz no tratamento da síndrome do ovário policístico (SOP), na qual a resistência à insulina parece ser um fator fundamental
O National Institute for Health and Clinical Excellence, agência governamental do Reino Unido, recomenda que mulheres com síndrome do ovário policístico e índice de massa corpórea (IMC) acima de 25 recebam metformina quando outros tratamentos não surtirem efeito
Vem sendo estudado o uso da metformina na doença hepática gordurosa não-alcoólica (DHGNA) e esteatoepatite não-alcoólica (NASH, EENA ou EHNA) e na puberdade precoce, três doenças que também envolvem resistência à insulina
Entretanto, a metformina ainda não foi aprovada para tais usos, e um estudo piloto demonstrou que seu benefício na DHGNA pode ser apenas passageiro.
O mecanismo de ação da metformina ainda é incerto, apesar de meio século de uso e benefícios terapêuticos bem caracterizados
A principal responsável pela atividade hipoglicemiante da metformina parece ser uma redução da produção de glicose no fígado (neoglicogênese), além de diminuição da absorção de glicose no trato gastrointestinal e aumento na sensibilidade à insulina, devido ao maior uso da glicose pelos músculos
A taxa de neoglicogênese de uma pessoa "média" com diabetes pode ser três vezes maior que a de uma pessoa sem a doença; a metformina é capaz de cortá-la em mais de 30%.
Um estudo publicado em 2001 demonstrou que a metformina estimula a função de uma enzima denominada AMPK, que desempenha um importante papel no metabolismo de lipídeos e da glicose
Os alvos moleculares com os quais a metformina interage diretamente ainda são desconhecidos.

Os efeitos adversos mais comuns da metformina são de natureza gastrointestinal – náuseas, vômitos, diarréia, gases, cólicas, e falta de apetite – e são mais freqüentes no início do tratamento ou após um aumento na dose
A metformina parece provocar desconforto gastrointestinal mais freqüentemente que a maior parte dos outros antidiabéticos
Em um estudo clínico norte-americano de 286 pacientes, mais da metade dos que receberam metformina relataram diarréia, contra pouco mais de 11% dos que receberam placebo, e um quarto dos pacientes relatou náuseas ou vômitos, contra pouco mais de 8% dos que tomaram o placebo.
Embora a metformina seja bem tolerada pela maior parte das pessoas, seus efeitos gastrointestinais podem ser bastante desconfortáveis; pode-se evitá-los começando o tratamento com uma dose baixa e aumentando-a gradualmente (titulação)
Desconforto abdominal após uso crônico (prolongado) é raro.
O uso prolongado da metformina está associado a um aumento nos níveis de homocisteína no sangue e a má-absorção da vitamina B12
Quanto maior a dose de metformina e o tempo de uso, maior a incidência de deficiência de vitamina B12; alguns autores recomendam estratégias de prevenção.
O efeito adverso potencial mais grave da metformina é a acidose láctica ou lactoacidose
Entretanto, é bastante rara, e parece ocorrer apenas em pessoas com comprometimento da função renal.
Outra biguanida, a fenformina, foi retirada do mercado em vários países (inclusive os Estados Unidos, Portugal e Brasil) devido a um risco inaceitável de provocar acidose láctica
A metformina, no entanto, é mais segura, e já se demonstrou que ela não aumenta a incidência de acidose láctica quando são respeitadas as contra-indicações conhecidas.
Um relato de caso norte-americano envolvendo quatro pessoas com disfunção da tireóide sugere que a metformina pode suprimir os níveis de hormônio tireoestimulante (TSH), sem sintomas de hipertireoidismo ou aumento apreciável nos níveis de tiroxina
O mecanismo pelo qual o efeito é produzido, bem como sua importância clínica, ainda é desconhecido.
A freqüência e gravidade dos efeitos adversos em crianças parecem ser semelhantes às em adultos.
A cimetidina (utilizada no tratamento da úlcera péptica) aumenta a concentração de metformina no sangue, pois torna a remoção de metformina pelos rins mais lenta
Tanto a metformina como a cimetidina (principalmente a forma catiônica, ou positivamente carregada, desta) são excretadas pelos rins do mesmo modo, e podem competir pelos mesmos mecanismos celulares de transporte
Um pequeno estudo duplo-cego demonstrou que o antibiótico cefalexina também aumenta a concentração de metformina, de modo semelhante; teoricamente, muitos fármacos catiônicos (como a digoxina, a morfina, o quinino e a vancomicina) podem produzir o mesmo efeito
A furosemida, um diurético, interage com a metformina; a concentração e a meia-vida da furosemida são reduzidas, enquanto a concentração de metformina aumenta, sem alteração de sua remoção do organismo.
O uso de metformina está contra-indicado em pessoas com qualquer doença que possa aumentar o risco de acidose láctica, como diminuição da função renal (níveis de creatinina no sangue acima de 1,4 a 1,5 mg/dl, embora tais limites sejam arbitrários), doenças do fígado, e estados associados à hipóxia (doenças pulmonares, sepse, infarto do miocárdio)
Há muito tempo a insuficiência cardíaca tem sido considerada uma contra-indicação à metformina, mas uma revisão sistemática publicada em 2007 demonstrou que a metformina é o único antidiabético oral não prejudicial a pessoas com insuficiência cardíaca.
Recomenda-se a suspensão temporária do uso da metformina antes de qualquer exame radiológico (como tomografia ou angiografia) no qual se utilize contraste iodado, pois o meio de contraste pode provocar um comprometimento temporário da função renal, causando um acúmulo de metformina no organismo e indiretamente levando à acidose láctica
No Brasil, recomenda-se que a metformina seja interrompida dois dias antes do exame, embora isso nem sempre seja possível (por exemplo, quando o exame precisa ser realizado em caráter emergencial)
Também se recomenda que o uso de metformina seja retomado após não menos de 48 horas, e contanto que a função dos rins esteja normal.
A metformina é administrada por via oral, na forma de comprimidos
Existem formas de liberação imediata (mais comuns) e prolongada, nas dosagens de 500, 850 e 1000 miligramas
A dose máxima recomendada é de 2550 mg.
As formas de liberação prolongada (por exemplo, Glifage XR da Merck) têm o intuito de reduzir os efeitos adversos e tornar o tratamento mais fácil
Em termos de eficácia, não há diferença entre a metformina de liberação imediata e a de liberação prolongada
No Brasil, tanto a metformina normal como suas formas de liberação prolongada fazem parte do programa Farmácia Popular do Ministério da Saúde
Genéricos da metformina estão disponíveis em muitos países, inclusive no Brasil e em Portugal.
A metformina é freqüentemente prescrita em combinação com outros antidiabéticos, como sulfoniluréias, rosiglitazona e pioglitazona (tiazolidinodionas que também aumentam a sensibilidade à insulina) e medicamentos mais recentes como a vildagliptina e a sitagliptina
Algumas dessas combinações estão disponíveis comercialmente, unindo ambos os medicamentos em um mesmo comprimido
A metformina também pode ser usada em conjunto com a insulinoterapia.
Doses e Administração da Metformina
Bula de Metformina - Portal Anvisa
Sociedade Portuguesa de Diabetologia
Sociedade Brasileira de Diabetes
243–244 °C 


℞ Prescription only
A azatioprina é um análogo sintético da purina e foi desenvolvida no final dos anos 50, na tentativa de impedir a degradação metabólica da 6-mercaptopurina (6-MP), o que destituía seus efeitos antileucêmicos
Atualmente, a azatioprina é usada em dermatologia, gastroenterologia, oncologia, reumatologia e várias outras áreas da medicina, devido às suas propriedades antileucêmicas, antiinflamatórias e imunossupressoras.
A azatioprina é bem absorvida pelo trato gastrintestinal após a administração oral
Tem uma curta meia-vida de cerca de três horas, como resultado de uma rápida conversão in vivo, mas os metabólicos permanecem ativos por muito tempo, o que permite que a administração do fármaco seja feita a cada 12 ou 24 horas
Ao entrar na circulação, a azatioprina sofre conversão não-enzimática e é metabolizada por três enzimas.


É sabido que a azatioprina pode causar efeitos colaterais hematológicos a partir de citopenias isoladas até grave depressão da medula óssea, o que pode levar à hospitalização e, raramente, à morte
A incidência destes efeitos secundários varia entre os estudos (5-25%)
O acompanhamento contínuo hematológico é necessário, para se identificar o início tardio de eventos leucopênicos
Muitos casos de citopenia irão se resolver com a redução da dose ou com a descontinuação do tratamento.
Os efeitos adversos gastrintestinais compreendem as queixas mais comuns
Os pacientes tipicamente se queixam de náuseas e/ou diarreia
Estes sintomas geralmente ocorrem durante as primeiras semanas da terapia e podem se resolver ao longo do tempo.
A azatioprina é tóxica para o fígado
Esta toxicidade é, geralmente, observada pela elevação dos testes de função hepática
Um estudo com 28 pacientes dermatológicos observou que nove destes desenvolveram reações adversas, dos quais, dois apresentaram anormalidades na função hepática.
A imunossupressão crônica aumenta o risco de um doente desenvolver um câncer
O exato risco do desenvolvimento de malignidades associadas ao tratamento dermatológico com a azatioprina é desconhecido
Um relatório sugeriu que os doentes em terapia dermatológica em longo prazo com azatioprina podem estar em risco para o desenvolvimento do carcinoma de células escamosas, especialmente se o paciente tiver história de exposição excessiva ao sol.
A hipersensibilidade é caracterizada principalmente por febre, náuseas, vômitos, diarreia, exantema e, ocasionalmente, choque
Embora relativamente incomum, é uma complicação potencialmente séria
A hipersensibilidade geralmente ocorre em quatro semanas do início da terapêutica e somente em alguns casos ocorreu poucas horas após a ingestão da primeira dose.
Interações fármaco-fármaco são um problema comum que os médicos têm que estar conscientes quando prescrevem qualquer medicamento
Vários medicamentos são conhecidos em interagir com a azatioprina
Provavelmente, uma das mais conhecidas interações seja com o alopurinol, que inibe a xantina oxidase (XO)
A combinação de azatioprina e alopurinol aumenta o risco de um indivíduo desenvolver mielotoxicidade grave
Se houver necessidade da prescrição do alopurinol, a dose da azatioprina deverá ser reduzida em dois terços
Além disso, contagens hematológicas deverão ser realizadas com freqüência
Sulfassalazina, inibidores da ECA e o trimetoprima-sulfametoxazol também foram relatados em poder causar o aumento do risco da mielotoxicidade induzida pela azatioprina.
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}



POM (UK) ℞-only (US)
A Ciclosporina é uma droga imunossupressora, da classe dos inibidores de calcineurina, isolada do fungo Tolypocladium inflatum, habitante do solo
A ciclosporina suprime as reações imunológicas que causam rejeição de órgãos transplantados, reduzindo a probabilidade de rejeição, com a vantagem de não apresentar os efeitos colaterais indesejáveis de outras drogas usadas para esse fim
A ciclosporina tornou-se disponível em 1979, possibilitando o retorno às atividades de transplante anteriormente abandonadas
Como resultado do uso da ciclosporina, as cirurgias bem-sucedidas de transplantes tornaram-se corriqueiras.
Por muitos anos foi considerado medicamento de primeira escolha na linha terapêutica, mas, devido diversos eventos adversos, atribuídos ao seu uso, entre eles a hiperplasia gengival vem sendo substituida por outros medicamentos da mesma classe terapêutica, como tacrolimo.


O efeito imunossupressivo da ciclosporina foi descoberto em 31 de janeiro de 1972 por empregados da Sandoz (hoje Novartis) em Basileia, Suíça, em um teste de imunodepressão projetado e realizado pelo doutor Hartmann F
Stähelin
O sucesso da Ciclosporina A na prevenção da rejeição de órgãos foi demonstrado em transplantes de fígado realizado pelo doutor Thomas Starzl, do Hospital da Universidade de Pittsburgh
O primeiro paciente, em 9 de março de 1980, foi uma mulher de 28 anos
O uso da Ciclosporina foi subsequentemente aprovado em 1983.
A ciclosporina é um imunomodulador específico com ação na inibição de linfócitos T.
Desde o início da década 1970, a ciclosporina teve indicação para tratamento da psoríase moderada a grave - doença sistêmica imunomediada - com excelentes resultados no controle clínico das lesões, sendo utilizado em doses baixas semanais e sem os efeitos tóxicos no fígado
É necessário controle com exames bioquímicos antes e durante o uso
Também é eficaz para alguns casos de artrite psoríasica, segundo consensos internacionais como do GRAPPA.
Nefrotoxicidade, hepatotoxicidade, neurotoxicidade, hipertricose, hiperplasia gengival, piora da hipertensão arterial sistêmica, náusea, vômito, anorexia, diarreia, dor abdominal, colite, hipomagnesemia, hipocalemia ou hipercalemia, hiperuricemia, hipercolesterolemia, fraqueza muscular, cãimbras, miopatia, tremor, tonturas, cefaleia, parestesia, convulsões, confusão mental, fadiga, aumento de peso, dismenorreia ou amenorreia, ginecomastia, trombocitopenia, pancreatite, distúrbios linfoproliferativos e neoplasias.
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


Uma doença autoimune é qualquer condição que tenha origem numa reação imunitária anormal em que o corpo ataca uma parte normal do seu próprio organismo (autoimunidade)
Existem pelo menos 80 tipos de doenças autoimunes
Praticamente qualquer parte do corpo pode ser afetada
Embora os sintomas dependam da condição, existem sintomas comuns à maioria das doenças autoimunes, como febre pouco elevada e fadiga
Em muitos casos os sintomas aparecem e desaparecem ciclicamente.
As causas são geralmente de origem desconhecida
Algumas doenças autoimunes, como o lúpus, são familiares, enquanto outras podem ser desencadeadas por infeções ou outros fatores ambientais
Entre as doenças mais comuns de origem autoimune estão a alopécia areata, doença celíaca, diabetes mellitus tipo 1, doença de Graves, doença inflamatória intestinal, esclerose múltipla, psoríase, artrite reumatoide ou lúpus eritematoso sistémico
Em muitos casos é difícil determinar o diagnóstico.
O tratamento depende do tipo e da gravidade da doença
Em muitas doenças é comum a administração de anti-inflamatórios não esteroides e imunossupressores
Em alguns casos também é administrada imunoglobulina por via intravenosa
Embora os tratamentos melhorem os sintomas, geralmente não existe cura para as doenças autoimunes.
Cerca de 7% da população dos Estados Unidos (24 milhões de pessoas) são afetadas por uma doença autoimune
As doenças são mais comuns entre mulheres do que entre homens
Geralmente têm início em idade adulta
As primeiras doenças autoimunes foram descritas no início do século XX.
Em ambas as doenças autoimunes e inflamatórias, a condição surge através de reações aberrantes do sistema imunológico adaptativo ou inato humano
Na autoimunidade, o sistema imunológico do paciente é ativado contra as próprias proteínas do corpo
Nas doenças inflamatórias crônicas, os neutrófilos e outros leucócitos são recrutados constitutivamente por citocinas e quimiocinas, levando ao dano tecidual
A mitigação da inflamação pela ativação de genes anti-inflamatórios e a supressão de genes inflamatórios em células imunes é uma abordagem terapêutica promissora
Há muitas evidências de que, uma vez que a produção de autoanticorpos tenha sido inicializada, os autoanticorpos têm a capacidade de manter sua própria produção.
Uma dose diária de bicarbonato de sódio pode ajudar a reduzir a inflamação destrutiva de doenças autoimunes, como a artrite reumatóide
Evidências científicas de como o antiácido barato e vendido sem receita pode estimular o baço a promover um ambiente antiinflamatório que pode ser terapêutico diante de uma doença inflamatória
O transplante de células-tronco também está sendo estudado e tem mostrado resultados promissores em alguns casos.
O ronco ou ressono (acto de ressonar) é uma obstrução parcial das vias respiratórias superiores durante o sono, que pode ocorrer em razão natural do contato das paredes musculares da faringe que tem diminuição do seu tónus induzido pelo repouso e a própria perda de elasticidade que acontece com o decorrer da idade; ou decorrente de uma obstrução nasal devida, a aumento do volume de secreções e produção de muco, a desvio de septo nasal, rinites, sinusites, pólipos nasais; à hiperplasia das amígdalas e adenoides, como ganho de massa gordurosa no pescoço; e a várias alterações das estruturas das vias aéreas superiores, como hipoplasia de mandíbula e maxila, macrogrossia, queixo duplo, alterações nos ossos da face entre outros
O ronco geralmente é a manifestação inicial de um problema mais sério que é apneia do sono.


O sono provoca o relaxamento dos músculos do tórax,o que induz a abertura involuntária da boca; como também altera a coordenação entre a contração do diafragma e dos músculos da garganta (faringe)
Quer dizer, que em repouso há diminuição do gasto energético e consequentemente do oxigénio
O organismo se encontra em metabolismo basal, os músculos ficam todos relaxados e se tem períodos de apneia várias vezes durante o sono, e que pode se estabelecer na síndrome de apneia do sono
O que acontece é que a obstrução que caracteriza o ronco, e devida ao colabamento das paredes da faringe, há uma hipoventilação alveolar e que tende para hipoxemia e hipercapnia, o que termina em esforço respiratório e que faz a pessoa despertar, durante o qual ocorrem as contrações musculares que abrem as vias aéreas superiores, restabelecendo a respiração
A obstrução, faz com que o ar encontre uma resistência a sua passagem, e ainda ao passar pela língua, na úvula e nas amígdalas
Por isso, vibra, ocasionando um barulho desagradável e com efeitos negativos na vida pessoal - estudos comprovam que é um dos fatores que levam ao divórcio de vários casais
A obesidade também é um grande fator, principalmente no homem onde o ganho de peso é comum no pescoço, toráx e abdome, ou seja, nas partes mais superiores do corpo; ao passo que na mulher isto não é comum, localizando o ganho de peso nos quadris, coxas, seios, pernas e abdome; parte mais inferiores do corpo
E é esta gordura toracoabdominal que atrapalha nas contrações diafragmáticas e empurra este para cima interferindo na respiração
A gordura abdominal é uma grande preocupação e se caracteriza como um fator de risco
Ela dificulta a circulação e sobrecarrega o aparelho cardiovascular e consequentemente o pulmonar
Por último, deve-se ficar atento ao um caso especial onde o ronco pode sugerir uma doença de neurodeficiência muscular, conhecida por garganta flácida
Nesta, há diminuição do tónus muscular da faringe, mas de ordem patológica, o que leva ao contacto (colabamento) das suas paredes e ocasiona a vibração por obstrução na passagem do ar, caracterizando-se pelo ronco.
Em estudos populacionais, estima-se que 19% das mulheres e 30% dos homens ronquem intensamente
Estima-se que a apneia do sono, por sua vez, ocorra em 2 a 4% da população geral, sendo mais comum nos homens de meia idade ou velha idade
(Knuiman, 2005; Reimão, 1996).
Discuta com seu médico sobre a necessidade de fazer o exame de polissonografia se você ronca e tem:
Nesses casos, a chance de que a polissonografia diagnostique apneia do sono é alta.
A apneia do sono aumenta o risco de morte, e de ter hipertensão, infarto do miocárdio, AVC (derrame cerebral), arritmia no coração e acidente de carro.
Apneia do sono é um distúrbio do sono caracterizado por episódios repetitivos de pausas na respiração ou períodos de respiração pouco profunda durante o sono
As pausas podem ocorrer várias vezes por noite e causam frequentemente dessaturação de oxigénio e microdespertares
Cada pausa pode durar de alguns segundos a alguns minutos
É comum que estas pausas sejam antecedidas por roncos ruidosos
Assim que a respiração regressa à normalidade, a pessoa pode emitir sons semelhantes a um engasgo ou grunhido
Uma vez que a apneia interfere com a qualidade do sono, as pessoas afetadas podem sentir-se sonolentas ou cansadas durante o dia
Em crianças, a condição pode ser a causa de problemas escolares ou hiperatividade.
Existem três formas de apneia do sono: "obstrutiva" (ASO), "central" (ASC) e uma conjugação das duas denominada "mista" (ASM)
Na ASO, a respiração é interrompida por um bloqueio das vias aéreas, enquanto na ASC a respiração é interrompida devido à falta de esforço respiratório
A ASO é a forma mais comum
Entre os fatores de risco da ASO estão a obesidade, historial da condição entre a família, alergias, pouco calibre das vias aéreas ou amígdalas aumentadas
As pessoas com apneia do sono podem não se aperceber de que têm a condição
Na maioria dos casos, a condição é observada pelo cônjuge ou um membro da família
A apneia do sono é muitas vezes diagnosticada com a ajuda de uma polissonografia
Para o diagnóstico de apneia do sono devem verificar-se mais de cinco episódios por hora.
O tratamento inclui alterações no estilo de vida, dispositivos bucais, dispositivos para ajudar a respirar e intervenções cirúrgicas
Entre as alterações no estilo de vida estão evitar o consumo de bebidas alcoólicas, perder peso, parar de fumar e dormir de lado
Entre os dispositivos para ajudar a respirar está o uso de um dispositivo de ventilação por pressão positiva contínua
Sem tratamento, a apneia do sono pode aumentar o risco de enfarte do miocárdio, acidente vascular cerebral, diabetes, insuficiência cardíaca, arritmia, obesidade e acidentes de trânsito.
A ASO afeta entre 1 e 6% dos adultos e 2% das crianças
A condição afeta duas vezes mais homens do que mulheres
Embora possa afetar pessoas de qualquer idade, é mais comum entre os 55 e 60 anos de idade
A apneia do sono central afeta menos de 1% das pessoas.


A falta de fluxo de ar adequada geralmente resulta em dessaturação da oxihemoglobina e, no caso de eventos prolongados, em aumento progressivo da pressão parcial de dióxido de carbono no sangue arterial (PaCO2)
Na maior parte das vezes, as apneias não são suficientes para despertar a pessoa, mas há uma alteração no padrão de sono, passando do sono profundo para um sono mais superficial
Como este sono não é repousante, as manifestações típicas são uma sensação de "noite mal dormida" ao despertar, assim como fadiga e sonolência durante o dia
O diagnóstico é confirmado através da polissonografia ou por um estudo cardio-respiratório, comummente conhecido como "estudo do sono".
Níveis clinicamente significativos de apneia do sono são definidos como cinco ou mais episódios por hora de qualquer tipo de apneia, através do estudo do sono
Existem três formas distintas de apneia do sono: central, obstrutiva e mista ou complexa (i.e., uma combinação da central e obstrutiva)
Na apneia do sono do tipo central, a respiração é interrompida pela "falta de esforço respiratório"; na apneia do sono do tipo obstrutivo, a respiração é interrompida por um bloqueio físico ao fluxo aéreo "apesar de esforço respiratório"
Na apneia do sono complexa (ou mista), há uma transição de características centrais para obstrutivas durante os eventos.
Em qualquer um dos tipos, o indivíduo com apneia do sono está raramente consciente de que tem dificuldade para respirar, mesmo depois de acordado
Apneia do sono é, muitas vezes identificada como um problema por outras pessoas que testemunham o indivíduo durante os episódios (durante o sono) ou porque apresentam sintomas típicos da patologia
Os sintomas podem estar presentes por anos (ou mesmo décadas) sem identificação.
Dos fatores predisponentes incluem-se:
Aumento da complacência das vias aéreas superiores por:
Na infância:
Apneia e hipopneia estão frequentemente correlacionados com:
Logo, é recomendado fazer um exame de polissonografia para diagnóstico de apneia do sono nos pacientes com diabetes, obesidade, hipertensão, insuficiência cardíaca, infarto, fibrilação atrial, AVC ou acidente vascular cerebral (derrame cerebral)
Especialmente após os 60 anos em pessoas acima do peso.
O fechamento parcial das vias aéreas superiores é definido como hipopneia, enquanto que o fechamento total constitui uma apneia
Nos fechamentos parciais, temos como principal manifestação o ronco, devido à produção de som pelo turbilhonamento alterado do ar expirado
Existe um espectro de doença desde o ronco normal e assintomático até o quadro completo de SAHOS
O ronco pode preceder e evoluir para SAHOS, sendo que a obesidade e o envelhecimento contribuem para isso.
Ocorrem frequentemente durante o sono REM e nos estágios 1 e 2 do sono NREM
As que ocorrem durante o sono REM costumam ser mais graves e duradouras.
O diagnóstico da apneia do sono é feito através de polissonografia.
O principal sintoma da apneia do sono é a sonolência intensa durante o dia
Esta sonolência pode levar a acidentes de automóvel ; ao sono intenso em horas inadequadas, como no trabalho ou na sala de aula
As outras manifestações da doença incluem o ronco (com pausas respiratórias, as apneias); e dificuldade de manter a concentração e a atenção pela sonolência diurna
Ao dormir, têm também movimentos muito frequentes, durante toda a noite, associados às pausas respiratórias (apneias)
(CAPLES, 2005; REIMÃO, 1996)
As apneias podem ser classificadas como obstrutivas, centrais ou mistas:
A gravidade da SAHOS é classificada conforme o índice de apneia e hipopneia (IAH - número de hipopneias e apneias por hora):
Medidas gerais:
Tratamento mecânico:
Tratamento cirúrgico:
Entre a população geral casos de apneia-hipopneia variam de 1% a 8% em homens e de 1,2% a 2,5% em mulheres, subindo para 10% da população acima de 65 anos e para 46% entre motoristas profissionais
Os primeiros relatos na literatura médica do que hoje é chamado de apneia obstrutiva do sono datam de 1965, quando foi independentemente descrito por pesquisadores franceses e alemães
Entretanto, o quadro clínico dessa condição já era reconhecido há bastante tempo como um traço pessoal, sem uma compreensão do processo patológico
O termo Síndrome de Pickwick, que é algumas vezes usado para a síndrome, foi cunhado pelo médico famoso do século 20 William Osler, que deve ter sido um leitor de Charles Dickens
A descrição de Joe, "o garoto gordo" no romance de Dickens "The Pickwick Papers", é uma figura clínica acurada de um adulto com síndrome da apneia do sono obstrutiva.
Os primeiros relatos na literatura médica descreviam indivíduos que eram muito gravemente afetados, frequentemente se apresentando com hipoxemia grave, hipercapnia e insuficiência cardíaca congestiva
Traqueostomia era o tratamento recomendado e, ainda que pudesse salvar a vida do paciente, as complicações no estoma eram frequentes nesses indivíduos muito obesos e de pescoço curto.
O manejo da apneia obstrutiva do sono foi revolucionado com a introdução do CPAP, primeiramente descrito em 1981 por Colin Sullivan e associados em Sydney, Austrália
Os primeiros modelos eram volumosos e barulhentos, mas o design foi rapidamente melhorado e, no final da década de 1980, CPAP foi amplamente adotado
A disponibilidade de um tratamento efetivo estimulou uma busca agressiva por indivíduos afetados e levou ao estabelecimento de centenas de clínicas especializadas dedicadas ao diagnóstico e tratamento de distúrbios do sono
Embora muitos tipos de problemas do sono sejam reconhecidos, a vasta maioria de pacientes que procuram esses centros têm problemas com sono relacionados à respiração.
O tabagismo é uma toxicomania caracterizada pela dependência física e psicológica do consumo de nicotina, substância presente no tabaco.
Segundo o Ministério da Saúde do Brasil, os cigarros contém cerca de 4720 substâncias tóxicas, sendo uma delas, a nicotina, responsável pela dependência.
De acordo com a Organização Pan-Americana da Saúde (OPAS), o tabagismo é o responsável por cerca de 30% das mortes por cancro (câncer no Brasil), 90% das mortes por cancro do pulmão, 25% das mortes por doença coronariana, 85% das mortes por doença pulmonar obstrutiva crónica e 25% das mortes por derrame cerebral
Ainda de acordo com a OPAS, não existem níveis seguros de consumo do tabaco.
As doenças ocasionadas pelo consumo de tabaco matam 4,9 milhões de pessoas por ano, o que significa cerca de 10 mil mortes por dia, com uma projeção estimada de óbitos em torno de 10 milhões até o ano 2030 - das quais 7 milhões ocorrerão nos países em desenvolvimento e metade dos afetados em idade ativa dos 35-70 anos
Vale a pena sublinhar que o tabagismo, hoje, mata mais que a soma das mortes por AIDS, cocaína, heroína, álcool, suicídios e acidentes de trânsito
As doenças causadas pelo tabaco são responsáveis por perdas econômicas de aproximadamente US$ 200 bilhões de dólares, no mundo.
O método de avaliação de Fagerström é, hoje, utilizado por especialistas, para ajudar a definir a melhor estratégia para quem quer largar o cigarro
Trata-se de um questionário utilizado por médicos a fim de determinar se uma pessoa está seriamente viciada na nicotina.


Em 15 de outubro de 1492 folhas secas de tabaco foram oferecidas a Cristovão Colombo pelos índios americanos.
Chegou a Europa como proposta curativa (o tabaco era mascado).
A relação entre o Tabagismo e Saúde é conhecida de forma geral pela maioria das pessoas
Sabe-se que "faz mal" mas o vício é de tal forma elevado que leva as pessoas a permanecer a sua atividade nociva com consequências variadas
O Tabagismo é responsável por:
No Brasil, estima-se que cerca de 290 mil mortes por ano são decorrentes do tabagismo
A proporção de fumantes no país é de 23,9% da população
Segundo dados da PNAD, em 2008, o Brasil tinha 24,6 milhões de fumantes habituais com idade a partir de 15 anos ou 17,2% da população de pessoas dessa faixa etária, sendo 15,1% fumantes diários.
Cerca de 90% dos fumantes tornam-se dependentes da nicotina entre os 5 e os 19 anos de idade
Há 2,8 milhões de fumantes nessa faixa etária, mas a maior concentração de fumantes está na faixa etária de 20 a 49 anos.
A região Sul do país é a que apresenta maior proporção de dependentes - 45% dos fumantes
Em 2008, a região Sul, com 19,3%, tinha o maior percentual de fumantes correntes.
No Nordeste, os fumantes dependentes são 31%
Os moradores da zona rural também fumam mais que os das zonas urbanas.
O fumo é responsável por 95% dos casos de câncer de boca; 90% das inflamações de mama; 80% da incidência de câncer no pulmão; por 97% dos casos de câncer da laringe; 50% dos casos de câncer de pele; 45% das mortes por doença coronariana (infarto do miocárdio) e também 25% das mortes por doença vascular-cerebral (derrames cerebrais).
O tabagismo, incluindo o passivo, é o fator de risco mais comum para a DPOC, Doença Pulmonar Obstrutiva Crônica
No Brasil, estima-se que a doença atinja cerca de 6 milhões de pessoas
Somente 12% dos pacientes são diagnosticados e, desses, apenas 18% recebem tratamento
Já no cenário mundial, a estimativa é de que aproximadamente 210 milhões de pessoas tenham DPOC e a previsão é que a doença se torne a terceira principal causa de morte por volta de 2020
Outros fatores que contribuem para o desenvolvimento da doença são a inalação de poeiras e produtos químicos em fábricas ou ambientes profissionais similares, poluição do ar, desenvolvimento pulmonar prejudicado e fatores genéticos.
Segundo uma pesquisa realizada em 20 países, o brasileiro, com 91%, é o que mais se arrepende de ter começado a fumar
Entre os fumantes brasileiros do estudo internacional, 63% apóiam campanhas e leis contra o fumo e 82% relatam que o fumo já lhes causou algum problema de saúde
Segundo os dados da Kantar Health, mesmo com restrições impostas, os fumantes parecem observar com razoável conforto as legislações que visam evitar que não fumantes sejam incomodados pela fumaça de cigarros, charutos e cachimbos
Dentre os respondentes do Reino Unido, França, EUA, China, Brasil e Espanha, a maioria alega não achar difícil restringir o consumo em locais restritos.
O Brasil é o maior exportador e quarto maior produtor mundial de tabaco - depois da China, EUA e Índia.
Deve-se ressaltar que o cultivo do tabaco expõe trabalhadores rurais a uma grande variedade de agrotóxicos aumentando o risco de manifestação de efeitos agudos e crônicos à saúde, como transtornos mentais e câncer
Durante a colheita das folhas de tabaco pode haver absorção dérmica da nicotina presente nas folhas úmidas, podendo ocasionar a denominada Doença da Folha Verde do Tabaco, cujos sintomas são muito semelhantes aos quadros de intoxicação por agrotóxicos e outras doenças.
Em 2015, um em cada quatro portugueses (25%) é fumador, mais dois pontos percentuais do que em 2012, 12% deixaram de fumar e quase dois terços (63%) nunca fumaram.
Na União Europeia (UE), a média de fumadores é de 26%, uma quebra de dois pontos na comparação com o inquérito de 2012.
Em Portugal, fumam mais os homens (34%) do que as mulheres (18%), em linha com a média da UE: 31% e 22%, respetivamente.
A maior prevalência é dada no grupo etário 25 a 34 anos (45,6% nos homens e 25,1% nas mulheres) e as mais baixas no grupo etário 65 a 74 anos (10,8% nos homens e 2,5% nas mulheres).
Hipercolesterolemia é o aumento da concentração de colesterol no sangue
 É uma forma de hiperlipidemia (concentração elevada de lípidos no sangue) e hiperlipoproteinemia (concentração elevada de lipoproteínas no sangue).
Uma vez que o colesterol é insolúvel em água, o seu transporte no plasma é feito por partículas de proteínas denominadas lipoproteínas
As lipoproteínas plasmáticas são classificadas de acordo com a sua densidade: as de muito baixa densidade (VLDL), de baixa densidade (LDL), de densidade intermédia (IDL) e de elevada densidade (HDL)
Embora todas as lipoproteínas transportem colesterol, uma maior concentração de lipoproteínas que não HDL (e sobretudo LDL) está associada a um risco acrescido de aterosclerose e doença coronária
Por outro lado, uma maior concentração de colesterol HDL tem efeitos protetores.
O aumento de concentração de colesterol não-HDL e de colesterol-LDL no sangue pode ser uma consequência da dieta, obesidade, doenças genéticas hereditárias (como mutações do recetor de LDL em hipercolestrolemia familiar) ou a presença de outras doenças como a diabetes ou hipotiroidismo
Geralmente recomenda-se a diminuição de gorduras saturadas na dieta para diminuir o colesterol total e LDL no sangue
Em pessoas com colesterol muito elevado, como na hipercolestrolemia familiar, o cuidado com a dieta é muitas vezes insuficiente para conseguir a diminuição desejaa de LDL, pelo que geralmente se torna necessária a administração de medicamentos que diminuem a produção ou absorção de colesterol
Em caso de necessidade clíncia, estão também disponíveis outros tipos de tratamento, como a aferese de LDL ou a cirurgia para subtipos particularmente graves de hipercolestrolemia familiar.


Embora a hipercolesterolemia em si seja assintomática, a longo prazo o aumento do colesterol no sangue pode causar aterosclerose
Ao longo de um período de décadas, os níveis continuamente altos de colesterol contribuem para a formação de placas ateromatosas nas artérias
Isto pode provocar estenose progressiva (estreitamento) ou bloqueio completo das artérias envolvidas
As placas mais pequenas podem também provocar a formação de um coágulo que obstrua a passagem do sangue
Um bloqueio súbito de uma artéria coronária pode causar um enfarte do miocárdio ou ataque cardíaco
Um bloqueio de uma artéria que irrigue o cérebro pode provocar um acidente vascular cerebral
Se o desenvolvimento do estreitamento ou bloqueio for gradual, o fornecimento de sangue aos tecidos e orgãos vai diminuindo lentamente até provocar a insuficiência desse órgão
A este ponto, esta restrição de fornecimento de sangue (isquemia) pode manifestar-se através de sintomas específicos
Por exemplo, a isquemia temporária do cérebro (denominada acidente isquémico transitório) pode manifestar-se através de perda temporária de visão, tonturas, perda de equilíbrio, afasia (dificuldade em falar), paresia (fraqueza) e parestesia (formigueiro), geralmente de um dos lados do corpo
O fornecimento insuficiente de sangue ao coração pode manifestar-se através de dores no peito, enquanto que ao olho se pode manifestar através de perda temporária de visão num dos olhos, e à perna se pode manifestar pela dor ao caminhar e nos intestinos como dor após a ingestão.
Alguns tipos de hipercolesterolemia têm consequências físicas específicas
Por exemplo, a hipercolesterolemia familiar pode estar associada a xantelasma (manchas amarelas nas pálpebras), arco senil (descoloração branca ou cinzenta da córnea periférica), e xantoma (depósitos de material amarelado rico em colesterol) nos tendões, especialmente nos dedos
A hiperlipidemia do tipo III pode estar associada a xantoma das palmas, joelhos e cotovelos.
Os fatores ambientais incluem: consumo regular de comidas gordurosas e falta de exercícios
Os fatores genéticas são normalmente devido a efeitos aditivos de múltiplos genes, embora, ocasionalmente, pode ser devido a um defeito genético único, como no caso de hipercolesterolemia familiar.
Doenças que aumentam o risco incluem:
Dentre os medicamentos que aumentam colesterol incluem alguns diuréticos, ciclosporina, glicocorticoides, betabloqueadores, ácido retinoico e alguns anticoncepcionais
O Tabagismo também influencia, indiretamente, por diminuir o HDL, popularmente conhecido como ¨colesterol bom¨

A aterosclerose é a principal causa do infarto agudo do miocárdio e do derrame cerebral
Ela não depende apenas do colesterol, mas também de outros fatores, como:
Todos estes fatores devem ser visto de maneira equilibrada, já que a doença final é resultante da interação de todos eles.
A partir da medida da quantidade total do colesterol e de suas frações
O colesterol é transportado em lipoproteínas
Conforme a densidade e tamanho destas lipoproteínas, elas são classificadas em Lipoproteínas de alta densidade (HDL), Lipoproteínas de baixa densidade (LDL) e Lipoproteínas de muito baixa densidade (VLDL)
Os níveis de VLDL e LDL raramente são medidos devido aos custos
Os níveis de VLDL são deduzidos a partir dos níveis de triglicerídeos
A proporção de colestrol transportado nas VLDL é de 20% do total de triglicerídeos do sangue
Os níveis LDL costumam ser estimados através dos outros valores obtidos, através da Fórmula de Friedewald:
As várias lipoproteínas podem também ser analisadas através de eletroforese.
O tratamento visa atingir metas
As metas são variáveis de pessoa a pessoa, conforme o estado geral de saúde
Por exemplo, no caso de uma mulher de 20 anos, com pressão normal, não fumante, sem história de familiar de doença cardio-vascular, um nível de 230 mg/dL de colesterol total não necessita de tratamento, já que este tratamento muito pouco adicionaria de proteção aquela pessoa, apenas mudanças na dieta pode ser suficiente
Já no caso de um senhor de 56 anos, diabético, com hipertensão arterial e que teve um infarto agudo do miocárdio há 1 ano, mesmos em níveis como 190 mg/dl já se recomenda uso contínuo de medicações para diminuir a chance de um novo infarto.
Possíveis tratamentos incluem:
E medicações como:
O mosaico genético que predispõe a hipercolesterolemia não é modificável
Sempre aquele indivíduo tenderá a elevar o colesterol
Desta maneira o acompanhamento e o tratamento tendem a ser perenes, com os ajustes feitos de tempos em tempos, conforme o envelhecimento da pessoa, o surgimento de outras doenças e modificações nas influências ambientais.
No Brasil, em 2012, cerca de 40% dos brasileiros tinham colesterol alto (acima de 200mg/dl) e cerca de 300 mil mortes por ano, são em decorrência de infartos e derrames
É um problema mais comum depois dos 30 anos e em sedentários, mas também pode afetar pessoas magras, pessoas ativas e jovens
No mundo, aproximadamente 17 milhões de pessoas morrem devido às doenças cardíacas.
Obesidade é uma condição médica em que se verifica acumulação excessiva de tecido adiposo ao ponto de poder ter impacto negativo na saúde
Uma pessoa é considerada obesa quando o seu índice de massa corporal (IMC) é superior a 7002294199500000000♠30 kg/m, e com excesso de peso quando o seu IMC é superior a 7002245166250000000♠25–30 kg/m
O IMC é calculado dividindo o peso da pessoa pelo quadrado da sua altura
A obesidade aumenta a probabilidade de ocorrência de várias doenças, em particular de doenças cardiovasculares, diabetes do tipo 2, apneia do sono obstrutiva, alguns tipos de cancro, osteoartrite, e depressão.
A causa mais comum de obesidade é uma combinação de dieta hiperenergética, falta de exercício físico e suscetibilidade genética
Alguns casos são causados por genes, doenças endócrinas, medicamentos ou perturbações mentais
Não há evidências que apoiem um metabolismo lento como causa de obesidade em pessoas obesas que comem pouco
Em média, as pessoas obesas consomem mais energia do que as restantes, uma vez que quanto maior a massa corporal, maior a necessidade de energia.
A prevenção da obesidade consiste em alterações sociais e escolhas pessoais
O tratamento da obesidade baseia-se na dieta e no exercício físico
A qualidade da dieta pode ser melhorada reduzindo o consumo de alimentos ricos em energia, tais como os que têm grande quantidade de gordura e açúcar, e aumentando a ingestão de fibra dietética
Para acompanhar a dieta adequada pode ser administrada medicação anti-obesidade para reduzir o apetite ou diminuir a absorção de gordura pelo corpo
Quando a dieta, o exercício e a medicação não demonstram ser eficazes, pode ser considerada a aplicação de uma banda gástrica ou uma cirurgia bariátrica para reduzir o volume do estômago ou o comprimento do intestino, o que faz com que a pessoa se sinta cheia mais cedo e que haja menor capacidade de absorção de nutrientes dos alimentos.
A obesidade é uma das principais causas de morte evitáveis em todo o mundo, com taxas de prevalência cada vez maiores em dultos e crianças
Em 2015, 600 milhões de adultos (12% do total) e 100 milhões de crianças eram obesas
A obesidade é mais comum entre mulheres do que entre homens
As autoridades de saúde consideram a obesidade um dos mais graves problemas de saúde pública do século XXI
Em grande parte do mundo contemporâneo, particularmente na sociedade ocidental, a obesidade é alvo de estigma social, embora ao longo da História tenha sido vista como símbolo de riqueza e fertilidade, perspetiva que ainda se mentém em algumas partes do mundo.


A obesidade é uma condição médica na qual se verifica acumulação de tecido adiposo em excesso ao ponto de poder ter impacto negativo na saúde
É definida em função do índice de massa corporal (IMC) e avaliada em termos de distribuição de gordura pelo índice de cintura e quadris e pelos factores de risco cardiovascular
O IMC está intimamente relacionado com a taxa de gordura corporal e a quantidade total de gordura no corpo.
Calcula-se o IMC dividindo o peso do indivíduo pelo quadrado da sua altura, através da seguinte forma:
As definições mais amplamente usadas a nível mundial e em vigor nos países lusófonos, definidas pela Organização Mundial de Saúde (OMS) em 1997 e publicadas em 2000, indicam os valores de referência na tabela à direita
No entanto, alguns países asiáticos redefiniram os valores de obesidade da OMS, uma vez que as populações asiáticas desenvolvem consequências de saúde negativas a um IMC menor do que os caucasianos
Por exemplo, o Japão define obesidade como qualquer IMC superior a 25 kg/m, enquanto que a China usa um IMC superior a 28 kg/m
Algumas entidades de saúde também realizam alterações à definição da OMS
Por exemplo, a literatura cirúrgica divide a obesidade de classe III em mais categorias, cujos valores precisos ainda se encontram em discussão.
Em crianças, o peso considerado saudável varia em função da idade e do sexo
A obesidade em crianças e adolescentes não é definida em função de um número absoluto, mas sim por um percentil
Assim, uma criança com idade superior a dois anos é considerada obesa quando o seu IMC é igual ou superior ao percentil 95 para o seu sexo e idade
Da mesma forma, considera-se que uma criança tem excesso de peso (pré-obesidade) quando o seu IMC está entre o percentil 85 e 95
Os dados de referência nos quais estes percentis se baseiam correspondem ao período entre 1963 e 1994, os quais não foram afetados pelo aumento recente da média de peso.
O excesso de massa corporal está associado a várias doenças, em particular doenças cardiovasculares, diabetes do tipo 2, apneia do sono, alguns tipos de cancro, osteoartrite e asma Em consequência destes factores, determina-se que a obesidade contribui para a diminuição da esperança de vida.
A obesidade é uma das principais causas de morte evitáveis em todo o mundo.
Em cada ano, morrem 3,4 milhões de adultos em consequência da obesidade ou do sobrepeso
A doença está também na origem de 44% dos casos de diabetes, 23% dos casos de doença arterial coronariana e entre 7 e 41% de determinados tipos de cancro
Na Europa, 7,7% das mortes (cerca de um milhão de pessoas) são atribuídas ao excesso de peso
Em média, a obesidade reduz a esperança de vida entre seis a sete anos
Um IMC entre 30 e 35 kg/m reduz a esperança de vida entre dois e quatro anos, enquanto que a obesidade grave (IMC > 40 kg/m) reduz a esperança de vida em dez anos.
O risco de mortalidade é menor no intervalo de IMC de 20-25 kg/m em não fumadores, e 24–27 kg/m em fumadores
Existe uma associação entre valores de IMC superiores a 32 kg/m e a duplicação da taxa de mortalidade entre mulheres, ao longo de um período de 16 anos.
A obesidade aumenta o risco de diversas complicações físicas e psicológicas
Estas comorbidades estão frequentemente integradas numa condição denominada síndrome metabólica, um conjunto de transtornos clínicos que engloba: diabetes mellitus tipo 2, pressão arterial elevada, colesterol elevado e níveis elevados de triglicerídeos
As complicações podem ser causadas diretamente pela obesidade ou de forma indireta, através de mecanismos com causas em comum, como por exemplo uma dieta desequilibrada ou um estilo de vida sedentário
A intensidade da relação entre a obesidade e complicações específicas é variável
Uma das mais fortes é a ligação com a diabetes do tipo II
O excesso de gordura corporal está na origem de 64% dos casos de diabetes em homens e 77% dos casos em mulheres.
As consequências da obesidade a nível da saúde podem ser classificadas em duas categorias genéricas: as que podem ser atribuídas aos efeitos do aumento da massa adiposa (como a osteoartrite, a apneia de sono ou o estigma social) e as que podem ser atribuídas ao aumento do número e do volume de células adiposas, como a diabetes, cancro, doenças cardiovasculares ou a doença hepática gordurosa não alcoólica
O aumento de gordura corporal altera a reação do corpo à insulina, o que pode provocar resistência à insulina, e também cria um estado pró-inflamatório e pró-trombótico.
A nível individual, pensa-se que maior parte dos casos de obesidade se deva a uma conjugação da ingestão de alimentos energéticos em excesso com a ausência de exercício físico
Uma percentagem pequena de casos deve-se principalmente a condições genéticas, transtornos psiquiátricos ou razões médicas em geral
Por outro lado, o aumento generalizado da prevalência de obesidade na sociedade deve-se à facilidade no acesso à dieta hiperenergética, ao aumento da dependência de transportes automóveis e à mecanização do trabalho.
Existe uma relação entre o consumo de energia total e a obesidade
A maior parte da energia consumida em excesso tem origem no aumento do consumo de hidratos de carbono, e não no consumo de gordura
As principais fontes destes hidratos de carbono em excesso são as bebidas açucaradas e as batatas fritas, e acredita-se que o seu consumo excessivo esteja a contribuir para o aumento dos índices de obesidade
À medida que as sociedades se tornam cada vez mais consumidoras de dietas hipercalóricas, fast-food e refeições de grandes porções, a ligação entre o consumo de fast-food e a obesidade torna-se mais evidente.
A disponibilidade de energia dietética per capita varia de forma acentuada entre diferentes regiões e países, e foi-se alterando de forma significativa ao longo do tempo
Entre o início da década de 1970 e o fim da década de 1990, a energia alimentar disponível por pessoa e por dia (a quantidade de alimentos comprados) aumentou em todas as partes do mundo, exceto na Europa do Leste
A maior disponibilidade encontra-se nos Estados Unidos, com 3654 cal por pessoa em 1996, valor que aumentou para 3754 Cal em 2003
Em finais da década de 1990, os europeus tinham disponíveis em média 3394 Cal por pessoa, enquanto que nas regiões em desenvolvimento da Ásia a disponibilidade era de 2648 por pessoa e na África subsariana de 2176 Cal por pessoa
Apesar de estarem disponíveis recomendações de nutrição em diversos países, continuam a existir problemas derivados da ingestão excessiva de alimentos e de escolhas dietéticas pouco saudáveis.
As políticas a as técnicas agrícolas introduzidas na Europa e na América do Norte no pós-guerra proporcionaram a descida acentuada do preço dos alimentos
Entre estas políticas estão os subsídios à produção agrícola, como os que são provenientes da Política Agrícola Comum
No entanto, grande parte dos subsídios destinou-se à produção de milho, soja, trigo e arroz, o que fez com que estes alimentos se tornassem as principais fontes de comida processada
Assim, apesar dos custos de produção e tecnologia envolvidos, a comida processada com base neste alimentos tornou-se mais barata do que a própria fruta ou os vegetais
No fim da década de 2000, começou-se a questionar e a discutir a distribuição de subsídios agrícolas no sentido de melhor adequá-los às necessidades dietéticas, promovendo o cultivo de frutas e vegetais.
O estilo de vida sedentário desempenha um papel significativo na obesidade
A OMS sugere que entre a população mundial verifica-se um declínio das atividades recreativas ativas e que, atualmente, cerca de 30% da população mundial não realiza exercício físico suficiente
Isto deve-se à tendência de evolução para condições de trabalho que exigem cada vez menos esforço físico, ao aumento da utilização de transportes mecanizados e à maior prevalência de tecnologia residencial
No caso das crianças, o declínio na quantidade de atividade física deve-se também à diminuição na quantidade de percursos feitos a pé e à inexistência de educação física.
Tanto em adultos quanto em crianças existe uma correlação entre o tempo passado em frente à televisão e o risco de obesidade
Um estudo de revisão constatou que 63 entre 73 estudos (86%) demonstraram existir um aumento da taxa de obesos em função do aumento da exposição aos meios de comunicação, no qual a taxa aumenta de forma proporcional ao tempo de visualização.
Tal como muitas outras condições médicas, a obesidade é o resultado da interação entre fatores genéticos e ambientais
Perante fatores ambientais idênticos, o risco de obesidade é maior nas pessoas com predisposição genética para a doença
Esta predisposição genética tem origem nos polimorfismos de vários genes que controlam o apetite e o metabolismo
Existem mais de 40 sítios do genoma humano que estão associados ao desenvolvimento de obesidade quando existe comida em quantidade suficiente.
As pessoas com duas cópias do gene FTO pesam em média 3 a 4 quilos a mais e apresentam um risco 1,67 vezes superior de obesidade, em comparação com a restante população
A percentagem de obesidade que pode ser atribuída a factores genéticos varia entre 6 e 85%, dependendo da população examinada
Verifica-se que 7% das pessoas com obesidade grave precoce (obesidade antes dos 10 anos de idade e com IMC três vezes superior ao normal) possuem mutação pontual no ADN
Cerca de 80% dos filhos de dois progenitores obesos são também obesos, valor que contrasta com os menos de 10% entre os filhos de pais com peso normal
A obesidade é também uma das principais características de diversas síndromes genéticas, como a síndrome de Prader-Willi ou a síndrome de Bardet-Biedl.
Embora a influência genética seja importante para compreender a obesidade, ela por si só não explica o aumento dramático da incidência em determinados países ou em escala global
Existem diversas atitudes sociais que aparentam aumentar o risco de obesidade, como o stress, a discriminação, a classe socioeconómica, o tabagismo, o número de filhos e a urbanização.
A correlação entre a classe social e o IMC varia consoante a região do mundo
Em países desenvolvidos, o grupo com menor probabilidade de obesidade são as mulheres das classes superiores
Por outro lado, nos países em desenvolvimento os homens, mulheres e crianças das classes sociais superiores são os que apresentam as maiores taxas de obesidade
No entanto, devido aos efeitos da globalização, as diferenças têm-se vindo a atenuar
Em países desenvolvidos, o número de adultos obesos e crianças com sobrepeso está correlacionado com a desigualdade económica
Têm sido propostas diversas explicações para a relação entre o IMC e a classe social: em países desenvolvidos, as pessoas com maior poder de compra têm a possibilidade de escolher alimentação mais equilibrada e saudável, estão sob maior pressão social para manterem o peso ideal e têm a possibilidade de praticar programas de fitness; em países em vias de desenvolvimento, o padrão observado pode ser explicado pela diferença no acesso à alimentação, pela grande quantidade de energia dispendida no trabalho físico e por valores culturais que favorecem um corpo maior.
Fumar tem um efeito assinalável no peso individual
As pessoas que desistem de fumar aumentam em média entre 4,4 kg (homens) e 5,0 kg (mulheres) nos dez anos seguintes
No entanto, a diminuição do número de fumadores tem tido pouco efeito nas taxas de obesidade entre a população.
Na sociedade ocidental, o número de filhos tem também uma correlação com o aumento do risco de obesidade
O risco de uma mulher aumenta 7% por cada filho, enquanto o de um homem aumenta 4%
Isto pode ser explicado em parte pelo facto de que ter crianças dependentes diminui a atividade física dos pais
Nos países em desenvolvimento, a urbanização também desempenha um papel no aumento das taxas de obesidade
Por exemplo, na China a taxa nacional de obesidade é inferior a 5%, enquanto que nalgumas cidades é superior a 20%.
Algumas doenças físicas e mentais, e os fármacos usados no seu tratamento, podem aumentar o risco de obesidade
Entre as doenças que aumentam o risco de obesidade estão diversas síndromes genéticas raras e algumas condições congénitas ou adquiridas, como o hipotiroidismo, síndrome de Cushing ou deficiência de hormona do crescimento, e transtornos alimentares, como o transtorno da compulsão alimentar periódica
No entanto, a obesidade não é considerada nem classificada como transtorno psiquiátrico
O risco de sobrepeso e obesidade é maior em pessoas com transtornos psiquiátricos.
A desnutrição durante os primeiros anos de vida também aparenta desempenhar um papel no aumento da taxa de obesidade nos países em desenvolvimento
As alterações endócrinas que ocorrem durante períodos de desnutrição podem promover o armazenamento de gordura a partir do momento em que a comida esteja outra vez disponível
Diversos estudos confirmam também que a obesidade está também associada a défices cognitivos.
Alguns medicamentos podem provocar aumento de peso ou alterações na composição do corpo, como a insulina, sulfonilureias, tiazolidinedionas, antipsicóticos atípicos, antidepressivos, glicocorticoides, alguns anticonvulsivos (fenitoína e valproato), pizotifeno e algumas formas de contraceção hormonal.
Tem-se verificado que a flora intestinal difere entre pessoas magras e obesas, havendo uma indicação de que a flora pode afetar o potencial metabólico
Acredita-se que esta alteração no potencial metabólico faz com que o organismo tenha maior capacidade de recolher energia, contribuindo assim para a obesidade
No entanto, ainda não foi demonstrado de forma inequívoca se estas diferenças são causa ou consequência da obesidade
Verificou-se também uma associação entre vírus e obesidade em seres humanos e diversas outras espécies
No entanto, ainda está por determinar a contribuição desta associação para o aumento da taxa de obesidade.
Existem diversos mecanismos fisiopatológicos envolvidos no desenvolvimento e manutenção da obesidade e que participam na regulação do apetite e na ingestão de comida, no padrão de armazenagem do tecido adiposo e no desenvolvimento de resistência à insulina
Desde a descoberta da leptina, foram estudados diversos outros mediadores, como a grelina, insulina, orexina, colecistocinina e a adiponectina
As adipocinas são mediadores produzidos pelo tecido adiposo e supõe-se que sua acção modifique diversas doenças relacionadas à obesidade.
A leptina e a grelina são complementares ao nível da regulação do apetite
A grelina produzida pelo estômago regula o apetite a curto prazo, fazendo com que a pessoa sinta fome quando o estômago está vazio e indicando o momento em que o estômago está cheio
A leptina é produzida pelo tecido adiposo para sinalizar as reservas de gordura no corpo e mediar a regulação do apetite a longo prazo; isto é, comer mais quando as reservas são poucas, e pouco quando as reservas são muitas
Embora a administração de leptina possa ser eficaz num pequeno subgrupo de indivíduos obesos com deficiência de leptina, pensa-se que a maior parte seja resistente à leptina, apresentando inclusive níveis elevados da hormona, o que explica a ineficácia da administração de leptina para suprimir o apetite em grande parte da população.
Embora a leptina e a relina sejam produzidas perifericamente, elas regulam o apetite através de ações no sistema nervoso central
As diversas hormonas reguladoras do apetite atuam no hipotálamo, uma região do cérebro onde está concentrada a regulação da ingestão de alimentos e a gestão de energia
Existem diversos circuitos no hipotálamo que contribuem para a sua função reguladora do apetite, dos quais o sistema das melanocortinas é o mais bem compreendido
O circuito tem início no núcleo arqueado, uma região do hipotálamo com ligações ao hipotálamo lateral e ao hipotálamo ventromedial, os centros responsáveis pela alimentação e sacieção, respetivamente.
O núcleo arqueado contém dois grupos distintos de neurónios
O primeiro grupo coexpressa o neuropeptídeo Y (NPY) e o peptídeo Agouti (AgRP), ao mesmo tempo que estimula o hipotálamo lateral e inibe o hipotálamo ventromedial
O segundo grupo coexpressa pró-opiomelanocortina (POMC) e transcrito regulado por cocaína (CART), estimula o hipotálamo ventromedial e inibe o hipotálamo lateral
Desta forma, os neurónios NPY/AgRP estimulam a alimentação e inibem a saciação, enquanto que os neurónios POMC/CART estimulam a saciação e inibem a alimentação
Ambos os grupos do núcleo arqueado são regulados em parte pela leptina
A leptina inibe o grupo NPY/AgRP e estimula o grupo POMC/CART
Assim, a presença de uma deficiência na sinalização de leptina, causada tanto por insuficiência de leptina como por resistência à leptina, provoca sobrealimentação e pode ser responsável por algumas das formas genéticas e adquiridas de obesidade.
O principal tratamento para a obesidade é uma dieta apropriada e exercício físico
Os programas dietéticos proporcionam redução de peso a curto prazo, embora manter o peso pretendido seja difícil, pelo que geralmente essa redução necessita de ser acompanhada por alterações permanentes no estilo de vida da pessoa, como exercício físico regular e uma dieta menos calórica
A taxa de sucesso da manutenção a longo prazo da redução de peso com alterações no estilo de vida é de cerca de 20%
As alterações na dieta e no estilo de vida são eficazes na limitação do ganho de peso durante a gravidez e têm impacto positivo na saúde da mãe e da criança.
Estão disponíveis alguns fármacos para o tratamento de obesidade
Os mais comuns são o orlistato, a lorcaserina e a associação fentermina/topiramato
No entanto, a aprovação ou não de cada substância pode diferir bastante entre países
Embora o uso de lorcaserina tenha sido aprovado pela Food and Drug Administration norte-americana, o medicamento não foi aprovado pela Agência Europeia do Medicamento
A perda de peso com o orlistato é modesta, em média 2,9 kg entre 1 e 4 anos
O seu uso está associado a taxas elevadas de efeitos adversos gastrointestinais e têm sido levantadas preocupações acerca dos efeitos negativos nos rins
Os outros dois fármacos estão disponíveis nos Estados Unidos, mas não na Europa
A lorcaserina proporciona uma perda de peso média de 3,1 kg superior ao placebo ao longo de um ano
No entanto, pode aumentar os problemas relacionados com as válvulas do coração
A associação fenternina/topiramato apresenta alguma eficácia, embora possa estar associado a problemas no coração
Não existe ainda informação sobre a forma como estes fármacos afetam complicações a longo prazo da obesidade, tais como doenças cardiovasculares ou morte.
O tratamento mais eficaz para a obesidade é a cirurgia bariátrica, ou cirurgia de redução do estômago
O tratamento cirúrgico da obesidade está associado à perda de peso a longo prazo e à melhoria nas condições médicas relacionadas
Verificou-se num estudo uma perda de peso entre 14 e 25% ao longo de dez anos, dependendo do tipo de cirurgia, e uma redução de 29% na mortalidade, em comparação com as medidas convencionais para perder peso
No entanto, ocorrem complicações em 17% dos casos e em 7% é necessária uma segunda intervenção cirúrgica
Devido ao seu custo e riscos associados, atualmente procuram-se novos tratamentos eficazes, mas menos invasivos.
Antes do século XX a obesidade era rara
No entanto, em 1997 a OMS reconheceu formalmente a obesidade enquanto epidemia à escala global
Em 2008, a OMS estimou 500 milhões de adultos (10%) eram obesos e que a prevalência da doença era maior entre as mulheres
A incidência de obesidade também aumenta em função da idade até aproximadamente aos 50-60 anos
Em alguns países desenvolvidos o crescimento da obesidade grave é maior do que o crescimento da obesidade no geral.
Anteriormente considerada um problema restrito aos países industrializados, atualmente verifica-se que o aumento da obesidade se dá à escala global, afetando tanto os países desenvolvidos como os países em vias de desenvolvimento
Este aumento verifica-se de forma mais acentuada em contexto urbano, e a única região do mundo onde não é um problema comum é na África subsariana.
Em Portugal, a prevalência de pré-obesidade é de cerca de 34%, enquanto a prevalência de obesidade de 12%
Cerca de metade da população portuguesa não pratica qualquer atividade física regular, o que tem vindo a contribuir para o aumento acentuado da obesidade no país
A percentagem de sobrepeso é maior entre sexo masculino
Entre a população com idade superior a 55 anos, a prevalência de obesidade é 7,2 vezes superior à média
A maior prevalência de pré-obesidade regista-se no interior norte e centro, enquanto que a maior prevalência de obesidade se regista no Alentejo e em Setúbal
Verifica-se também que a prevalência de obesidade é maior em meio urbano do que em meio rural, e que diminui em função do grau de instrução dos pais
Segundo dados de 2004, 44,1% dos homens adultos apresentavam diagnóstico sobrepeso (IMC 25-29,9) e 14,5% apresentavam diagnóstico de obesidade (IMC ≥30)
Entre as mulheres adultas, 31,9% apresentavam diagnóstico de sobrepeso e 14,6% diagnóstico de obesidade
Nas crianças dos 7 aos 9 anos de idade, a prevalência da obesidade e da pré-obesidade é de 31,56%, sendo a prevalência maior em crianças do sexo feminino
Em 2009-2010, Portugal apresentava a segunda maior taxa de sobrepeso entre adolescentes europeus (32%).
No Brasil, segundo dados de 2008–2009, cerca de metade da população apresenta diagnóstico de sobrepeso
Verificou-se diagnóstico de obesidade em 12,5% dos homens e 16,9% das mulheres com mais de 20 anos, 4,0% dos homens e 5,9% das mulheres entre 10 e 19 anos e 16,6% das crianças do sexo masculino e 11,8% das crianças do sexo feminino entre 5 a 9 anos
Em homens, o excesso de peso e obesidade são mais prevalentes nas Regiões Sudeste, Sul e Centro-Oeste do que nas Regiões Norte e Nordeste, enquanto que nas mulheres a prevalência é maior na região Sul, embora de forma menos acentuada
O excesso de peso é maior em áreas urbanas em relação a áreas rurais
A prevalência de sobrepeso e obesidade no Brasil tem vindo a aumentar, particularmente a partir do final da década de 1990
Em 1974–1975, a prevalência média de sobrepeso em adultos do sexo masculino foi de 18,5%, enquanto que em 2008-2009 foi de 50,1%
Em mulheres adultas, a prevalência aumentou de 28,7% para 48%, respetivamente
Nas crianças entre os 5 e os 9 anos, o aumento é ainda mais acentuado
Em 1974-75, no sexo masculino a prevalência de sobrepeso foi de 10,9% e a prevalência de obesidade de 2,9%, em contraste com 34,8% de sobrepeso e 16,6% de obesidade em 2008-2009
No sexo feminino, a prevalência de sobrepeso aumentou de 8,6% para 32% e a prevalência de obesidade de 1,8% para 11,8%
Em 2008, apenas 10,2% dos brasileiros com 14 anos ou mais de idade praticava exercício físico regularmente
Entre 1970 e 2008, a percentagem da população envolvida no setor agrícola, que é aquele que possibilita maior gasto energético, diminuiu de 44% para 17,4%.
A Guiné-Bissau apresenta a taxa de obesidade mais elevada da África subsariana em ambos os sexos, tanto em adultos como em crianças
Entre os adultos, a taxa é de 16,8% nos homens e 24,2% nas mulheres e entre as crianças a taxa é de 8,1% no sexo masculino e 8,3% no sexo masculino
O país apresenta ainda taxas muito elevadas de sobrepeso (44% nos homens, 47,8% nas mulheres, 15,8% em crianças do sexo masculino e 20,4% no sexo feminino
Em Angola a taxa de obesidade engloba 12% dos homens, 18,7% das mulheres, 5,7% das crianças do sexo masculino e 6% do sexo feminino
No mesmo país, verifica-se sobrepeso em 42,9% dos homens, 49,1% das mulheres, 15,5% dos rapazes e 20,9% das raparigas.Em Moçambique, a taxa de sobrepeso afeta 14,1% dos homens, 26,5% das mulheres, 12,3% dos rapazes e 14,4% das raparigas
Em São Tomé e Príncipe 30,6% dos homens, 45,7% das mulheres, 12,3% dos rapazes e 18,9% das raparigas apresentam sobrepeso
Em Cabo Verde, o sobrepeso afeta 31,8% dos homens, 44% das mulheres, 11,5% dos rapazes e 18,3% das raparigas.
Em agosto de 2015, investigadores da Universidade de Harvard e do MIT descobriram que o gene FTO ativa dois outros genes que impedem a gordura de ser queimada na forma de calor - um processo chamado termogénese
Demonstraram também que é possível desativar estes genes através de uma técnica inovadora (CRISPR) que recorta código de ADN com erros e o substitui pela sequência correta.
"Obesidade" tem origem no latim obesitas, que significa gordo ou corpulento
Ēsus é o particípio passado de edere (comer), com o prefixo ob (sobre)
Os gregos foram a primeira civilização a reconhecer a obesidade enquanto transtorno de saúde
Hipócrates escreveu que "a corpulência não só é uma doença, como é o prenúncio de outras"
O cirurgião indiano Sushruta (século VI a.C.) associou a obesidade à diabetes e às doenças cardiovasculares, recomendando a cura através de exercício físico.
Ao longo de grande parte da História, a humanidade lutou continuamente contra a escassez de alimentos, pelo que a obesidade foi considerada em vários períodos um sinal de prosperidade e riqueza
Muitas culturas viam a obesidade enquanto resultado de defeitos de caráter
Na comédia grega, o obesus era um glutão e uma personagem ridicularizada
Durante a época paleocristã, a gula era vista como um sete pecados capitais.
A obesidade foi particularmente comum entre as elites europeias durante a Idade Média e o Renascimento e nas civilizações do oriente asiático
Durante a revolução industrial constatou-se que o poder económico e militar dos países está intimamente relacionado com a força e o tamanho do corpo dos seus trabalhadores e soldados
O crescimento do IMC médio entre a população, desde o que hoje se considera um peso inferior ao normal até ao que agora se considera peso normal, contribuiu de forma significativa para o desenvolvimento das sociedades industrializadas
Ao longo de todo o século XIX, a média de altura e de peso entre a população do mundo ocidental aumentou de forma significativa
No século XX, à medida que a população ia atingindo o seu potencial genético em termos de altura, o peso começou a aumentar de forma superior à altura, tendo como consequência o aumento da prevalência de obesidade
No pós-guerra, o aumento de prosperidade nos países desenvolvidos fez com que a taxa de mortalidade infantil diminuísse
No entanto, à medida que o índice de massa corporal aumentou, as doenças renais e cardiovasculares foram-se tornando cada vez mais comuns.
Na cultura ocidental contemporânea, o excesso de peso é muitas vezes visto como pouco atrativo e a obesidade está associada a diversos estereótipos negativos
Em qualquer idade, as pessoas obesas enfrentam estigma social e podem ser alvo de bullying, preconceito e discriminação
No entanto, em diversas regiões africanas a obesidade ainda é vista como sinal de riqueza e bem-estar, situação que se tornou ainda mais comum desde o início da epidemia de VIH.
A Organização Mundial de Saúde (OMS) antevê que a preocupação com o sobrepeso e a obesidade possa em breve sobrepôr-se a outras preocupações de saúde pública, como a subnutrição ou as doenças infecciosas, enquanto principal causa de problemas de saúde
A obesidade representa um problema de saúde pública devido à sua prevalência, custos e efeitos na saúde
As medidas de saúde pública procuram compreender e corrigir os fatores ambientais responsáveis pela prevalência cada vez maior de obesidade na população
As soluções apontadas procuram alterar os factores que provocam o consumo excessivo de energia e que inibem a atividade física, como por exemplo implementar refeições saudáveis nas escolas, restringir a publicidade a junk food dirigida a crianças, e diminuir o acesso a bebidas açucaradas na escolas
A nível do planeamento urbano têm sido realizados esforços no sentido de aumentar o acesso a parques e criar espaços pedestres.
No conjunto de todos os países europeus, a obesidade é a causa de 10 a 13% das mortes e estima-se que os custos diretos e indiretos com a doença correspondam a 2–8% da despesa em saúde
Os custos diretos e indiretos dos países União Europeia com a obesidade, em 2002, foram superiores a 32,8 mil milhões de euros
No mesmo ano, em Portugal, o custo direto da obesidade foi estimado em 297 milhões de euros (2,5% da despesa total em saúde), valor a que acrescem os custos indiretos de cerca de 200 milhões de euros.
Nos Estados Unidos, estima-se que em 2005 as despesas médicas devidas à obesidade tenham correspondido a 190,2 mil milhões de dólares, valor que representa 20,6% do total em despesas de saúde desse ano
enquanto que no Canadá o custo da obesidade foi estimado em 2 mil milhões de dólares canadianos em 1997 (2,4% dos custos totais)
Nos Estados Unidos, estima-se que a despesa anual em produtos dietéticos seja um valor entre 40 e 100 mil milhões de dólares.
Os programas de prevenção da obesidade reduzem o custo do tratamento de doenças relacionadas com a obesidade
No entanto, o aumento da esperança de vida leva a custos económicos com outras doenças, pelo que os investigadores concluem que embora a redução da obesidade possa melhorar a saúde pública, é pouco provável que haja redução na despesa total em saúde.
A obesidade pode levar ao estigma social e desvantagens no emprego
Alguns estudos verificaram que as pessoas obesas têm menos probabilidades de serem contratadas para um emprego ou de serem promovidas
As pessoas obesas também recebem, em média, ordenados inferiores às pessoas de peso normal para o mesmo posto de trabalho
As mulheres obesas ganham, em média, 6% menos e os homens 3%
Quando comparados com pessoas de peso normal, os trabalhadores obesos têm, em média, maiores taxas de absentismo do trabalho e maior número de baixas médicas, o que aumenta os custos para os empregadores e diminuiu a produtividade
Um estudo verificou que as pessoas com um IMC superior a 40 kg/m acionavam duas vezes mais seguros de trabalho e tinham doze vezes mais faltas ao trabalho em comparação com o grupo com IMC de 18,5–24,9 kg/m
As lesões mais comuns neste grupo deviam-se a quedas ou esforços, afetando principalmente os membros inferiores, pulsos, costas e mãos.
A obesidade também tem impacto económico em setores específicos
Por exemplo, devido ao crescimento da taxa de obesidade, as companhias de aviação têm encargos com combustível cada vez maiores e pressão para aumentar o tamanho dos bancos
Em 2000, o custo acrescido dos passageiros obesos foi estimado em 275 milhões de dólares
Os prestadores de cuidados de saúde também se vêm obrigados a investir em equipamento especial para pacientes com obesidade grave, como por exemplo equipamento elevatório específico ou âmbulâncias bariátricas
Com a classificação da obesidade como doença crónica, pensa-se que as companhias de seguros apresentem maior abertura para cobrir o tratamento, aconselhamento e cirurgia relacionados com a obesidade, e que diminuam os custos com a investigação e desenvolvimento de fármacos ou terapias genéticas caso sejam compartcipados
No entanto, esta classificação não é obrigatória em termos de legislação, pelo que as seguradoras têm o direito de rejeitar a cobertura para este tipo de tratamento.
Existem diversas organizações que promovem a aceitação da obesidade, as quais se tornaram mais proeminentes a partir da segunda metade do século XX
A principal causa do movimento pró-obesidade é diminuir a discriminação em relação às pessoas obesas ou com sobrepeso
Estes grupos muitas vezes defendem o reconhecimento da obesidade enquanto invalidez
No entanto, alguns setores dentro do movimento também tentam questionar a relação estabelecidade entre a obesidade e os efeitos nocivos que provoca na saúde.
As primeiras representações escultóricas do corpo humano, realizadas há 20 000–35 000 anos, representam mulheres obesas
Alguns historiadores atribuem estas estatuetas de Vénus à tendência para enfatizar a fertilidade, enquanto que outros alegam que possam representar a obesidade das pessoas na época
No entanto, este tipo de corpulência não se observa na arte grega ou romana, provavelmente em função dos ideais de moderação destas civilizações
Esta ausência verifica-se também ao longo de grande parte da arte cristã europeia, onde grande parte dos obesos representados correspondiam a pessoas de estratos socioeconómicos inferiores
Durante o Renascimento, alguns elementos da aristocracia europeia começam a ostentar a sua corpulência, como pode ser observado nos retratos de Henrique VIII
Rubens pintava com frequência retratos de corpo inteiro de mulheres obesas, facto que está na origem do termo "rubenesco"
Durante o século XIX a perspetiva ocidental sobre a obesidade alterou-se profundamente
Após vários séculos em que a obesidade era vista como sinónimo de riqueza e estatuto social, a norma social desejável passou a ser a magreza.
No século XXI, a obesidade infantil atingiu proporções epidémicas, com taxas em ascensão tanto nos países desenvolvidos como nos países em vias de desenvolvimento
Por exemplo, a taxa de obesidade entre crianças do sexo masculino no Canadá subiu de 11% na década de 1980 para mais de 30% na década de 1990
No Brasil, no mesmo período, a taxa de obesidade infantil aumentou de 4 para 14%.
Tal como no caso dos adultos, existem diversos factores que contribuem para o recente aumento da obesidade infantil
Acredita-se que as alterações dietéticas e a cada vez menor atividade física sejam as duas causas mais relevantes
Uma vez que em muitos casos a obesidade infantil persiste na fase adulta e está associada a diversas doenças crónicas, as crianças com obesidade são frequentemente examinadas com o intuito de diegnosticar hipertensão arterial, diabetes, hiperlipidemia e fígado gorduroso
O tratamento em crianças passa sobretudo por intervenções ao nível do estilo de vida e técnicas de comportamento, embora as tentativas de fazer aumentar a atividade física em crianças tenham geralmente pouco êxito
Não se encontra aprovada medicação para este grupo etário.
A obesidade em animais de estimação é relativamente comum em diversos países
Por exemplo, as taxas de sobrepeso e de obesidade em cães nos Estados Unidos variam entre 23 e 41%, sendo 5,1% obesos
No caso dos gatos, a taxa de obesidade era ligeiramente superior a 6,4%
O risco de obesidade em cães está relacionado com o facto dos seus donos serem ou não obesos, embora não se verifique esta relação no caso dos gatos.
Hipertensão arterial é uma doença crónica em que a pressão sanguínea nas artérias se encontra constantemente elevada
A doença geralmente não causa sintomas
No entanto, a longo prazo é um dos principais fatores de risco para uma série de doenças graves como a doença arterial coronária, acidente vascular cerebral, insuficiência cardíaca, doença arterial periférica, incapacidade visual, doença renal crónica e demência.
A hipertensão arterial pode ser classificada como primária ou secundária
Cerca de 90–95% dos casos são primários, tendo origem em fatores não específicos genéticos e de estilo de vida
Entre os fatores relacionados com o estilo de vida que aumentam o risco de hipertensão estão o excesso de sal na dieta, excesso de peso, tabagismo e consumo de álcool
Os restantes 5–10% dos casos são secundários, uma vez que têm origem em causas identificáveis, como doença renal crónica, estenose da artéria renal, doenças endócrinas ou uso de pílula contracetiva.
A pressão arterial é expressa em duas medidas: a pressão sistólica e pressão diastólica
A pressão sistólica é a pressão máxima, enquanto a diastólica é a pressão mínima
Na maior parte dos adultos, a pressão arterial normal em repouso sistólica é de 100 a 130 milímetros de mercúrio (mmHg) e a diastólica de 60 a 80 mmHg
Para a maior parte dos adultos, considera-se que a pessoa tem hipertensão arterial quando a pressão arterial em repouso é consistentemente igual ou superior a 130/90 ou 140/90 mmHg
Em crianças, os valores de referência são diferentes
A monitorização em ambulatório ao longo de 24 horas oferece uma medição mais rigorosa do que os medidores portáteis.
As alterações no estilo de vida e a medicação permitem diminuir a pressão arterial e o risco de complicações
Entre as alterações no estilo de vida estão perder peso, diminuir o consumo de sal, praticar exercício físico e manter uma dieta saudável
Quando as alterações no estilo de vida não são suficientes podem ser administrados medicamentos anti-hipertensivos
Existem três medicamentos que permitem controlar a pressão arterial em 90% das pessoas
O tratamento de pressão arterial de grau II (≥160/100 mmHg) com medicação está associado a um aumento da esperança de vida
O tratamento da pressão arterial entre 130/80 e 160/100 mmHg é menos claro, dado que algumas revisões da literatura observam benefícios enquanto outras não observam benefícios claros
A hipertensão arterial efata entre 16 e 37% de toda a população mundial
Estima-se que em 2010 a hipertensão tenha sido um fator em 18% de todas as mortes (9,4 milhões em todo o mundo).


A hipertensão foi definida como a pressão sanguínea de valor igual ou superior a 140/90 mmHg para um adulto jovem
Esta definição surgiu após 12 anos de experiência em 350 000 indivíduos de idades compreendidas entre os 18 e os 74 anos corroborados posteriormente pelo estudo JNC7
Levantou-se uma polémica acerca deste valor em virtude de a maioria dos médicos, cardiologistas ou não, considerar normal o valor de 140 mmHg
Após um longo consenso, a OMS (Organização Mundial de Saúde) juntamente com a Sociedade International de Hipertensão (ISH), tendo em conta a relação benefício/riscos do tratamento, fixou os limites em 140/90 mmHg sendo considerados normotensos  todos os indivíduos adultos com uma pressão arterial de 140/90 mmHg.
No adulto com mais de 74 anos, (faixa etária não englobada no estudo JNC7) pode-se aceitar um limite de 150/90 mmHg, tendo em conta a rigidez fisiológica da parede arterial
A pseudo-hipertensão entre os idosos é também um factor a considerar
Esta situação deve-se à calcificação das artérias, o que resulta em níveis de leitura anormalmente elevados no esfigmomanómetro enquanto que as medições intra-arteriais são normais
O processo de endurecimento das paredes arteriais com o envelhecimento é progressivo e o aumento de pressão arterial sistólica com a idade também será progressivo sem que isto signifique hipertensão arterial.
A classificação varia consoante estamos perante:
Existem várias classificações da hipertensão arterial, introduzindo cada uma delas, pequenas diferenças nos critérios de inclusão de um determinado valor no grupo hipertensivo.
Assim, segundo a classificação JNC7, em indivíduos de idade igual ou superior a 18 anos, a hipertensão define-se pela medição regular de valores de pressão sistólica e/ou diastólica mais altos do que os valores de referência (actualmente 139 mmHg para a sistólica e 89 mmHg para a diastólica: ver tabela)
No caso de monitorização constante, como a que possa ser feita em casa ou em ambulatório durante o prazo mínimo de 24 horas, são usados valores de referência mais baixos (135 mmHg para a sistólica ou 85 mmHg para a diastólica)
Ainda segundo o relatório JNC7, foram criadas categorias inferiores à hipertensão propriamente dita, chamadas de pré-hipertensão, de forma a melhorar a percepção da existência de um risco contínuo ao longo de qualquer valor acima do valor de 120 mmHg
A classificação JNC7, de 2003, uma revisão de JNC6 assim como de inúmeras publicações, recorre ao termo pré-hipertensão para valores de pressão sanguínea entre 120 e 139 mmHg para a sistólica e entre 80 e 89 para a diastólica
Se bem que os limites da pressão diastólica sejam incontestáveis, já os da pressão sistólica têm sido contestados e o interesse deste conceito de pré-hipertensão não tem sido provado, salvo em grupos com múltiplos factores de risco.
Estes trabalhos, com critérios muitos rígidos e englobando muitos indivíduos que na realidade se verificou serem normotensos, estiveram na base da tomada de posição da OMS para o estabelecimento dos valores acima dos quais se considera hipertensão num consenso de avaliação da relação benefício/risco
Por sua vez, as orientações da ESH-ESC de 2007 e da BHS IV de 2004, subdividem os valores de pressão inferiores a 140/90 nas categorias óptimo, normal e normal alta.
A própria hipertensão pode também ser dividida em várias classificações: a JNC7 distingue a hipertensão de estágio I, II e a hipertensão sistólica isolada
Esta refere-se à pressão sistólica elevada, mas com pressão diastólica normal, sendo comum entre os idosos
As orientações ESH-ESC de 2007 e a BHS IV de 2004 referem ainda um terceiro estágio (hipertensão de estágio III) para indivíduos com pressão sistólica acima dos 179 mmHg ou pressão diastólica acima dos 109 mmHg.
Para concluir, o próprio relatório JNC7 reconhece que a opinião do médico responsável pelo paciente é que é preponderante na determinação do valor normal de pressão arterial para esse doente
Existe unanimidade no que respeita os valores da pressão diastólica que deverão ser inferiores ou iguais a 90 mmHg em qualquer grupo etário (no idoso, por exemplo, se uma pressão sistólica de 149 mmHg pode ser considerada normal, já a diastólica terá que corresponder a um valor igual ou inferior a 90 mmHg).
A ocorrência de hipertensão em crianças e adolescentes ocorre entre 2 e 9% dos indivíduos, dependendo da idade, sexo e etnia, e obesidade
Está também associada ao risco de vir a padecer de complicações clínicas a longo prazo
Hoje em dia, recomenda-se que sejam feitas medições de rotina em crianças com idade superior a 3 anos, sempre que consultem um médico ou façam exames, mas os valores devem ser confirmados ao longo de várias consultas antes de se poder diagnosticar a presença de hipertensão numa criança
Durante a infância, a pressão sanguínea aumenta em proporção com a idade e, nas crianças, define-se como hipertensão a pressão sanguínea média sistólica ou diastólica que seja em três ou mais medições igual ou superior ao percentil 95 de acordo com o sexo, idade e altura da criança
Define-se como pré-hipertensão a pressão sanguínea média sistólica ou diastólica igual ou maior do que o percentil 90, mas menor que o percentil 95
Nos adolescentes, tem sido proposto que o diagnóstico de pré e hipertensão seja realizado com critérios iguais ao dos adultos.
A ocorrência de hipertensão em recém-nascidos é rara, ocorrendo apenas entre 0,2 a 3% dos indivíduos, e a medição da pressão arterial não faz parte dos exames de rotina
A hipertensão é mais comum em recém-nascidos de alto risco
Na determinação da pressão normal em recém-nascidos, devem ser levados em conta outros factores como a idade gestacional e o peso à nascença
Segundo a sua fisiopatologia, a hipertensão é classificada em dois tipos
O primeiro, a hipertensão arterial primária (essencial ou idiopática) que significa que a elevada pressão sanguínea não tem causa médica identificável, correspondendo a 90 a 95% dos casos
Neste tipo de hipertensão, existe uma tendência familiar acentuada mas, como em muitas outras doenças, ainda não se pode falar de hereditariedade
Os restantes cinco a dez por cento correspondem ao segundo tipo, a hipertensão arterial secundária, que é provocada por outros transtornos que afetam os rins, as artérias, o sistema endócrino ou ainda por iatrogenia.
A hipertensão raramente é acompanhada de outros sinais ou sintomas, e o seu diagnóstico usualmente acontece depois de um rastreio ou durante uma consulta médica por outros problemas
Uma parte significativa de hipertensos revela sofrer de dores de cabeça sobretudo na occipital (parte posterior da cabeça) e durante a manhã, assim como vertigens, zumbidos, distúrbios na visão ou mesmo episódios de desmaio.
Durante um exame físico, pode-se suspeitar de hipertensão caso se verifique retinopatia hipertensiva durante a observação do fundo do globo ocular através da oftalmoscopia
Normalmente, o grau de severidade da retinopatia hipertensiva é classificado numa escala de I a IV, embora possa ser difícil distinguir os graus intermédios entre si
O exame oftalmoscópico pode também indicar se um paciente sofre de hipertensão recente ou de longa data.
Outros sinais e sintomas podem sugerir a presença de hipertensão secundária, isto é, a hipertensão cuja causa possa ser identificada, como no caso de doenças renais ou endócrinas
Por exemplo, a obesidade de tipo andróide, a pouca tolerância à glicose e estrias azuladas sugerem a presença de uma síndrome de Cushing
As doenças da tiróide e a acromegalia podem também causar hipertensão e têm sintomas característicos
O sopro abdominal pode ser indicador de estenose da artéria renal, um estreitamento das artérias que irrigam os rins, enquanto a baixa pressão arterial nas extremidades inferiores e/ou pulsações ausentes ou fracas na artéria femoral podem indicar coarctação da aorta (estreitamento da aorta descendente)
Hipertensão instável ou paroxística acompanhada por dores de cabeça, palpitações, palidez e transpiração levantam suspeitas da presença de feocromocitoma.
A pressão arterial muito elevada (diastólica superior a 120 mmHg), de aparecimento súbito, é designada por "crise hipertensiva"
A pressão sanguínea acima destes níveis acarreta um risco elevado de complicações.
Urgência hipertensiva é a crise hipertensiva em que não se verifica lesão de órgãos alvo
A maior parte dos indivíduos com crise hipertensiva tem já antecedentes de pressão arterial elevada; no entanto, o aumento súbito pode dever-se a outros factores
Na maior parte dos casos verifica-se que houve controlo incorrecto da doença ou a interrupção na tomada da medicação
Contudo, estas crises aparecem só em 1% dos hipertensos
As causas mais frequentes são: a interrupção da tomada dos medicamentos, doenças vasculares, uso de algumas drogas como, por exemplo, cocaína e anfetaminas, traumatismo craniano, alguns tipos de tumores, glomerulonefrite aguda, eclampsia ou pre-eclampsia
Estes pacientes raramente são assintomáticos, sendo mais susceptíveis de relatar dores de cabeça (22% dos casos), um estado geral de confusão cognitiva, tonturas, distúrbios visuais tais como visão nublada, flashes de luz, diplopia, sensação de falta de ar devido a pré-edema pulmonar.
Emergência hipertensiva é o termo que se aplica à crise hipertensiva quando o aumento brusco da pressão arterial se acompanha de lesão dos órgãos alvo
Anteriormente designada por "hipertensão maligna", é uma crise hipertensiva mais grave, com compromisso de outros órgãos e pode ser diagnosticada mediante a observação de danos diretos nesses órgãos alvo
Raramente se verifica a lesão de órgãos em valores de pressão diastólica inferiores a 130 mmHg
Entre eles, é de referir a
Nestas situações, é imperativa a redução urgente da pressão arterial de modo a parar o processo de degradação dos órgãos alvo
Se as urgências hipertensivas podem ser tratadas com medicação oral, já as emergências hipertensivas necessitam de um tratamento rápido e eficaz usualmente por via endovenosa pois o paciente está sob um elevado risco de hemorragia cerebral e edema pulmonar mortal
No entanto esta redução deverá ser feita por "patamares" e nunca de uma maneira brusca e abusiva que pode pôr o paciente em estado de choque por hipotensão; esta é uma das razões da introdução de medicamentos por via endovenosa pois permite regular a velocidade de administração e subsequentemente e descida progressiva da pressão arterial.
A hipertensão manifesta-se em cerca de 8 a 10% dos casos de gravidez
Na maior parte casos de hipertensão durante a gravidez já existia uma hipertensão arterial primária prévia
A pressão arterial elevada durante a gravidez pode ser o primeiro sintoma de pré-eclampsia, um estado grave que pode ocorrer durante a segunda metade da gravidez e durante o período puerpério (período pós-parto que dura cerca de seis semanas, até o útero recuperar as suas dimensões normais)
A pré-eclampsia, primeira fase da toxémia gravídica conhecida de longa data, e de etiologia ainda desconhecida, caracteriza-se pela subida da pressão arterial, pela presença de proteínas na urina e edema
Ocorre em cerca de 5% das gravidezes e é responsável por cerca de 16% da mortalidade materna a nível mundial
Esta patologia duplica também o risco de mortalidade perinatal
Geralmente a doença, no início, não tem sintomas específicos e é detectada através de exames de rotina
Quando os sintomas se manifestam, verificam-se normalmente cefaleias (dores de cabeça), distúrbios da visão (frequentemente flashes de luz), vómitos, dores epigástrias e edemas
No que se refere ao edema é frequente o seu aparecimento na face e mãos, localização que é mais habitual nas doenças renais (sinal semiológico que faz o médico suspeitar de uma causa renal, em presença desta localização do edema)
Pode por vezes evoluir para a segunda fase da toxémia gravídica, um estado grave, com risco de vida, designado eclampsia, que constitui uma emergência hipertensiva e envolve várias complicações graves como perda de visão, edema cerebral, convulsões, insuficiência renal, edema pulmonar e coagulação intravascular disseminada (CIVD)
Esta última situação, também chamada de coagulopatia de consumo, caracteriza-se pela presença de tromboses principalmente dos pequenos vasos, hemorragias, petéquias (pequenas hemorragias cutâneas), e evolução rápida para o coma por falência de múltiplos órgãos como os rins, fígado e cérebro
A paciente nesta situação só se salva se for tratada muito precocemente antes de estabelecido o círculo vicioso trombose-hemólise-trombose
A descrição desta situação clínica, feita por Pritchard em 1954 difere um pouco da CIVD clássica e assemelha-se mais à anemia hemolítica microangiopática
Em 1982 Louis Weinstein denominou de síndrome HELLP, acrónimo que reúne as primeiras letras de cada um dos principais sinais laboratoriais em inglês, (Hemolysis, Elevated Liver enzymes, Low Platelet count) a tríade que descreve rapidamente a síndrome laboratorial que acompanha a eclâmpsia no auge da sua gravidade.
Em recém-nascidos e bebés, sintomas como a dificuldade de crescimento, convulsões, irritabilidade, fadiga e síndrome da angústia respiratória do recém-nascido podem estar associados à hipertensão
Mais tarde, em crianças, a hipertensão pode levar a dores de cabeça frequentes, irritabilidade sem causa aparente, fadiga, dificuldade de crescimento, visão turva, hemorragia nasal ou paralisia facial.
A hipertensão arterial primária, essencial, ou idiopática, é a forma mais comum de hipertensão, contabilizando 90 a 95% de todos os casos da doença
Em praticamente todas as sociedades contemporâneas a pressão arterial aumenta a par do envelhecimento, o que é fisiológico e relacionado com o aumento de rigidez da parede arterial.
A hipertensão essencial é consequência de uma interação complexa entre genes e fatores ambientais nomeadamente o consumo de sal
Entre os maus hábitos que contribuem para o aumento da pressão arterial estão o consumo de muito sal na dieta
Ainda não é conclusiva a possível influência de outros factores como o stress, o consumo de cafeína ou a insuficiência de vitamina D.
Pensa-se que a resistência à insulina, comum em casos de obesidade e um dos componentes da síndrome metabólica, contribua também para a hipertensão
Investigações recentes têm vindo a responsabilizar alguns acontecimentos ocorridos durante o início da vida, como o baixo peso à nascença, o tabagismo durante a gravidez e a ausência de amamentação considerando-os factores de risco para a hipertensão primária na idade adulta, embora os mecanismos exactos dessa relação continuem por esclarecer.
A hipertensão arterial secundária é consequência de uma causa identificável
As doenças renais são a causa mais comum de hipertensão secundária, ocupando lugar de destaque a estenose da artéria renal, a par de transtornos endócrinos como a síndrome de Cushing, o hipertiroidismo, o hipotiroidismo, a acromegalia, o hiperaldosteronismo primário ou síndrome de Conn, o hiperparatiroidismo e tumores como os para-gangliomas e os feocromocitomas
Na coartação da aorta a hipertensão arterial existe unicamente acima do nível da coartação, havendo hipotensão nos membros inferiores
Entre as outras possíveis causas encontra-se a obesidade, a apneia do sono, a gravidez, o consumo excessivo de alcaçuz e o uso de determinados medicamentos tais como:
A hipertensão hipercaliémica familiar, conhecida por síndrome de Gordon ou pseudo-hipoaldosteronismo do tipo II, é uma forma muito rara de hipertensão arterial, austosómica dominante, caracterizada por hipercaliémia, acidose metabólica com hiperclorémia e função renal normal, tendo servido de base aos os primeiros estudos genéticos da hipertensão arterial.
Na maior parte dos indivíduos com hipertensão primária, o aumento da resistência periférica total é o primum movens do aumento da pressão sanguínea mantendo-se o débito cardíaco normal.
Alguns jovens com pré-hipertensão têm débito cardíaco elevado, frequência cardíaca elevada e resistências periféricas normais, o que é denominado por "hipertensão periférica hipercinética"
Esta situação enquadra-se dentro da "síndrome hipercinético" cardiovascular e normalmente está relacionado com a ansiedade, sobretudo no adolescente
É ainda motivo de controvérsia se este padrão é comum ou não a todas as pessoas que vêm eventualmente a desenvolver hipertensão
O aumento da resistência periférica total em casos onde a hipertensão está já implementada é geralmente atribuído à vasoconstrição das pequenas e médias artérias e arteríolas.
A pressão de pulso (a diferença entre pressão sanguínea sistólica e diastólica) aumenta frequentemente em pessoas idosas com hipertensão
Isto significa que a pressão sistólica está elevada, enquanto a pressão diastólica se mantém normal ou baixa e é habitualmente designada por hipertensão sistólica
A pressão de pulso elevada nos idosos com hipertensão ou hipertensão sistólica isolada pode ser explicada pelo enrijecimento das artérias, que normalmente acompanha o processo de envelhecimento, mas deve ser sublinhado que um paciente com insuficiência aórtica tem uma diminuição da pressão diastólica o que leva a um aumento da pressão do pulso sem hipertensão.
De modo simplificado, a dinâmica do sangue dentro de um vaso segue exactamente os mesmos princípios da dinâmica dos fluidos
Assim o fluxo de sangue numa artéria reger-se-ia pela equação 



Q
=



(

P

1


−

P

2


)

R




{\displaystyle Q={\frac {(P_{1}-P_{2})}{R}}}

 sendo 




Q



{\displaystyle {Q}}

 o débito, 




R



{\displaystyle {R}}

 a resistência ao fluxo, 





P


1




{\displaystyle {P}_{1}}

 e 





P


2




{\displaystyle {P}_{2}}

 as pressões na origem e na extremidade da artéria, respectivamente.
Chamemos de 




△


P



{\displaystyle {\triangle }{P}}

 o valor 





P


1


−


P


2




{\displaystyle {P}_{1}-{P}_{2}}


O mesmo é dizer que 




△



{\displaystyle {\triangle }}






P



{\displaystyle {P}}

 = 




Q



{\displaystyle {Q}}

 



×


{\displaystyle \times }

 




R



{\displaystyle {R}}

 ou seja, o gradiente de pressão é directamente proporcional à resistência que, no caso da circulação sistémica, seria a resistência periférica total
Se forem introduzidas as variáveis viscosidade do sangue (




η



{\displaystyle {\eta }}

), raio (




r



{\displaystyle {r}}

) e comprimento do vaso (




l



{\displaystyle {l}}

), encontramos a lei de Poiseuille 



Q
=



P
π

r

4




8
l
η





{\displaystyle Q={\frac {P\pi r^{4}}{8l\eta }}}

 ou 



Δ
P
=



8
η
l
Q


π

r

4







{\displaystyle \Delta P={\frac {8\eta lQ}{\pi r^{4}}}}

.
Daqui se evidencia que a resistência é inversamente proporcional ao raio do vaso
Também é de salientar que a influência do raio do vaso é elevada à quarta potência (




r



{\displaystyle {r}}

) o que ajuda a compreender a facilidade com que qualquer influência sobre o raio faz aumentar ou diminuir a pressão
Por outro lado, o débito cardíaco 




Q



{\displaystyle {Q}}

 é o produto do volume de sangue ejectado ("stroke volume" no diagrama) a cada contração cardíaca pela frequência cardíaca
A resistência vascular depende directamente da estrutura vascular, isto é, do estado da parede arterial e das suas propriedades contráteis (noção importante quando se está a avaliar a pressão arterial de pessoas idosas).
Têm sido propostos vários mecanismos que explicam o aumento das resistências periféricas na hipertensão: A falência da atuação dos baroreceptores, as anomalias de funcionamento do sistema nervoso simpático, e a retenção de sódio e vasoconstrição pelo Sistema renina-angiotensina-aldosterona e as causas de origem genética.
Os baroreceptores são sensores do tipo mecanorreceptores, localizados nos vasos, que captam a pressão média no seu interior e enviam mensagens ao cérebro de modo a baixar ou aumentar a pressão mantendo-a nos níveis considerados habituais para o indivíduo em causa
O cérebro, mais precisamente o núcleo do trato solitário no bulbo raquidiano responde, via sistema nervoso autónomo, influenciando o débito cardíaco mas sobretudo as resistências periféricas
Atuam assim de imediato, como uma parte de um mecanismo de feedback negativo mais propriamente chamado baroreflexo
São um importante mecanismo de regulação rápida da pressão arterial
Por vezes esta regulação é "exagerada" como no exemplo clássico das crises hipotensivas
O paciente sofre uma brusca descida de tensão arterial, podendo mesmo desmaiar, o baroreflexo atua e uns minutos depois encontramos tensão arterial 160/110 por exemplo, o que pode induzir num erro diagnóstico de hipertensão
Outro exemplo da sua atuação é na hipotensão ortostática: quando passamos da posição de decúbito para o ortostatismo, a força da gravidade e a pressão ortostática fazem com que haja um afluxo súbito de sangue para as regiões de declive com diminuição secundária a nível cerebral
No adulto jovem o baroreflexo atua rapidamente quando o indivíduo passa da posição de decúbito para o ortostatismo e não há sintomatologia
Mas na pessoa idosa, o baroreflexo é mais lento e é frequente a sensação de tontura ou desequilíbrio com estas bruscas mudanças de posição
Quando a hipertensão se estabelece e fica um longo período sem ser diagnosticada e tratada, os baroreceptores estabelecem os novos valores como sendo os "normais", dificultando por vezes o início do tratamento e podendo estar relacionados com a crise hipertensiva quando o paciente suspende bruscamente a medicação
Pelo mesmo mecanismo, se a hipertensão for detectada no início, com o tratamento os baroreceptores fazem um "reset" e é frequente, passado algum tempo, o paciente necessitar de menos medicação e progressivamente suspendê-la.
Os efeitos reguladores da atividade simpática renal, sobre a produção de renina, a filtração glomerular e a reabsorção tubular do sódio, são hoje bem conhecidos
Mesmo os níveis que não são suficientes para provocar vasoconstrição, aumentam a secreção de renina e a retenção de sódio
O stress, que se acompanha de estimulação simpática, é um factor de peso para o aumento da pressão arterial sobretudo diastólica (reflexo do aumento das resistências periféricas)
Assim o sistema nervoso simpático tem um efeito desencadeador não só diretamente a nível vascular mas também, de modo indireto estimulando o sistema renina-angiotensina
Muito se tem discutido sobre a ação deste sistema
Todos os estudos apontam para a ação predominante do SNS na fisiopatologia da hipertensão por intermédio do sistema renina-angiotensina-aldosterona e não, exclusivamente, por uma ação direta isoloada.
A maior parte das evidências apontam para este mecanismo do Sistema renina-angiotensina-aldosterona como o responsável pelo aparecimento da hipertensão, via retenção de sódio e vasoconstrição
Este sistema é uma cascata hormonal, envolvendo péptidos, enzimas e recetores e cuja ação se manifesta no controlo da pressão arterial, do equilíbrio hidroeletrolítico e da volémia
A renina, primeiro interveniente nesta cascata, foi descoberta em 1898, por Robert Tigerstedt e Per Bergman
Desde então, a investigação não parou mas foram necessários cerca de 50 anos para que os outros intervenientes neste complexo sistema fossem descobertos e conduzissem ao conhecimento e às consequências terapêuticas.
Os principais intervenientes neste sistema são o angiotensinogénio, a renina, a angiotensina I, a enzima de conversão da angiotensina (ECA) e a angiotensina II
O angiotensinogénio é uma α-2 globulina produzida pelo fígado
A renina, produzida no aparelho justaglomerular do rim como uma pré-hormana (a pré-renina), é ativada pela perda do seu péptido N-terminal
Vai então atuar sobre o angiotensinogénio destacando o péptido terminal e originando assim a angiotensina I, que é inativa
Entra então em ação o enzima de conversão da angiotensina, produzida pelo epitélio vascular renal e pulmonar principalmente, que atua sobre a angiotensina I e a transforma em angiotensina II, péptido biologicamente ativo
Este péptido liga-se a pelo menos quatro tipos de recetores, sendo os melhor estudados os recetores de tipo 1: receptor AT1
Ao ligar-se ao recetor, a angiotensina I provoca vasoconstrição
Mas esta interligação não origina só vasoconstrição
Outros efeitos deletérios foram também referenciados como aumento da reabsorção do Na pelo rim, inflamação, stress oxidativo, efeitos sobre o coração com aumento do inotropismo, aumento da proliferação celular com hipertrofia ventricular esquerda, aumento da produção de aldosterona e de ADH por interferência no córtex suprarenal e no sistema nervoso central, respectivamente
Todo este complexo sistema é autorregulado com um sistema de feedback impressionante: assim a produção de renina é estimulada pela diminuição da concentração de cloreto de sódio, o aumento de atividade simpática, a diminuição da pressão arterial com diminuição da pressão de perfusão renal e estimulação dos baroreceptores
A presença de uma quantidade aumentada de angiotensina I junto do aparelho justaglomerular tem uma ação inibidora da formação de renina
Por sua vez, a produção de angiotensinogénio é estimulada por estrogénios, glicocorticóides e citocinas inflamatórias como a interleucina-1.
A alteração mais simples e mais frequente a nível do DNA é o polimorfismo de nucleotídeo único (SNP) que consiste na a troca de um par de bases do DNA
Isto pode originar a troca de um aminoácido na proteína codificada pelo gene, com possível alteração nos mecanismos de controle da pressão arterial
Este tipo de variação genética é considerada atualmente como uma das causas da predisposição individual para uma determinada doença
Os fatores ambientais, associados a este substrato genético polimórfico, vão conferir a predisposição de cada indivíduo a desenvolver ou não uma patologia de causa multifatorial como é o caso da hipertensão arterial
Foram identificados cerca de 150 genes, separados por classes funcionais, relacionados com a hipertensão
O SNP e outros tipos de alterações nestes genes estão sendo intensamente investigados
Pouco se sabe sobre os genes envolvidos na regulação da pressão arterial
As evidências sugerem que 30% dos casos são devidos a hereditariedade
Os genes que regulam o complexo sistema renina-angiotensina são alvo de estudos recentes
Segundo alguns trabalhos, o SNP do gene regulador da formação de angiotensinogénio (AGT) está associado com o aumento plasmático desta substância e com níveis tensionais mais altos nos pacientes portadores desta mutação, porém especula-se ainda sobre a ação destes e dos genes que regulam os receptores da angiotensina II de tipo 1 (AGT1R) e os receptores da angiotensina II do tipo 2 (AGT2R)
O gene da enzima de conversão da angiotensina está um pouco melhor estudado e o seu SNP está relacionado com os níveis plasmáticos da referida enzima.
Têm vindo a ser identificados outros genes comuns capazes de efectuar alterações na pressão sanguínea; os genes CYP3A5 e ABCB1 interatuam sobre a pressão arterial e o seu efeito é modificado pelo consumo de sal
Alguns trabalhos também sugerem que o efeito do gene ABCB1 no controlo da pressão arterial parece estar ligado à interacção do sistema renina-angiotensina com o sódio
Alguns estudos chegaram à conclusão que a glicoproteína-P (PGP em inglês) e o gene CYP3A5 interactuam um com o outro
A hipertensão é assim considerada como uma doença crónica, poligénica e multifactorial, em que as alterações genéticas ainda não estão estabelecidas mas tudo leva a crer que interatuem com os factores ambientais para que a patologia se manifeste ou não.
O diagnóstico de hipertensão faz-se na presença de pressão sanguínea elevada e persistente
Tradicionalmente, isto implica três medições com esfigmomanómetro efectuadas em consultório médico, depois de o doente estar em repouso pelo menos 10 minutos, efectuadas em posição sentada e repetidas com um intervalo a considerar consoante a gravidade do aumento de pressão arterial, se tal for o caso
No caso de se tratar de uma hipertensão limite, o intervalo poderá ser de um mês
Nos casos se hipertensão severa o doente deverá ser imediatamente medicado
De modo a evitar o "efeito bata branca" em que por ansiedade a pressão arterial aumenta em presença do médico, poderá ser facultada a medição da pressão arterial em casa, com medições a várias horas do dia, sempre após os 10 minutos de repouso
O paciente fará assim um mapping durante 3 a 7 dias que será avaliado pelo seu médico assistente
As medições deverão no primeiro dia ser efectuadas nos dois braços, e se houver uma diferença de mais de 20 mmHg na pressão sistólica, as medições seguintes serão sempre efectuadas no braço com pressão mais alta
Em caso contrário será sempre escolhido o braço direito, pois antes de chegar às artérias do lado esquerdo já foi alimentado o braço direito e o cérebro e a pressão será assim discretamente mais baixa do lado esquerdo
O diagnóstico inicial de hipertensão deve também considerar um exame físico e todo o historial médico do paciente
A pseudohipertensão entre os idosos pode também ser um factor a considerar no diagnóstico
Esta situação deve-se à calcificação das artérias, o que resulta em níveis de leitura anormalmente elevados no esfigmomanómetro enquanto que as medições intra-arteriais são normais
Não esquecer que o processo de endurecimento das paredes das artérias é progressivo com o envelhecimento e o aumento de pressão arterial sistólica com a idade também será progressivo sem que isto signifique hipertensão arterial
Estes dados desafiam o consenso actual, muito rígido nos critérios de hipertensão arterial acima dos 70 anos.
Uma vez completo o diagnóstico da hipertensão, o médico pode tentar identificar a causa com base em outros sintomas eventuais
A hipertensão secundária é mais comum na infância e adolescência, sendo na maior parte dos casos causada por doenças renais
A hipertensão primária é mais comum entre adultos e corresponde a múltiplos factores de risco, incluindo obesidade, hábitos alimentares em que predomina o excesso de sal, o consumo diário de águas ricas em cloreto de sódio e antecedentes familiares
Podem também ser realizados exames de laboratório de modo a identificar possíveis causas de hipertensão secundária, e determinar também se a hipertensão já causou danos no coração, olhos ou rins
Também são normalmente realizados exames complementares para a diabetes e colestrol elevado, uma vez que ambos são factores adicionais de risco para a eventualidade de uma doença cardiovascular e podem requerer tratamento complementar.
A creatinina no soro é medida com o intuito de despistar a eventual presença de doenças renais, que podem ser tanto causa como consequência da hipertensão
A creatinina do soro por si só pode sobrestimar a taxa de filtração glomerular (TFG), e orientações recentes têm indicado o uso de equações preditivas para avaliar correctamente a taxa
A TFG indica também uma medida base da função renal que pode ser usada para monitorizar efeitos secundários nos rins de determinados fármacos anti-hipertensivos
Para além disso, detecção de proteínas em amostras de urina é usada como indicador secundário de eventuais doenças renais
É feito também um electrocardiograma (ECG) de modo a revelar eventuais indícios de que o coração esteja a ser submetido a um esforço adicional devido à pressão arterial elevada
Pode também mostrar se existe ou não uma hipertrofia do ventrículo esquerdo ou se o coração foi já sujeito a um distúrbio menor, como por exemplo um enfarte silencioso
Pode ainda ser realizada uma radiografia torácica ou um ecocardiograma de modo a verificar sinais indicadores de um eventual aumento ou danos no coração.
A maior parte das complicações que a pressão arterial elevada acarreta é experienciada por indivíduos que não estão diagnosticados como hipertensos
Deste modo, torna-se necessária a adopção de estratégias de redução das consequências da pressão arterial elevada e reduzir a necessidade de terapias à base de fármacos anti-hipertensivos
Antes de se iniciar qualquer tratamento, recomenda-se alterações do estilo de vida de modo a reduzir a pressão arterial
Como meio de prevenção primária da hipertensão, as orientações de 2004 da Sociedade Britânica de Hipertensão, em consonância com as definidas já pelo Programa Educativo para a Alta Pressão Sanguínea dos Estados Unidos em 2002 recomendam as seguintes alterações ao estilo de vida:
As alterações dos hábitos e estilo de vida, quando feitas correctamente, podem baixar a pressão arterial para valores idênticos aos obtidos com medicação
A combinação de duas ou mais alterações pode produzir resultados ainda melhores.
Com a evolução da investigação sobre a genética da hipertensão arterial será possível no futuro estudar geneticamente a população, detetar os fatores de risco geneticamente relacionados com a doença e fazer a profilaxia desta.
A primeira forma do tratamento da hipertensão é idêntica às alterações no estilo de vida recomendadas na prevenção e incluem: alterações na dieta, exercício físico, e controle do peso
Todas estas medidas têm demonstrado reduzir de forma significativa a pressão arterial em indivíduos hipertensos
No entanto, se a pressão for tão elevada que justifique o uso imediato de medicamentos, as alterações dos hábitos de vida continuam a ser recomendadas em conjunto com a medicação
Tem-se publicitado vários programas de redução da hipertensão arterial através da redução do stress psicológico, como técnicas de relaxamento, meditação ou biofeedback
No entanto, as alegações de eficácia quase nunca são confirmadas por estudos científicos, e os poucos que existem são de qualidade e metodologia duvidosa.
A alteração dos hábitos alimentares, como a adopção de uma dieta de baixo teor de sal, é benéfica
Está demonstrado que uma dieta com pouco sal durante um período de apenas quatro semanas, oferece benefícios tanto em hipertensos como em pessoas com pressão arterial regular
De igual modo, está também demonstrado que uma dieta rica em frutos secos, cereais integrais, peixe, carne branca, frutas e vegetais, diminui de forma significativa a pressão arterial
Uma das principais vantagens da dieta é diminuir o consumo de sódio, embora seja rica em potássio, magnésio, cálcio e proteínas.
Estão disponíveis várias classes de fármacos para o tratamento da hipertensão, referidos em conjunto como anti-hipertensivos
A prescrição deve considerar sempre o risco cardiovascular do paciente (incluindo o risco de enfarte do miocárdio e acidente vascular cerebral) e os valores de pressão arterial medidos, de forma a obter um perfil cardiovascular preciso do paciente
Caso seja dado início ao tratamento com medicamentos, o JNC7 recomenda que o médico não só monitorize a resposta do paciente à medicação, como identifique os efeitos secundários que possam vir a ocorrer
Segundo o relatório JNC7, a redução da pressão arterial em apenas 5 mmHg pode reduzir o risco de um AVC em 34%, de cardiopatia isquémica em 21%, e a probabilidade de vir a sofrer de demência, insuficiência cardíaca e do risco de morte por doença cardiovascular
O objectivo do tratamento deve ser reduzir a pressão arterial para valores iguais ou inferiores a 140/90 mmHg na maior parte dos indivíduos (tendo em conta a idade e a rigidez ou mesmo calcificação da parede arterial) e inferiores nos que sofrem de diabetes ou de doenças renais (alguns profissionais recomendam a manutenção de valores inferiores a 120/80 mmHg) porém tendo sempre em conta cada caso em particular
Caso não se consiga atingir este objectivo, deve ser realizada uma alteração no tratamento, já que a inércia clínica é um claro impedimento do controlo da pressão arterial.
As orientações para a selecção de fármacos e a determinação da melhor forma de tratar vários subgrupos têm mudado ao longo dos anos e entre os próprios países
O melhor fármaco de primeira linha é ainda controverso
As orientações da Colaboração Cochrane, da Organização Mundial de Saúde, as Guideline americanas, as do Reino Unido, as VI Diretrizes Brasileiras de Hipertensão, variam muito sobre qual o medicamento de primeira linha a usar no tratamento da hipertensão, mas são unânimes na utilização dos inibidores da enzima de conversão da angiotensina (IECAs) e/ou dos antagonistas dos receptores da angiotensina II (ARAs)
No Japão e no Canadá é aceitável começar o tratamento com qualquer uma das seis classes de medicamentos, que incluem IECAs, Bloqueador dos canais de cálcio, diuréticos, bloqueadores beta e bloqueadores alfa, se bem que no Canadá os bloqueadores alfa estão excluídos
Vemos assim que as opiniões divergem muito e o médico assistente do paciente ou o cardiologista deverá avaliar cada caso de modo a decidir qual a melhor terapêutica para o seu paciente.
Os antagonistas dos receptores da angiotensina IIs, provaram ser excelentes medicamentos para um controlo inicial da hipertensão arterial e são muito eficazes quando associados aos IECAs, em muitas das hipertensões até então consideradas resistentes, em casos de insuficiência renal ou cardíaca
Os bloqueadores do cálcio provocam com muita frequência edemas dos membros inferiores que podem chegar ao estádio de eritromelalgia e são pouco aconselháveis nos idosos cuja mobilidade está diminuída e no adulto jovem em presença de insuficiência venosa dos membros inferiores
Os diuréticos têm um papel predominante assim como os beta-bloqueantes.
Recentemente, os inibidores diretos da renina, dos quais o alisquireno é o único disponível, são promissores, podem ser úteis quando outros bloqueadores falharam, porém estão ainda em fase experimental, não se conhecendo as suas contra-indicações nem os eventuais efeitos secundários
Estão obviamente contra-indicados na gravidez e não se conhecendo os efeitos colaterais também não se pode conhecer as interações medicamentosas
Há estudos que demonstram a potencialização do efeito quando administrados conjuntamente com os diuréticos, os IECAs e os antagonistas dos receptores da angiotensina IIs porém é ainda muito cedo para tirar conclusões e usá-los na clínica diária, sobretudo em pacientes com outras patologias tomando medicação diferente da anti-hipertensiva.
A maioria dos pacientes necessita de mais do que um fármaco para controlar a hipertensão
As orientações da JNC7 e ESH sugerem iniciar o tratamento com dois fármacos quando a pressão arterial for superior ao objectivo pretendido em 20 mmHg (160 mmHg)para a sistólica e 10 mmHg (99 mmHg) para a diastólica
As combinações sugeridas são inibidor do sistema renina-angiotensina-aldosterona com diuréticos ou inibidores do sistema renina-angiotensina com bloqueadores dos canais de cálcio
As combinações aceitáveis são antagonistas dos receptores da angiotensina IIs+IECAs, antagonistas dos receptores da angiotensina IIs ou IECAs+ Bloqueadores beta; se necessário juntar a estas duplas terapêuticas um diurético
As associações de bloqueadores dos canais de cálcio com diuréticos, bloqueadores de canais de cálcio à base de diidropiridina com bloqueadores beta, ou bloqueadores dos canais de cálcio à base de diidropiridina com diltiazem são menos eficazes e acompanham-se de efeitos colaterais já mencionados.
As combinações inaceitáveis são o triplo bloqueio, por exemplo, antagonistas dos receptores da angiotensina IIs + IECAs + beta bloqueadores.
Devido ao elevado risco de insuficiência renal aguda, deve ser evitada sempre que possível a combinação de um inibidor da enzima de conversão da angiotensina ou antagonista do receptor da angiotensina II com anti-inflamatórios não esteróides, sobretudo inibidores selectivos da COX-2 ou medicamentos de venda livre como o ibuprofeno
Estão disponíveis no mercado embalagens com combinações fixas de duas classes de fármacos que, embora possíveis de usar por qualquer pessoa, devem ser reservados para aqueles que já tenham sido sujeitos a uma terapêutica à base de um fármaco único.
Após exclusão de arteriopatia com calcificações da parede arterial, que falseiam a medição correcta da pressão arterial, a hipertensão classifica-se como "resistente" quando a medicação se mostra incapaz de a diminuir para níveis normais.
Se bem que a OMS (Organização Mundial de Saúde) considere idoso todo o indivíduo com mais de 60 anos, o termo "velho" está mais relacionado com o estado fisiológico do que com o cronológico e só a partir dos 65 anos, em termos de fisiologia, o adulto passa a ser englobado verdadeiramente na medicina geriátrica
Mas mesmo em geriatria, as particularidades de um paciente com setenta anos serão muito diferentes do paciente com 85 anos mesmo que ambos sejam saudáveis ou tenham a mesma patologia
Isto deve-se ao envelhecimento dos órgãos chave que manipulam os medicamentos (fígado e rins principalmente)
 O tratamento da hipertensão moderada ou grave em indivíduos com setenta anos ou mais contribui para a redução da mortalidade e da percentagem dessa mortalidade associada a doenças cardiovasculares
Existem poucos estudos que levam em conta indivíduos com idade superior a 80 anos, mas uma revisão recente concluiu que o tratamento da hipertensão diminui o número de indivíduos afectados e de mortes por doenças cardiovasculares, embora tal não reduza de forma significativa o número total de mortes.
O valor aceitável de pressão arterial em indivíduos com mais de 74 anos, é discretamente mais elevado, 150/90 mmHg, isto porque tem que se ter em atenção a rigidez da parede arterial (normal na pessoa idosa)
Vejamos porquê: quando medimos a pressão arterial máxima, o valor que obtemos é a pressão existente dentro da artéria (pressão do sangue) adicionado à pressão necessária para colapsar a parede arterial
Este último valor é desprezível quando se trata de um adulto jovem sem artériopatia
Já o mesmo não acontece na pessoa idosa onde a rigidez da parede arterial, própria da idade torna este valor significativo
Além disso, havendo um aumento das resistências cerebrais (fisiológico na pessoa idosa) é necessária uma pressão máxima um pouco mais elevada para que a irrigação cerebral seja feita correctamente
Se tratarmos uma pessoa idosa como a intenção de mantermos a sua pressão arterial sistólica a menos de 140 mmHg essa pessoa irá fazer hipotensão ortostática, hipotensão após as refeições, hipotensão com queda muito frequente ao levantar-se a meio da noite para urinar (como tantas vezes acontece)
Mais de 30% dos idosos caem cada ano e em cerca de 10% a intervenção cirúrgica é necessária
Nestes pacientes é fácil termos uma ideia do estado arterial pela palpação das artérias dos membros superiores sobretudo a nível da prega do cotovelo
A artéria humeral, de parede rija e muitas vezes calcificada, é sentida como um cordão duro debaixo dos dedos do médico
Os cuidados a ter no tratamento da pessoa idosa estão bem regulamentados em vários países, com base nos estudos que têm sido efetuados e publicados, sobretudo com base nos critérios de Beers.
O tratamento deve ser muito cauteloso: Segundo Chobanian, o melhor será começar com um IECA ou com um inibidor dos receptores da angiotensina, cujos efeitos colaterais são pequenos, salvo existência de patologias paralelas
Os diuréticos serão utilizados se necessário mas não deve ser esquecido que a pessoa idosa bebe pouca água e desidrata facilmente sobretudo durante o verão; além disso facilmente perdem potássio
Se excluirmos esta situação e se uma monitorização do potássio sérico for feita, os diuréticos da classe das tiazidas podem ser utilizados como drogas de primeira linha no tratamento da hipertensão arterial do idoso
Quanto aos bloqueadores dos canais de cálcio, o seu uso deverá ser ponderado na medida em que estes medicamentos provocam um "pooling" venoso importante com edema dos membros inferiores, com a agravante de que estes pacientes andam pouco e o trabalho dos músculos das pernas não contribui para a drenagem do sistema venoso
Além disso os bloqueadores dos canais de cálcio com mais efeito vasodilatador (Dihidropiridinas) podem provocar taquicardias, taquiarritmias e aumentam assim o consumo de oxigénio pelo miocárdio, podendo agravar uma doença coronária pré-existente.
Depois de excluir a hipótese de o doente ter as suas artérias calcificadas, como já tem sido presenciado em muitos serviços de cardiologia e nos quais a hipertensão sistólica a 300 mmHg pode ser documentada, define-se hipertensão resistente como a hipertensão que se mantém em valores superiores aos pretendidos apesar do uso combinado de pelo menos três fármacos anti-hipertensivos pertencentes a três classes diferentes de drogas anti-hipertensivas
Têm vindo a ser publicadas orientações para tratamento da hipertensão resistente no Reino Unido e nos Estados Unidos.
A hipertensão é o fator de risco mais importante e evitável nos casos de morte prematura à escala mundial
Aumenta significativamente o risco de cardiopatia isquémica, acidentes vasculares cerebrais, doença arterial periférica, e outras doenças cardiovasculares, incluindo insuficiência cardíaca, aneurisma da aorta, aterosclerose e embolia pulmonar
A hipertensão arterial constitui ainda um fator de risco para a insuficiência renal crónica e para o transtornos cognitivos como perturbações da memória e períodos de confusão e mesmo demência
Outras complicações podem ainda incluir retinopatia hipertensiva e nefropatia hipertensiva.
Numa análise bibliográfica efetuada entre 1998 e 2000, usando Medline, complementada por pesquisa manual, foi feito um estudo estatístico na Universidade de Tulane (Nova Orleães) que chegou à conclusão de que cerca de mil milhões de pessoas sofrem de hipertensão arterial, o que corresponde a 26% da população adulta mundial
No entanto, outros estudos mostram que a taxa varia de região para região, desde taxas de 0% nos Bushmen do deserto do Kalahari (a ausência de sal na alimentação tem sido considerada como uma das razões mas também a alimentação à base de carnes com pouca gordura, ausência de alimentos fritos, etc), 3,4% (homens) e 6,8% (mulheres) na Índia rural, até taxas alarmantes de 34% na população americana, apresentando os adultos afro-americanos as taxas de hipertensão mais altas do mundo (44%)
Seguindo as normas de JNC7, foi feito um estudo prospetivo Cortar sobre a taxa de incidência de hipertensão em Portugal, mais precisamente na região do Porto
300 000 indivíduos foram contactados por telefone no domicílio
A idade mínima de inclusão no estudo foi ≥ 18 anos e a máxima 80 anos, a pressão arterial considerada como hipertensão ≥140/90
Os valores encontrados são impressionantes pois cerca de 40% da população são hipertensos e há uma taxa de incidência de 47,3/1000-ano (cerca de duas vezes mais que na população espanhola)
A conclusão deste estudo é: Portugal tem uma taxa de incidência muito alta, a qual aumenta com a idade, a falta de escolaridade e a obesidade
A Polónia também apresenta muito taxas elevadas
A população estudada englobou indivíduos dos 18 aos 93 anos, considerando ≥140/90 como sendo hipertensão.
Em zonas de Portugal onde antigamente (há uns 40 anos) se conservava os alimentos no sal, o aparecimento dos congeladores reduziu a incidência da hipertensão nessas zonas
Porém o consumo de sal em algumas regiões é ainda exagerado
Portugal tem o pão mais salgado da Europa! Este estudo efetuado pelo Professor Mário Espiga Macedo reflete de modo excelente a prevalência da hipertensão em Portugal: apesar de a população estudada (5023 indivíduos)atingir idades compreendidas entre os 18 e os 90 anos, o estudo foi efetuado por grupos etários, dos 18 aos aos 34 anos, dos 35 aos 63 e acima de 64 anos
Os critérios utilizados foram os do Multiple Risk Factor Intervention Trial considerando hipertensos todos os indivíduos com valores de pressão arterial ≥140/90 mmHg
Assim, os hipertensos do estádio 2 segundo JNC7 (≥160 mmHg de pressão máxima) foram encontrados valores de prevalência de 2,4% antes dos 35 anos, 13,2% dos 35 aos 64 e 37,1% com mais de 65 anos (dos 65 aos 90 anos)
No que diz respeito à pressão arterial estádio 1 (≥140–159 mmHg) encontraram-se valores 16,3%, 27,7% e 32,2% respetivamente.
Fazendo uma análise da bibliografia é difícil avaliar a incidência de hipertensão no mundo na medida em que cada país, e em cada país cada região, tem os seus hábitos alimentares e estes condicionam fortemente a incidência da hipertensão arterial
A maioria destes estudos estatísticos utiliza os critérios de hipertensão emanados do estudo Multiple Risk Factor Intervention Trial (cuja população em estudo compreendeu indivíduos de 18 a 74 anos), que estabeleceu como hipertensão todo o valor de pressão arterial ≥140 mmHg para a sistólica, e englobam nas populações estudadas idosos até 80 e mesmo 90 anos (o estudo em Portugal) e 93 anos (caso da Polónia) cuja rigidez da parede arterial falseia o resultado
Estes critérios estão em desacordo com o valor de 140 mmHg considerado normal pela OMS e pela Sociedade Internacional de Hipertensão (ISH) e com as directivas emanadas pelas diferentes Sociedades de Geriatria
Num estudo de bibliografia efetuado no Brasil pelo Grupo de Pesquisa em Epidemiologia de Doenças Crónicas e Ocupacionais da Faculdade de Medicina da Universidade Federal de Minas Gerais, Belo Horizonte, com a colaboração de Secretaria de Vigilância em Saúde, Ministério da Saúde, Brasília, usando Medline e LILACS, e segundo os critérios JNC7, foram selecionados 13 trabalhos de prevalência com base populacional realizados desde 1990
Conclui-se haver uma elevada prevalência de 44,4%, 47,9 no sexo masculino e 41% no sexo feminino
Quando estes dados foram estudados segundo os critérios da OMS, sendo hipertensão arterial a pressão sistólica >140 mmHg e/ou pressão diastólica >90 mmHg e/ou uso corrente de anti-hipertensor, os estudos mostraram taxas de prevalência à volta de 20%, sem distinção de sexo, mas com a tendência de aumento com a idade
Estes mesmos valores são encontrados em outros países da América Latina
Estes resultados são importantíssimos em saúde pública e refletem a disparidade dos valores prevalência, do simples ao dobro, só pela inclusão no grupo de hipertensos de todos os indivíduos com pressão arterial igual a 140 mmHg.
A hipertensão infantil acompanha a subida da incidência da obesidade infantil
Normalmente está associada a uma história familiar de hipertensão e obesidade
A maior parte da hipertensão infantil, sobretudo entre pré-adolescentes, deve-se à presença de outro transtorno
Para além da obesidade, as doenças renais são a causa mais comum (60-70%) de hipertensão infantil
A investigação está a estudar as causas genéticas da hipertensão infantil e os estudos mais recentes apontam para um importância incontestável do fator genético
Porém os resultados ainda necessitam de maior precisão e confirmação.
Já na Antiguidade, a curiosidade pela circulação do sangue era uma realidade
Giovanni di Paolo (1403-83) no seu quadro, A decapitação de São João o Baptista, pintou como três jatos de sangue jorravam a diferentes velocidades do pescoço decapitado do santo
Em Itália, físicos e matemáticos sob a tutela de Galileu, entre eles Giovanni Borelli, interessavam-se pelo estudo da circulação
Borelli defendia as propriedades hidráulicas da circulação tendo o coração a função de bomba
Contudo ainda não existia um método de medida que pudesse validar os seus resultados
Em 1551, o Doutor Amato Lusitano (João Rodrigues de Castelo Branco, 1511-1568), médico português, descreveu a circulação do sangue na sua obra em sete volumes Curationum Medicinalium Centuriæ Septem e, pela primeira vez, afirmou que as veias tinham válvulas
77 anos depois, William Harvey (1578-1657), na obra Exercitatio Anatomica de Motu Cordis et Sanguinis in Animalibus, descreveu também a circulação sanguínea
Mas só em 1733, o Rev
Stephen Hales, Reitor de Farringdon em Hampshire e ministro em Teddington no Middlesex, publicou o primeiro método de medida da pressão arterial no segundo volume de "Statical Essays, Containing Haemastaticks"
Apesar do conhecimento já aprofundado de Hales sobre a circulação, foi Thomas Young, físico do St George's Hospital, autor da teoria ondulatória da luz e tradutor da Pedra de Roseta, que publicou um dos primeiros escritos sobre a pressão arterial
Porém a tentativa de quantificação da pressão sanguínea só começou após Jean Louis Marie Poiseuille ter inventado o manómetro de mercúrio.
O conhecimento da hipertensão deve-se aos estudos de Richard Bright iniciados por volta do ano 1820
Contemporâneo de Addison e Hodgkin, seus colegas, estudou por autópsia as consequências da hipertensão e deu um contributo incalculável para o conhecimento que se tem hoje
Em 1827, Bright publicou o seu livro "Reports of Medical Cases Selected with a view to Illustrating the Symptoms and Cure of Disease by a Reference to Morbid Anatomy"
Estava descrita a Doença de Bright
Em 1868, George Johnson descreveu pela primeira vez a hipertrofia da camada muscular da parede das pequenas artérias do rim, e subsequentemente em outros órgãos, dos doentes com doença de Bright
Em 1871, na Alemanha, Ludwig Traube e, em 1872, Sir William Gull, confirmam os achados de Johnson sobre a doença de Bright.
O manómetro de Poiseuille foi usado em membros que iam ser amputados pois a artéria ficava destruída após a sua utilização
A primeira medida indirecta da pressão arterial foi feita por Hérisson em 1834, com um esfigmomanómetro "artesanal" (um simples copo com um tubo graduado e coberto por uma membrana a qual era comprimida contra a artéria radial - lia-se depois o nível do mercúrio que subia no tubo graduado)
Foi o precursor dos manómetros de membrana que tornaram possível a medida indirecta da pressão sem destruição da artéria
O primeiro instrumento especificamente designado para medir a pressão arterial foi o de Vierordt em 1854, de técnica de utilização complicada
Em 1863, Étienne-Jules Marey de Paris inventou o primeiro esfigmomanómetro; Frederick Akbar Mahomed (1849–1884) o aperfeiçoou e este médico foi o primeiro a medir de modo sistemático a pressão arterial
Scipione Riva-Rocci inventou em 1896 um esfigmomanómetro com "cuff" (em português, braçadeira insuflável  ou manguito ), mas os instrumentos com braçadeiras mais largas devem-se a Recklinghausen, em 1901
Von Basch, em 1893, melhorou a técnica de medida da pressão arterial e estabeleceu pela primeira vez os valores normais entre 135 e 165 mmHg, mais tarde alterados para 135–150 mmHg
Allbut, professor de Física em Cambridge, descreveu a hipertensão sem lesão renal e classificou pela primeira vez três tipos de hipertensão, um dos quais é a hipertensão da pessoa idosa, com três publicações a este respeito "Diseases of the Arteries, Including Angina Pectoris (1915)", "Greek Medicine in Rome (1921)" e "A System of Medicine, 8 vol
(1896–99)"
Em 1895 e em 1889, Huchard, professor de medicina em Paris, chamou de "presclerosis" a hipertensão arterial que não se acompanha de lesão renal
Finalmente, em 1905, Nikolai Korotkov refinou a técnica de medição da pressão arterial ao descrever os "sons de Korotkov" que são ouvidos quando a artéria é auscultada com um estetoscópio, durante a fase de esvaziamento da braçadeira do esfigmomanómetro
Este modo de medida é o comummente utilizado atualmente.
Concomitantemente aos esforços de investigação para descobrir a circulação, a hipertensão arterial e como medi-la, muitas foram as diligências tomadas no sentido de tratar esta doença.
Durante séculos, o tratamento para aquilo que se designava por "doença do pulso rígido" consistia em reduzir a quantidade de sangue no organismo através de sangrias ou da aplicação de sanguessugas
Este método foi defendido por Aulo Cornélio Celso, Galeno e pelo próprio Hipócrates
Entre o final do século XIX e o início do século XX, antes de estarem disponíveis quaisquer fármacos para o tratamento da hipertensão, eram usadas três modalidades de tratamento, todas com vários efeitos secundários: uma restrição completa de sódio (por exemplo, uma dieta à base de arroz), a remoção de um gânglio simpático ou de outras partes do sistema nervoso simpático, e a terapia pirética, que consistia na injecção de substâncias que induziam febre, reduzindo de forma indirecta a pressão sanguínea
O primeiro elemento químico usado no tratamento da hipertensão, o tiocianato de sódio, começou a ser prescrito por volta de 1900, mas os inúmeros efeitos secundários tornaram-no bastante impopular
Após a II Guerra Mundial foram desenvolvidos vários fármacos, sendo os mais populares e relativamente eficazes, a hidralazina e a reserpina, esta extraída da planta medicinal rauwolfia serpentina
O maior avanço, no entanto, deu-se após a descoberta dos primeiros fármacos orais bem tolerados
O primeiro foi a hidroclorotiazida, a primeira tiazida diurética, desenvolvida a partir do antibiótico sulfanilamida, Robert Wilkins que a descobriu recebido o Prémio Lasker Especial Saúde de 1958.
A Organização Mundial de Saúde apontou a hipertensão, ou a pressão arterial elevada, como a principal causa de mortalidade cardiovascular
A Liga Mundial de Hipertensão, uma organização que congrega 85 ligas e institutos nacionais de hipertensão, divulgou que mais de 50% dos hipertensos no mundo não estão conscientes desse estado
De modo a aumentar a percepção pública do problema, a organização iniciou em 2005 uma campanha global de consciencialização e decretou o dia 17 de Maio como Dia Mundial da Hipertensão
Nos últimos anos o número de sociedades aderentes tem vindo a aumentar, sendo que em 2007 participaram no evento 47 países-membros
Durante a semana do Dia Mundial da Hipertensão todos os países – em associação com o governo local, profissionais de saúde, ONG e empresas privadas – promovem a consciencialização para o problema da hipertensão, recorrendo aos meios de comunicação social e a eventos públicos, alcançando um público-alvo de 250 milhões de pessoas.
A pressão arterial elevada é a doença crónica que dá origem ao maior número de consultas nos sistemas de cuidados de saúde nos Estados Unidos
A American Heart Association estima que os custos directos e indirectos da pressão arterial elevada tenham sido, em 2010, de 76,6 mil milhões de dólares
Oitenta por cento dos hipertensos norte-americanos estão conscientes do seu estado
Embora 71% tome medicação anti-hipertensiva, só 48% dos que estão conscientes que têm a doença é que são adequadamente controlados
A gestão correcta da hipertensão pode ser impedida por diagnósticos, medições ou tratamentos inadequados
Os prestadores de cuidados de saúde deparam-se com vários obstáculos no controlo da doença, entre os quais a renitência em tomar múltiplos medicamentos
Os próprios pacientes podem também ter dificuldade em se adaptar aos horários da medicação e às alterações dos hábitos de vida
Ainda assim, é perfeitamente possível atingir-se a pressão arterial pretendida e, sobretudo, a diminuição da pressão arterial reduz de forma significativa o risco de morte por doenças cardíacas e AVC, o desenvolvimento de outros estados debilitantes e os custos associados a cuidados médicos avançados.
Miocardite (Doença de Chagas)
Cardiomiopatia: Dilatada (Alcoólica) · Hipertrófica · Restritiva (Endocardite de Loeffler, Amiloidose cardíaca, Fibroelastose endocardíaca)
Fibrose cardíaca · Cardiomegalia · Hipertrofia ventricular (Esquerdo, Direito/Corpulmonale)
148–150 °C
360 °C (decomposto)
Colesterol é um álcool policíclico de cadeia longa, usualmente considerado um esteroide, encontrado nas membranas celulares e transportado no plasma sanguíneo de todos os animais
É um componente essencial das membranas celulares dos mamíferos
O colesterol é o principal esterol sintetizado pelos animais
Pequenas quantidades são também sintetizadas por outros eucariotas como fungos, porém alguns procariotas como certas bactérias também são capazes de sintetizá-lo.
Não existe colesterol em nenhum produto de origem vegetal
Plantas apresentam um tipo de composto similar chamado de fitosterol.
A maior parte do colesterol presente no corpo é sintetizada pelo próprio organismo, sendo apenas uma pequena parte adquirida pela dieta
Portanto, ao contrário de como se pensava antigamente, o nível de colesterol no sangue não aumenta se não ingerido quantidades adicionais de colesterol através da dieta (a menos, claro, que haja um distúrbio genético)
O colesterol é mais abundante nos tecidos que mais sintetizam ou têm membranas densamente agrupadas em maior número, como o fígado, medula espinhal, cérebro e placas ateromatosas (nas artérias)
O colesterol tem um papel central em muitos processos bioquímicos, mas é mais conhecido pela associação existente entre doenças cardiovasculares e as diversas lipoproteínas que o transportam, e os altos níveis de colesterol no sangue (hipercolesterolemia).
O colesterol é insolúvel em água e, consequentemente, insolúvel no sangue
Para ser transportado através da corrente sanguínea ele liga-se a diversos tipos de lipoproteínas, partículas esféricas que tem sua superfície exterior composta principalmente por proteínas hidrossolúveis
Existem vários tipos de lipoproteínas, e elas são classificadas de acordo com a sua densidade
As duas principais lipoproteínas usadas para diagnóstico dos níveis de colesterol são:


Os elementos presentes na formula química do colesterol são o carbono, o oxigênio e o hidrogênio (C27H46O)
A estrutura química do colesterol é arranjada em quatro anéis A, B, C e D
Ela assemelha-se às estruturas químicas de todos as hormonas que ele origina: progesterona, testosterona e cortisol.
O colesterol é necessário para construir e manter as membranas celulares; regula a fluidez da membrana em diversas faixas de temperatura
O grupo hidroxil presente no colesterol interage com as cabeças fosfato da membrana celular, enquanto a maior parte dos esteroides e da cadeia de hidrocarbonetos estão mergulhados no interior da membrana
Algumas pesquisas recentes indicam que o colesterol pode atuar como um antioxidante
O colesterol também ajuda na fabricação da bílis (que é armazenada na vesícula biliar e ajuda a digerir gorduras), e também é importante para o metabolismo das vitaminas lipossolúveis, incluindo as vitaminas A, D, E e K
Ele é o principal precursor para a síntese de vitamina D e de vários hormônios esteroides (que incluem o cortisol e a aldosterona nas glândulas suprarrenais, e os hormônios sexuais progesterona, os diversos estrógenos, testosterona e derivados).
Recentemente, o colesterol também tem sido relacionado a processos de sinalização celular, pela hipótese seria um dos componentes das chamadas "jangadas lipídicas" na membrana plasmática
Também reduz a permeabilidade da membrana plasmática aos íons de hidrogênio e sódio.
O colesterol é necessário para o funcionamento normal da membrana plasmática de células de mamíferos, sendo sintetizado no retículo endoplasmático das células ou derivado da dieta, sendo que na segunda fonte é transportado pela via sanguínea pelas lipoproteínas de baixa densidade e é incorporado pelas células através de endocitose mediada por receptores em fossas cobertas de clatrina na membrana plasmática, e então hidrolizados em lisossomas.
O colesterol é sintetizado primariamente da acetil CoA através da cascata da HMG-CoA redutase em diversas células e tecidos
Cerca de 20 a 25% da produção total diária (~1 g/dia) ocorre no fígado; outros locais de maior taxa de síntese incluem os intestinos, glândulas adrenais e órgãos reprodutivos
Em uma pessoa de cerca de 68 kg, a quantidade total de colesterol é de 35 g, a produção interna típica diária é de cerca de 1 g e a ingesta é de 200 a 300 mg
Do colesterol liberado ao intestino com a produção de bile, 92-97% é reabsorvido e reciclado via circulação entero-hepática.
Etapas principais da síntese do colesterol:
Konrad Bloch e Feodor Lynen dividiram o Nobel de Fisiologia ou Medicina de 1964, pelas suas descobertas sobre os mecanismos de regulação do colesterol e metabolismo de ácidos graxos.
A biossíntese do colesterol é regulada diretamente pelos níveis presentes do mesmo, apesar dos mecanismos de homeostase envolvidos ainda serem apenas parcialmente compreendidos
Uma alta ingestão de colesterol da dieta leva a uma redução global na produção endógena, enquanto que uma ingestão reduzida leva ao efeito oposto
O principal mecanismo regulatório é a sensibilidade do colesterol intracelular no retículo endoplasmático pela proteína de ligação ao elemento de resposta a esterol (SREBP)
Na presença do colesterol, a SREBP se liga a outras duas proteínas: SCAP (SREBP-cleavage activating protein) e Insig1
Quando os níveis de colesterol caem, a Insig-1 se dissocia do complexo SREBP-SCAP, permitindo que o complexo migre para o aparelho de Golgi, onde a SREBP é clivada pela S1P e S2P (site 1/2 protease), duas enzimas que são ativadas pela SCAP quando os níveis de colesterol estão baixos
A SREBP clivada então migra para o núcleo e age como um fator de transcrição para se ligar ao elemento regulatório de esterol (SRE) de diversos genes para estimular sua transcrição
Entre os genes transcritos estão o receptor LDL e o HMG-CoA redutase
O primeiro procura por LDL circulante na corrente sanguínea, ao passo que o HMG-CoA redutase leva a uma produção endógena aumentada de colesterol.
Uma grande parte deste mecanismo foi esclarecida pelo Dr
Michael S
Brown e Dr
Joseph L
Goldstein nos anos 1970s
Eles receberam o Prêmio Nobel de Fisiologia ou Medicina por seu trabalho em 1985.
A quantidade média de colesterol no sangue varia com a idade, tipicamente aumentando gradualmente até a pessoa chegar aos sessenta anos de idade
Parece haver variações sazonais nos níveis de colesterol em humanos, aumentando, em média, no inverno.
O colesterol é excretado do fígado na bile e é reabsorvido nos intestinos
Dentro de certas circunstâncias, quando está mais concentrado, como na vesícula biliar, ele se cristaliza e é um dos principais constituintes da maioria das pedras na vesícula biliar, embora possam ser formadas, menos frequentemente, pedras de lecitina e bilirrubina na vesícula biliar.
O colesterol é minimamente solúvel em água; não podendo se dissolver e ser transportado diretamente na corrente sanguínea, que é à base de água
Ao invés, ele é transportado na corrente sanguínea pelas lipoproteínas, que são solúveis em água e carregam o colesterol e triglicerídeos internamente
As apolipoproteínas que formam a superfície de uma dada partícula de lipoproteína determinam de que células o colesterol será removido e para onde ele será fornecido.
As maiores lipoproteínas, que transportam principalmente gorduras da mucosa intestinal para o fígado, são chamadas de quilomícrons
Elas carregam principalmente gorduras na forma de triglicerídeos e colesterol
No fígado, as partículas de quilomícron liberam triglicerídeos e um pouco de colesterol
O fígado converte os metabólitos dos alimentos não queimados em lipoproteínas de densidade muito baixa (VLDL) e secreta-as no plasma onde são convertidas em partículas de lipoproteínas de baixa densidade (LDL) e ácidos graxos não esterificados, que podem afetar outras células do corpo
Em indivíduos saudáveis, as relativamente poucas partículas de LDL são de tamanho grande
Em contraste, números aumentados de partículas de LDL de baixa densidade (sdLDL) são fortemente associados com a presença de doença ateromatosa nas artérias
Por esta razão, o LDL é considerado o "colesterol ruim".
O programa nacional de educação sobre o colesterol nos Estados Unidos, de 1987, sugere que o níveis de colesterol total no sangue sejam:
As partículas de lipoproteína de alta densidade (HDL) transportam colesterol de volta para o fígado para a excreção, mas variam consideravelmente em sua efetividade em fazer isto
Geralmente é chamada de "colesterol bom", pois ter partículas grandes de HDL em grandes quantidades traz benefícios à saúde
Em contraste, ter pequenas quantidades de partículas grandes de HDL está associado a progressão de doenças com ateromas no interior das artérias.
O termo hipercolesterolemia refere-se a níveis aumentados de colesterol na corrente sanguínea
Condições com elevadas concentrações de partículas LDL oxidadas, especialmente partículas LDL pequenas, estão associadas com a formação de ateromas nas paredes das artérias, uma condição conhecida como aterosclerose, que é a principal causa de doença coronariana cardíaca e outras formas de doença cardíaca
Em contraste, as partículas de HDL (especialmente HDL grandes) têm sido identificadas como um mecanismo pelo qual o colesterol e mediadores inflamatórios podem ser removidos do ateroma
As taxas aumentadas de HDL estão relacionadas a taxas menores de progressão e até mesmo regressão dos ateromas.
Os níveis elevados de frações de lipoproteínas, LDL, IDL e VLDL são considerados aterogênicos (propensos a causas aterosclerose)
Os níveis destas frações, ao invés do nível de colesterol total, se relacionam com o aumento e a progressão de aterosclerose
Desta maneira, o nível de colesterol total pode estar dentro dos limites normais, embora composto principalmente de pequenas partículas de LDL e de HDL, o que, sob estas condições, faria com que as taxas de crescimento de ateromas continuariam altas
Em contraste, entretanto, se o número de partículas LDL é baixo (principalmente de partículas grandes) e uma grande porcentagem de partículas de HDL é grande, então as taxas de crescimento de ateromas são geralmente baixas, até mesmo negativas, para qualquer concentração de colesterol total.
Estes efeitos são ainda mais complicados pela concentração relativa de dimetilarginina assimétrica (ADMA) no endotélio, já que a ADMA "regula para baixo" ("down-regulation") a produção de óxido nítrico, um relaxante do endotélio
Consequentemente, níveis altos de ADMA, associados com níveis aumentados de LDL oxidadas proporcionam um fator de risco aumentado à doença cardiovascular
A Associação Americana do Coração relaciona os seguintes níveis de colesterol sanguíneos totais em jejum e o risco para doenças cardíacas:
Entretanto, como os métodos atuais de exames determinam o colesterol LDL ("ruim") e o HDL ("bom") separadamente, este modo simplístico de se avaliar o nível de colesterol se tornou obsoleto
O nível desejável de colesterol LDL é menos do que 100 mg/dL (2,6 mmol/L), embora um novo alvo de <70 mg/dl pode ser considerado para indivíduos em alto risco baseado em alguns dos testes mencionados acima
O nível ideal de colesterol HDL é de >60 mg/dl(1.56mmol/l) 
Uma proporção de colesterol total para o HDL — outra forma útil de medição — de menos de 5:1 acredita-se ser saudável
Como nota, os valores típicos de LDL para criança antes que os estágios iniciais de ateroma comecem a se desenvolver é 35 mg/dL.
Os pacientes devem estar conscientes que a maioria dos métodos de examinação para LDL não medem realmente o LDL em seus sangue, uma partícula de tamanho muito menor
Por razões de custo, os valores de LDL têm sido estimados usando-se a fórmula Friedewald: [colesterol total] − [HDL total] − 20% do valor de triglicerídios = LDL estimado
A base disto é que o colesterol total é definido como a soma de HDL, LDL e VLDL
Geralmente somente o colesterol total, o HDL e os triglicerídios são realmente medidos
O VLDL é estimado a quinta parte (1/5) dos triglicerídios
É importante estar em jejum por pelo menos 8-12 horas antes do exame de sangue porque os níveis de triglicerídios variam significativamente com a ingesta de alimentos.
Cada vez mais existem evidências clínicas que fortemente sustentam o maior valor de predição dos exames mais sofisticados que medem tanto as concentrações de partículas de LDL e HDL e tamanho, ao contrário dos exames comuns citados acima.
Os níveis anormalmente baixos de colesterol são chamados de hipocolesterolemia
As pesquisas sobre as causas desta condição são relativamentes limitadas: enquanto alguns estudos sugerem uma relação com a depressão, câncer e hemorragia cerebral, ainda não se sabe ao certo se os níveis baixos de colesterol são a causa destas condições ou se são um epifenômeno.[1]
Na alimentação humana, o colesterol é encontrado nas gorduras animais: todos os alimentos que contêm gorduras animais possuem colesterol, ao passo que os alimentos que não contêm gorduras animais são isentos de colesterol ou possuem quantidades inexpressivas
As principais fontes de colesterol na dieta incluem os ovos, carne de vaca, de galinha e de porco.
Deve-se observar, no entanto, que o colesterol pode ser sintetizado no organismo humano em grandes quantidades, mesmo com uma dieta vegetariana ou pobre em colesterol, como resultado de distúrbios no metabolismo
Portanto, elevações pequenas nos níveis de colesterol podem ser inicialmente tratadas apenas com mudança dos hábitos alimentares, mas hipercolesterolemias severas geralmente exigem a associação com tratamento farmacológico.
Produtos vegetais (como linhaça e amendoim) também contêm compostos como o colesterol, os fitoesteróis, que são sugeridos para diminuir os níveis de colesterol no sangue.
Alguns derivados do colesterol geram a fase colestérica cristalina líquida
A fase colestérica é na verdade uma fase nemática quiral, e muda de cor quando a temperatura é alterada
Dessa maneira, os derivados do colesterol são geralmente usados em termômetros de cristal líquido e em corantes e tintas sensíveis à temperatura.
Modelo espacial da molécula de colesterol…
Farnesil pirofosfato • Escaleno • 2,3-oxidoescaleno • Lanosterol
Lanosterol • Latosterol • 7-deidrocolesterol • Colesterol
Pregnenolona • 17-hidroxipregnenolona • 17-hidroxiprogesterona • 11-deoxicortisol • Cortisol
DHEA • Androstenediona/5-androstenediol • Testosterona • Diidrotestosterona
Gastroplastia, também chamada de Cirurgia Bariátrica, Cirurgia da Obesidade ou ainda de Cirurgia de redução do estômago, é, literalmente, a plástica do estômago (gastro = estômago, plastia = plástica) que tem como o objetivo reduzir o peso de pessoas com o IMC muito elevado.
É uma cirurgia realizada em pessoas com o peso muito acima do ideal, os chamados obesos mórbidos.
O Brasil é o 2º colocado em número absoluto de cirurgias bariátricas, com 60 mil por ano, ficando atrás apenas dos EUA, onde são realizadas 300 mil.


A classificação da obesidade é de acordo com o IMC =(Peso/altura²) O aumento de peso atualmente está divido em:
Mas esses índices variam
Um atleta pode ter um alto IMC sem ser obeso, já que músculos pesam mais do que gordura.
O tratamento clínico é escolha em pacientes com sobrepeso e obesidade leve (IMC entre 30-34,9 Kg/m²)
Hoje está estabelecido que o tratamento cirúrgico está indicado em pacientes definidos com obesidade moderada (IMC > 35 Kg/m²) que tenham comorbidades como apneia do sono, hipertensão, diabetes mellitus, dislipidemia, artropatias ou aqueles pacientes com IMC > 40 Kg/m² independente de haver comorbidades ou não
Isso porque já foi evidenciado que existe um risco muito maior do paciente morrer por complicações clínicas relacionadas à obesidade do que morrer com a realização da cirurgia e os benefícios que ela traz.
A mortalidade por cirurgia bariátrica laparoscópica em 2009 é 0,3%
Estudos vão ainda mais longe demonstrando que o risco de morte em pacientes obesos submetidos à cirurgia bariátrica é 35% menor do que aqueles que seguem tentando realizar somente tratamentos clínico com IMC > 35 Kg/m² com comorbidades ou IMC>40 Kg/m²  .
Tipo de mecanismo das cirurgias bariátricas:
Os tipos de cirurgias bariátricas mais frequentemente realizados segundo Kawahara são:
A técnica mais conhecida e estudada é a chamada Cirurgia de Bypass em Y de Roux
A cirurgia inicia com uma videolaparoscopia
Na sequência, os procedimentos são idênticos
O estômago, que tem capacidade para cerca de dois litros é seccionado com um grampeador cirúrgico de maneira a se obter um novo estômago com capacidade para apenas 15-30ml
Uma alça intestinal é anastomosada ao novo estômago para permitir a saída e a absorção dos alimentos que é chamada anastomose gastrojejunal
O funcionamento da cirurgia é através da restrição da ingestão de alimentos, e em menor parte por disabsorção, uma vez que cerca de 150 cm de intestino delgado são desviados (técnica mista - predominantemente restritiva)
O emagrecimento acentuado pode requerer cirurgias plásticas para a retirada do excesso de pele.
Um outro grupo de cirurgias para redução de peso é o das cirurgias chamadas "predominantemente disabsortivas" e as principais representantes deste grupo são as realizadas pela técnica de Scopinaro e o "Duodenal Switch"
O paciente pode apresentar diarreia ao ingerir alimentos gordurosos e ter desnutrição proteica sobretudo no Scopinaro
Tanto o Scopinaro quanto o Duodenal Switch podem ser feitos por laparoscopia.
Em todas as técnicas, o paciente precisa ser acompanhado de perto por uma equipe especializada multidisciplinar e receber suplementos de vitamina B12, Cálcio e polivitamínicos.
A hiperglicemia (do grego, ὑπέρ- "excesso", γλυκός "açúcar", αἷμα "sangue") é uma condição caracterizada pelo elevado nível de glicose no sangue
Os níveis normais de glicose no sangue está entre 70 e 99mg/dL em jejum 8h e entre 100 e 140mg/dL pós-prandial (depois de comer)
Níveis alterados desses valores podem sugerir crises hipo ou hiperglicêmicas, por diversas etiologias (origens)
Ao persistirem os níveis alterados, a procura a um serviço de saúde se torna essencial, podendo caracterizar-se por quadros patológicos, como a Diabetes Mellitus.


A glicemia pode ser elevada por:
Uma glicemia superior a 200mg/dL pode causar:
Níveis elevados de glicose no sangue podem conduzir, a longo prazo, a alterações irreversíveis nos nervos e nos grandes e pequenos vasos sanguíneos
O diabetes também pode reduzir a capacidade do corpo em resistir a infecções, assim como aumentar a propensão a problemas oculares, doenças renais, pressão alta, ataques cardíacos, acidentes vasculares-cerebrais e amputação de membros superiores e inferiores.
Entre as complicações crónicas da hiperglicemia relacionam-se:
Caracterizada pelo comprometimento dos vasos sanguíneos capilares, por nefropatia e retinopatia.
Caracterizada pelo comprometimento dos vasos arteriais e por deficiência circulatória no cérebro, coração e membros inferiores.
Caracterizada por alterações na visão como a percepção de pontos flutuantes, anéis ou halos coloridos, dificuldade de visão diurna, pressão ou dor sobre os olhos, ou hipersensibilidade à luz.
Caracterizada pela presença de albuminúria persistente (excreção de albumina em níveis superiores a 300 mg/dl) na ausência de outro distúrbio renal.
Caracterizada pela sensação de formigueiros, impotência sexual, alterações digestivas, urinárias e/ou circulatórias, ressecamento da pele, lesões ulcerosas nos pés e pernas, entre outros.
Os diabéticos que fazem a monitorização da glicose rotineiramente podem detectar aumentos da glicemia, sem, entretanto, apresentar sintomas de hiperglicemia
Para estes pacientes recomenda-se regularmente verificar o nível da glicose no sangue
Isto pode ser feito preferencialmente nas seguintes ocasiões:
Mais de 200mg/dL de glicemia a qualquer momento, é critério diagnóstico de diabetes mellitus.
Caso sejam identificados níveis elevados de glicose no sangue, deve-se procurar um médico ou um serviço de saúde para diagnóstico e tratamento apropriados
O controle adequado da hiperglicemia pode auxiliar a prevenir e não evitar os problemas, em conjunto com mudanças saudáveis no estilo de vida do paciente como:
A glicemia (do grego γλεῦκος, mosto, por extensão doce) é a concentração de glicose no sangue ou mais precisamente no plasma.
O nosso corpo transforma alguns dos hidratos de carbono ingeridos em glicose e a glicemia é o nível de glicose presente no nosso sangue
Ou seja, quando comemos muito, a glicemia aumenta, ao passo que quando comemos pouco, esta mantém-se baixa
O aumento da glicemia está intimamente relacionado ao consumo de carboidratos na dieta, sejam eles integrais (aumento glicêmico lento e seguro) ou refinados (aumento glicêmico rápido e perigoso), também levando em consideração para isso as combinações de alimentos numa refeição ou lanche.
Mede-se a glicemia através da confirmação dos sinais e sintomas clássicos da glicemia em jejum (exame de sangue onde são verificadas as taxas de glicose no sangue) e do teste padronizado de tolerância à glicose (TTG).
Estes critérios diagnosticados estão baseados nas recomendações da comunidade médico-científica atual:
Além da insulina, diabéticos podem controlar a glicemia através de dietas específicas e pratica de exercícios físicos, pois, a prática regular de exercício físico aumenta a ação da insulina, fazendo com que a glicose saia da corrente sanguínea, diminuindo, conseqüentemente, a glicemia
Actualmente tornou-se comum a "contagem de carboidratos" dos alimentos através do "indice glicêmico", um indicador de qualidade do carboidrato quanto à sua habilidade em aumentar e/ou influenciar a glicemia.
A manutenção da glicemia em valores fora do padrão normal, tanto para mais quanto para menos, acarreta uma série de complicações para a saúde, além do diabetes
Pesquisa publicada no respeitado periódico Neurology em setembro de 2012 comprovou que até mesmo valores de glicemia considerados um pouco acima do normal são um grave perigo para a saúde cerebral
De acordo com o estudo, idosos que mantiveram os valores de glicemia bem próximos ao valor considerado normal (110 mg/dL) apresentaram uma perda de 6-10% no volume cerebral ao longo de quatro anos, o que pode acarretar doenças neurológicas como Alzheimer e demência
O encolhimento cerebral exibido por eles foi consideravelmente maior em comparação a idosos que possuíam valores de glicemia menores.
Hipoglicemia é uma condição em que a taxa de glicose no sangue diminui para valores inferiores ao normal
A condição causa vários sintomas, entre os quais desorientação, dificuldade em falar, estado de confusão, perda de consciência, convulsões ou morte
Podem ainda estar presentes sintomas como fome, sudação em excesso, tremores e fadiga
Geralmente os sintomas manifestam-se de forma súbita
A condição oposta é a hiperglicemia.
A causa mais comum de hipoglicemia são os medicamentos antidiabéticos usados no tratamento da diabetes, como a insulina e as sulfonilureias
O risco é maior em diabéticos que comeram menos do que é habitual ou que ingeriram bebidas alcoólicas
Entre outras possíveis causas estão a insuficiência renal, alguns tumores como o insulinoma, doenças hepáticas, hipotiroidismo, inanição, erro metabólico hereditário, infeções graves, hipoglicemia reativa e uma série de drogas, incluindo álcool
A hipoglicemia pode também ocorrer em bebés de outro modo saudáveis que não tenham comido durante várias horas.
A taxa de glicose no sangue que define a hipoglicemia varia
Em pessoas com diabetes, o diagnóstico corresponde a uma taxa inferior a 3,9 mmol/L (70 mg/dL)
Em adultos sem diabetes, o diagnóstico é confirmado quando se verifica simultaneamente sintomas relacionados com a hipoglicemia, baixa glicose no sangue durante os sintomas, e melhoria desses sintomas assim que a taxa regressa ao normal
Quando não se manifestam sintomas, pode ser usado um valor de referência inferior a 2,8 mmol/L (50 mg/dL) em jejum ou após a realização de exercício físico
Em recém-nascidos, uma taxa inferior a 2,2 mmol/L (40 mg/dL), ou inferior a 3,3 mmol/L (60 mg/dL) quando acompanhada de sintomas, indica a presença de hipoglicemia
Os valores de glicose são medidos com análises ao sangue
Entre outros exames que podem ser úteis para determinar a causa estão os valores de insulina e de peptídeos-C no sangue.
Nas pessoas com diabetes, a prevenção da hipoglicemia consiste em adequar a dieta à quantidade de exercício físico praticado e aos medicamentos usados
Quando as pessoas sentem que a taxa de glicose pode estar a diminuir, recomenda-se o uso de um medidor de glicemia portátil
Como algumas pessoas manifestam poucos sintomas iniciais quando a taxa de glicose diminui, recomenda-se a este grupo que monitorize frequentemente a taxa de glicose
O tratamento consiste em ingerir alimentos ricos em açúcares simples ou na toma de dextrose
Nos casos em que a pessoa não consegue ingerir alimentos pela boca, pode ser necessária uma injeção de glicagina
O tratamento da hipoglicemia sem relação com a diabetes consiste em tratar também o problema subjacente e numa dieta saudável.


Os sintomas hipoglicêmicos podem ser divididos naqueles produzidos pelos hormônios contra-regulatórios (adrenalina e glucagon), acionados pelo declínio da glicose, e naqueles produzidos pela redução de açúcar no cérebro.
Nem todas as manifestações anteriores ocorrem em casos de hipoglicemia
Não há ordem certa no aparecimento dos sintomas
Manifestações específicas variam de acordo com a idade e com a severidade da hipoglicemia
Em crianças jovens com hipoglicemia matinal, há vômito frequentemente acompanhado de cetose
Em crianças maiores e em adultos, a hipoglicemia moderadamente severa pode parecer mania, distúrbio mental, intoxicação por drogas ou embriaguez
Nos idosos, a hipoglicemia pode produzir efeitos parecidos com uma isquemia focal ou mal-estar sem explicação.
Em recém-nascidos, a hipoglicemia pode produzir irritabilidade, agitação, ataque mioclônico, cianose, dificuldade respiratória, episódios de apneia, sudorese, hipotermia, sonolência, hipotonia, recusa a se alimentar e convulsões
Também pode parecer asfixia, hipocalcemia, sepse ou falha cardíaca.
Em ambos, pacientes de longa data ou não, o cérebro pode se habituar a níveis baixos de glicose, com redução dos sintomas perceptíveis em momentos de neuroglicopenia
Diabéticos insulinodependentes chamam a neuroglicopenia incondicionalmente de hipoglicemia, e que é um problema clínico importante quando tenta-se melhorar o controle glicêmico desses pacientes
Outro aspecto desse fenômeno ocorre em glicogenose tipo I, onde a hipoglicemia crônica antes do diagnóstico pode ser mais bem tolerada do que episódios agudos após o início do tratamento.
Quase sempre a hipoglicemia severa a ponto de ocasionar convulsões ou inconsciência pode ser revertida sem danos ao cérebro
Os casos de morte ou dano neurológico permanente que ocorreram com um único episódio envolvem ocorrências conjuntas de inconsciência não tratada ou prolongada, ou interferência na respiração, ou doenças concorrentes severas ou outros tipos de vulnerabilidade
De qualquer maneira, hipoglicemias severas podem eventualmente resultar em morte ou dano cerebral.
Mais raramente, a hipoglicemia pode revelar:
Da mesma forma que a maioria das células de animais, o metabolismo cerebral depende primeiramente de glicose para trabalhar
Em casos de privação de glicose, pode-se conseguir uma quantidade limitada dela armazenada nos astrócitos, mas que é consumida em minutos
De qualquer forma, o cérebro é dependente de fornecimento contínuo de glicose, que difunde do sangue ao tecido intersticial dentro do sistema nervoso central, e aos próprios neurônios.
Por isso, se a quantidade de glicose suprida pelo sangue cai, o cérebro é um dos primeiros órgãos a percebê-lo
Na maioria das pessoas, a eficiência mental parece diminuir quando a glicemia cai abaixo de 65 mg/dL (3,6 mM)
Ocorre limitação de ações e de julgamento geralmente quando a glicemia cai abaixo de 40 mg/dL (2,2 mM)
Se cair ainda mais, podem ocorrer convulsões
Próxima ou abaixo de 10 mg/dL, a maior parte dos neurônios fica eletricamente desligada, resultando no coma.
A importância de um fornecimento adequado de glicose ao cérebro é clara pelo fato de ocorrerem inúmeras respostas nervosas, hormonais e metabólicas para combater uma hipoglicemia
A maior parte delas é defensiva ou adaptiva: ou tentando aumentar o açúcar no sangue via gliconeogênese e glicogenólise, ou providenciando formas de energia alternativas.
Embora se cite que 70 mg/dL (3.9 mmol/L) seja o limite inferior da glicemia normal, podem definir-se diferentes valores como baixos em diferentes populações, propósitos e circunstâncias
O nível preciso de glicemia considerado baixo o bastante para se definir uma hipoglicemia depende de: (1) método de medição; (2) idade da pessoa; (3) presença ou ausência de sintomas.
O nível de glicose neste artigo é o de plasma venoso ou em soro, medido por métodos-padrão de glicose oxidase usados em laboratórios
Para finalidades clínicas, tanto o nível no plasma quanto o no soro são similares o bastante para serem intercambiados
O plasma arterial ou em soro são levemente superiores do que os níveis venosos, e os níveis capilares estão entre os arteriais e os venosos
A diferença entre os níveis arterial e venoso é pequena sob jejum, mas é amplificada e pode ser até 20% maior em estado pós-prandial
Por outro lado, os níveis de glicemia totais (por exemplo os medidos por glicosímetros digitais) são cerca de 10-15% menores do que os níveis em plasma venoso
Além disso, os glicosímetros disponíveis garantem apenas exatidões de 15% em relação a valores de laboratórios clínicos.
Dois outros fatores afetam significantemente a medição da glicose
A disparidade entre a concentração venosa e a concentração total é maior quando o hematócrito é alto, como no caso de recém-nascidos
Em segundo, a menos que a amostra tenha sido colocada em um tubo de fluoreto ou processada imediatamente para separar o soro ou plasma das células, a glicose mensurável será gradualmente metabolizada in vitro.
Dados estatísticos de crianças e adultos saudáveis mostram que glicemias em jejum abaixo de 60 mg/dL (3,3 mM) ou acima de 100 mg/dL (5,6 mM) são encontradas em menos de 5% da população
Em até 10% dos recém-nascidos e crianças jovens, foram encontrados níveis abaixo de 60 mg/dL depois de jejum noturno
Em outras palavras, muitas pessoas saudáveis podem eventualmente ter níveis glicêmicos na faixa de hipoglicemia sem apresentar sintomas ou distúrbios.
A faixa glicêmica normal de recém-nascidos ainda é motivo de debate
As estatísticas e a experiência revelam níveis de açúcar frequentemente abaixo de 40 mg/dL (2,2 mM) e, mais raramente, abaixo de 30 mg/dL (1,7 mM) em bebês saudáveis de gravidez a termo nos primeiros dias de vida
Foi proposto que os cérebros de recém-nascidos são mais facilmente capazes de usar combustíveis alternativos quando os níveis glicêmicos estão baixos, em relação a adultos
Os especialistas continuam o debate quanto à significância e ao risco desses níveis glicêmicos, embora a tendência seja recomendar a manutenção dos níveis de glicose acima de 60–70 mg/dL (3,3-3,9 mM) após os primeiros dias de vida
Em bebês prematuros, adoecidos ou abaixo do peso é mais comum encontrar baixos níveis de glicose, mas há um consenso de que os açúcares devam ser mantidos ao menos acima de 50 mg/dL (2,8 mM) nestas circunstâncias
Alguns especialistas defendem 70 mg/dL (3,9mM) como um objetivo terapêutico, especialmente em circunstâncias tais como hiperinsulinismo, onde combustíveis alternativos podem ser mais escassos.
Pesquisas mostram que a eficiência mental diminui levemente mas de modo sensível quando a glicemia cai abaixo de 65 mg/dL (3,6 mM), em adultos saudáveis
Os mecanismos de defesa hormonal (adrenalina e glucagon) são ativados assim que a glicemia passa por limiares (cerca de 55 mg/dL ou 3,0 mM para a maioria das pessoas), produzindo tremores e disforia
Por outro lado, não ocorre com frequência um prejuízo de capacidade mental até que a glicemia caia abaixo de 40 mg/dL (2,2 mM), e até 10% da população pode eventualmente ter níveis de glicose abaixo de 65 (3,6) pela manhã sem efeitos aparentes
Os efeitos da hipoglicemia, chamados de neuroglicopenia, é que determinam quando um certo nível glicêmico é realmente um problema ao indivíduo.
É preferível que a pessoa com hipoglicemia use tanto os sintomas quanto os dados numéricos de seu glicosímetro para determinar as medidas a serem tomadas
É fácil notar hipoglicemia quando o valor lido é 50 mg/dL (2,8 mM); porém, um paciente que está com a diabetes descompensada e frequentemente lê valores acima de 200 mg/dL (11,1 mM) pode sentir sintomas de hipoglicemia quando o nível de glicose no sangue chegar a valores "normais" de 90 mg/dL (5,0 mM)
Neste caso, a pessoa não apresenta uma hipoglicemia clássica, mas terá alívio de sintomas com o tratamento rotineiro para hipoglicemias
Além disso, quando a glicemia diminui a uma taxa rápida, também podem surgir sintomas de hipoglicemia.
Este critério é por si só complicado de se admitir pelo fato de os sintomas da hipoglicemia serem vagos e poderem ser produzidos por outros motivos; além do que, quando a pessoa passa por níveis baixos de glicemia com recorrência, ela pode perder a sensação de limiar, de forma que pode haver agravamento de seus sintomas (por neuroglicopenia) sem que ela note
Para completar a dificuldade, os glicosímetros são inexatos para baixos valores, o que descredita a sua utilidade nessas horas.
Procure sempre encontrar a causa de uma baixa glicémia
A glicémia diária normal não deverá ser inferior a 90 mg/dl (5 mmol/l)
Utilize os testes à glicémia para evitar a hipoglicémia
É particularmente importante testar a glicémia ao deitar
Nenhuma criança diabética deverá deitar-se antes das refeições sem que lhe seja feito o teste da glicémia
Não injete insulina antes duma refeição se o valor for inferior a 90 mg/dl (5 mmol/l)
Espere que a criança acabe a refeição e só depois injete insulina
O açúcar sanguíneo pode subir ao valor normal em minutos da seguinte forma: consumindo (por conta própria) ou recebendo (por outrem) 10-20 g de carboidrato
Pode ser em forma de alimento ou bebida caso a pessoa esteja consciente e seja capaz de engolir
Essa quantidade de carboidrato está contida nos seguintes alimentos:
O amido é rapidamente transformado em glicose, mas a adição de gordura ou proteína retarda a digestão
Os sintomas começam a melhorar em 5 minutos, embora demore 10-20 min até a recuperação completa
O abuso de alimentos não acelera a recuperação e se a pessoa for diabética isto simplesmente causará uma hiperglicemia mais tarde.
Se a pessoa está sofrendo de efeitos severos de hipoglicemia de maneira que não possa (devido a combatividade) ou não deva (devido a convulsões ou inconsciência) ser alimentada, pode-se dar a ela uma infusão intravenosa de glicose ou uma injeção de glucagon..
A prevenção depende da causa da hipoglicemia
O risco de novos episódios pode ser frequentemente reduzida pelo abaixamento da dose de insulina ou medicamento, ou pela atenção maior à glicemia durante eventos inesperados, diminuição do ritmo de exercícios físicos ou de ingestão de álcool.
Muitos tipos de disfunções congêneres do metabolismo requerem evitar ou encurtar os intervalos de jejum, ou evitar carboidratos extras
Para distúrbios mais severos, como a glicogenose tipo I, isto pode ser feito pelo consumo de amido de milho de hora em hora ou por infusão gástrica contínua.
Vários tratamentos são usados em caso de hipoglicemia hiperinsulinêmica, dependendo da forma exata e do grau de severidade
Algumas formas de hiperinsulinismo congênito respondem bem ao diazóxido ou octreótido
A remoção cirúrgica da parte hiper-reativa do pâncreas é eficaz com risco mínimo quando o hiperinsulinismo é focal, ou devido a um tumor benigno produtor de insulina
Quando o hiperinsulinismo congênito é difuso ou imune às medicações, a pancreatectomia subtotal pode ser o tratamento de último caso, mas neste caso é menos efetivo e passível de várias complicações.
A hipoglicemia devida a deficiências hormonais como hipopituitarismo ou insuficiência adrenal geralmente cessa quando se administra o hormônio apropriado.
A hipoglicemia devida à síndrome do empachamento (ou Síndrome de dumping no português brasileiro) e outras condições pós-cirúrgicas é mais bem tratada com alteração da dieta
A inclusão de gordura e proteína com carboidratos pode retardar a digestão e reduzir a secreção antecipada de insulina
Alguns desses casos respondem a tratamento com um inibidor de glicosidase, que retarda a digestão de amido.
A hipoglicemia reativa com baixa glicose no açúcar é frequentemente um incômodo previsível, que pode ser evitado pelo consumo de gordura e proteína com carboidratos, pela adição de lanches pela manhã e à tarde e pela redução do consumo de álcool.
A síndrome pós-prandial idiopática sem níveis baixos de glicose no momento dos sintomas pode ser mesmo um desafio de conduta
Muitas pessoas encontram melhorias com a mudança no padrão de alimentação (refeições menores, evitando açúcar em demasia, refeições mistas em detrimento de carboidratos), ou fazendo mudanças no estilo de vida para evitar o estresse, ou diminuindo o consumo de estimulantes como cafeína.
Diabetes mellitus do tipo 2 é um distúrbio metabólico caracterizado pelo elevado nível de glicose no sangue, resistência à insulina e relativa falta de insulina
Os sintomas mais comuns são a sede excessiva, micção frequente e perda de peso inexplicável
Outros possíveis sintomas são fome excessiva, fadiga e feridas que não cicatrizam
Em muitos casos os sintomas manifestam-se de forma gradual e lenta
Entre as complicações a longo prazo dos níveis elevados de glicose estão doenças cardiovasculares, acidentes vasculares cerebrais, retinopatia diabética que pode causar cegueira, insuficiência renal e má circulação de sangue nos membros que pode levar a amputações
Pode ainda ocorrer Coma hiperosmolar hiperglicémico de aparecimento súbito, embora a cetoacidose diabética seja pouco comum.
A diabetes do tipo 2 ocorre como consequência da obesidade e falta de exercício físico
Algumas pessoas apresentam uma predisposição genética superior
A diabetes do tipo 2 corresponde a 90% dos casos de diabetes, sendo os restantes 10% constituídos principalmente por diabetes do tipo 1 e diabetes gestacional
Na diabetes do tipo 1, as células beta do pâncreas não produzem insulina em quantidade suficiente para controlar a glicose no sangue
O diagnóstico da diabetes é feito com análises ao sangue que avaliam a quantidade de glicose no plasma, provas de tolerância à glicose oral ou hemoglobina glicosilada.
A diabetes do tipo 2 pode ser parcialmente evitável mantendo um peso saudável, praticando exercício físico com regularidade e mantendo uma dieta equilibrada
O tratamento consiste em exercício físico e dieta adequada
Quando estas medidas não são suficientes para diminuir a quantidade de glicose no sangue, geralmente é recomendada a administração de metformina
Muitas pessoas podem eventualmente necessitar de injeções de insulina
A avaliação periódica dos níveis de glicose está recomendada para pessoas que se encontram a tomar insulina, embora nem sempre seja necessária em pessoas a tomar apenas medicação
Em pessoas obesas, a cirurgia bariátrica pode melhorar a diabetes.
A incidência da diabetes tem subido de forma significativa desde a década de 1960, em paralelo com a obesidade
Em 2015 havia 392 milhões de pessoas diagnosticadas com diabetes do tipo 2, muito mais do que os 30 milhões em 1985
A doença tem geralmente início durante a meia-idade ou durante a terceira idade, embora a incidência esteja a aumentar em pessoas jovens
A diabetes do tipo 2 está associada a uma diminuição de dez anos na esperança de vida
A diabetes foi uma das primeiras doenças a ser descrita
A importância da insulina na diabetes foi determinada na década de 1920.


Os sintomas habituais da diabetes são a poliúria (micção frequente), a polidipsia (sensação de sede), polifagia (sensação de fome) e perda de peso
Entre os outros sintomas descritos no momento do diagnóstico estão a visão turva, prurido, neuropatia, infecções vaginais recorrentes e fadiga
No entanto, muitos indivíduos não apresentam qualquer sintoma durante os primeiros anos da doença e são apenas diagnosticados com diabetes através de exames de rotina
Os indivíduos com diabetes do tipo 2 podem, ainda que raramente, apresentar coma hiperosmolar hiperglicémico, uma condição hiperglicémica associada à diminuição do estado de consciência e reduzida pressão arterial.
A diabetes de tipo 2 é normalmente uma doença crónica, à qual corresponde uma diminuição da esperança média de vida de dez anos
Isto deve-se em parte a uma série de complicações graves associadas à doença, nas quais se inclui o risco duas a quatro vezes maior de doenças cardiovasculares, como a cardiopatia isquémica ou um AVC, um risco vinte vezes maior de amputações dos membros inferiores e a uma maior taxa de hospitalizações
Nos países desenvolvidos, e em progressão nas demais regiões, a diabetes é a principal causa de cegueira não-traumática e de insuficiência renal crónica
A doença tem também sido associada a um risco acrescido de disfunções cognitivas e de demência, manifestado através de outras doenças como a doença de Alzheimer ou a demência vascular
Entre outras complicações possíveis estão a acantose nigricans, a disfunção eréctil e infecções regulares.
O desenvolvimento da diabetes de tipo 2 é causado pela combinação de factores genéticos com o estilo de vida
Enquanto alguns desses factores de risco podem ser controlados pelo próprio, como a dieta alimentar e a obesidade, há outros que são impossíveis de controlar, como a predisposição genética, o envelhecimento e o género feminino
A privação de sono tem também sido associada à diabetes de tipo 2, que se acredita dever-se às implicações no metabolismo
A situação nutricional da mãe durante o desenvolvimento do feto pode também ter alguma influência, tendo sido proposto como mecanismo de actuação a alteração da metilação do ADN .
Há uma série de fatores relacionados com o estilo de vida que são relevantes no desenvolvimento da diabetes do tipo 2, entre eles a obesidade (definida por um índice de massa corporal superior a 30), a falta de exercício físico, uma dieta desequilibrada, o stress e a urbanidade
O excesso de massa corporal está relacionado com 30% dos casos em indivíduos de ascendência Chinesa e Japonesa, com 60 a 80% dos casos nos de ascendência Europeia e Africana, e com a totalidade dos casos nos índios Pima e nos naturais das Ilhas do Pacífico
Mesmo os que não são obesos apresentam frequentemente um índice cintura/quadril elevado
Os fatores dietéticos influenciam também o risco de vir a desenvolver diabetes do tipo 2
O consumo excessivo de bebidas açucaradas está associado ao aumento do risco
O tipo de gorduras consumido é igualmente relevante, uma vez que as gorduras saturadas e os ácidos gordos trans aumentam o risco, enquanto que as gorduras poliinsaturadas e monoinsaturadas diminuem o risco de vir a desenvolver a doença
O consumo excessivo de arroz branco aparenta também aumentar o risco, enquanto que a falta de exercício mostra estar na origem de 7% dos casos.
A maioria dos casos de diabetes envolve vários genes, e cada um desses genes representa uma pequena contribuição para a probabilidade de um indivíduo poder vir a ser um diabético do tipo 2
Se um gémeo idêntico tem diabetes, a probabilidade de o outro vir a desenvolver a doença ao longo da vida é superior a 90%, enquanto que para gémeos falsos é de apenas 25 a 50%
Até 2011, foram identificados mais de 36 genes que contribuem para o risco de diabetes do tipo 2
O alelo TCF7L2, por exemplo, aumenta uma vez e meia o risco de vir a desenvolver a doença e é o que representa maior risco entre as variantes genéticas mais comuns
A maior parte dos genes relacionados com a diabetes estão implicados nas funções das células beta.
Existem casos raros de diabetes que têm origem numa anomalia de um único gene, conhecidos como diabetes monogénica
Estes casos englobam, entre outros, a diabetes MODY, a síndrome de Donahue e a síndrome de Rabson-Mendenhall
A diabetes MODY corresponde a 1-5% do total de casos de diabetes em jovens.
Existem uma série de medicamentos e de outros problemas de saúde que podem provocar a predisposição para a diabetes
Entre estes medicamentos estão os glicocorticóides, a tiazida, os bloqueadores beta, os antipsicóticos atípicos e as estatinas
Indivíduos que tenham tido diabetes gestacional apresentam maior risco de vir a desenvolver diabetes do tipo 2.
A diabetes do tipo 2 deve-se à produção insuficiente de insulina pelas células beta no âmbito da resistência à insulina
A resistência à insulina, que é a incapacidade das células em responder de forma adequada ao nível normal de insulina, ocorre principalmente nos músculos, fígado e tecido adiposo
Numa situação normal, a insulina suprime a libertação de glicose no fígado
No entanto, caso se verifique resistência à insulina, o fígado liberta impropriamente glicose para o sangue
A proporção de resistência à insulina e do nível de disfunção das células beta varia de indivíduo para indivíduo
Enquanto que em alguns se verifica sobretudo resistência à insulina e apenas uma lacuna ligeira na secreção de insulina, outros apresentam apenas uma ligeira resistência à insulina ao mesmo tempo que uma deficiência acentuada na secreção de insulina.
Entre outros mecanismos potencialmente associados com a diabetes do tipo 2 encontra-se o aumento da separação de lípidos nas células adiposas, a resistência a ou a falta de incretina, o nível elevado de hormonas glicagina no sangue, o aumento da retenção de sal e água nos rins e a regulação inadequada do metabolismo pelo sistema nervoso central
No entanto, nem todas as pessoas com resistência à insulina desenvolvem diabetes, uma vez que também é necessário que haja incapacidade das células pancreáticas em segregar insulina.
Segundo os critérios da Organização Mundial de Saúde, o diagnóstico da diabetes, quer seja do tipo 1 ou 2, pode ser determinado com recurso a dois métodos, dependendo se existem ou não sintomas associados
Quando não existem sintomas associados, é necessário confirmar a doença através de uma prova de tolerância à glicose oral
A prova consiste numa colheita de sangue em jejum, seguindo-se a ingestão de uma sobrecarga de 75 g de glicose e fazendo-se nova colheita duas horas depois
A doença é confirmada se qualquer uma das amostras apresentar valores de concentração plasmática de glicose superiores aos de referência, nomeadamente:
Sempre que se manifestem os sintomas habituais da diabetes, é possível confirmar o diagnóstico através de uma única colheita de sangue aleatória, confirmando-se o diagnóstico caso se registem valores superiores a 11,1 mmol/l (200 mg/dL) ou de hemoglobina glicosilada(HbA1c) superior a 6,5%
Em 2009, uma comissão internacional de peritos que envolveu representantes da Associação Americana de Diabetes, da Federação Internacional de Diabetes e da Associação Europeia para o Estudo da Diabetes, recomendou que no diagnóstico de diabetes fosse estabelecido um valor de referência ≥6,5% HbA1c
Recomendou também que se devem repetir quaisquer exames com resultados positivos, a não ser que a pessoa manifeste também sintomas e valores de glicemia >11,1 mmol/l (>200 mg/dl).
Os valores de referência no diagnóstico da diabetes têm por base a relação entre os resultados dos testes de tolerância à glicose, à glicose em jejum ou à hemoglobina glicosilada, e complicações como lesões na retina
É preferível uma colheita aleatória em jejum em relação à prova de tolerância à glicose, uma vez que é mais cómoda para a pessoa
O exame à hemoglobina glicosilada tem a vantagem de não requerer o jejum e dos resultados serem mais estáveis, mas é significativamente mais caro que os exames à concentração de glicose no sangue
Estima-se que 20% das pessoas afectadas com diabetes nos Estados Unidos não saibam que têm a doença
A diabetes mellitus do tipo 2 caracteriza-se pela elevada concentração de glicose no sangue no âmbito da resistência à insulina e pela insuficiência relativa de insulina
Distingue-se da diabetes mellitus tipo 1, na qual se verifica a deficiência completa de insulina devido à destruição dos ilhéus de Langerhans no pâncreas; e da diabetes gestacional, que é a hiperglicemia resultante da intolerância a hidratos de carbono que se manifesta durante a gravidez
É possível distinguir entre os tipos 1 ou 2 de diabetes com base nas circunstâncias
Se houver dúvidas em relação ao diagnóstico pode ser realizado um exame à imunoglobulina para confirmar a diabetes do tipo 1, ou aos níveis de péptidos C para confirmar a diabetes de tipo 2.
Nenhuma das principais organizações clínicas recomenda o rastreio universal da diabetes, uma vez que não está demonstrado que tal programa viesse a ter impacto significativo no controlo da doença
Nos Estados Unidos, a United States Preventive Services Task Force recomenda o rastreio em adultos sem sintomas, mas cuja pressão arterial seja superior a 135/80 mmHg
Não há ainda evidências suficientes que permitam concluir a favor ou contra o rastreio em indivíduos que apresentem menores valores de pressão arterial
A Organização Mundial de Saúde recomenda o rastreio apenas para grupos de alto risco, que englobam indivíduos com mais de 45 anos, ou que tenham um familiar em primeiro grau diabético, que pertençam a determinadas etnias ou ainda que apresentem um histórico de diabetes gestacional, síndrome do ovário policístico, excesso de peso, e condições relacionadas com a síndrome metabólica.
O aparecimento da diabetes de tipo 2 pode ser adiado ou prevenido através de uma dieta equilibrada e de exercício físico regular
O exercício é sempre benéfico, independentemente do peso inicial ou do peso que se venha a perder
No entanto, são ainda escassas as evidências que sustentem que apenas alterações na dieta, sem serem acompanhadas de exercício, sejam por si só benéficas
Alguns estudos apontam para benefícios individuais de uma dieta rica em hortaliças folhosas e outros para os benefícios da restrição do consumo de bebidas açucaradas, como os refrigerantes
Em indivíduos com anomalia da tolerância à glicose, a alteração na dieta e o exercício físico, sozinhos ou combinados com metformina ou acarbose, podem reduzir o risco de desenvolver diabetes
A intervenção no estilo de vida é, no entanto, mais eficaz que a metformina.
O tratamento da diabetes de tipo 2 foca-se na manutenção do nível de glicose no sangue dentro dos parâmetros normais, e em intervenções no estilo de vida, fazendo assim diminuir outros factores de risco cardiovascular
Em 2008, foi recomendado o autocontrolo da glicose em indivíduos a quem tinha sido recentemente diagnosticada diabetes do tipo 2, embora tenham já sido questionados os eventuais benefícios dessa acção em pacientes que não estejam a tomar múltiplas doses de insulina
Gerir outros factores de risco cardiovascular, como a hipertensão, o colestrol elevado e a albumina, aumenta a esperança de vida do diabético
A redução intensiva do nível de glicose (HbA1C <6%), em comparação com a redução normal (HbA1C 7-7.9%), não aparenta ter qualquer efeito na mortalidade
O objectivo do tratamento são normalmente valores de HbA1C inferiores a 7% ou de glicose em jejum inferior a 6,7 mmol/L (120 mg/dL)
No entanto, este objectivo pode variar em função da consulta e da avaliação realizada por um profissional de saúde, que leva em conta outros factores de risco como a hipoglicemia e a esperança de vida
Recomenda-se que todos os indivíduos com diabetes do tipo 2 façam regularmente exames oftalmológicos.
As fundações do tratamento da diabetes são o exercício físico e uma dieta adequada
O exercício físico em quantidade produz melhores resultados
O exercício aeróbico permite reduzir os valores de HbA1C e aumentar a sensibilidade à insulina
O exercício de resistência é igualmente benéfico e a combinação dos dois tipos de exercício pode ser o mais eficaz
É importante também uma dieta diabética que permita perder peso
Embora a questão da melhor dieta seja ainda bastante controversa, a dieta do baixo índice glicémico tem revelado melhorar o controlo do nível de glicose no sangue
O esclarecimento clínico apropriado à cultura do paciente, nos casos de diabéticos de minorias étnicas, pode também ajudar no controlo glicémico
Se as alterações nos hábitos de vida em indivíduos com casos leves de diabetes não melhorarem o nível de glicose ao fim de seis semanas, deve ser considerada a hipótese de medicação
Por incrível que pareça, um estudo chegou à conclusão que o consumo moderado de bebida alcoólica reduziu a frequência de diabetes em 32% em homens e 27% em mulheres.
Estão disponíveis várias classes de antidiabéticos
A metformina é normalmente o recomendado para iniciar o tratamento, já que existem algumas evidências de que reduz também a mortalidade
Pode-se recorrer a um segundo agente oral de classe diferente caso a metformina não seja suficiente
Entre as outras classes disponíveis encontram-se as sulfonilureias, secretagogos não sulfonilureia, inibidores da alfaglicosidase, tiazolidinedionas, miméticos do GLP-1 e inibidores da dipeptidil peptidase-4
A metformina não deve ser prescrita para indivíduos com problemas graves no fígado ou pâncreas
As injecções de insulina podem ser usadas isoladamente ou como complemento à medicação oral.
A maior parte dos diabéticos não precisa de insulina imediatamente
Quando há necessidade de se recorrer a um tratamento com insulina, normalmente prescreve-se uma dose nocturna de longa duração e em conjunto com a medicação oral
A dose pode ser aumentada para se ajustar ao nível de controlo do nível de glicose pretendido
Quando a insulina nocturna se mostra insuficiente, a administração de duas doses ao dia pode permitir obter melhor controlo
As insulinas de longa duração – glargina e detemir – não aparentam ser significativamente superiores em relação à insulina NPH, embora tenham maiores custos de produção
Em grávidas, o tratamento com insulina é normalmente preferencial.
A cirurgia de redução de peso em indivíduos obesos é uma medida eficaz no tratamento da diabetes
Grande parte dos que se submetem ao tratamento são capazes de conservar níveis de glicose normais depois da cirurgia, recorrendo a pouca ou nenhuma medicação, diminuindo também a mortalidade a longo prazo
A intervenção apresenta, no entanto, um risco menor de mortalidade a curto prazo inferior a 1%
Os valores do índice de massa corporal para os quais a cirurgia seja recomendada não são ainda claros
É no entanto recomendado que esta opção seja considerada nos casos em que o paciente não seja capaz de controlar o peso e o nível de glicemia.
Estima-se que no ano de 2010, à escala mundial, 285 milhões de pessoas fossem portadoras de diabetes de tipo 2, o que corresponde a 90% dos casos de diabetes e que equivale a 6% da população mundial adulta
A diabetes é vulgar tanto nos países desenvolvidos como em desenvolvimento
No entanto, é invulgar em regiões sub-desenvolvidas
O risco de vir a contrair a doença aparenta ser maior nas mulheres, assim como em determinadas etnias, como nos povos da Ásia Meridional, nos povos insulares do Pacífico, nos latino-americanos e nos ameríndios
Isto pode estar relacionado com uma maior sensibilidade em relação ao estilo de vida ocidental em determinadas etnias
Até agora considerada uma doença adulta, o número de diagnósticos de diabetes de tipo 2 em crianças tem vindo a crescer, em paralelo com o aumento da prevalência da obesidade
Entre os adolescentes norte-americanos, por exemplo, o diagnóstico de diabetes de tipo 2 é actualmente tão frequente como o de tipo 1.
Em 1985 estimava-se que houvesse 30 milhões de diabéticos, tendo o número crescido para 135 milhões em 1995 e para 217 milhões em 2005
Acredita-se que este aumento seja devido sobretudo ao envelhecimento da população, à diminuição do exercício físico e ao aumento da proporção de obesos
No ano 2000, os cinco países com o maior número de diabéticos foram a Índia (31,7 milhões), a China (20 milhões), os Estados Unidos (17,7 milhões), a Indonésia (8,4 milhões) e o Japão (6,8 milhões)
A Organização Mundial de Saúde reconheceu a doença como epidemia global.
A diabetes foi uma das primeiras doenças a ser descrita
Um manuscrito Egípcio datado de ca
1500 a.C
faz referência a um "esvaziamento muito grande de urina"
Pensa-se que os primeiros casos descritos sejam de diabetes do tipo 1
Por volta da mesma época, a doença foi identificada por médicos Indianos, que a designaram como "urina de mel" depois de repararem que a urina diabética tinha a particularidade de atrair formigas
No entanto, o termo "diabetes" só viria a ser introduzido em 230 a.C
pelo Grego Apolónio de Mênfis
A doença era rara durante o Império Romano, e Galeno chegou a comentar que durante toda a sua carreira tinha observado apenas dois casos
A separação dos tipos 1 e 2 de diabetes enquanto condições médicas distintas foi feita pela primeira vez pelos Indianos Sushruta e Charaka durante o século V d.C., associando o tipo 1 com a juventude e o tipo 2 com o excesso de peso
O termo "mellitus", ou "do mel", foi acrescentado pelo Britânico John Rolle no fim do século XVIII, de forma a separar esta condição da diabetes insipidus que está igualmente associada com a micção frequente
O primeiro tratamento eficaz só viria a ser desenvolvido já no início do século XX, depois de os Canadianos Frederick Banting e Charles Best terem descoberto a insulina em 1921 e 1922, que por sua vez possibilitou o desenvolvimento da Insulina NPH durante a década de 1940.
O infarto ou enfarte é a consequência máxima da falta de oxigenação de um órgão ou parte dele
Quando existe uma lesão arterial que diminua a irrigação de um órgão, este órgão passa a sofrer de isquemia
Se o problema arterial não for resolvido rapidamente então dá-se o que se chama de "enfarte" - as células morrem
Assim, enfarte é sinônimo de necrose
Quando o enfarte não atinge todo um órgão, a zona de necrose está rodeada por uma zona de isquemia onde a diminuição do fluxo arterial põe as células em sofrimento, mas não é suficientemente grave para provocar necrose
O infarto do miocárdio ocorre quando parte desse músculo cardíaco deixa de receber sangue pelas artérias coronárias que os nutrem
Quando isso acontece, a parte do músculo que não é eliminada deixa de funcionar, o que pode levar a pessoa a morte.
Os órgãos mais acometidos por esta complicação são o miocárdio e cérebro (ver artigos detalhados: Enfarte cardíaco e AVC), no entanto qualquer órgão do corpo humano pode ser alvo deste problema
Por exemplo, numa oclusão intestinal por aderências, as aderências provocam uma torção de uma ansa intestinal, comprometendo a sua circulação, levando primeiro a isquemia e depois necrose com rotura da ansa e a peritonite concomitante
Outro exemplo seria o caso muito raro numa cirurgia da aorta abdominal, na qual uma complicação levaria a um infarto medular.
A aterosclerose com estenoses severas produz isquémia, como acontece nas artérias dos membros inferiores ou nas artérias mesentéricas
Esta última situação é responsável por muitos quadros de abdómen agudo na pessoa idosa
Já nos membros inferiores a necrose de uma extremidade só acontece quando várias artérias estão completamente obstruídas pois existem anastomoses que conseguem irrigar a distalidade
Por exemplo para que se dê a necrose do pé é necessário que as três artérias tibial anterior, tibial posterior e peronial estejam ocluídas e que não tenha havido tempo para desenvolver uma rede colateral eficaz
Nestes casos é habitual utilizar também a palavra gangrena como sinónimo de necrose.
Um acidente vascular cerebral (AVC) ocorre quando problemas na irrigação sanguínea do cérebro causam a morte das células, o que faz com que partes do cérebro deixem de funcionar devidamente
Existem dois tipos principais de AVC: isquémico, causado pela interrupção da irrigação sanguínea, e hemorrágico, causado por uma hemorragia
Entre os sinais e sintomas de um AVC estão a incapacidade de mover ou de sentir um dos lados do corpo, dificuldades em compreender ou em falar, sensação de que os objetos em volta se movimentam ou perda de um dos lados da visão
Na maior parte dos casos, os sinais e sintomas manifestam-se imediatamente após o AVC
Quando a duração dos sintomas é inferior a uma ou duas horas, o episódio denomina-se acidente isquémico transitório (AIT), ou mini-derrame
Uma hemorragia subaracnóidea pode também estar associada a dores de cabeça intensas
Os sintomas de um AVC podem ser permanentes
Entre as complicações a longo prazo estão a pneumonia ou incontinência urinária.
O principal fator de risco de um AVC é a hipertensão arterial
Entre outros fatores de risco estão fumar, a obesidade, colesterol elevado, diabetes, ter tido anteriormente um acidente isquémico transitório e fibrilação auricular
Um AVC isquémico é geralmente causado pelo bloqueio de um vaso sanguíneo, embora existam outras causas menos comuns
Um AVC hemorrágico é causado por um derrame, quer por uma hemorragia diretamente no cérebro quer por uma Hemorragia subaracnóidea no espaço entre as meninges
Estas hemorragias podem ocorrer devido à rutura de um aneurisma cerebral
O diagnóstico é geralmente feito com recurso a imagiologia médica, como uma TAC ou ressonância magnética, acompanhada por uma avaliação física da pessoa
Podem ser realizados outros exames, como análises ao sangue ou eletrocardiograma, para determinar fatores de risco e descartar outras possíveis causas
A hipoglicemia pode provocar sintomas semelhantes a um AVC.
A prevenção consiste em diminuir os fatores de risco, assim como na possibilidade de ser administrada aspirina ou estatinas
Em pessoas com estenose da carótida pode ser considerada uma Endarteriectomia para alargar as artérias do cérebro
Em pessoas fibrilação auricular pode ser administrada varfarina
Um AVC ou AIT geralmente necessita de assistência médica urgente
Quando um AVC isquémico é detectado nas primeiras três horas e meia a quatro horas, é possível ser tratado com medicação trombolítica que dissolve os coágulos sanguíneos e com aspirina
Em alguns AVC hemorrágicos pode ser considerada neurocirurgia
Algumas das funções perdidas durante o AVC podem ser recuperadas com tratamentos de reabilitação e recuperação
No entanto, em muitas regiões do mundo estes tratamentos não estão disponíveis.
Em 2013 cerca de 6,9 milhões de pessoas sofreram um AVC isquémico e 3,4 milhões um AVC hemorrágico
Em 2010, encontravam-se vivas cerca de 33 milhões de pessoas que no passado tinham sofrido um AVC
Entre 1990 e 2010 o número de AVC ocorrido em cada ano diminuiu cerca de 10% nos países desenvolvidos e aumentou cerca de 10% nos países em vias de desenvolvimento
Em 2013, os AVC foram a segunda principal causa de morte, a seguir à doença arterial coronária, tendo sido responsáveis por 6,4 milhões de mortes em todo o mundo, o que corresponde a 12% do total de mortes
Cerca de 3,3 milhões de mortes foram causadas por AVC isquémico e 3,2 milhões por AVC hemorrágico
Cerca de metade das pessoas que sofrem um AVC vivem menos de um ano
Dois terços dos AVC ocorrem em pessoas com mais de 65 anos de idade.


Os acidentes vasculares do cérebro podem ser basicamente decorrentes da obstrução de uma artéria que irriga o cérebro (ou seja, por isquemia) ou podem ser por vazamento de sangue de um vaso sanguíneo (ou seja, hemorrágico)
Cabe ressaltar que o termo "derrame" não é apropriado, visto que em apenas uma parte dos AVC's (na verdade a minoria deles) ocorre um derramamento de sangue no parênquima encefálico.
É o tipo de AVC mais comum, presente em cerca de 80% dos casos
Ocorre pela falta de fluxo sanguíneo cerebral, levando ao sofrimento e enfarte do parênquima do sistema nervoso
Essa queda no fluxo sanguíneo pode ser decorrente de:
Nos primeiros momentos do AVC isquêmico não há morte de tecido cerebral, mas a falta de suprimento sanguíneo provoca a rápida degeneração do tecido cerebral, um tecido metabolicamente muito ativo e que demanda muito oxigénio e glicose para manter seus neurónios vivos
A área central do acidente vascular morre em pouco tempo, pois está praticamente sem nenhum fluxo de sangue
Todavia, existe uma região ao redor do infarto central que possui um fluxo de sangue reduzido, que se mantém viável por mais tempo
A essa área dá-se o nome de penumbra
É na penumbra, uma área parcialmente perfundida, mas ainda viável, que deve-se concentrar os esforços terapêuticos
É por isso também que o tempo do início do ataque vascular cerebral até a reversão da obstrução de sangue é importante na evolução do AVC isquêmico.
O AIT ou ataque isquêmico transitório pode ser considerado um tipo de AVC isquêmico
Corresponde a uma isquemia (entupimento) passageira que não chega a constituir uma lesão neurológica definitiva e não deixa sequela
Ou seja, é um episódio súbito de déficit sanguíneo em uma região do cérebro com manifestações neurológicas que se revertem em minutos ou em até 24 horas sem deixar sequelas (se deixar sequelas por mais de 24 horas, passa a se chamar acidente isquêmico vascular por definição)
Constitui um fator de risco muito importante, visto que uma elevada porcentagem dos pacientes com AIT apresentam um AVC nos dias subsequentes
É possível que a definição de AIT venha a sofrer alterações, pois com exames mais acurados já é possível identificar lesões/sequelas cerebrais antes imperceptíveis em alguns AITs e, além disso, estudos clínicos mostram que a maioria dos AITs dura menos de 1 hora
Assim, o AIT que dura mais de uma hora provavelmente será um AVC e talvez possa provocar uma lesão cerebral, mesmo que imperceptível.
É o acidente vascular cerebral menos comum presente em cerca de 20% dos casos, mas não menos grave
Ocorre pela ruptura de um vaso sanguíneo intracraniano
O sangue em contato com o parênquima nervoso tem ação irritativa
Além disso, a inflamação e o efeito de massa ou pressão exercida pelo coágulo de sangue no tecido nervoso prejudica e degenera o cérebro e a função cerebral
Pode ser divido em dois tipos, O sangramento intraparenquimatoso ou a hemorragia subaracnóidea:
O diagnóstico do AVC é clínico, ou seja, é feito pela história e exame físico do paciente
Os principais sintomas são:
Durante um exame pode-se pedir ao paciente que sorria, levante os dois braços e repita uma frase (como "trinta e três")
Diante desses sintomas, quanto mais rápido o socorro, menor a probabilidade de sequelas, este teste é designado Escala de Cincinnati
Outros sintomas menos específicos, como queda do estado geral e coma, também elevam o risco de AVC.
Os médicos recomendam que a hipótese seja confirmada por um exame de imagem, tomografia computadorizada e ressonância magnética, que permitem ao médico identificar a área do cérebro afetada e o tipo de AVC.
A tomografia pode ser o exame inicial de escolha por sua disponibilidade e rapidez
Serve principalmente para diferenciar o AVC por entupimento/isquemia do hemorrágico, o que muda radicalmente a conduta médica
Uma tomografia normal dentro das primeiras 24 horas de um AVC isquêmico é algo esperado e confirma o diagnóstico, pois a maioria dos ataques isquêmicos não provoca lesões visíveis tão precoces nesse exame
Apenas lesões extensas ou mais antigas podem ser vistas na tomografia no AVC isquêmico ou, ainda, sinais indiretos de AVC como edema cerebral
Já o AVC hemorrágico costuma vir com imagem na tomografia indicando vazamento de sangue
Pode-se, ainda que menos comum, usar mão da retirada por punção lombar do líquor para o diagnóstico de AVC hemorrágico com tomografia normal.
Embora mais precisa que a tomografia, a ressonância magnética não costuma mudar a conduta médica e pode ainda atrasar o tratamento correto, o que pode ter impacto na recuperação do paciente
Contudo, é uma opção que pode ser útil em casos selecionados.
O processo de reabilitação pode ser longo, dependendo das características do próprio AVC, da região afetada, da rapidez de atuação para minimizar os riscos e do apoio que o doente tiver
O sistema nervoso central todo pode ser acometido por esta doença, o que inclui, além do cérebro, o tronco encefálico, o cerebelo e até a medula espinhal.
Assim o lobo frontal está mais ligado às decisões e movimentos; o lobo parietal com os movimentos do corpo, parte da fala e com a sensibilidade do pescoço até os pés; e o lobo occipital com a visão
Já o cerebelo está ligado com o equilíbrio e o tronco cerebral está ligado à respiração e aos movimentos e sensibilidade da cabeça
Claro que isto é uma explicação básica e deve-se ter em mente que todo sistema nervoso está interligado podendo uma lesão em uma mínima parte ter grandes repercussões no todo
A localização e as implicações da lesão podem ser difíceis de diagnosticar, devendo a pessoa acometida ser avaliada por um médico e equipe multidisciplinar, ou seja, com vários profissionais da saúde de diversas áreas.
No caso de um AIT ou acidente isquêmico transitório, não ocorre sequela
No entanto, a prevenção de outro AVC deve ser instituída devido ao alto risco de novo ataque dessas pessoas
No caso de um acidente encefálico associado a déficits motores, necessita-se de acompanhamento da equipe de fisioterapeutas, fonoaudiólogos e terapeutas ocupacionais para potencializar e fortalecer os músculos que ainda possuem a inervação funcionante para assim diminuir as deficiências que podem ter sido causadas; no caso de problemas na fala e/ou deglutição um fonoaudiólogo pode ser necessário.
Vale lembrar que o AVC é uma doença que merece muita atenção pela mudança que pode provocar na dinâmica da vida da vítima, da vida da sua família e das pessoas que dela cuidam
A vítima, antes totalmente funcional, pode se tornar totalmente dependente física e financeiramente de seus cuidadores
Pode, uma vez acamada, desencadear outras complicações, como escaras de decúbito, pneumonia e obstipação
Além disso, existe descrito o stress do cuidador - que, aliás, também deve ser abordado e ouvido no tratamento do paciente acamado, minimizando as sequelas familiares.
A melhor maneira de lidar com o AVC é preveni-lo controlando todos os fatores causais já citados, novamente mencionando que a principal é a hipertensão arterial sistêmica.
O AVC geralmente causa um impacto significativo na vida funcional, cognitiva e social do paciente, sendo comum que o paciente desenvolva transtornos psicológicos após o derrame
Entre 10 e 34% desenvolvem depressão maior, agravando ainda mais o prejuízo funcional, cognitivo e social do paciente
Quanto maior o prejuízo na qualidade de vida e dificuldade de adesão ao tratamento mais importante é o acompanhamento psicológico e psiquiátrico para a reabilitação da vítima do derrame.
Existem diversos fatores considerados de risco para a chance de ter um AVC, sendo o principal a hipertensão arterial sistêmica não controlada e, além dela, também aumentam a possibilidade o diabete melitus, doenças reumatológicas, trombose, uma arritmia cardíaca chamada fibrilação atrial, estenose da válvula mitral, entre outras.
Como todas as doenças vasculares, o melhor tratamento para o AVC é identificar e tratar os fatores de risco como a hipertensão, aterosclerose, o diabetes mellitus, o colesterol elevado, cessar o tabagismo e o etilismo, além de reconhecer e tratar problemas cardíacos
A essa prática se dá o nome de prevenção primária.
Se houver atendimento médico rápido, dentro de um determinado tempo, a área afetada poderá ser normalizada
A essa prática de prevenção que se baseia no atendimento médico eficiente se dá o nome de prevenção secundária.
Caso ocorram sequelas, deve ser iniciado um programa de reabilitação e cuidados com o paciente que inclui equipe multidisciplinar, ou seja, com vários profissionais de diferentes áreas da saúde - fisioterapia, fonoaudiologia, psicologia, técnicos em enfermagem, terapeutas ocupacionais, enfermeiros e médicos
A reabilitação é um tipo de prevenção terciária do paciente.
O manejo da pressão arterial no AVC isquêmico é altamente polêmico, uma vez que tanto pressões muito altas como muito baixas podem ser fatais
Ambas as situações podem apresentar um potencial de morbi-mortalidade, pois a hipertensão pode estar associada à transformação hemorrágica e recorrência do AVC, enquanto a hipotensão é suspeita de levar a uma baixa perfusão, provocando lesões definitivas da zona da penumbra isquêmica e levando a um pior prognóstico
O tratamento de redução da PA desses pacientes já foi associado a uma melhora de prognóstico e a um aumento da eficiência e segurança do tratamento trombolítico, mas outros estudos correlacionam a redução da PA, assim como a hipotensão do AVC com um pior prognóstico neurológico, com maior morbidade e mortalidade
Alguns especialistas chegam a sugerir o aumento induzido da pressão arterial em pacientes hipotensos com AVC
A causa desse aparente paradoxo não é bem esclarecida, e suspeita-se que diferentes modalidades e circunstâncias do AVC determinem um papel diferente para a pressão arterial no prognóstico do paciente.
A maioria dos neurologistas concorda que pressões excessivamente elevadas (PAS > 220 mmHg) estão associadas a um prognóstico pior, mas a hipotensão (PAS < 60 mmHg) parece ser igualmente deletéria
Vários estudos sugerem que uma redução moderada da pressão, se acompanhada por tratamento trombolítico (como o ativador do plasminogênio tecidual, que é um agente fibrinolítico), pode reduzir significantemente a morbi-mortalidade
Os mesmos estudos tendem a concordar que a redução da pressão, se não acompanhada por trombólise, pode não ser segura.
Em presença dessas incertezas, o protocolo de manejo da PA em pacientes com AVC isquêmico agudo se baseia essencialmente na opinião de especialistas, que recomendam reduzir a PA em casos nos quais esta se encontra excessivamente elevada (PAS>220 mmHg), ou quando a redução for associada ao tratamento trombolítico
Nos demais casos a redução da PA não é recomendada.
A gravidade das sequelas dependem de quanto tempo demorou para o paciente ser atendido, sendo que, quanto mais rápido o tratamento apropriado comece, menos sequelas o paciente provavelmente sofrerá.
Embora ainda existam pessoas usando a nomenclatura Acidente Vascular Encefálico (sigla: AVE) no ano de 1996, visando dirimir dúvidas e tentar unificar o termo a ser usado no Brasil, tal assunto foi colocado em discussão durante a Assembleia Geral da Sociedade Brasileira de Doenças Cerebrovasculares (Sigla:SBDCV), ocorrida na cidade de Curitiba, durante o Congresso Brasileiro de Neurologia
Foi aprovado que o termo que deveria ser empregado seria o de "Acidente Vascular Cerebral", quando se dirigir ao público médico e/ou especializado e "derrame" quando for voltado ao público leigo
Tal decisão foi ratificada em 2008, quando este assunto foi novamente discutido, em reunião extraordinária da SBDCV (Quando da elaboração do 2º Consenso do Tratamento da Fase Aguda do AVC) e os termos AVC e derrame foram novamente recomendados.
Em 2010 a Revista Neurociências publicou um artigo intitulado: Acidente Vascular Cerebral ou Acidente Vascular Encefálico? Qual a melhor nomenclatura? Tal artigo explica detalhadamente o porquê dos termos AVC e Derrame serem mantidos.
Insuficiência renal é uma condição médica em que os rins deixam de funcionar
Divide-se em insuficiência renal aguda, de desenvolvimento súbito, ou insuficiência renal crónica
Os sintomas mais comuns são inchaço das pernas, cansaço, vómitos, perda de apetite ou confusão
As complicações mais comuns são uremia, elevada concentração de potássio ou excesso de volume de sangue nas cavidades do coração
Entre as complicações da doença crónica estão também doenças cardiovasculares, hipertensão arterial ou anemia.
As causas mais comuns de insuficiência renal aguda são a diminuição da pressão arterial, bloqueio do trato urinário, alguns medicamentos, perda de músculo e síndrome hemolítico-urémica
As causas mais comuns de insuficiência renal crónica são nefropatia diabética, hipertensão arterial, síndrome nefrótica e doença renal policística
O diagnóstico da doença aguda geralmente baseia-se numa associação de fatores como diminuição da produção de urina ou aumento da quantidade de creatinina no soro
O diagnóstico de doença crónica geralmente baseia-se num valor da taxa de filtração glomerular inferior a 15 ou na necessidade de terapia de substituição renal
É também equivalente ao estádio 5 da doença renal crónica.
O tratamento da doença aguda geralmente depende da causa subjacente
O tratamento da doença crónica pode incluir hemodiálise, diálise peritoneal ou um transplante de rim
A hemodiálise é realizada por uma máquina que filtra o sangue no exterior do corpo
Na diálise peritoneal é colocado um líquido específico na cavidade abdominal que depois é drenado, sendo este processo repetido várias vezes por dia
O transplante de rim envolve a colocação, através de cirurgia, de um rim de outra pessoa, seguida pela administração de medicamentos imunossupressores para prevenir a rejeição de transplante
Entre outras medidas recomendadas para a doença crónica estão manter-se ativo e alterações específicas na dieta.
Nos Estados Unidos, a doença aguda afeta em cada ano 3 em cada 1000 pessoas
A doença crónica afeta 1 em cada 1000 pessoas
A cada ano, 3 em cada 10 000 pessoas desenvolvem a condição
A doença aguda é em muitos casos reversível, enquanto a doença aguda não
No entanto, com tratamento adequado, muitas pessoas com doença crónica conseguem continuar a trabalhar.

bexiga urinária: Cistite (Cistite intersticial, Trigonite) - Bexiga neurogênica - Fístula êntero-vesical
uretra: Uretrite (Uretrite não-gonocócica) - Síndrome uretral - Estenose uretral

Doenças cardiovasculares são uma classe de doenças que afetam o coração ou os vasos sanguíneos
Entre estas doenças estão as doenças arteriais coronárias, como a angina de peito e o enfarte agudo do miocárdio, acidentes vasculares cerebrais (AVC), cardiopatia hipertensiva, febre reumática, miocardiopatia, arritmia cardíaca, cardiopatia congénita, valvulopatias, cardite, aneurisma da aorta, doença arterial periférica e trombose venosa.
Os mecanismos subjacentes variam de acordo com a doença em questão
A doença arterial coronária, os acidentes vasculares cerebrais e a doença arterial periférica envolvem aterosclerose, que pode ser causada por hipertensão arterial, tabagismo, diabetes, falta de exercício físico, obesidade, colesterol elevado, dieta inadequada e consumo excessivo de bebidas alcoólicas
A hipertensão arterial é a causa de 13% das mortes por doenças cardiovasculares, o tabaco de 9%, a diabetes de 6%, a falta de exercício de 6% e a obesidade de 5%
A febre reumática cardíaca pode ter origem numa faringite estreptocócica que não tenha sido tratada.
Estima-se que 90% dos casos de doenças cardiovasculares possam ser evitados com medidas de prevenção
A prevenção da aterosclerose pode ser feita diminuindo os fatores de risco, através de medidas como seguir uma alimentação saudável, praticar exercício físico, evitar a exposição ao fumo de tabaco e limitando o consumo de álcool
O tratamento da hipertensão arterial e da diabetes também é benéfico
O tratamento das pessoas com faringite estreptocócica com antibióticos pode diminuir o risco de febre reumática
Ainda não é claro o benefício do uso de aspirina em pessoas de outra forma saudáveis
O United States Preventive Services Task Force recomenda que a aspirina não seja usada como medida de prevenção em mulheres com menos de 55 e homens com menos de 45 anos de idade, embora seja recomendada em alguns indivíduos mais idosos
O tratamento de pessoas com doenças cardiovasculares melhora o prognóstico.
As doenças cardiovasculares são a principal causa de morte em todo o mundo, exceto em África
Em conjunto, foram responsáveis pela morte de 17,3 milhões de pessoas em 2013 (31,5%), um aumento em relação às 12,3 milhões em 1990 (25,8%)
Quando padronizadas para a idade, as mortes por doenças cardiovasculares são mais comuns e têm vindo a aumentar em grande parte dos países em vias de desenvolvimento, enquanto nos países desenvolvidos têm vindo a diminuir desde a década de 1970
A doença arterial coronária e o AVC são responsáveis por 80% das mortes por doenças cardiovasculares em homens e 75% em mulheres
As doenças cardiovasculares são progressivamente mais comuns com o avanço da idade
Nos Estados Unidos, apenas 11% das pessoas entre os 20 e 40 anos têm doenças cardiovasculares, 37% entre os 40 e 60 anos de idade, 71% entre os 60 e 80 anos de idade e 85% em pessoas com mais de 80 anos
A idade média de morte por doença arterial coronária em países desenvolvidos é de 80 anos, enquanto que nos países em desenvolvimento é de 68 anos
A doença manifesta-se em média sete a dez anos mais cedo em homens do que em mulheres.
Miocardite (Doença de Chagas)
Cardiomiopatia: Dilatada (Alcoólica) · Hipertrófica · Restritiva (Endocardite de Loeffler, Amiloidose cardíaca, Fibroelastose endocardíaca)
Fibrose cardíaca · Cardiomegalia · Hipertrofia ventricular (Esquerdo, Direito/Corpulmonale)
Retinopatia é o termo utilizado para designar formas de lesões não inflamatórias da retina ocular
Normalmente é associada a deficiente aporte sanguíneo
Com frequência, as retinopatias são manifestações localizadas de doenças sistémicas.
As principais causas e diferentes tipos de retinopatia são:
A retinopatia pode progredir para cegueira se for severa ou afectar a mácula
Esta condição pode ser diagnosticada por um oftalmologista ou ortoptista clínico durante um exame ocular
O tratamento depende da causa da doença.

pálpebra: inflamação (Hordéolo, Calázio, Blefarite) - Entrópio - Ectrópio - Lagoftalmo - Blefarocalásia - Ptose - Blefarofimose - Xantelasma - Triquíase
sistema lacrimal: Dacrioadenite - Epífora - Dacriocistite
Estrabismo paralítico: Oftalmoparesia - Oftalmoplegia externa progressiva - Paralisia (III, IV, VI) - Síndrome de Kearns-Sayre Outros estrabismos: Esotropia/Exotropia - Hipertropia - Heterophoria (Esophoria, Exoforia) - Síndrome de Brown - Síndrome de Duane
Outras binoculares: Paralisia do olhar conjugado - Insuficiência de convergência - Oftalmoplegia internuclear - Síndrome do um e meio
Deficiência visual ou perda visual é a perda ou diminuição grave e irreversível da função visual que não é corrigível com lentes ou cirurgia e que interfere com as tarefas do dia-a-dia
A perda visual pode ser súbita e grave ou ser o resultado de uma deterioração gradual, em que objetos a grande distância se tornam cada vez mais difíceis de ver
A condição causa à pessoa dificuldades em realizar atividades do dia-a-dia, como conduzir veículos, ler, socializar ou deslocar-se a pé
A deficiência visual engloba todas as condições em que existe comprometimento da visão
A Organização Mundial de Saúde classifica a deficiência visual em seis graus de acordo com a acuidade visual (AV) da pessoa
Quando a perda de visão é parcial denomina-se visão subnormal
A visão subnormal pode ser ligeira, moderada ou grave
Quando a perda de visão é total ou quase total denomina-se cegueira
A cegueira divide-se em cegueira profunda, quase total e total
A maior parte dos cegos possui alguma função visual e percebe luzes, sombras e movimento
Só uma pequena percentagem é que não possui qualquer sensação visual.
As causas mais comuns de perda visual são erros refrativos não corrigidos em tempo útil (43%), cataratas (33%) e glaucoma (2%)
Os erros refrativos mais comuns são a miopia, hipermetropia, presbiopia e astigmatismo
As cataratas são a causa mais comum de cegueira
Entre outras possíveis doenças que causam perda visual estão a degeneração macular relacionada com a idade, retinopatia diabética, opacidade da córnea, cegueira infantil e diversas infeções
A perda visual pode ainda ser causada por problemas neurológicos na sequência de um acidente vascular cerebral, parto prematuro ou trauma, entre outros
Estes casos denominam-se deficiência visual cortical
O diagnóstico de perda visual baseia-se em exames oculares
O rastreio visual em crianças permite corrigir atempadamente os problemas de visão e inverter o insucesso escolar que daí resulta
No entanto, os benefícios do rastreio em adultos não são claros.
Estima-se que 80% dos casos de deficiência visual sejam evitáveis ou tratáveis
Nos casos evitáveis inclui-se a perda visual causada por cataratas, tracoma, oncocercose, glaucoma, retinipatia diabética e alguns casos de cegueira infantil
A muitas pessoas com perda visual profunda é recomendada a reabilitação funcional, alterações no ambiente e utilização de equipamentos auxiliares.
Em 2015 havia 940 milhões de pessoas em todo o mundo com algum grau de perda visual
Entre estas, havia 246 milhões com défice de visão e 39 milhões com cegueira
A maioria das pessoas com dificuldades de visão encontram-se nos países em vias de desenvolvimento e têm mais de 50 anos de idade
A prevalência de deficiência visual tem vindo a diminuir desde a década de 1990
A condição tem custos económicos elevados, derivdados não só do custo do tratamento em si, como também da incapacidade para o trabalho
Algumas definições incluem pessoas com dificuldades de visão por não terem acesso a óculos ou lentes de contacto.


Segundo a 10 ª Revisão da OMS de Classificação Estatística Internacional de Doenças, Lesões e Causas de Morte, a visão subnormal é definida como acuidade visual inferior a 20/60 (6/18), mas igual ou melhor que 20/200 (6/60), ou correspondente a perda de campo visual menor que 20 graus, no melhor olho com a melhor correção possível
A cegueira é definida como acuidade visual menor que 20/400 (6/120), ou correspondente a perda de campo visual menor que 10 graus, no melhor olho com a melhor correção possível.
Cegueira é a condição de falta de percepção visual, devido a fatores fisiológicos ou neurológicos
Várias escalas têm sido desenvolvidas para descrever a extensão da perda de visão e definir a cegueira
Cegueira total é a completa falta de percepção visual de forma e luz e é clinicamente registrado como NLP, uma abreviação para "no light perception" (sem percepção de luz)
Cegueira é frequentemente usada para descrever a deficiência visual grave, com visão residual
Aqueles descritos como tendo apenas percepção de luz têm apenas a capacidade de diferenciar o claro do escuro e a direção de uma fonte de luz.
A cegueira é definida pela Organização Mundial de Saúde como visão menor que 20/500 no melhor olho de um pessoa ou campo visual inferior a 10 graus
Esta definição foi criada em 1972 e há uma discussão em curso sobre se ela deve ser alterada.
Deficiência visual é uma categoria que abrange pessoas cegas e com visão reduzida
Na definição pedagógica, a pessoa é cega, mesmo possuindo visão subnormal, quando necessita da instrução em braile; a pessoa com visão subnormal pode ler tipos impressos ampliados ou com auxílio de potentes recursos ópticos.
A definição clínica define como cego o indivíduo que apresenta acuidade visual menor que 0,1 (com a melhor correção no melhor olho) ou campo visual abaixo de 20 graus; como visão reduzida quem possui acuidade visual de 6/60 e 18/60 (escala métrica) e/ou um campo visual entre 20 e 50 graus, e sua visão não pode ser corrigida por tratamento clínico nem com óculos convencionais.
Cegueira pode ocorrer diante de algumas condições tais como retardo mental, espectro autista, paralisia cerebral, surdez e epilepsia
Em um estudo com 228 crianças com deficiência visual na região metropolitana de Atlanta entre 1991 e 1993, 154 (68%) tinha uma deficiência adicional além da deficiência visual
Cegueira em combinação com a perda auditiva é conhecida como surdocegueira.
Deficiência visual grave possui uma variedade de causas:
De acordo com estimativas da OMS, as causas mais comuns de cegueira em todo o mundo em 2002 foram:
Em termos de prevalência mundial de cegueira, a um número muito maior de pessoas e maior probabilidade de serem afetadas em países em desenvolvimento, significa que as causas de cegueira nessas áreas são numericamente mais importantes
A catarata é responsável por mais de 22 milhões de casos de cegueira e glaucoma seis milhões, enquanto que a lepra e oncocercose cegam aproximadamente um milhão de indivíduos em todo o mundo
O número de indivíduos cegos por tracoma caiu drasticamente nos últimos 10 anos de seis para 1,3 milhões, colocando-o em sétimo lugar na lista de causas de cegueira no mundo
É estimado que a xeroftalmia afete cinco milhões de crianças a cada ano; 500 mil desenvolvem o envolvimento da córnea ativa, e metade destes tornam-se cegos
Ulceração da córnea central é também uma importante causa da cegueira monocular no mundo, o que representa uma estimativa de 850 mil casos de cegueira corneal todos os anos apenas na Índia
Como resultado, as cicatrizes corneanas por todas as causas agora são a quarta maior causa global da cegueira.
A degeneração macular relacionada à idade (DMRI) é uma doença degenerativa da retina que provoca uma perda progressiva da visão central e leva a cegueira
Atualmente é apontada como a causa mais comum de perda de visão nas pessoas acima de 55 anos
Segundo dados da Foundation Fighting Blindness, 10 milhões de pessoas nos EUA tem DMRI ou possuem risco considerável de desenvolver a doença
Estima-se que no ano de 2020, até 8 milhões de pessoas com 65 anos ou mais poderão apresentar DMRI
A taxa de acometimento pela DMRI aumenta com a idade.
Pessoas nos países em desenvolvimento são significativamente mais propensas a adquirir a deficiência visual como consequência de doenças tratáveis ou evitáveis do que suas contrapartes em países desenvolvidos
Enquanto a deficiência visual é mais comum em pessoas com mais de 60 anos de idade em todas as regiões, as crianças em comunidades mais pobres são mais propensas a serem afetadas do que seus pares mais ricos.
A ligação entre pobreza e deficiência visual tratável é mais evidente quando se realizam comparações regionais sobre a causa
A maioria dos adultos com deficiência visual na América do Norte e na Europa Ocidental tem como causa degeneração macular relacionada à idade e retinopatia diabética
Enquanto ambas as condições estão sujeitos a tratamento, nenhuma delas pode ser curada.
Nos países em desenvolvimento, onde as pessoas têm menor expectativa de vida, catarata e parasitas transmitidos pela água —ambas podem ser tratadas eficazmente— são na maioria das vezes os culpados
Em países desenvolvidos, onde doenças parasitárias são menos comuns e cirurgia de catarata é mais disponível, a degeneração macular relacionada à idade, glaucoma e retinopatia diabética são geralmente as principais causas da cegueira.
Cegueira infantil pode ser causada por condições relacionadas à gravidez, tais como a síndrome da rubéola congênita e retinopatia da prematuridade.
Lesões nos olhos, na maioria das vezes ocorrem em pessoas com menos de 30, são a principal causa de cegueira monocular (perda de visão em um olho) em todo o Estados Unidos
Lesões e cataratas afetam o olho em si, enquanto anormalidades tais como hipoplasia do nervo óptico afetam o feixe nervoso que envia sinais do olho para trás do cérebro, que pode levar à diminuição da acuidade visual.
Pessoas com lesões no lóbulo occipital do cérebro podem, apesar de terem os olhos e nervos ópticos danificados, ainda serem legalmente ou totalmente cegos.
Pessoas com albinismo têm frequentemente perda de visão e muitos são legalmente cegos, embora poucos deles realmente não possam ver
Neuropatia óptica hereditária de Leber pode causar cegueira total ou perda de visão grave desde o nascimento ou na infância.
Os recentes avanços no mapeamento do genoma humano identificaram outras causas genéticas de baixa visão ou cegueira
Um exemplo é a síndrome de Bardet-Biedl.
Raramente, a cegueira é causada pela ingestão de determinados produtos químicos
Um exemplo bem conhecido é o metanol, que é apenas levemente tóxico e minimamente intoxicante, mas não quando o etanol compete com o metabolismo, metanol decompõe-se em formaldeído e ácido fórmico substâncias que por sua vez pode causar cegueira, uma série de outras complicações de saúde e até a morte
O metanol é comumente encontrado em bebidas alcoólicas, o álcool etílico desnaturado, para evitar pagar impostos sobre a venda de etanol destinados ao consumo humano
Álcool etílico é por vezes usado por alcoólatras como um substituto desesperado e barato para bebidas alcoólicas.
Cegueira tem sido usada como um ato de vingança e tortura em alguns casos, para privar uma pessoa de um sentido importante pelo qual ela pode guiar-se ou interagir com o mundo, agir com total independência e estar ciente dos acontecimentos que os rodeiam
Um exemplo da esfera clássica é Édipo, que fura seus próprios olhos após perceber que cumpriu a terrível profecia sobre ele
Assassino de búlgaros, o imperador bizantino Basílio II Bulgaróctono cegou 15 mil prisioneiros, antes de libertá-los.
Em 2003, um tribunal antiterrorista paquistanês condenou um homem a ser cegado depois de ter realizado um ataque com ácido contra a sua noiva, que resultou em sua cegueira
A mesma sentença foi dada em 2009 para o homem que cegou Ameneh Bahrami.
Um estudo de 2008 publicado no New England Journal of Medicine testou o efeito do uso de terapia genética para ajudar a restaurar a visão de pacientes com uma forma rara de cegueira hereditária, conhecida como Neuropatia óptica de Leber ou NOL
A Neuropatia óptica de Leber danifica os receptores de luz na retina e normalmente começa a afetar a visão na infância, com piora da visão até a cegueira completa em torno da idade de 30 anos.
O estudo utilizou um vírus comum do resfriado para levar uma versão normal do gene chamado RPE65 diretamente nos olhos dos pacientes acometidos
Notavelmente todos os 3 pacientes com idades de 19, 22 e 25 responderam bem ao tratamento e relataram melhora da visão após o procedimento
Devido à idade dos pacientes e a natureza degenerativa do NOL a melhoria da visão dos pacientes em terapia genética é encorajadora para os investigadores
Espera-se que a terapia genética possa ser ainda mais eficaz em pacientes mais jovens que sofreram perda de visão limitada, bem como em outros indivíduos cegos ou parcialmente cegos.
Dois tratamentos experimentais para os problemas de retina incluem um substituto cibernética e transplante de células da retina fetal.
Muitas pessoas com sérias deficiências visuais podem se locomover de forma independente, usando uma ampla gama de ferramentas e técnicas
Especialistas em orientação e mobilidade são os profissionais que são treinados especificamente para ensinar as pessoas com deficiência visual como se locomover com segurança, confiança, e de forma independente em casa e na comunidade
Estes profissionais também podem ajudar as pessoas cegas na prática de locomoção em rotas específicas, que possam ser utilizadas, muitas vezes, como a rota da casa para uma loja.
Ferramentas como a bengala branca com uma ponta vermelha — o símbolo internacional da cegueira — também podem ser usadas para melhorar a mobilidade
A bengala cano-longo é usada para aumentar o alcance da sensação de toque do usuário
Geralmente é usada com ela para baixo em um movimento de balanço, através do caminho planejado, para detectar obstáculos
No entanto, as técnicas para manuseio da bengala podem variar dependendo do utilizador e/ou da situação
Algumas pessoas com deficiência visual não possuem esses tipos de bengalas, optando pela menor e mais leve bengala de identificação (ID)
Outros ainda necessitam de uma bengala de apoio
A escolha depende da visão do indivíduo, motivação e outros fatores.
Um pequeno número de pessoas utilizam cães-guia para ajudar em sua mobilidade
Estes cães são treinados para desviar de vários obstáculos, e indicar quando se torna necessário subir ou descer um degrau
No entanto, a utilidade dos cães-guia é limitado pela incapacidade de cães de entender os complexos caminhos
A metade humana da equipe traça o caminho, com base em habilidades adquiridas através da formação de mobilidade anterior
Neste sentido, o manipulador pode ser comparado ao navegador de uma aeronave, que deve saber como ir de um lugar para outro, e que o cão o piloto, que deve levá-los ao destino com segurança.
Algumas pessoas cegas usam GPS para deficientes visuais como ajuda em sua mobilidade
Esses softwares podem ajudar as pessoas cegas, com orientação e navegação, mas não é um substituto para ferramentas de mobilidade tradicionais, tais como bengalas brancas e cães-guia.
Tecnologia para permitir que pessoas cegas possam conduzir veículos motorizados começou a ser desenvolvida em 2011, por pesquisadores do Instituto Politécnico e Universidade Estadual da Virgínia, juntamente com a Federação Nacional dos Cegos dos Estados Unidos.
Ações do governo são algumas vezes tomadas para tornar lugares públicos mais acessíveis a pessoas cegas
O transporte público está disponível gratuitamente para os cegos em muitas cidades
Piso tátil e semáforos com autofalantes podem tornar mais fácil e mais seguro para os pedestres com deficiência visual atravessarem as ruas
Além de fazer regras sobre quem pode e não pode usar uma bengala, alguns governos obrigam que se de a preferência aos usuários de bengalas brancas ou cães-guia.
O tema da cegueira e da educação incluiu abordagens da evolução e percepção pública da melhor forma de abordar as necessidades especiais de alunos cegos
A prática de institucionalização em asilos dos cegos tem uma história que remonta mais de mil anos, mas só no século XVIII que as autoridades criaram escolas para eles, onde as crianças cegas, particularmente aqueles mais privilegiadas, geralmente eram educadas em tais ambientes especializados
Essas instituições fornecem desde a formação profissional e a simples adaptação, bem como aprofundamento em assuntos acadêmicos oferecidos através de formatos alternativos
Literatura, por exemplo, foi sendo disponibilizada para alunos cegos por meio de relevo nas letras romanas.
Os antigos egípcios foram a primeira civilização a mostrar interesse nas causas e curas para a deficiência e, durante alguns períodos as pessoas cegas foram registrados como representando uma porção substancial dos poetas e músicos na sociedade.
A primeira escola destinada a preparação de alunos com deficiência visual foi fundada por Valentin Haüy, em 1784, na cidade de Paris, a Instituição Real para Jovens Cegos em Paris (hoje o Instituto Nacional para Jovens Cegos, o INJA)
A primeira escola para cegos no Brasil foi o Imperial Instituto dos Meninos Cegos, fundado por Dom Pedro II no Rio de Janeiro, hoje o Instituto Benjamin Constant
Em Portugal a primeira instituição de ensino para cegos foi a Associação Promotora dos Ensino Cegos (APEC) que inaugurou sua primeira escola em 1888.
A maioria dos deficientes visuais que não são totalmente cegos leem impressões, sejam de um tamanho normal ou aumentado por dispositivos de ampliação
Muitos também leem impressões ampliadas que é mais fácil para se ler sem nenhum tipo de dispositivo
Uma variedade de lentes de aumento, algumas portáteis e outras não, podem tornar a leitura mais fácil para eles.
Outros leem Braille (ou o raramente usado alfabeto da lua) ou contam com livros falados e leitores ou máquinas de leitura, que convertem texto impresso em fala ou em Braille
Eles usam computadores com hardware especiais, tais como scanners e monitores Braille, bem como software que escrevem especificamente para os cegos, como aplicativos de reconhecimento óptico de caracteres e leitores de tela.
Algumas pessoas acessam estes materiais através de agências para os cegos, como Bibliotecas para Cegos.
Circuitos fechados de televisão são equipamentos que aumentam e contrastam os itens textual, são uma alternativa mais "high-tech" do que dispositivos de ampliação tradicional.
Há também mais de 100 serviços de rádio para se ler em todo o mundo que proporciona às pessoas com deficiência visual leituras periódicas através do rádio
A Associação Internacional de Serviços de Informação de Áudio fornece links para todas essas organizações.
Acesso a tecnologias, tais como leitores de tela, ampliadores de tela e monitores Braille permitem aos cegos a usar aplicações informáticas e telefones celulares
A disponibilidade de tecnologia assistiva está aumentando, acompanhada de esforços concertados para garantir a acessibilidade das tecnologias de informação a todos os potenciais utilizadores, incluindo os cegos
Versões mais recentes do Microsoft Windows incluem um Assistente de Acessibilidade e Lupa para aqueles com visão parcial, e Microsoft Narrator, um leitor de tela simples
Distribuição Linux (como CDs ao vivo) para cegos incluem Oralux e Knoppix, este último desenvolvido em parte por Adriane Knopper, que tem uma deficiência visual
Mac OS também vem com um leitor de tela embutido, chamado de VoiceOver.
O movimento em direção à maior acessibilidade da web está abrindo um número muito maior de sites para tecnologia adaptativa, tornando a web um lugar mais convidativo para deficientes visuais.
Modificações na produção visual que incluem letras grandes e/ou limpar gráficos simples pode ser um benefício para os usuários com alguma visão residual.
Pessoas cegas podem usar equipamentos que falam como termômetros, relógios, balanças, calculadoras, e bússolas
Eles também podem ampliar ou colocar marcadores em dispositivos tais como fornos e termostatos para torná-los utilizáveis
Outras técnicas usadas por pessoas cegas para auxiliá-los nas atividades diárias incluem:
A maioria das pessoas, uma vez que foram deficientes visuais por tempo suficiente, elaboram suas próprias estratégias de adaptação em todas as áreas de gestão pessoal e profissional.
A OMS estima que em 2002 havia 161 milhões de pessoas com deficiência visual no mundo (cerca de 2,6% da população total)
Deste número 124 milhões (cerca de 2%) tinham baixa visão e 37 milhões (cerca de 0,6%) estavam cegos
Em ordem de freqüência as principais causas foram catarata, erros refrativos não corrigidos (miopias, hipermetropias, ou astigmatismos), glaucoma e degeneração macular relacionada à idade
Em 2000, o número de pessoas cegas no Brasil foi estimado em 0,4 a 0,5% da população, ou seja, 4 a 5 por cada mil
Considerando-se na época a população brasileira de 160 milhões de habitantes, estima-se existirem 640.000 cegos no país
Em Portugal, no ano de 2008, existiam entre 130 e 140 mil cegos, 1% da população.
A fim de determinar quais as pessoas podem necessitar de assistência especial por causa de sua deficiência visual, várias jurisdições governamentais formularam definições mais complexas, conhecida como "cegueira legal".
No Brasil, "cegueira legal" é quando a acuidade visual é igual ou menor que 0,05 (20/400) no melhor olho, com a melhor correção óptica;
Em muitos lugares, as pessoas com acuidade média, que, no entanto têm um campo visual inferior a 20 graus (o normal é 180 graus) também são classificadas como sendo legalmente cegas
Cerca de dez por cento daqueles considerados legalmente cegos, por qualquer medida, não têm visão
O resto tem alguma visão, e percepção de luz, uma acuidade relativamente boa
Visão subnormal é por vezes utilizado para descrever acuidade visual de 20/70 a 20/200.
Diferentes culturas através da história têm retratado a cegueira de formas diferentes; para os gregos, por exemplo, era um castigo dos deuses, para o qual o indivíduo afligido muitas vezes recebia uma compensação na forma do gênio artístico
A literatura judaico-cristã trata a cegueira como um defeito; e só através do amor de Deus uma cura poderia o se manifestar, quando os olhos de um indivíduo afligido entrasse em contato com um homem santo ou relíquia
Quase sem exceção na literatura antiga as pessoas cegas poderiam trazer esta condição sobre si por causa de pecados ou ofensas contra os deuses, mas nunca foram os únicos instrumentos para sua reversão.
É impossível fazer uma generalização sobre como os cegos foram tratados na literatura,—eles foram maravilhosos, talentosos, maus, maliciosos, ignorantes, sábios, indefesos, inocentes, ou onerosos dependendo da história—mas sempre a cegueira foi dita como uma perda que deixa uma marca que não se apaga no caráter de uma pessoa.
Mesmo pioneiros no treinamento dos cegos, como Dorothy Harrison Eustis, abrigavam estereótipos negativos sobre eles
Pessoas cegas estavam, em sua opinião, tão acostumadas a esperar dos outros a ponto de serem passivas e melancólicas.
Father Thomas Carroll, que fundou o Carroll Centre for the Blind (Centro para cegos Carroll), escrveu o livro Blindness: What It Is, What It Does and How to Live with It (Cegueira: O Que É, O Que Ela Faz e Como Conviver com ela) em 1961
Nela, ele caracteriza a cegueira como sendo 20 perdas, e como a "morte" do indivíduo que enxergava.
No mito grego, Tirésias era um profeta famoso por sua clarividência
De acordo com um mito, ele foi cegado pelos deuses como castigo por ele ter revelado seus segredos, enquanto outro afirma que ele foi cegado como punição por ver Atena nua enquanto ela estava se banhando
Em a Odisseia, o ciclope Polifemo captura Ulisses, que cega-o, para poder escapar
Na mitologia nórdica, Loki engana o Deus cego Hoder fazendo-o matar seu irmão Balder, o Deus da felicidade.
No Novo Testamento contém numerosos exemplos de Jesus realizando milagres para curar os cegos
De acordo com os Evangelhos, Jesus curou os dois cegos da Galileia, o cego de Betsaida, o cego de Jericó e o homem que nasceu cego.
A parábola os cegos e um elefante cruzou entre muitas tradições religiosas e faz parte do Jainismo, Budismo, Sufismo e Hinduísmo
Em várias versões do conto, um grupo de cegos (ou homens no escuro) tocam em um elefante para aprenderem o que é
Cada um se sente uma parte diferente, mas apenas uma parte
Eles, então, comparam o que sentiram e descobrem que eles estão em completo desacordo.
"Three Blind Mice" (lit
"Três Ratos Cegos") é uma cantiga de roda medieval inglesa sobre três ratos cegos, cujas caudas são cortadas após perseguirem a mulher do fazendeiro
O trabalho é explicitamente incongruente, terminando com o comentário Você já viu tal visão em sua vida, Como três ratos cegos?
John Milton que se tornou cego na meia-idade, compôs On His Blindness (lit
Em Sua Cegueira), um soneto sobre como lidar com a cegueira
A obra postula que [aqueles] que conseguissem o urso mais manso [para Deus], seriam os melhores para servi-lo.
O pintor e gravador neerlandês Rembrandt muitas vezes mostravam cenas do apócrifo livro de Tobias, que conta a história de um patriarca cego que é curado por seu filho, Tobias, com a ajuda do arcanjo Rafael.
John Newton compôs o hino Amazing Grace sobre um infeliz que dizia "eu estava perdido, mas agora fui encontrado, estava cego, mas agora vejo." Cegueira, neste sentido, é usada tanto metaforicamente (para se referir a alguém que era ignorante, mas depois se tornou conhecedor) e, literalmente, como uma referência para aqueles curados na Bíblia
Nos últimos anos de sua vida, Newton se tornaria cego.
A música hino da luta pelos direitos civis "Blowin' in the Wind" de Bob Dylan duas vezes faz alusão à cegueira metafórica: Quantas vezes pode um homem virar sua cabeça / / e fingir que ele simplesmente não vê..
Quantas vezes precisará um homem olhar para cima / / Antes que ele possa ver o céu?
A ficção contém numerosos personagens cegos conhecidos
Alguns desses personagens podem "ver" por meio de dispositivos fictícios, como o super herói da Marvel Comics o Demolidor, que podem "ver" através de sua acuidade auditiva super-humana, ou Geordi La Forge de Star Trek que pode ver, com o auxílio de um VISOR, um dispositivo fictício que transmite sinais ópticos para seu cérebro.
Pessoas cegas e com visão parcial praticam esportes como natação, esqui na neve, e atletismo
Alguns esportes foram inventados ou adaptados para cegos, como golbol, futebol de cinco, críquete, judô e golfe
A autoridade mundial em esportes para cegos é a Federação Internacional de Desportos para Cegos (IBSA)
Pessoas com deficiência visual participam dos Jogos Paralímpicos desde o Jogos Paralímpicos de Verão de 1976 em Toronto.
A palavra "cego" (adjetivo e verbo) é frequentemente utilizada com o significado de falta de conhecimento de algo
Por exemplo, um encontro às cegas é uma data em que as pessoas envolvidas não foram previamente conhecidas; um experimento cego é aquele onde nem o examinado nem o examinador sabe o que está sendo utilizado como variável em um dado momento
A expressão "cego guiando cego" refere-se a pessoas incapazes de liderar outras pessoas incapazes, expressão que tem origem religiosa (vide O cego levando o cego)
Um "ponto cego" é uma área em que alguém não pode ver, por exemplo, onde um motorista de carro não pode ver porque parte de carroçaria do seu carro estão no caminho
A expressão "o amor é cego" diz que se deve olhar não só para a beleza exterior da pessoa.
Muitos ditados populares usam a cegueira tanto de forma metafórica quanto real
"Mais perdido do que cego em tiroteio" é um ditado popular atribuído a pessoas que não conseguem entender algo
"Em terra cego, quem tem um olho é rei" é outro dito, que refere-se a elevação de pessoas se comparadas a outras de pouco valor, por exemplo em uma área onde a procura por mão de obra qualificada é muita escassa, uma pessoa qualificada mesmo que minimamente já é muito boa
"O pior cego é aquele que não quer ver" fala sobre as pessoas que se recusam aceitar verdade
"Mais vale ser cego dos olhos do que do coração" é um provérbio árabe que enfatiza o amor.
Declarações de que certas espécies de mamíferos "nasceram cegas" refere-se a eles nascerem com os olhos fechados e as suas pálpebras se fundirem; os olhos ainda abrem
Um exemplo é o coelho
Nos seres humanos as pálpebras são fundidas no período que antecede o nascimento, mas são abertas novamente antes da hora do nascimento normal, mas os bebês muito prematuros, às vezes, nascem com os olhos fechados, que se abrem mais tarde
Outros animais como o rato-toupeira cego são realmente cegos e dependem de outros sentidos.
Animais cegos, em geral incluem animais noturnos e animais do subterrâneo, mas há outros como o peixe-cego, o grilo-cego, a salamandra do Texas , os platelmintos camarão sem olhos, peixe sem olhos, o besouro-cego, o lagostim-cego, e alguns artrópodes, isópodos, copépodes e troglóbios.
Animais cegos tem sido um tema poderoso na literatura
Equus peça de Peter Shaffer conta a história de um menino que cega seis cavalos
Romance clássico de Theodore Taylor, The Trouble With Tuck é sobre uma adolescente, Helen, que treina seu cão cego a seguir e confiar em um cão-guia.

pálpebra: inflamação (Hordéolo, Calázio, Blefarite) - Entrópio - Ectrópio - Lagoftalmo - Blefarocalásia - Ptose - Blefarofimose - Xantelasma - Triquíase
sistema lacrimal: Dacrioadenite - Epífora - Dacriocistite
Estrabismo paralítico: Oftalmoparesia - Oftalmoplegia externa progressiva - Paralisia (III, IV, VI) - Síndrome de Kearns-Sayre Outros estrabismos: Esotropia/Exotropia - Hipertropia - Heterophoria (Esophoria, Exoforia) - Síndrome de Brown - Síndrome de Duane
Outras binoculares: Paralisia do olhar conjugado - Insuficiência de convergência - Oftalmoplegia internuclear - Síndrome do um e meio
Genética clássica
Evolução
Evol
molecular
Genét
mendeliana
Genét
molecular
Genét
populacional
Genét
quantitativa
Hereditariedade
Variabilidade genética
Mutação
CRISPR/Cas
Sequenciamento de DNA
Engenharia genética
Genômica (tópicos)
Genética médica
Edição de genoma é um tipo de engenharia genética em que o ADN é inserido, substituído, ou removido de um genoma utilizando nucleases modificadas artificialmente, ou "tesoura molecular".
A edição do genoma com nucleases de engenharia, uma poderosa ferramenta para entender a função biológica e revelar a causalidade, foi construída em um esforço conjunto pela academia e indústria de 1994 a 2010
O uso do CRISPR/Cas9 é a implementação mais recente (2013) na "caixa de ferramentas" de edição genética.
A estratégia de substituição baseada em recombinação homóloga nasceu nos anos 70 nos laboratórios de Gerry Fink e Ron Davis que mostraram que um gene de levedura pode ser substituído por um marcador selecionável e, portanto, eliminado
Este método tornou-se uma fonte chave da "genética do fermento", e ao longo das três décadas subsequentes, a comunidade de pesquisa de leveduras o usa, entre outras coisas, para fazer uma coleção de alelos nulos e hipomórficos em todo o genoma do fermento, amplamente utilizado para reversão malhas genéticas.


O Projeto Genoma Humano (AO 1945: Projecto Genoma Humano) (PGH) consistiu num esforço internacional para o mapeamento do genoma humano e a identificação de todos os nucleótidos que o compõem
Após iniciativa dos Institutos Nacionais da Saúde estadunidenses (NIH), centenas de laboratórios de todo o mundo se uniram à tarefa de sequenciar, um a um, os genes que codificam as proteínas do corpo humano e também aquelas sequências de DNA que não são genes
Laboratórios de países em desenvolvimento também participaram do empreendimento com o objetivo de formar mão-de-obra qualificada em genómica.


O projeto foi fundado em 1990 e James D
Watson, na época chefe dos Institutos Nacionais de Saúde dos Estados Unidos, assumiu inicialmente a direção do projeto
Em 1990, o PGH tinha o envolvimento de mais de 5000 cientistas, de 250 diferentes laboratórios, que contavam com um orçamento, segundo diferentes fontes, que variou de US$ 3 bilhões a US$ 53 bilhões
O PGH contou com um financiamento de 3 milhões de dólares do Departamento de Energia dos Estados Unidos e do NIH estadunidense.
O Projeto contou com o envolvimento de diversos laboratórios e centros de pesquisa ao redor do mundo, criando dessa forma o Consórcio Internacional de Sequenciamento do Genoma Humano
Este consórcio publicou um esboço inicial na revista científica Nature em fevereiro de 2001 com cobertura de cerca de 90 por cento do genoma.
No dia 10 de julho de 1999 foi anunciado o primeiro rascunho do genoma humano
Como a precisão do resultado precisava ser máxima, muita análise e revisão foram feitas de modo que cada base no genoma fosse sequenciada num total de 10 a 12 vezes.
Em 14 de abril de 2003, um comunicado de imprensa conjunto anunciou que o projeto fora concluído com sucesso, com a sequenciação (no Brasil, sequenciamento) de 99% do genoma humano com uma precisão de 99,99%.
O PGH foi um consórcio internacional
Basicamente, 17 países iniciaram programas de pesquisas sobre o genoma humano
Os maiores programas desenvolvem-se na Alemanha, Austrália, Brasil, Canadá, República Popular da China, Coreia do Sul, Dinamarca, Estados Unidos, França, Israel, Itália, Japão, México, Países Baixos, Reino Unido, Rússia e Suécia.
Alguns países em desenvolvimento, não incluídos na relação acima, participam através de estudos de técnicas de biologia molecular de aplicação à pesquisa genética e estudos de organismos que têm interesse particular para suas regiões geográficas.
Informações sobre estes países e suas pesquisas de contribuição para o PGH podem ser obtidas através da "Human Genome Organization" (HUGO), que conta com cerca de 1000 membros de 50 países, para ajudar a coordenar a colaboração internacional ao projeto.
Em 1998, liderada pelo cientista Craig Venter, a Celera Genomics entra na corrida pelo genoma, prometendo sequenciar o genoma humano em menos tempo com um financiamento de apenas dois bilhões de dólares, um valor relativamente menor do que o proposto inicialmente pelo Projeto Genoma
O propósito da participação da empresa era fornecer o código decifrado por um determinado preço àqueles associados ao grupo, além de buscar a patente dos genes envolvidos nos principais distúrbios e doenças humanas.
O PGH, conduzido pelos órgãos do governo obteve dados de alta qualidade e precisão - inclusive para as porções do DNA que não contêm gene
Por esse setor foi usada a tecnologia de Whole Genome Sequencing.
A iniciativa privada, formada pela empresa Celera Genomics e liderada por Craig Venter, juntou-se ao projecto em vista do potencial de lucro que as pesquisas poderiam trazer, especialmente para as indústrias farmacêuticas
A rapidez na obtenção de resultados, que podem ser transformados em patentes, tornou-se crucial para elas
Então optaram por um método mais objectivo: sequenciamento por Shotgun (whole genome “shotgun” sequencing), é uma abordagem mais rápida, evidentemente, embora menos precisa.
No dia 4 de Setembro de 2003, o grupo de pesquisa do Instituto J
Craig Venter publicou a sequência completa do genoma do próprio pesquisador Craig Venter
A grande revolução nesse novo trabalho é a de que o genoma avaliado corresponde ao genoma diplóide, contendo a informação de cada par de cromossomo herdado de nossos pais, ao contrário da sequência determinada pelo Projeto Genoma que corresponde ao genoma haplóide
Como resultado, descobriu-se que a semelhança das sequências genéticas entre dois indivíduos é de 99,5% e não de 99,9% como se imaginava ao fim do Projeto Genoma Humano.
O projeto genoma humano é muito importante para a saúde humana,pois,é a revolução da comunidade científica.
Um aspecto particular do PGH estadunidense é que ele procurou abordar também os aspectos éticos, legais e sociais envolvidos.
Os responsáveis pelo projecto acreditavam que a descoberta da posição de cada gene, além de sua composição, seria valiosa para diagnóstico e a cura de muitas doenças, como cancro, obesidade, diabetes, doenças auto-imunes e hipertensão
Os críticos do projeto, no entanto, alertavam para o perigo do uso indevido das informações genéticas
Candidatos a emprego, por exemplo, poderiam ser recusados com base em testes capazes de revelar predisposição genética para certas doenças, como o alcoolismo.
A empresa Celera fez o pedido da patente dos 6500 genes que mapeou
Esse pedido de patente gerou problemas de ordem ética, pois isso poderia inviabilizar a produção de medicamentos baseados nesse conhecimento, levando ao presidente dos Estados Unidos Bill Clinton declarar que o genoma humano não poderia ser patenteado.
Foram sequenciados todos os genes, em torno de 25.000 e constituindo pouco mais de 20% do material genético total humano
Por limitações tecnológicas, cerca de 1% do genoma não pode ser sequenciado por possuir muitas repetições de bases nitrogenadas (centrómeros e telómeros dos cromossomas, p
ex.)
Também é importante ressaltar que a maior parte do genoma humano parece não ser codificante e existe provavelmente por razões estruturais e regulatórias.
De todos os genes que tiveram sua sequência determinada, aproximadamente 50% codificam proteínas de função conhecida.
Apesar dessas lacunas, a conclusão do genoma já está facilitando o desenvolvimento de fármacos muito mais potentes, a compreensão de diversas doenças genéticas humanas e facilitando a realização de novos projetos genoma.
O PGH já completou a descoberta de mais de 1800 genes de doença, assim como facilita a identificação de outros genes associados a doenças
Além disso, pelo menos 350 produtos biotecnológicos resultantes dos conhecimentos gerados pelo PGH estariam passando por ensaios clínicos
As ferramentas desenvolvidas no PGH continuam servindo para caracterizar genomas de outros organismos importantes.

Bioinformática  · Biologia sistêmica  · Farmacogenética  · Farmacogenômica  · Genômica computacional  · Genômica estrutural  · Genômica funcional  · Glicômica  · Imunômica  · Metabolômica  · Metagenômica  · Paleopoliploidia  · Projeto Genoma  · Projeto Genoma Humano  · Proteômica  · Quimiogenômica  · Quimioinformática  · Toxicogenômica
O sistema CRISPR (do inglês Clustered Regularly Interspaced Short Palindromic Repeats), ou seja, Repetições Palindrômicas Curtas Agrupadas e Regularmente Interespaçadas, consiste em pequenas porções do DNA bacteriano compostas por repetições de nucleotídeos
Cada uma dessas repetições encontra-se adjacente a um “protoespaçador” (“espaçador de DNA”), que corresponde a uma região não-codificante inserida no DNA bacteriano após o contato com genomas invasores provenientes de bacteriófagos ou plasmídeos
A transcrição do locus CRISPR resulta em pequenos fragmentos de RNA com capacidade de desempenhar o reconhecimento de um DNA exógeno específico e atuar como um guia de modo a orientar a nuclease Cas, que irá promover a clivagem e consequente eliminação do DNA invasor caso este entre novamente em contato com a bactéria, atuando como importante mecanismo de defesa contra DNAs invasores .
O CRISPR é frequentemente usado como um termo geral para se referir à edição genômica, mas é o acoplamento do CRISPR e do sistema Cas9 que permite a deleção seletiva do DNA
Diversos são os mecanismos pelos quais a molécula de RNA guia pode ser sintetizada, entretanto, o sistema tipo II no qual baseiam-se os sistemas atualmente disponíveis para realização da edição gênica, requer a presença de um RNA transativador (tracRNA), e uma molécula pequena de RNA complementar à sequência repetida capaz de associar-se ao transcrito inicial do locus CRISPR, denominada CRISPR RNA (crRNA-sequências que consistem em um protoespaçador ligado a uma sequência repetida com estrutura de grampo)
Esta associação origina o complexo tracRNA-crRNA, uma molécula de RNA dupla fita que após ser processada pela RNase III é convertida em uma molécula híbrida madura com função importante no que diz respeito à associação e direcionamento de uma nuclease para eliminação do DNA invasor
Nesse sistema especificamente, a nuclease envolvida na clivagem refere-se à Proteína Associada a CRISPR 9 (Cas9) .
A alta taxa de insucesso, custo elevado e excesso de tempo necessário para realização das metodologias disponíveis para edição gênica, tais como Recombinação Homóloga (comumente empregada na manipulação genica de células-tronco), Nucleases Dedos de Zinco (ZFN, do inglês Zinc Fingers Nucleases) e Nucleases Efetoras semelhantes à Ativadores de Transcrição (TALENs, do inglês Transcription Activator–like Effector Nucleases), estas duas últimas requerem o reconhecimento em ambas as fitas de DNA para que a clivagem promovida por nucleases sintetizadas especificamente para tais metodologias seja bem sucedida, o que nos permite considerar tais métodos mais trabalhosos quando comparados ao sistema CRISPR .
A junção de todos estes fatores fez com que a recente descoberta de um sistema imune bacteriano contra fagos e plasmídeos invasores ganhasse destaque no que diz respeito a técnicas de edição gênica e obtenção de organismos geneticamente modificados (OGMs) .
Atualmente encontra-se disponível um gRNA (RNA guia) que consiste na construção de uma molécula de RNA desenvolvida biotecnologicamente, com a capacidade de mimetizar o que ocorre naturalmente em bactérias, e desta forma, promover o direcionamento da nuclease Cas9 para uma sequência alvo específica para que esta promova a clivagem e a sequência de interesse tornando esta disponível para atuação da maquinaria de reparo da célula e assim, promover edição da porção de interesse presente no genoma alvo
Tais fundamentos nos permitem considerar o sistema CRISPR (CRISPR/Cas) uma técnica rápida, com relativa facilidade de manipulação e baixo custo quando comparada a técnicas anteriores 
No entanto, este sistema não é restrito a bactérias, o gigantesco Mimivírus se defende de invasores utilizando um semelhante sistema CRISPR implementado por bactérias e outros microorganismos
O sistema de defesa do Mimivírus pode levar a novas ferramentas de edição de genoma.


Originalmente encontradas no genoma de Escherichia coli em 1987 e descritas por Yoshizumi Ishino e colaboradores , as sequências curtas intercaladas regularmente só começaram realmente a ser investigadas no início dos anos 2000, sendo então encontradas em diversos outros organismos procarióticos, tanto do domínio Bacteria, quanto Archaea , e em 2002 a sigla CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) foi criada para denominar tais sequências .
Somente em 2005 foram obtidas as informações necessárias para indicar a função destes loci
Foi descrito que as sequências espaçadoras têm origem extracromossômica, sendo derivadas de sequências de plasmídeos ou de vírus
Além disso, foi também descrito que vírus tornam incapazes de infectar arqueias que possuem sequências espaçadoras correspondentes ao seu genoma, inseridas após uma infecção prévia .
No ano seguinte foi postulada a hipótese de que o CRISPR é um sistema de defesa adaptativo de bactérias e arqueias que faz uso de RNA antisenso como assinaturas de memória de invasões anteriores 
Esta proposta recebeu o suporte necessário quando foi evidenciada experimentalmente em Streptococcus thermophilus , levando a sua primeira aplicação no campo da biotecnologia, a fim de imunizar bactérias utilizadas na indústria de laticínios contra infecção por bacteriófagos .
Evidências obtidas em seguida mostraram que as sequências espaçadoras de DNA invasor intercaladas com os arranjos de repetições intrínsecas são transcritos em grandes moléculas de RNAs, e estas são cortadas em pedaços menores pela nuclease Cas9 auxiliada pelo tracrRNA, tornando-se crRNAs, que por sua vez formam complexos com as proteínas tipo Cas
O complexo age de forma a impedir a proliferação viral em bactérias, devido a capacidade de clivagem do DNA invasor pela Cas9, o complexo tracrRNA-crRNA tem um papel fundamental no direcionamento desta nuclease, tendo o DNA invasor como alvo 
Nos últimos anos, estudos mostraram que aparentemente a Cas9 é a principal nuclease envolvida no processo de clivagem de DNA invasor  dentre os vários tipos de Cas descritos,  algumas ainda precisam ter suas funções elucidadas.
Em 2011, foi demonstrado que é possível transferir a memória imune de uma espécie de bactéria para outra, gerando novas possibilidades de aplicações do mecanismo , o que levou aos estudos que mostraram que Cas9 purificadas são capazes de clivar DNA alvo in vitro quando guiadas por crRNAs 
O que resultou na utilização do sistema CRISPR como uma ferramenta de engenharia genética, tornando possível editar com sucesso o genoma de células de mamíferos, assim como de inúmeros outros sistemas modelos .
O locus CRISPR é composto por cerca de 20 a 50 pares de base, normalmente dispostos simetricamente, o que favorece a formação de uma estrutura em “grampo” ou “hairpin”
Neste locus são encontradas repetições separadas por protoespaçadores de tamanho similar, os quais podem ser adicionados rapidamente como parte da resposta imune bacteriana contra infecção ocasionada por fagos além de variar em tamanho e sequência .
Têm sido descrito que dentre os 198 genomas completos disponíveis no banco de dados NCBI, é possível encontrar cerca de 50 genomas onde o gene Cas1 está presente 
Além disso, sabe-se que a grande maioria dos “protoespaçadores” possui homologia com genes conhecidos, frequentemente provenientes de elementos extra-cromossômicos tais como fagos e plasmídeos 
Em Yersinia pestis estas repetições ocorrem preferencialmente pela absorção do DNA de bacteriófagos .
O primeiro estudo demonstrando como ocorre o direcionamento do complexo CRISPR/Cas9, de modo a permitir a ligação com a sequência complementar do gene alvo, e eliminação de um agente infeccioso em bactérias ocorreu em Streptococcus thermophilus em 2010 .
Atualmente, sabe-se que este distinto sistema imune pode ser dividido em três tipos principais, baseado na conservação dos genes e organização dos loci (CRISPR Tipo I, Tipo II e Tipo III) .
Uma particularidade do sistema CRISPR Tipo I se dá pela presença de ao menos um gene que codifique a nuclease Cas3, a qual participa ativamente na clivagem de uma molécula de DNA invasor .
O sistema CRISPR Tipo II é considerado o mais robusto para aquisição de plasmídeos e fagos
Nele são encontrados apenas quatro genes, dentre os quais sempre haverá ao menos um gene que codifique a nuclease Cas9, a qual pode participar tanto no processamento de RNA quanto na eliminação do DNA alvo 
Uma peculiaridade pode ser observada no sistema CRISPR Tipo III, que foi subsequentemente dividido em dois subtipos
Tais sistemas foram denominados como CRISPR TipoIII-A, o qual é capaz de atuar sobre DNA plasmidial in vivo, e CRISPR Tipo III-B responsável pela clivagem apenas de RNA fita simples in vitro
Estas observações sugerem que seja possível a existência de diferentes mecanismos de atuação envolvendo subtipos distintos de CRISPR .
Vale ressaltar a possibilidade de encontrar mais de um sistema CRISPR em um mesmo organismo, o que claramente demonstra a compatibilidade entre estes sistemas, bem como a possibilidade de compartilhamento dos componentes funcionais presentes nos diferentes sistemas 
Recentemente, verificou-se a capacidade de fagos em promover mutações em seu genoma de modo a conseguir evadir a resposta imune bacteriana
Esta capacidade tem sido considerada o modelo básico de evolução CRISPR, uma vez que tais mutações impossibilitam a complementaridade do sistema tracRNA/crRNA com o fago e, portanto, impedem a associação com a nuclease Cas9 e a subsequente clivagem do DNA invasor 
No entanto, os cientistas que disseram que o CRISPR é perigoso não podem sequer replicar seus próprios resultados.
De maneira geral, todos os mecanismos CRISPR expressam as mesmas vias de aquisição, expressão e interferência, conforme descrito a seguir :
a)     Aquisição de novos protoespaçadores: Geralmente realizada através do reconhecimento e clivagem de ácidos nucleicos exógenos mediados por Cas1 e Cas2 para sua integração ao cromossomo bacteriano em regiões conhecidas como locus CRISPR .
b)    Transcrição completa do locus CRISPR como um pre-crRNA: Processamento e amadurecimento do transcrito em pequenas moléculas de RNA (crRNA) capazes de reconhecer uma única sequencia alvo .
c)     Associação com proteínas Cas: Formação de complexo ribonuclear capaz de guiar nucleases de maneira especifica em direção ao DNA alvo presente em bacteriófagos e plasmídeos .
A integração de uma nova informação nos loci CRISPR inicia-se pela imunidade bacteriana mediada por esse sistema, onde uma pequena porção do DNA invasor, é integrada ao locus CRISPR do hospedeiro como um protoespaçador através da atuação de nucleases específicas .
Devido à alta afinidade encontrada entre a nuclease  Cas1 e ácidos nucleicos, tem sido sugerido que esta enzima possua papel significativo no que se refere a integração e aquisição de novos protoespaçadores
Além disso, a ausência de necessidade de uma sequencia especifica de nucleotídeos para o acontecimento deste tipo de ligação com a Cas1 reforça esta ideia, uma vez que esta poderia atuar sobre qualquer seqüência protoespaçadora presente no genoma viral .
Outro ponto importante a ser destacado no que diz respeito a aquisição de novos protoespaçadores é a importância da manutenção da estrutura do locus
Desta forma, seguida da adição de um novo protoespaçador, uma nova sequencia de repetição CRISPR é sintetizada favorecendo a organização “repeat-spacer-repeat”, essencial para o reconhecimento do locus CRISPR .
A organização do locus CRISPR tem sido sugerida como ferramenta de grande valia para a distinção entre um DNA invasor e o do genoma hospedeiro pela maquinaria de reparo celular
Além disso, há relatos de que a seqüência líder possua elementos capazes de promover o recrutamento deste mecanismo de reparo celular de modo a favorecer a integração do protoespaçador no DNA bacteriano .
Os sinais moleculares envolvidos neste processo de distinção ainda não estão completamente elucidados
Contudo, o mapeamento das sequências espaçadoras presentes nos genomas virais revelam uma seqüência de poucos nucleotídeos de comprimento próxima ao protoespaçador, denominada Motivo Adjacente ao Protoespaçador (Protospacer Adjacent Motif - PAM) .
Cada domínio PAM pode ter a sequência variável de acordo com o tipo de sistema CRISPR, sugerindo que proteínas Cas presentes nos distintos tipos de CRISPR estejam envolvidas no reconhecimento do domínio PAM .
O sistema CRISPR Tipo I pode ser dividido em 6 subtipos categorizados de A a F
Neste sistema, a transcrição do locus CRISPR é seguida pela dobragem sobre si mesma das sequências repetidas para formar estruturas em grampo (hairpins) entre os protoespaçadores, seguida da clivagem do transcrito mediada pela nuclease Cas6e/f originando crRNA 
Um complexo efetor conhecido como Cascade (Complexo associado a CRISPR para defesa antiviral) reúne cinco proteínas Cas  ligadas ao crRNA
Este complexo é direcionado à sequência apropriada presente no DNA invasor por meio de reconhecimento do domínio PAM na fita complementar do crRNA 
Uma vez que a identificação da sequência tenha sido estabelecida, uma mudança conformacional em Cascade recruta Cas3, a qual cliva o ácido nucleico invasor de modo sequência-específica .
O sistema do tipo II é comumente encontrado em Archaea e pode ser dividido em 3 subtipos distribuídos de A a C .
Neste caso, a transcrição do locus CRISPR é seguida pelo pareamento de bases do tracrRNA à sequência repetida localizada entre os protoespaçadores 
A clivagem do dsRNA pela RNaseIII em fragmentos de sequências formadas por um único proto-espaçador  juntamente com a porção 3’ da sequência repetida é denominado crRNA 
O tracrRNA se liga à sequência repetida complementar do crRNA e essa molécula híbrida associa-se à nuclease Cas9 para promover o seu direcionamento à sequência apropriada do DNA invasor usando o domínio PAM como guia  
A proteína Cas 9 é constituída por cerca de 800-1400 aminoácidos, com uma estrutura de 2 lóbulos  que possui dois sítios com atividade nuclease: O RuvC-like (RNase-H fold) responsável pela clivagem da sequencia não alvo e o domínio HNH (McrA-like) responsável pela clivagem da sequencia alvo 
Posterior ao reconhecimento, a clivagem do DNA invasor mediada pelo complexo Cas9-crRNA-tracrRNA é realizada importante destacar que ao contrario do sistema Tipo I, o reconhecimento do domínio PAM no sistema Tipo II ocorre na mesma fita do crRNA .
Sistemas CRISPR CAS Tipo III compreendem dois subtipos, III-A e III-B, ambos possuem o gene CAS 10 específico dos sistemas Tipo III, entretanto podem ser diferenciados pelos genes acessórios: csm no subtipo III-A e cmr no subtipo IIIB 
Além disso, eles não requerem domínios PAM para o reconhecimento da sequencia alvo por parte do crRNA ou para sua clivagem 
A transcrição do locus CRISPR é seguida pela ligação do transcrito ao redor de Cas6 e pela clivagem 8 nucleotídeos a montante da junção entre a sequência repetida e o protoespaçador
Isto resulta em uma série de protoespaçadores com sequências repetidas nos dois extremos, 5’ e 3’, similar aso Tipo II 
Entretanto, enquanto no Tipo II a clivagem é realizada no extremo 5’ deixando a porção 3’ da sequência repetida ligada ao protoespaçador, no Tipo III a clivagem ocorre no extremo 3’ e deixa cada protoespaçador com a porção 5’ da sequência repetida .
No Tipo III-A a maturação do crRNA intermediário é essencial para a interferência dirigida
De fato, enquanto os crRNAs intermediários podem ser ligados dentro do complexo proteico csm-Cas10 (conforme mencionado abaixo), o subsequente complexo ribonucleoprotéico é incapaz de degradar o DNA invasor .
No Tipo III-B o crRNA é tomado pelo complexo de proteínas conhecido como cmr (módulo Cas RAMP, proteínas misteriosas associadas a repetições) 
Diferentes proteínas membros dos módulos RAMP podem ser expressas entre diversas espécies
Os complexos cmr usualmente consistem de várias proteínas Cas (tipicamente Cas1-6) 
De fato, existem diversas famílias identificadas dos complexos cmr  que quando complexadas com Cas10 realizam clivagem de RNA através da interação de complementaridade de pares de bases do crRNA com o RNA invasor .
Os sistemas do Tipo III-A são geralmente caraterizados pela presença de genes csm (tipicamente csm 2-5 – membros da superfamília RAMP) os quais, da mesma forma que os genes cmr, codificam para proteínas envolvidas na formação do complexo com Cas10 e subsequente degradação do DNA invasor guiado por crRNA, num modo sequência específico .
Inúmeras são as vantagens obtidas pelo emprego do sistema CRISPR uma vez que trata-se de uma metodologia rápida, fácil com baixo custo e principalmente com alta taxa de sucesso devido a sua alta sensibilidade para o reconhecimento de sequências específicas presentes no DNA alvo de células em cultura ou até mesmo em modelos animais .
Com o emprego desta metodologia é possível avançar mais rapidamente no ramo da engenharia genética e no estudo funcional gênico, o que pode ser justificado pela capacidade desta ferramenta em excluir ou modificar genes específicos para obtenção de organismos geneticamente modificados passíveis de serem empregados como modelo de estudo para compreensão de condições fisiopatológicas nas mais diversas espécies .
Aplicações de CRISPR abrangem quase todos os setores envolvendo sistemas biológicos
Danisco (DuPont) foi um dos pioneiros na utilização comercial da tecnologia CRISPR para aumentar a imunidade viral em bactérias utilizadas para a produção de iogurtes e queijos .
Aplicações na agricultura têm obstáculos regulatórios mais baixos do que aplicação biomédica e alguns desses mercados preveem o retorno dos investimentos muito rapidamente
Dow AgroSciences desenvolveu propriedade intelectual com Sangamo Biosciences para o desenvolvimento de culturas geneticamente modificadas utilizando Cas9, e Cellectis Ciências Vegetais está levando a tecnologia para as plantações 
CRISPR tem o potencial para se tornar uma força importante na ecologia e conservação, especialmente quando combinada com outras ferramentas de biologia molecular
Pode, por exemplo, na criação de genes que atrasem disseminação de espécies invasoras como ervas daninhas
Pode vir a ser o próximo grande salto na conservação ou melhoraria do meio ambiente 
Aplicações baseadas em Cas9 na indústria agrícola e em setores da saúde humana encontram-se em crescimento acelerado
Estes mercados incluem: terapia gênica, terapia celular e imunoterapia, o desenvolvimento rápido e eficiente de pesquisa de animais transgênicos, descoberta de medicamentos, bem como a validação de alvo e de triagem 
A modulação da transcrição de diferentes alvos genéticos tem usado cada vez mais a tecnologia CRISPR/Cas9 em substituição aos modelos atuais, como RNA interferência, ZFN e TALENs
Estas técnicas apresentaram limitações por serem trabalhosas e demoradas, enquanto que nas primeiras tentativas de inativação de gene alvo com CRISPR/Cas9 foram obtidos bons resultados .
Conforme citado anteriormente, o uso em produtos laticínios é um dos principais exemplos de aplicação
Tais produtos comumente sofrem infecções por fagos o que prejudica ciclos de fermentação normais e diminui a qualidade do produto final
Para contornar esse problema as indústrias criaram cepas de bactérias resistentes a fagos .
A técnica se baseia no sistema CRISPR tipo II com uso da S
thermophilus, já envolvida no processo de acidificação do leite
Com a edição do gene alvo e ação das enzimas Cas, há o controle do espaçador e defesa contra fagos
Tal procedimento permite o isolamento de cepas resistentes a vários bacteriófagos, mas que ainda conservam as mesmas propriedades de cultura original  
Experimentos de perturbação dos genes para analisar sua função ou esclarecer a causa de variantes genéticos têm sido feitos com facilidade diante da simplicidade da Cas9 em direcionar um RNA guia
Assim, uma variedade de proteínas ou ssRNA podem ser ligados a Cas9 ou sgRNA (single guide RNA) para modificar a transcrição específica de genes, monitorar posição da cromatina, ou até mesmo manipular a organização tridimensional do genoma .
A caracterização dos fenótipos da doença é um dos principais objetivos para a geração de animais geneticamente modificados
Transformações genéticas em animais, simulando as mutações encontradas em humanos, permitem determinar a função de genes, estruturas reguladoras e confirmação de resultados obtidos em cultura de células .
A edição genômica mediada por Cas9 permitiu geração acelerada de modelos geneticamente modificados e ampliando as pesquisas biológicas tradicionais de estudo de organismos-modelo, podendo ser aplicada para desenvolver novas modificações gênicas com introdução ou correções de mutações específicas in vivo .
Como exemplo disso, já foi possível observar modificações de genes alvo de forma eficaz através da micro-injeção em células embrionárias de peixe-zebra, injetando mRNA que codifica uma Cas9 personalizada
Ou ainda a injeção de Cas9/mRNA e sgRNAs com diferentes genes alvos de zigotos de camundongos, levando ao desenvolvimento de mutações em determinados alelos, reforçando que a utilização de CRISPR/Cas pode ser empregado para a modificação de múltiplos genes ao mesmo tempo .
A partir de 1981 foram desenvolvidos os primeiros camundongos transgênicos, e processo precisou ser melhorado até se alcançar uma metodologia mais adaptável e fácil de usar .  Os métodos tradicionais para criar modelos de animais geneticamente modificados costumavam levar de 8 a 13 meses de trabalho, tornando-se um processo laborioso e custoso, já usando CRISPR /Cas9, para criar animais transgênicos, foi possível observação de fenótipo albino após uma única micro-injeção em embriões de camundongo da linhagem C57BL/6J, ressaltando que este tipo de roedor tem como característica pelagem marrom escuro .
Dessa maneira, podemos perceber que CRISPR simplifica o desenvolvimento de animais para estudo em pesquisa que simulem doenças ou exponham as consequências quando um gene é nocauteado ou mutado de maneira especifica . 
A identificação de genes responsáveis por um dado fenótipo de interesse é facilitada pelo sistema CRISPR/Cas9, devido a sua habilidade de alterar diferentes alvos, individualmente ou mesmo simultaneamente 
Estudos realizados com a tecnologia de CRISPR estão confirmando sua capacidade de rastreio genômico através da manipulação dos domínios catalíticos de Cas, sendo possível a construção de sistemas de repressão (CRISPRi) e ativação (CRISPRa) .
A CRISPRi é usada para controle da transcrição com uso de Cas9 (dCas9) com mutações nos domínios catalíticos tornando-a deficiente em atividade nucleolítica ou através de sgRNA sendo utilizado como alvo na região do promotor,  gerando impedimento estérico na associação entre os motivos de DNA e seus fatores de transcrição, levando a contenção do início da transcrição
Sendo assim, CRISPRi é uma forma eficiente de redirecionamento do genoma para a manipulação da transcrição sem modificar  a sequência de alvo de DNA .
CRISPRa tem como objetivo aumentar a transcrição de certo gene com o uso da dCas9, citada anteriormente, fusionado a domínios de ativação da transcrição e esse complexo é direcionados para a região promotora de genes endógenos, possibilitando a modulação da expressão do gene .
CRISPRi e CRISPRa em estudos de escala genômica vem buscando genes endógenos que atuem como repressores ou ativadores transcricionais relacionados a supressão de tumores, regulação de diferenciação e a sensibilidade celular para cólera ou toxina da difteria, por exemplo, demonstrando suas aplicações como ferramentas fundamentais para complexos de mapeamento .
Conforme definição o complexo CRISPR/Cas age como um sistema imune adaptativo antiviral em bactérias, dessa forma, pode ser empregado para o tratamento de doenças infecciosas em indivíduos contaminados pela eliminação do genoma do agente infeccioso .
O uso desse sistema tem destaque especial na terapia de HIV através do bloqueio da proliferação do vírus
Demonstrou-se que perturbação da região LTR (repetições longas terminais) pode ser realizada em vírus HIV-1
O DNA do vírus contém duas regiões LTR e ambas as extremidades podem se integrar ao genoma, o que significa que o sistema CRISPR/Cas9 tem a capacidade de remover a sequência do HIV associado por clivagem em ambas as LTRs, retirando assim a sequência de HIV integrada ao DNA de indivíduos infectados
A técnica ainda se encontra em um estágio inicial, mas se mostra muito promissora na determinação de alvos através de um sistema de entrega segura e eficaz .
A tecnologia CRISPR-Cas9 também vem sendo amplamente estudada como ferramenta na cura de doenças genéticas
Usando camundongos como modelo, por exemplo, a falha genética causadora da catarata foi corrigida (reparo do fenótipo funcional da doença) pela injeção de CRISPR/Cas9 em zigotos
De acordo com análises de sequenciamento de DNA, foram observadas que as modificações necessárias ocorreram somente no alelo mutante dos animais portadores da doença e não afetaram os demais genes, confirmando a especificidade do sgRNA em atingir exclusivamente o alelo mutante .
Camundongos já foram usados como modelo na correção do gene mutante da distrofina, evitando o desenvolvimento de distrofia muscular e também no reparo do locus do receptor transmembranar da fibrose cística por recombinação homóloga de células-tronco intestinais cultivadas de pacientes humanos com esta doença, evidenciando a CRISPR como técnica promissora para a terapia genética em pacientes humanos 
Os pesquisadores têm utilizado para tratar uma forma grave de distrofia muscular em camundongos
Eles empregaram CRISPR/Cas para cortar a parte de um gene defeituoso com distrofia muscular de Duchenne, permitindo que os animais a fazer uma proteína muscular essencial
A abordagem é a primeira vez que CRISPR foi entregue com sucesso por todo o corpo para o tratamento de animais adultos com uma doença genética.
Como toda aplicação do ramo da Biotecnologia, o uso da nova técnica traz à tona discussões nos campos da ética e da segurança biológica, em grande parte pelo fato de que suas aplicações estão fortemente ligadas a interesses econômicos de diversos grupos e empresas.
Atualmente já se negociam bilhões de dólares e travam-se na justiça disputas acirradas sobre vários aspectos das patentes que podem ser geradas.
Citando o artigo publicado no jornal Zero Hora pela Professora Cristina Bonorino, titular de Imunologia da PUCRS e pesquisadora 1C do CNPq:
"As pesquisadoras que primeiramente desvendaram o mecanismo de funcionamento do sistema CRISPR, duas da Universidade da Califórnia em Berkeley, Jenifer Doudna e Jill Banfield, e a francesa Emmanuelle Charpentier, patentearam o sistema pensando no potencial para testes diagnósticos de vírus
Publicaram seus achados na Science em 2012, e seguiram-se uma enxurrada de premiações, milhões de dólares captados para as empresas de biotecnologia que fundaram e sua inclusão na lista das 100 pessoas mais influentes no mundo pela revista Time
Enquanto isso, a DuPont anuncia que alimentos editados com CRISPR estarão em nossas mesas em menos de cinco anos
Eles também patentearam usos do sistema para modificar sementes e probióticos.
Paralelamente, um pesquisador do Massachussets Institute of Technology (MIT), Feng Zhang, trabalhava em uma versão do CRISPR altamente focada
As pesquisadoras que descobriram o CRISPR descreviam o seu mecanismo de ação
Zhang queria ser o primeiro a usar o sistema para editar genomas humanos
Ele escreveu essa patente, com esse foco, e o MIT depositou-a logo após a de Berkeley
Contudo, o depósito do MIT entrou numa categoria acelerada – para a qual se paga uma taxa a mais no depósito (!) e ele ganhou a prioridade
Isso importa muito no meio da propriedade intelectual, e vale muito, muito dinheiro
Qualquer empresa que quiser trabalhar com algum organismo outro que não bactérias, precisa licenciar a patente de Zhang
Bilhões de dólares estão em jogo, e ambas as instituições entraram com recursos e digladiam-se na justiça pelos direitos
Todos os pesquisadores fundaram startups de biotecnologia que vêm recebendo capital de investidores, como a megafarma Novartis
Mas quem conseguir a patente de editar células humanas vai com certeza ser o centro das atenções." 
Apesar do otimismo despertado pelo desenvolvimento na utilização desta nova ferramenta da biotecnologia, os riscos envolvidos na manipulação genética indiscriminada de organismos não devem ser minimizados em prol de interesses de mercado, sendo essencial a continuidade das pesquisas, desenvolvimento de protocolos adequados de controle e estabelecimento de marcos regulatórios através de discussão dos aspectos técnicos e sócio ambientais, com a consideração dos riscos e ganhos advindos de sua utilização.
Como verificamos CRISPR apresenta diversos campos de aplicação, assim suas funções podem ser resumidas em:
Infecção  ou infeção  é a invasão de tecidos corporais de um organismo hospedeiro por parte de organismos capazes de provocar doenças; a multiplicação destes organismos; e a reação dos tecidos do hospedeiro a estes organismos e às toxinas por eles produzidas
Uma doença infecciosa corresponde a qualquer doença clinicamente evidente que seja o resultado de uma infeção, presença e multiplicação de agentes biológicos patogénicos no organismo hospedeiro.
As infecções são causadas por agentes infecciosos, como os vírus, viroides e priões, por micro-organismos como as bactérias, por nematódeos, por artrópodes como as carraças, ácaros, pulgas e piolhos, por fungos e por outros macroparasitas
O hospedeiro é capaz combater a infeção através do seu sistema imunitário
Os mamíferos reagem à infecção através do sistema imune inato, um processo que envolve muitas vezes a inflamação à qual sucede uma resposta do sistema imune adquirido.


Os agentes infecciosos, na maioria das vezes, são seres microscópicos tais como vírus, bactérias, fungos, parasitas (muitos macroscópicos), virions e príons
Os príons estão associados a várias doenças, como por exemplo, a encefalopatia espongiforme bovina, uma doença que acomete o gado conhecida como "doença da vaca louca", ou a sua variante humana, a doença de Creutzfeldt-Jakob
Desta definição conclui-se que em todas as infecções existe uma inflamação, mas nem todas as inflamações são infecções
A inflamação é definida como a presença de edema (inchaço), hiperemia (vermelhidão), hiperestesia (dor ao toque), aumento da temperatura no local e, às vezes, perda de função
Assim, uma simples queimadura de sol já produz uma inflamação, pois a pele fica vermelha, ardida, quente e inchada
Mas, em princípio, não existe infecção pois não há bactérias ou vírus causando esta inflamação
Já uma amigdalite aguda, vulgarmente chamada de dor de garganta, apresenta, na garganta, todos os aspectos da inflamação e mais a presença de bactérias ou vírus que produziram esta inflamação
A infecção pode levar a formação de pus, num processo conhecido por supuração.
Infecção comunitária é a infecção presente ou em incubação no ato de admissão do paciente, desde que não relacionada com internamento anterior no mesmo hospital
São, também, comunitárias: 1
As infecções associadas a complicações ou extensão da infecção já presente na admissão, a menos que haja troca de microrganismo ou sinais ou sintomas fortemente sugestivo da aquisição de nova infecção
2
Infecção em recém-nascido, cuja aquisição por via transplacentária é conhecida ou foi comprovada e que tornou-se evidente logo após o nascimento (exemplos: herpes simples, toxoplasmose, rubéola, citomegalovirose, sífilis e AIDS)
Adicionalmente, são, também, consideradas comunitárias todas as infecções de recém-nascidos associadas com ruptura da bolsa amniótica superior a 24 horas.
"Infecção hospitalar" ou "infecção nosocomial" é toda infecção (pneumonia, infecção urinária, infecção cirúrgica...) adquirida dentro de um ambiente relacionado à saúde (hospitais, unidades básicas, asilos...)
A maioria das infecções hospitalares são de origem endógena, isto é, são causadas por microrganismos do próprio paciente
Isto pode ocorrer por fatores inerentes ao próprio paciente (exemplos: diabetes, tabagismo, obesidade, imunossupressão etc.) ou pelo fato de, durante a hospitalização, o paciente ser submetido a procedimentos invasivos diagnósticos ou terapêuticos (cateteres vasculares, sondas vesicais, ventilação mecânica etc.)
As infecções hospitalares de origem exógena geralmente são transmitidas pelas mãos dos profissionais de saúde ou outras pessoas que entrem em contato com o paciente.
No Brasil, para reduzir os riscos de ocorrência de infecção hospitalar, um hospital deve constituir uma Comissão de Controle de Infecção Hospitalar (CCIH), que é responsável por uma série de medidas como o incentivo da correta higienização das mãos dos profissionais de saúde; o controle do uso de antimicrobianos, a fiscalização da limpeza e desinfecção de artigos e superfícies etc.
A infecção hospitalar é causa de grande preocupação das instituições de saúde do Brasil
Enquanto a média mundial de índice de infecção é 5%, o país apresenta o porcentual de 15,5% entre os pacientes internados, conforme dados do Ministério da Saúde
Um número que assusta não só os pacientes, como também as instituições de saúde, que, por conseqüência, têm suas despesas elevadas.
Para evitar e tratar a infecção hospitalar, além de permitir que o doente tenha um atendimento de qualidade e seguro, uma série de estudos coordenados pelo doutor Victor Rosenthal, especialista no assunto, revelou que programas de educação e implementação das melhores práticas no ambiente hospitalar associados à utilização de sistemas fechados de infusão podem reduzir, em alguns casos, em mais de 80% os riscos de infecção da corrente sanguínea.
As primeiras pesquisas começaram em 2000 na Argentina e, nos anos seguintes, hospitais de outros países (México, Brasil e Itália) foram concluídas e incluídos no projeto desenvolvido pela Baxter - empresa global e diversificada no segmento de saúde nas áreas de medicamentos, equipamentos médicos e biotecnologia.
O objetivo é avaliar a incidência de infecções da corrente sanguínea nos centros estudados e como medidas de prevenção podem reduzir o tempo de internação, a mortalidade e conseqüentemente os custos hospitalares.
Dados epidemiológicos do doutor Rosenthal, que lidera um consórcio internacional de controle de infecção hospitalar, já mostraram que o Brasil se destaca como um dos países com maior índice de infecções da corrente sanguínea associada ao uso de cateteres venosos entre os países que usam sistema aberto de infusão
Esses países, segundo o especialista, possuem índices bem superiores aos apresentados pelos padrões norte-americanos.
Para avaliar alternativas eficazes no combate à infecção hospitalar, o doutor Rosenthal seguiu alguns critérios nos centros estudados
Primeiramente, foram medidos os níveis basais de infecção da corrente sanguínea associadas ao uso de cateteres venosos centrais
Em seguida, foi introduzido um programa educacional com toda a equipe de profissionais médicos e de enfermagem a fim de colocar em prática as diretrizes de prevenção estabelecidas pelo Centro de Controle de Doenças (CDC) como, por exemplo, a higiene correta das mãos
E por fim, houve a substituição do sistema aberto de infusão utilizado nos hospitais, incluídos no estudo, por sistema fechado com bolsas flexíveis, ou seja, aquele que não necessita da entrada de ar para seu funcionamento e escoamento total da solução.
No Brasil, o Hospital Santa Marcelina, em São Paulo, foi o centro estudado e teve, como investigador principal, o infectologista Reinaldo Salomão
Foram avaliados 1 127 pacientes em três unidades de terapia intensiva
Após adotar as medidas descritas acima, foi registrada redução de 54% nos índices de infecção da corrente sanguínea adquirida durante a internação e as despesas hospitalares diminuíram significativamente, uma vez que na análise comparativa, um paciente infectado permaneceu internado (utilizando recursos do hospital e antibióticos) em média 23 dias a mais que um paciente não-infectado.
Na Argentina, a diminuição de pacientes infectados foi de 64%, o que proporcionou uma redução de 83% nos gastos do hospital para o tratamento de pacientes infectados e 91% na taxa de mortalidade
E no México, a redução de pacientes com infecção hospitalar atingiu 82%
Os dados consolidados do Brasil estão sendo apresentados pelo doutor Rosenthal nos mais importantes congressos mundiais de controle de infecção.
Os sistemas fechados já são obrigatórios em diversos países do mundo, como Estados Unidos,Austrália e Colômbia
No Brasil, a Agência Nacional de Vigilância Sanitária (Anvisa) determinou, conforme resolução RDC 45, que, a partir de 2008, todos os sistemas abertos de infusão deverão ser substituídos pelos sistemas fechados.
Alguns hospitais já utilizam o sistema fechado com bolsas flexíveis, como o Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulos, o Hospital Israelita Albert Einstein, o Hospital Sírio-Libanês, o Hospital Santa Catarina e São Luiz e vários outros serviços de saúde do Brasil.
Diferentemente dos recipientes rígidos e semirrígidos, os sistemas fechados de infusão para soluções parenterais que utilizam bolsas flexíveis, não necessitam de elementos externos adicionais, como entrada de ar e equipos com filtro
Essas bolsas são produzidas em policloreto de vinila em sua maioria ou por outros tipos de plásticos
Desta forma, o sistema isolado e vedado, evitando infecções por micro-organismos do ambiente externo.
A Baxter é uma das empresas que introduz a bolsa plástica e os sistemas flexíveis fechados
Presente há mais de 35 anos no mercado e utilizada em cerca de 140 países, as bolsas flexíveis Viaflex são consideradas um avanço significativo na administração com eficiência e segurança de soluções e medicamentos aos pacientes.
A importância da resistência bacteriana aos antibióticos deve-se ao fato das bactérias que constituem a microbiota hospitalar estarem "acostumadas" a muitos antibióticos, ou melhor: os antibióticos usados no hospital em grande quantidade e diariamente vão matando as bactérias mais sensíveis, deixando que as bactérias que tem resistência ao antibiótico usado sem concorrência e livres para se multiplicarem, ocupando o espaço daquelas que morreram
Quando as bactérias resistentes causarem uma infecção, os antibióticos normalmente usados não surtirão efeito e será necessário utilizar antibióticos cada vez mais tóxicos, selecionando também bactérias cada vez menos sensíveis a este, e criando um círculo vicioso
O grande problema atual é a necessidade do uso racional destes antibióticos, tentando romper este ciclo.
Existem 13 tipos:
Metástase (do grego metastatis – mudanças de lugar, transferência) é a formação de uma nova lesão tumoral a partir de outra, mas sem continuidade entre as duas
Isto implica que as células neoplásicas se desprendem do tumor primário, caminhando através do interstício - ganham assim uma via de disseminação - sendo levadas para um local distante onde formam uma nova colônia neoplásica.
Em cada um destes passos, as células malignas têm de superar os sistemas de controle do organismo que mantêm as células nos seus sítios primitivos
Metástases só se formam em tumores malignos; contudo, nem todos os cancros originam metástases, mesmo os que são localmente invasivos, como o carcinoma basocelular
Metástases são o selo definitivo de malignidade (por definição, neoplasias benignas não originam metástase), sendo um sinal de mau prognóstico
Em muitos pacientes, a primeira manifestação clínica de um cancro está relacionada com suas metástases.
Quando as células cancerosas se disseminam pela corrente sanguínea e formam colônias em outros locais, as colônias são chamadas metástases
Esta condição agrava muito a situação da doença e dificulta o processo de cura
Apenas 1 em cada 1.000 células que se desprendam do tumor primário poderá formar metástase, isso porque elas precisam de habilidades específicas para transpor as barreiras celulares e se disseminar
É comum acontecer das células se "encalharem" em algum gânglio e ali originar um novo tumor.

Linfócitos T ou células T são um grupo de glóbulos brancos(leucócitos) responsáveis pela defesa do organismo contra agentes desconhecidos (antígenos)
Seu papel principal é como imunidade específica e imunidade celular, induzindo a Apoptose(autodestruição) de células invadidas por vírus, bactérias intracelulares, danificadas ou cancerígenas
Se diferenciam de acordo com sua função em: citotóxicas (CD8), auxiliares (CD4), natural killer (NKT), memória(CD45), reguladoras (FOXP3) ou gama-delta (γδ)
Amadurecem no timo, por isso se chamam linfócitos T.


São originados a partir de linfoblastos na medula óssea, mesma célula que dá origem aos linfócitos B e linfócitos NK, e passam pela maturação no timo
Nesse órgão, os linfócitos T adquirem os receptores de membrana específicos CD4 ou CD8, além de um TCR, dos quais a maioria possuem cadeias αβ (95%) e alguns poucos cadeia γδ
Para serem ativados precisam por células apresentadoras de antígeno e por interleucinas para atuar.
O TCR (do inglês T cell receptor, ou seja receptor de células T), receptor específico dessas células, é formado a partir do processo de recombinação somática e é diferente em cada célula T
Dessa forma, a população dessas células é capaz de reconhecer uma variedade enorme de antígenos, capacitando os indivíduos para se defender das mais diversas ameaças
O TCR é intimamente ligado a a diversas proteínas, notavelmente o complexo CD3, importante para a ativação dessas células e as proteínas CD4 e CD8, responsáveis pelo reconhecimento da cadeia constante de MHC classe II e I, respectivamente, tendo papel na transdução desse sinal.
Após a maturação no timo, os linfócitos são enviados para a circulação
A expressão de L-selectina, uma selectina, e de receptores de quimiocinas como CCR7, nos linfócitos virgens (ou seja, ainda não ativados com antígeno), permite o reconhecimento de adressinas expressas pelas células dos vasos sanguíneos em linfonodos (células das HEV)
Essa ligação promove a migração da célula T para o parênquima do órgão, onde, na região paracortical, o contato com células apresentadoras de antígeno, permite que se inicie uma resposta imune a partir do reconhecimento de um antígeno.
Há vários grupos de linfócitos T, destacando-se entre eles os Linfócitos T Auxiliares CD4+ (Helper) e Citotóxicos CD8
Dentre esses grupos, ainda há diversos subgrupos responsáveis por processos como memória imunológica e regulação do sistema imune
O segundo subgrupo, conhecido como “Tregs” expressa ou fator de transcrição FoxP3 ou FoxA1 e são essenciais para a proteção do indivíduo contra doenças auto imunes como lupus e esclerose múltipla.
O linfócito T auxiliar, CD4, tem a função de coordenar a função de defesa imunológica contra vírus, bactérias e fungos, principalmente através da produção e liberação de citocinas e interleucinas
São capazes de estimular a resposta imune humoral através de ligação direta com linfócitos B, ativados através da expressão de MHC de classe II carregado com antígeno, que interagem com o TCR.
O linfócito T citotóxico, CD8, tem como função principal a eliminação de células infectadas por parasitas intracelulares, nominalmente os vírus
Dentro dessas células, a produção de proteínas não pertencentes ao indivíduo são em parte processadas pelo proteassoma, produzindo peptídeos exógenos, que, após envio ao Retículo Endoplasmático Rugoso com auxílio da proteína TAP, são expostos na parte de fora da célula
Ao reconhecer um antígeno como não próprio, o linfócito citotóxico libera grânulos contendo perforinas e granzimas que causam dano direto às células adjacentes, além de fatores como o ligante de Fas e TNFα que induzem apoptose na célula alvo, prevenindo o espalhamento da infecção.
Em 2016 pesquisadores da Holanda e da Noruega usaram células T do sistema imunológico de um doador saudável podem atacar o câncer de um paciente, o experimento deu resultados e as células T foram capazes de reconhecer as células anômalas.
Células T de memória são derivadas de outros linfócitos T que aprenderam a responder a um invasor específico, por exemplo uma espécie de bactéria, ou um tipo de fungo ou mesmo a um alérgeno e foram bem sucedidos em eliminar-los
Passam a viver por muitos anos, e podem ser re-ativados para uma resposta mais rápida a um invasor similar ao que combateu no passado
Por exemplo, um linfócito que foi ativado para combater sarampo (por contato direto ou por vacina) pode seguir combatendo novas invasões pelo vírus do sarampo garantindo imunidade vitalícia a esse indivíduo.
As células T reguladoras (Treg) são uma subpopulação de células T com desenvolvimento e função distintas, que expressam o fator de transcrição forkhead box P3 (FOXP3) e são indispensáveis para a manutenção da tolerância imunitária ao próprio e da homeostasia
Disfunções nestas células podem levar a problemas graves como doenças auto-imunes fatais, imunopatologias e alergias.
As células T reguladoras FOXP3 podem suprimir a ativação, proliferação e as funções efetoras (ex
produção de citocinas) de uma vasta gama de células imunitárias, tais como células CD4 e CD8, células natural killer (NK), células B e células apresentadoras de antigénios (APCs).
As células Treg FOXP3 podem também suprimir respostas imunes anti-tumorais e favorecer assim a progressão do tumor.
As células Treg podem ainda servir como uma ligação entre a imunidade e o metabolismo, ou seja, a função imune é influenciada pela forma metabólica através da modulação das Treg em três níveis de regulação: estado nutricional do hospedeiro; micróbios comensais e metabolismo celular das próprias células Treg. 
Linhagem linfóide: Linfócito B · Linfócito T (Linfócito T citotóxico, Célula T natural killer, Célula T reguladora, Linfócito T auxiliar) · Célula NK
células da glia: Glioblasto (Astrócito, Oligodendrócito) · Micróglia
Magnocellular neurosecretory cell  · Stellate cell · Boettcher cell
estômago (Célula principal, Célula parietal) · Célula de Goblet · Célula de Paneth
Célula G · D cells · ECL cells · I cells  · K cells  · S cells
Célula enteroendócrina · Célula enterocromafim · Célula APUD
osso: Osteoblasto · Osteócito · Osteoclasto · dente: Ameloblasto · Cementoblasto
cartilagem: Condroblasto · Condrócito · pele e anexos: Melanócito · Queratinócito
O sistema imunitário, sistema imunológico ou ainda sistema imune é um sistema de estruturas e processos biológicos que protege o organismo contra doenças
De modo a funcionar corretamente, o sistema imunitário deve detectar uma imensa variedade de agentes, desde os vírus aos parasitas, e distingui-los do tecido saudável do próprio corpo.
Os agentes patogénicos podem rapidamente evoluir e adaptar-se de modo a evitar a detecção e neutralização por parte do sistema imunitário, pelo que os vários mecanismos de defesa também evoluíram no sentido de os reconhecer e neutralizar
Até mesmo os simples organismos unicelulares possuem um sistema imunitário rudimentar, na forma de enzimas que os protegem de infecções por bacteriófagos
Outros mecanismos imunitários básicos acompanharam a evolução dos eucariotas e estão hoje presentes nos seus descendentes contemporâneos, como as plantas e os insectos
Entre estes mecanismos estão a fagocitose, os peptídeos antimicrobianos designados defensinas, e o sistema complemento
Os vertebrados mandibulares, entre os quais o ser humano, desenvolveram mecanismos de defesa ainda mais complexos, entre os quais a capacidade de ao longo do tempo se adaptarem para reconhecer de forma eficiente agentes patogénicos específicos
Através da imunidade adquirida, o organismo cria memória imunitária na sequência de uma resposta inicial a um agente específico, o que lhe permite responder de forma mais eficaz a novos ataques pelo mesmo agente
O processo de imunidade adquirida é a base da vacinação.
Os transtornos do sistema imunitário podem levar ao aparecimento de doenças autoimunes, inflamações e cancro
A imunodeficiência verifica-se quando a actividade do sistema imunitário é inferior ao normal, o que está na origem de infecções recorrentes e onde existe risco de vida
No ser humano, a imunodeficiência pode ser consequência de uma doença genética, de uma condição adquirida como o VIH/SIDA, ou do uso de imunossupressores
Por oposição, a autoimunidade é a consequência de um sistema imunitário hiperactivo que ataca tecido normal como se fosse um agente externo, como é o caso da artrite reumatóide ou a diabetes de tipo 1
A imunologia é a área científica que estuda todos os aspectos do sistema imunitário.


O sistema imunitário protege o organismo de infecções através de mecanismos de defesa estratificados com especificidade progressiva
Em termos simples, as barreiras físicas impedem a entrada dos agentes patogénicos
No caso de um patógeno penetrar estas barreiras, o sistema imunitário inato, presente em todas as plantas e animais, desencadeia uma resposta imediata, embora não específica
Caso o patógeno evite a resposta inata, os vertebrados possuem um segundo nível de defesa, o sistema imune adquirido, que é activado pela resposta inata e através do qual o sistema imunitário adapta a sua resposta durante uma infecção de acordo com a identificação do patógeno
Através da memória imunológica, o corpo memoriza esta resposta, o que permite ao sistema imunitário adquirido realizar ataques cada vez mais rápidos e robustos cada vez que esse mesmo patógeno é detectado.
Tanto a imunidade inata como adquirida dependem da capacidade do sistema imunitário em distinguir as moléculas exteriores das suas próprias moléculas
Em imunologia, as moléculas próprias são os componentes do organismo que o sistema imunitário consegue diferenciar de substâncias externas
Pelo contrário, as moléculas que não são próprias são aquelas que reconhece como estranhas
Uma classe destas moléculas são os antigénios, substâncias que se ligam a receptores imunológicos específicos e provocam uma resposta imunitária.
O sistema inato é composto por mecanismos de defesa não-específicos, que constituem uma resposta indiferenciada ao agente invasor
Constituem as estratégias de defesa mais antigas, sendo algumas destas formas encontradas nos seres multicelulares mais primitivos, nas plantas e fungos.
Existem várias barreiras mecânicas, químicas e biológicas que protegem os organismos de infecções
A cutícula cerosa de determinadas folhas, o exoesqueleto dos insetos, a casca e as membranas dos ovos ou a pele são exemplos de barreiras mecânicas que são a primeira linha de defesa contra as infecções
No entanto, uma vez que os organismos não podem ser completamente estanques em relação ao meio ambiente, existem outros sistemas destinados a proteger os orifícios do corpo como os pulmões, intestino ou o sistema genito-urinário
Nos pulmões, a tosse e os espirros expelem mecanicamente agentes patogénicos e irritantes do trato respiratório
A lavagem proporcionada pelo fluido lacrimal e pela urina expele igualmente os patógenos, enquanto que o muco segregado pelos tratos respiratório e digestivo retém os microorganismos.
A pele e o trato respiratório segregam peptídeos antimicrobianos como as β defensinas
Há determinadas enzimas com função antisséptica, como a lisozima e a fosfolipase A2, presentes na saliva e no leite materno
As secreções vaginais após a menarca proporcionam uma barreira química, ao tornarem-se ligeiramente ácidas, enquanto que o sémen contém defensinas e zinco para eliminar os patógenos
No estômago, o suco gástrico e as proteases actuam como poderosas defesas químicas contra os patógenos ingeridos.
No interior dos tratos genito-urinário e gastrointestinal, a flora comensal actua como barreira biológica ao competir com bactérias patogénicas por espaço e alimentação e, nalguns casos, alterando as próprias condições do meio, como o pH
Isto reduz a probabilidade dos patógenos virem a atingir um número suficiente para causar uma infecção
No entanto, uma vez que a maior parte dos antibióticos atacam todas as bactérias e não afectam os fungos, os antibióticos orais podem fazer com que haja um crescimento excessivo dos fungos e, por sua vez, dar origem a infecções fúngicas como a candidíase.
Os microorganismos ou toxinas que conseguem penetrar no organismo deparam-se com as células e os mecanismos do sistema imune inato
A resposta inata é normalmente espoletada quando os receptores de reconhecimento de padrões, que identificam componentes comuns a um vasto número de microorganismos, ou quando as células danificadas, lesadas ou em stresse enviam sinais de alarme, muitos dos quais são identificados pelos mesmos receptores que identificam os patógenos
As defesas do sistema imune inato não são específicas, o que significa que respondem a patógenos de forma genérica
O sistema inato não confere imunidade permanente contra um patógeno
A imunidade inata é o sistema de defesa predominante na maior parte dos organismos.
O sistema complemento é uma cascata bioquímica que ataca a superfície das células invasoras
É composto por mais de vinte proteínas diferentes e complementa o processo de eliminação dos patógenos pelos anticorpos
O sistema complemento é o maior componente humoral da resposta imune inata
Muitas espécies têm sistemas complemento, até mesmo fora dos mamíferos, como as plantas, peixes e alguns invertebrados.
No ser humano, esta resposta é activada pela ligação complementar a anticorpos que se juntaram a estes micróbios ou pela ligação de proteínas complementares aos hidratos de carbono na superfície dos micróbios
Este sinal de reconhecimento desencadeia uma resposta de eliminação rápida
A velocidade da resposta dá-se em função da amplificação do sinal que ocorre após a activação proteolítica das moléculas complementares, que são também proteases
Quando as proteínas complemento se ligam ao micróbio, a sua actividade protease é activada, e por sua vez activa outras proteases complemento
Isto dá origem a uma cascata catalítica que amplifica o sinal inicial através de retroalimentação positiva controlada
A cascata provoca a produção de peptídeos que atraem células do sistema imune, aumentam a permeabilidade vascular e revestem a superfície dos microorganismos com opsonina, marcando-os para serem destruídos
Este revestimento pode também ser capaz de matar directamente as células através da destruição da sua membrana plasmática.
Os leucócitos compreendem a segunda linha de defesa do sistema imune inato e actuam como organismos independentes e unicelulares
Os leucócitos inatos podem ser divididos em:
Estas células identificam e eliminam os patógenos, quer atacando os patógenos maiores através de contactos, quer fagocitando e matando os micro-organismos ou as células infectadas
As células inatas são também mediadores importantes na activação do sistema imune adquirido, sendo realizadas pelas Células Apresentadoras de Antígenos.
A fagocitose é uma característica importante da imunidade inata celular, sendo desempenhada por células denominadas fagócitos que envolvem, ou se alimentam de, patógenos ou partículas
Os fagócitos normalmente patrulham o corpo à procura de patógenos, mas podem ser chamados pelas citocinas a atuar em locais específicos
Quando um patógeno é envolto por um fagócito, fica imobilizado dentro de uma vesícula intracelular denominada fagossoma, que depois se funde com outra vesícula denominada lisossoma para formar um fagolisossoma
O patógeno é morto através da atividade de enzimas digestivas ou na sequência de uma explosão oxidativa que liberta radicais livres para o fagolissoma
A fagocitose é talvez a mais antiga forma de defesa imunitária, tendo sido identificados fagócitos tanto em vertebrados como invertebrados
A fagocitose desenvolveu-se com o intuito de obter nutrientes, mas este papel nos fagócitos foi alargado de modo a incluir a absorção de patógenos enquanto mecanismo de defesa.
Os neutrófilos e macrófagos são fagócitos que percorrem o corpo à procura de patógenos invasores
Os neutrófilos encontram-se normalmente na corrente sanguínea e são o tipo mais abundante de fagócito, correspondente a entre 50% e 60% do total de leucócitos em circulação
Durante a fase aguda das inflamações, sobretudo das que são o resultado de infecções bacterianas, os neutrófilos deslocam-se para o local da inflamação durante um processo denominado quimiotaxia, e são habitualmente as primeiras células a chegar ao local da infecção
Os macrófagos são células versáteis no interior dos tecidos que produzem um vasto leque de químicos, incluindo enzimas, proteínas complemento e factores reguladores como a interleucina 1
Os macrófagos também actuam como necrófagos, eliminando do corpo células mortas e outros detritos, e como células apresentadora de antígeno que activam o sistema imune adquirido.
As células dendríticas são fagócitos que se encontram em tecidos em contacto com o ambiente externo, sobretudo na pele, nariz, pulmões, estômago e intestinos
São assim denominadas pela sua semelhança com os dendritos neuronais, embora as células dendríticas não tenham qualquer relação com o sistema nervoso
Estas células actuam como ligação entre os tecidos corporais e os sistemas inato e adquirido, pois atuam como Célula apresentadora de antígeno principalmente aos linfócitos T, um dos tipos essenciais de células do sistema imune adquirido.
Os mastócitos estão alojados no tecido conjuntivo e nas mucosas, e são responsáveis pela regulação da resposta inflamatória
São frequentemente associados às alergias e a anafilaxia
Os basófilos e eosinófilos estão relacionados com os neutrófilos
Segregam mediadores químicos envolvidos na defesa contra parasitas e têm um papel activo nas reacções alérgicas como a asma
As células NK são leucócitos que atacam e destroem células tumorais ou células infectadas por vírus.
Para que células do sistema imune inato reconheçam os micro-organismo invasores de um hospedeiro é necessário que na superfície externa de suas membranas, ou no meio intracelular, contenham receptores capazes de diferenciar os padrões moleculares das células próprias (moléculas que fazem parte do organismo hospedeiro) dos padrões moleculares do micro-organismo e reagir contra estes no caso da identificação dessas moléculas estranhas os hospedeiro
Há três tipos de receptores característicos da resposta imune inata por não apresentarem especificidade, são eles:
moléculas PAMPs-que são padrões moleculares associados aos patógenos, ou capazes de reconhecer moléculas DAMPs- que são padrões moleculares associados à danos.
A inflamação é uma das primeiras respostas do sistema imunitário à infecção
A inflamação manifesta-se através de vermelhidão, inchaço, sensação de calor e dor localizada, causadas pelo aumento da circulação sanguínea nos tecidos afectados
É o resultado da acção de eicosanoides e citocinas, libertadas pelas células danificadas ou infectadas
Entre os eicosanoides estão as prostaglandinas, que provocam febre e vasodilatação dos vasos sanguíneos associados à infecção, e os leucotrienos, que atraem determinados leucócitos (glóbulos brancos)
Entre as citocinas mais comuns estão as interleucinas, responsáveis pela comunicação entre os leucócitos; as quemoquinas, que promovem a quimiotaxia; e os interferões, que têm propriedades antivirais, como por exemplo paralisar a síntese proteica na célula anfitriã
Podem também ser libertados factores de crescimento e factores citotóxicos
As citocinas, entre outros químicos, recrutam células imunes para o local da infecção e promovem a cura de qualquer tecido danificado posteriormente à remoção dos patógenos.
Todo o sistema específico se concentra na capacidade das células imunitárias distinguirem proteínas produzidas pelas células do próprio corpo (antigénio "self" - ou seja do próprio organismo), e proteínas produzidas por invasores ou pelas células humanas sob o controlo de vírus (antigénio "non-self" - ou seja, que não é reconhecido como sendo do próprio organismo)
Esta distinção é feita através de receptores, os TCR (T-cell receptors) ou BCR (B cell receptors que são anticorpos presos à membrana)
Estes receptores, TCR ou BCR, para serem eficazes têm de ser produzidos com milhões de conformações
De outro modo não se ligariam a muitos tipos de proteínas de invasores, e não os reconheceriam
Esta diversidade de receptores não caberia no genoma da célula, e milhões de genes, cada um para cada receptor possível, não seria prático
O que acontece é que há algumas famílias de genes, tendo cada uma vários membros ligeiramente diferentes
Através de um processo especial e único nas células humanas, estes genes nos linfócitos recombinam-se, num único gene, de forma totalmente aleatória.
Assim, por exemplo, cada anticorpo ou BCR dos linfócitos B tem seis porções, e é criado de dois genes únicos desse linfócito, gerados pela recombinação (união) de um gene aleatório de cada família
Se houver seis famílias, com 50, 30, 9, 6, 40, 5 membros, o número possível total de anticorpos diferentes é de 50x30x6x9x40x5 = 16 milhões.
Além disso há outros processos muito complexos que aumentam a diversidade dos BCR ou TCR ainda mais, por mutação acelerada dos genes em causa
A variabilidade dos anticorpos é na práctica ilimitada, e o sistema imunitário cria anticorpos contra qualquer molécula, e mesmo contra moléculas artificiais nunca existentes na natureza.
Muitos dos TCR e BCR assim gerados vão reagir com péptidos próprios
Uma das funções do Timo e Medula óssea é manter os jovens linfócitos sequestrados até que seja possível determinar quais reagem com moléculas do próprio organismo
Essa função é feita por células especializadas desses órgãos que apresentam aos linfócitos jovens moléculas produzidas por elas (e portanto próprias)
Todos os linfócitos que reagem a elas são destruídos, e apenas aqueles indiferentes a própria (mais possivelmente reactivos a não-próprios) são largados na corrente sanguínea.
Os linfócitos que não reagem a própria são milhões, cada um com milhões de configurações possíveis de receptores e haverá inclusive vários, cada um com receptor para zonas diferentes de cada proteína microbiana possível
A esmagadora maioria dos linfócitos nunca encontra uma proteína para a qual o seu receptor seja espécifico
Aqueles poucos que a encontram, são estimulados e multiplicam-se
São geradas células efectoras com o receptor específico (produtoras de anticorpos ou citotóxicas, ou ainda coordenadoras) e células memória
As células de memória são quiescentes, têm vida longa e são capazes de reconhecer esse antigénio mesmo muito depois, multiplicando-se em maior número e respondendo mais rapidamente a infecções futuras.
O sistema imunitário especifico é controlado e efectuado largamente pelos linfócitos
Há vários tipos de linfócitos.
Os linfócitos B possuem um BCR, que é em tudo semelhante ao anticorpo, mas está preso na membrana
Os linfócitos B concentram-se nos gânglios linfáticos, onde filtram a linfa, à espera de uma molécula que não seja do próprio organismo, e assim, reaja especificamente com o seu receptor aleatório
Para cada molécula possível há vários linfócitos específicos
Logo assim que haja uma ligação específica antigénio-receptor e se o linfócito for estimulado simultaneamente por citocinas produzidas pelos linfócitos T CD4 (reguladores,ou Helper), eles multiplicam-se e diferenciam-se em plasmócitos e em células-memória (Linfócito B de memória)
Estas, se a infecção se repetir muitos anos depois, podem iniciar a reposta mais rapidamente
Os plasmócitos produzem então grandes quantidades BCR solúvel e não preso à membrana, ou seja, anticorpos específicos para aquela molécula.
Os anticorpos são assim proteínas receptoras livres no sangue, que são especificas e se ligam à molecula não-self e possivelmente invasora
Os anticorpos podem assim ligar-se a antígenos na superfície de bactérias, vírus ou parasitas
Eles os eliminam de várias formas
Podem neutralizar o invasor directamente (cobrindo a superfície de um vírus e impedindo-o de se ligar aos seus receptores nas células por exemplo); atrair fagócitos (que reconhecem e são estimulados por eles); activar o sistema complemento de forma a lisa-los; ou ainda estimular as células citotóxicas (assassinas) para destruírem as células identificadas pelo anticorpo.
Os linfócitos que produzem anticorpos algo eficazes (do tipo IgM) ainda sofrem novo processo de selecção nos foliculos linfóides
Aí, multiplicam-se rodeadas de linfócitos T CD4 que secretam citocinas, as quais induzem por mecanismos complexos altas taxas de mutação nos seus genes dos anticorpos
Depois destroem os linfócitos B que produzem anticorpos com menor afinidade para o antigénio e estimulam a divisão dos que têm maior afinidade (graças a mutações fortuitas), podendo esta no final ser muitas vezes superior nos sobreviventes.
Há vários tipos de anticorpos: IgM é sempre o primeiro tipo a ser produzido; IgG é o principal grupo de anticorpos sanguíneos e há vários subtipos, aparece mais tarde que IgMs, e têm maior afinidade após hipermutação; os IgAs são anticorpos secretados para as mucosas, como intestino, genitais e brônquios; as IgE têm funções de luta contra parasitoses; os IgD estimula o sistema imunitário.
Os Linfócitos T CD8 são os linfócitos citotóxicos ou também chamado de Killers
Naturais Killers (NK) não são a mesma coisa que Linfócito citotóxico CD8 pois não possuem TCR que é um dímero, mas também são linfócitos
Eles têm cada um, um tipo de receptor especifico nas suas membranas, gerado aleatoriamente numa fase de recombinação genética do seu desenvolvimento, denominado de TCR (T-cell receptor, semelhante aos anticorpos da célula B, mas de localização membranar)
Esses receptores ligam-se a outros que todas as células humanas possuem (complexo MHC I), e que apresentam péptidos (fragmentos de proteínas) que elas estejam a produzir à superficie da célula
No caso que os complexos MHC I (Complexo de Histocompatibilidade) - péptido seja reconhecidos por uma célula T CD8, esta última desencadeará a morte da célula que apresenta o péptido através de enzimas citoliticas chamadas de porinas que induzem a apoptose da célula alvo por desequilíbrio osmótico.
Todos os linfócitos T CD8 que têm receptores que reagem a substâncias do próprio corpo morrem durante o seu "estágio" no timo
Quando o linfócito T CD8 reconhece um antígeno não-self com o seu receptor numa molécula MHC classe I de uma célula do organismo, ele liberta substâncias (perforina) que criam um poro na membrana, lisando (rompendo osmoticamente) a célula, ou então libertam mediadores (granzima) que induzem a célula a iniciar a apoptose (morte celular programada)
Há milhões de linfócitos CD8 em circulação no organismo, cada um com receptores aleatórios para todos os péptidos possíveis não-self
Normalmente o linfócito T CD8 naïve só mata as células se for estimulado por citocinas dos linfócitos T CD4 (reguladores: ver mais à frente)
Se um linfócito T CD8 com determinado receptor for estimulado dessa forma, ele divide-se em mais células citotóxicas e um pequeno grupo de células quiescentes e de longa esperança de vida, as células memória Memory T cells (ver na wiki em Inglês), manter-se-ão em circulação (entre o sangue e os gânglios linfáticos)
Estas células de memória podem ser activadas mais tarde de uma forma mais eficiente, mais rápida e independentemente da presença de citocinas produzidas pelos linfócitos CD4, após reconhecimento do péptido para o qual são específicas apresentado por uma molécula de MHC classe I.
Apesar de os fagócitos serem um mecanismo inato, já que respondem a qualquer corpo estranho, eles também são efectores de primeira linha das decisões dos linfócitos.
Os fagócitos, especialmente os macrófagos, respondem a citocinas geradas pelos linfócitos (IL-1)
Os monócitos são os precursores dos macrófagos e eles transformam-se em macrófagos se estimulados por citocinas dos T4
Além disso são atraídos por outras citocinas e factores libertados de células em locais de infecção activa.
Se estimulados apropriadamente pelas citocinas libertadas de forma localizada e controlada pelos linfócitos T4, os macrófagos libertam suficientes quantidades de enzimas e radicais livres para destruir totalmente uma região localizada, matando ambos invasores e células humanas.
Além disso, sob controle dos linfócitos, os macrófagos são responsáveis por algumas reacções imunológicas especificas como o granuloma e o abcesso
O granuloma ocorre na invasão por micobactérias e fungos, sendo o exemplo mais célebre a tuberculose
É uma reacção ordenada por citocinas dos T4, quando há infecção intracelular dos próprios fagocitos
De forma a impedir a disseminação pelo sangue do invasor dentro dessas células móveis, os linfócitos T4 secretam citocinas que chamam mais macrófagos, e os tornam mais resistentes à infecção ("alerta de bactéria endocelular")
Além disso as citocinas provocam a adaptação pelos macrófagos de morfologia epitelial em volta do núcleo da invasão, com numerosas camadas de células imobilizadas ligadas por conexões impermeáveis, de forma a sequestrar o invasor
A micobactéria da tuberculose não se pode disseminar e permanece localizada
Hoje mil milhões de pessoas saudáveis têm micobactérias controladas dessa forma nos seus pulmões (visível nas radiografias)
Só naqueles poucos que têm um episódio de grande debilidade imunitária é que o organismo escapa e se inicia a tuberculose propriamente dita
O abcesso é semelhante mas em redor de um cisto/quisto de pus
É importante para sequestrar bactérias piogénicas cuja toxicidade mata os fagócitos (formando o pus) e não permite a limpeza eficaz.
Os Linfócitos T4, ou helper, são os controladores de toda a resposta imunitária
São eles que "decidem" que reacções desenvolver a uma invasão, activando ou inibindo todas as outras células imunitárias através de citocinas (espécie de hormonas ou mediadores moleculares)
Daí que na doença que ataca os próprios T4, a SIDA/AIDS, todo o sistema imunitário colapse.
Os linfócitos T4 conseguem decidir se há invasão ou não porque cada um deles contêm um receptor gerado aleatoriamente o TCR (T-cell receptor, semelhante aos anticorpos da célula B, mas membranar)
Todos os fagócitos e ainda algumas outras células como as células dendriticas ou de Langerhans, depois de digerir as proteínas do invasor, apresentam péptidos (pedaços) delas numa proteína membranar, o MHC II (major histocompatibility complex)
Os TCR dos T4 ligam-se a essas MHC2 com péptido e se a ligação for eficaz, libertam citocinas
Nenhum linfócito T4 tem receptores para proteínas do próprio corpo porque esses foram destruídos na sua fase de desenvolvimento no Timo
Se os niveis dessas citocinas forem suficientemente altos, e se outros factores menos bem conhecidos existirem no sangue, o T4 "decide" que há uma invasão e de que tipo é, dando origem a uma resposta imunitária especifica
Ele então produz outras citocinas estimulando todas as outras células para o tipo de resposta apropriado
Tal como todos os outros linfócitos, os T4 estimulados multiplicam-se e alguns servem de células-memória para mais rápida resposta ao mesmo invasor no futuro.
Há basicamente dois tipos de células T4 helper, correspondendo a dois tipos de resposta
Não se sabe exactamente o que desencadeia um tipo ou o outro
A resposta TH1 caracteriza-se por produção de citocinas como IL-2, IFN-gama e TNF-beta
Há activação dos macrófagos e da fagocitose, e dos mecanismos citotóxicos (linfócitos T), levando a extensa destruição das zonas infectadas
É eficaz na eliminação dos patogénios intracelulares (vírus e bactérias intracelulares)
Na resposta TH2 há secreção de IL-4 e IL-5
Caracteriza-se pelo estimulo da produção de anticorpos pelos linfócitos B
É eficaz contra organismos que circulem no sangue, como bactérias extracelulares e parasitas.
Que resposta, TH1 ou TH2, é produzida, tem importância para a progressão da infecção
Por exemplo na Lepra, uma infecção pela bactéria intracelular Mycobacterium leprae, a resposta TH1 é extremamente eficaz e os danos são mínimos (lepra tuberculoide); mas se for activada uma resposta TH2, ineficaz contra organismos intracelulares, surge a lepra comum, com danos profundos e desprendimento de pele (lepra lepromatosa).
Há ainda um terceiro tipo de linfócito T regulador, os linfócitos supressores, que limitam e suprimem a reacção imunitária, um mecanismo muito importante considerando a destruição extrema que o sistema imunitário pode produzir.
Complementando o que foi visto acima,os mastócitos são células do tecido conjuntivo, originadas a partir de células mesenquimatosas (células de grande potência de diferenciação que dão origem às células do tecido conjuntivo)
Possuem citoplasma rico em grânulos basófilos (coram-se por corantes básicos)
Sua principal função é armazenar potentes mediadores químicos da inflamação, como a histamina, heparina, ECF-A (fator quimiotáxico – de atração- dos eosinófilos) e fatores quimiotáxicos (de atração) dos neutrófilos
Elas participam de reações alérgicas (de hipersensibilidade), atraindo os leucócitos até o local e proporcionando uma vasodilatação.
A vasodilatação aumenta a temperatura no local inflamado, dificultando a proliferação de microrganismos e estimulando a migração de células de defesa
Algumas das substâncias liberadas no local da inflamação alcançam o centro termorregulador localizado no hipotálamo, originando a febre (elevação da temperatura corporal)
Apesar do mal-estar e desconforto, a febre é um importante fator no combate às infecções, pois além de ser desfavorável para a sobrevivência dos microorganismos invasores, também estimula muitos dos mecanismos de defesa de nosso corpo.
As citocinas são hormonios do sistema imunitário que permitem às células comunicar entre si e com outras de outros órgãos
São um sistema incrivelmente complexo e inteligente ainda pouco conhecido
Algumas citocinas mais importantes:
O sistema imune é uma estrutura notável que incorpora especificidade, indutibilidade e adaptação
No entanto, ocorrem falhas na defesa, que são classificadas em três grupos genéricos: imunodeficiências, autoimunidade e hipersensibilidades.
As imunodeficiências ocorrem quando um ou mais dos componentes do sistema imunitário estão inactivos
A capacidade do sistema imunitário de resposta aos patógenos é menor nas camadas mais jovens e mais velhas da população
A resposta imunitária entra em declínio por volta dos 50 anos de idade devido à imunossenescência
Em países desenvolvidos, a obesidade, o alcoolismo e o uso de drogas são as causas mais comuns da insuficiência imunitária
No entanto, a má nutrição é a causa mais comum de imunodeficiência em países em desenvolvimento
Uma dieta insuficiente em proteínas está associada com debilidades na imunidade mediada por células, actividade complementar, funcionamento dos fagócitos, concentrações de anticorpos IgA e na produção de citocina
Para além disso, a perda do timo em idade precoce através de mutação genética ou remoção cirúrgica está na origem de uma imunodeficiência severa e elevada susceptibilidade a infecções.
As imunodeficiências também podem ser herdadas ou adquiridas
Um exemplo de imunodeficiência congénita, ou herdada, é a doença granulomatosa crónica, na qual os fagócitos têm dificuldade em destruir os patógenos
A SIDA e alguns tipos de cancro estão na origem de imunodeficiência adquirida.
No outro extremo das disfunções imunes estão as respostas imunes em excesso, sobretudo os transtornos autoimunes
Neste tipo de transtornos, o sistema imunitário não consegue distinguir as células externas das suas próprias células e ataca partes do seu próprio corpo
Em circunstâncias normais, muitos dos linfócitos T e anticorpos reagem com peptídeos próprios
Existem células especializadas, localizadas no timo e na medula óssea, cuja função é apresentar aos novos linfócitos produzidos os antigénios produzidos pelo corpo e eliminar as células que são capazes de reconhecer os antígenos próprios, prevenindo assim a autoimunidade.
A hipersensibilidade é uma resposta imunitária que danifica os tecidos do próprio corpo
Divide-se em quatro classes (tipos I a IV) com base nos mecanismos envolvidos e no intervalo de tempo da reacção hipersensível
A hipersensibilidade do tipo I é uma reacção anafilática, normalmente associada à alergia
Os sintomas variam entre algum desconforto e a morte
O tipo I é mediado pela imunoglobulina E, que espoleta a degranulação dos mastócitos e dos basófilos quando ligados por um antigénio
A hipersensibilidade do tipo II ocorre quando os anticorpos se ligam a antigénios nas próprias células do indivíduo, marcando-as para destruição
Este tipo também é denominado hipersensibilidade citotóxica dependente de anticorpos, e é mediada pelos anticorpos IgG e IgM
Os complexos imunes (agregados de antigénios, proteínas complemento e anticorpos IgG e IgM) depositados em vários tecidos desencadeiam reacções hipersensíveis do tipo III
A hipersensibilidade do tipo IV (também conhecida por hipersensibilidade mediada por células) normalmente leva entre dois a três dias para se desenvolver
As reacções do tipo IV fazem parte de muitas doenças autoimunes e infecciosas, embora possam também estar associadas com a dermatite de contacto
Estas reacções são mediadas pelos linfócitos, monócitos e macrófagos.
É provável que o sistema imune adaptativo e multicomponente tenha surgido com os primeiros vertebrados, uma vez que os invertebrados não produzem linfócitos ou qualquer resposta imunitária humoral
No entanto, muitas espécies utilizam mecanismos que aparentam ser precursores destes aspectos da imunidade em vertebrados
Os sistemas imunitários podem ser observados até mesmo nas formas de vida mais simples
As bactérias usam um mecanismo de defesa único, denominado sistema de restrição modificação como defesa em relação a patógenos virais, ou fagos
Os procariontes também possuem imunidade adquirida através de um sistema que usa sequências CRISPR para conservar fragmentos do genoma de fagos com que tiveram contacto no passado, o que lhes permite bloquear a replicação dos vírus através da interferência de RNA.
Os receptores de reconhecimento padrão são proteínas usadas por praticamente qualquer organismo para identificar moléculas associadas com os patógenos
As defensinas, peptídeos antimicrobianos, são um componente conservado durante a evolução presente em todos os animais e plantas, e representam a principal forma de imunidade sistémica dos invertebrados
O sistema complemento e os fagócitos são também usados por maior parte das formas de vida invertebrada
A ribonuclease e o processo de interferência RNA estão presentes em todos os eukaryota, e pensa-se que tenham um papel na resposta imunitária contra vírus.
Ao contrário dos animais, as plantas não têm células fagócitas, mas grande parte das respostas imunitárias nas plantas envolvem sinalização química sistémica enviada através do seu organismo
Cada célula nas plantas responde de forma individual a moléculas associadas a patógenos conhecidas como padrão molecular associado a patógenos
Quando parte da planta é infectada, a planta produz uma resposta hipersensível localizada, durante a qual as células no local da infecção sofrem uma apoptose extremamente rápida de modo a evitar a propagação a outras partes da planta
A Rresistência sistémica adquirida é um tipo de resposta defensiva usada por plantas que torna toda a planta resistente a determinado agente infeccioso
Os mecanismos de silenciamento de RNA são particularmente importantes para esta resposta sistémica, uma vez que são capazes de impedir a replicação de vírus.
Outro papel importante do sistema imunitário é a identificação e a eliminação de tumores
As células modificadas dos tumores expressam antigénios que não estão presentes em células normais
O sistema imunitário interpreta este antigénios como exteriores e a sua presença leva a que as células imunitárias ataquem as células do tumor
Os antigénios expressos por tumores podem ter várias origens
Alguns são derivados de vírus cercinogénicos, como o vírus do papiloma humano que provoca o cancro do colo do útero, enquanto que outros têm origem nas próprias proteínas do organismo, tendo pouca intensidade em células normais mas atingindo valores elevados nas células dos tumores
Um exemplo é a tirosinase que, quando expressa em níveis elevados, transforma determinadas células da pele (melanócitos) em tumores denominados melanomas
Uma terceira fonte para os antígenos tumorais são as proteínas normalmente importantes para a regulação do crescimento celular, que de forma frequente sofrem mutação para molécula indutoras do cancro denominadas oncogenes.
A principal resposta do sistema imunitário aos tumores é a destruição das células anormais com recurso a linfócitos T citotóxicos, por vezes com a assistência de linfócitos T auxiliares
Os antígenos tumorais são apresentados em moléculas MHC Classe I de forma semelhante aos antígenos virais
Isto permite aos linfócitos T citotóxicos reconhecer como anormal a célula do tumor
As células NK também eliminam células tumorais da mesma forma, sobretudo se as células do tumor tiverem menos moléculas MHC Classe I na sua superfície do que o normal; fenómeno comum entre tumores
Sometimes antibodies are generated against tumor cells allowing for their destruction by the complement system.
Alguns tumores conseguem evadir o sistema imunitário e evoluem até se tornarem cancros
As células dos tumores têm muitas vezes poucas moléculas MHC Classe I na superfície, evitando assim a sua detecção pelos linfócitos T citotóxicos.Algumas das células dos tumores também libertam substâncias que inibem a resposta imunitária; por exemplo, através da segregação da citocina TGF-β, que impede a acção dos macrófagos e os linfócitos
Para além disso, pode-se desenvolver tolerância imunológica em relação aos antígenos dos tumores, o que faz com que o sistema imunitário deixe de atacar as células tumorais.Paradoxalmente, os macrófagos podem promover o crescimento dos tumores.
As hormonas podem actuar como imunomoduladores, alterando a sensibilidade do sistema imunitário
Por exemplo, as hormonas sexuais femininas são imunoestimulantes, tanto da resposta do sistema adquirido como do inato
Algumas doenças autoimunes, como o lupus eritematoso, têm maior prevalência no sexo feminino e o seu aparecimento muitas vezes coincide com a puberdade
Pelo contrário, as hormonas sexuais masculinas como a testosterona aparentam ser imunossupressoras
Há outras hormonas que também aparentam regular o sistema imunitário, particularmente a prolactina, a hormona do crescimento e a vitamina D.
Ao encontrar um patógeno externo, um linfócito T estende um receptor da vitamina D
Isto é essencialmente um dispositivo de sinalização que permite ao linfócito ligar-se à forma activa da vitamina D, a hormona esteroide calcitriol
Os linfócitos T apresentam uma relação simbiótica com a vitamina D
O linfócito não só estende o receptor, como também expressa o gene CYP27B1, responsável pela conversão da versão pré-hormona da vitamina D (calcidiol) na versão hormona esteroide (calcitriol)
Só depois de se ligarem ao calcitriol é que os linfócitos podem desempenhar a sua função
Entre as células do sistema imunitário que se sabe expressarem o gene CYP27B1, activando assim o calcidiol, estão as células dendríticas, os queratinócitos e os macrófagos.
Leventa-se a hipótese de que o declínio progressivo dos níveis hormonais com a idade seja parcialmente responsável pela diminuição da resposta imune em idosos
Da mesma forma, algumas hormonas são também reguladas pelo sistema imunitário, sobretudo a actividade da hormona tiroideia
O declínio da função imune provocado pela idade está também relacionado com a diminuição do nível de vitamina D em idosos
À medida que as pessoas envelhecem, verificam-se duas situações que afectam negativamente a quantidade de vitamina D; primeiro, como permanecem mais tempo dentro de casa estão menos expostas ao sol e produzem menos colecalciferol através de radiação UVB: segundo, a própria pele torna-se menos apta a produzir vitamina D.
O sistema imunitário é afectado pela qualidade do sono e descanso, e e privação de sono prejudica a função imune
Os circuitos complexos de realimentação que envolvem citocinas também aparentam ter algum papel na regulação do sono REM
Desta forma, a resposta imunitária à infecção pode ter como consequência alterações no ciclo do sono, entre as quais um aumento da fase sono de ondas lentas em relação às fases REM.
A sobrenutrição está associada a doenças como a diabetes e obesidade, as quais se sabe afectarem a função imune
A malnutrição moderada, assim como determinadas deficiências em minerais e noutrientes, podem também comprometer a resposta imune
O subdesenvolvimento do feto pode também ter como consequência deficiências imunitárias ao longo da vida
Por outro lado, os alimentos ricos em determinados ácidos gordos podem promover um sistema imunitário saudável.
A resposta imune pode ser manipulada para suprimir respostas indesejadas provocadas pela autoimunidade, alergias ou rejeição de transplantes, e para estimular respostas protectores conta patógenos que contornam o sistema imunitário
São usados fármacos imunossupressores para controlar transtornos ou inflamações autoimunes, quando se verifique danos excessivos nos tecidos, e para prevenir a rejeição de órgãos após o transplante.
Os fármacos anti-inflamatórios são regularmente usados para controlar os efeitos da inflamação
Os glicocorticoides são os mais potentes, embora esta classe de fármacos possa ter vários efeitos secundários indesejáveis, como a obesidade abdominal, hiperglicemia ou osteoporose, pelo que o seu uso deve obedecer a critérios rígidos
Muitas vezes são administradas doses reduzidas de anti-inflamatórios em conjunto com fármacos citotóxicos ou imunosupressores como o metotrexato ou a azatioprina
Os fármacos citotóxicos inibem a resposta imunitária ao matar as células durante o processo de divisão, como os linfócitos T activados
No entanto, a morte é indiscriminada e também são afectadas células em constante divisão, o que provoca efeitos adversos tóxicos
Os fármacos imunossupressores como a ciclosporina impedem os linfócitos T de responder correctamente aos sinais através da inibição dos caminhos de transdução de sinal.
Os fármacos maiores (<500 Da) podem provocar uma reposta imunitária neutralizadora, sobretudo se são administrados repetidamente ou em doses elevadas
Isto limita a eficácia das drogas baseados nos peptídeos maiores e nas proteínas  Nalguns casos, não é o próprio fármaco que é imunogénico, mas pode ser administrado em conjunto com um composto imunogénico, como acontece com o paclitaxel
Têm sido desenvolvidos modelos computacionais que tentam prever a imunogenicidade dos peptídeos e das proteínas, sendo úteis sobretudo no desenho de anticorpos terapêuticos, avaliando a probabilidade de virulência das mutações em partículas de revestimento virais, e na validação de novos tratamentos à base de peptídeos
As técnicas anteriores baseavam-se principalmente na observação de que os aminoácidos hidrófilos estão sobrerrepresentados nas regiões do epítopo em relação aos aminoácidos hidrófugos
No entanto, os métodos atuais baseiam-se em técnicas de aprendizagem de máquina que recorrem a bases de dados de epítopos conhecidos, normalmente em vírus de proteínas amplamente estudados, tendo sido implementada uma base de dados de acesso público para a catalogação dos epítopos a partir de patógenos que se saiba serem reconhecidos pelos linfócitos B
A área emergente do estudo da imunogenicidade com base na bioinformática é designado por "imunoinformática".
O êxito de determinado patógeno depende da sua capacidade em iludir a resposta imune do hospedeiro, tendo para isso desenvolvido vários métodos ao longo da evolução
As bactérias muito frequentemente superam as barreiras físicas ao segregar enzimas que destroem essas barreiras usando, por exemplo, um sistema secretor do tipo II
Por outro lado, usando um sistema do tipo III são capazes de inserir um tubo oco na célula hospedeira, abrindo assim uma via de passagem direta para as proteínas do patógeno para o hospedeiro
Estas proteínas são depois usadas para desativar as suas defesas.
Uma das estratégias evasivas usadas por vários patógenos para contornar o sistema imunitário é através da sua ocultação entre as células do hospedeiro (também designado por patogénese intracelular)
Através deste recurso, o patógeno passa a maior parte do seu ciclo de vida no interior das células, onde está protegido do contacto direto com as células imunitárias, anticorpos e sistema complemento
Entre estes patógenos intracelulares estão os vírus, a Salmonella e os parasitas que provocam a malária
Outro tipo de bactérias, como a Mycobacterium tuberculosis, vivem no interior de uma cápsula protetora que impede a sua lise por parte do sistema complemento
Muitos patógenos segregam compostos que diminuem ou desviam a resposta do sistema imune
Algumas bactérias formam biofilmes para se protegerem do sistema imunitário, biofilmes esses que estão presentes em muitas infecções bem sucedidas, como a Pseudomonas aeruginosa crónica e a Burkholderia cenocepacia, características da fibrose cística
Há outras bactérias que geram proteínas de superfície que se ligam aos anticorpos, tornando-os ineficazes, como a Streptococcus (proteína G), Staphylococcus aureus (proteína A), ou a Peptostreptococcus magnus (proteína L).
Os mecanismos usados pelos patógenos para evadir o sistema imune adquirido são ainda mais complexos
A abordagem mais simples é alterar rapidamente os epítopos não essenciais (aminoácidos ou açúcares) na sua superfície, enquanto mantêm os epítopos essenciais resguardados
Isto designa-se por variação antigénica
Um exemplo é o VIH, cujas mutações rápidas levam a que as proteínas no seu envelope viral, essenciais para entrar na célula hospedeira, estejam em constante mudança
Estas alterações frequentes nos antígenos podem explicar a razão das falhas nas vacinas destinadas a este vírus
O parasita Trypanosoma brucei recorre a uma técnica semelhante, alternando constantemente entre dois tipos de proteínas de superfície, permitindo-lhe manter-se um passo à frente da resposta imune
Outra estratégia comum é disfarçar os antígenos com moléculas do hospedeiro
No VIH, o envelope que reveste o vírus é formado a partir da membrana exterior da célula hospedeira, tornando muito difícil a sua detecção como estruturas externas pelo sistema imune.
O Vírus da Imunodeficiência Humana (VIH ou HIV, do inglês Human Immunodeficiency Virus) é um lentivírus que está na origem da Síndrome da Imunodeficiência Adquirida, uma condição em seres humanos na qual a deterioração progressiva do sistema imunitário propicia o desenvolvimento de infeções oportunistas e cancros potencialmente mortais
A infeção com o VIH tem origem na transferência de sangue, sémen, lubrificação vaginal, fluido pré-ejaculatório ou leite materno
O VIH está presente nestes fluidos corporais, tanto na forma de partículas livres como em células imunitárias infectadas
As principais vias de transmissão são as relações sexuais desprotegidas, a partilha de seringas contaminadas, e a transmissão entre mãe e filho durante a gravidez ou amamentação
Em países desenvolvidos, a monitorização do sangue em transfusões praticamente eliminou o risco de transmissão por esta via.
A infeção por VIH em seres humanos é atualmente uma pandemia
Cerca de 0,6% da população mundial está infetada com o VIH
Entre 1981 e 2006, a SIDA foi responsável pela morte de mais de 25 milhões de pessoas
Um terço destas mortes ocorreu na África subsariana, atrasando o crescimento económico e aumentando a pobreza
Até 2013, estimou-se que 78 milhões de pessoas foram contaminadas, 39 milhões das quais morreram.
O VIH infecta células vitais no sistema imunitário, como os linfócitos T auxiliares CD4, macrófagos e células dendríticas
A infeção por VIH provoca a diminuição do número linfócitos T CD4 através de diversos mecanismos, entre os quais a apoptose de células espectadoras, a morte viral direta de células infectadas, e morte de linfócitos T CD4 através de linfócitos T citotóxicos CD8 que reconhecem as células infetadas
Quando o número de linfócitos T CD4 desce abaixo do limiar aceitável, o corpo perde a imunidade mediada por células e torna-se progressivamente mais suscetível a infeções oportunistas.
A maior parte das pessoas infetadas com VIH, quando estão sem tratamento, desenvolve SIDA
A elevada mortalidade desta doença deve-se ao colapso progressivo do sistema imunitário, ao qual está associado o aparecimento de infeções oportunistas ou tumores malignos
Sem tratamento, cerca de nove em cada dez pessoas infetadas com VIH desenvolve SIDA após de 10-15 anos, embora algumas pessoas desenvolvam muito mais cedo
O tratamento com antirretrovirais aumenta a esperança de vida de portadores do VIH, mesmo que a infeção tenha já evoluído para um diagnóstico de SIDA
Estima-se que a esperança de vida com tratamento seja de cinco anos
Mas com a entrada de novos antiretrovirais a expectativa passou para algo em torno de 20-50 anos (provavelmente, esta expectativa pode ser ainda maior, posto que atualmente há novos medicamentos e terapias mais toleráveis ao organismo dos portadores)
Na ausência de tratamento, a morte ocorre geralmente no prazo de um ano.


O VIH é um membro do género Lentivirus, e parte da família Retroviridae
Os lentivírus têm diversas propriedades morfológicas e biológicas em comum
Muitas espécies são infectadas por lentivírus, que são caracteristicamente responsáveis por doenças de longa duração com período de incubação longo
Os lentivírus são transmitidos como vírus ARN encapsulados, de sentido positivo e de cadeia única
Ao entrar na célula-alvo, o genoma ARN viral é convertido em ADN de cadeia dupla pela transcriptase reversa, que é transportada juntamente com o genoma viral na partícula do vírus
O ADN viral resultante é então importado para o núcleo celular e integrado no ADN celular pela integrase e cofactores
Uma vez integrado, o vírus pode tornar-se latente, permitindo-lhe a si e à célula hospedeira não serem detectados pelo sistema imunitário
Em elternativa, o vírus pode ser transcrito, produzindo novos genomas ARN e proteínas virais que são libertadas das células como novas partículas virais que iniciam novamente o ciclo de reprodução.
Foram identificados dois tipos de VIH: o VIH-1 e o VIH-2
O VIH-1 é o vírus que foi inicialmente descoberto e denominado LAV e HTLV-III
É o mais virulento, mais infeccioso, e o que provoca a maioria das infeções por VIH a nível mundial
A menor infecciosidade do VIH-2 em comparação com o VIH-1 indica que, a cada exposição, o risco de contágio é menor
Devido à sua reduzida capacidade de contágio, o VIH-2 está maioritariamente restrito à África Ocidental.
A estrutura do VIH é diferente da de outros retrovírus
É aproximadamente esférica e com um diâmetro de cerca de 120 nm, cerca de 60 vezes menor que um glóbulo vermelho, ainda que grande para um vírus
É composto por duas cópias de ARN positivo de cadeia única de senso positivo com aproximadamente 9749 nucleotídeos q que codifica os nove genes do vírus, envolto por um capsídeo cónico composto de 2000 cópias da proteína viral p24
O ARN de cadeia único está intimamente ligado às proteínas da nucleocapside, p7, e às enzimas necessárias ao desenvolvimento do virião como a Transcriptase reversa, a aspartate protease, ribonuclease e integrase
O capsídeo é envolto por uma matriz composta pela proteína viral p17, assegurando a integridade da partícula do virião.
Este conjunto é por sua vez envolto pelo envelope viral, que é composto por duas camadas de moléculas gordas denominadas fosfolípidos, obtidas a partir da membrana de uma célula humana quando uma partícula viral recém-formada brota da célula
No envelope viral estão incorporadas proteínas da célula anfitriã e cerca de 70 cópias de uma proteína complexa do VIH que é proeminente na superfície da partícula viral
Esta proteína, conhecida por Env, consiste num conjunto de três moléculas denominadas glicoproteína (gp) 120, e uma haste que consiste em três moléculas gp41 que ligam a estrutura ao envelope viral
Este complexo glicoproteico permite ao vírus ligar-se e fundir-se com as células-alvo de modo a dar início ao ciclo de infeção
Estas duas proteínas de superfície, sobretudo a gp120, têm vindo a ser identificadas como o alvo de futuros tratamentos ou vacinas contra o VIH.
O genoma de ARN consiste em pelo menos sete marcos estruturais (LTR, TAR, RRE, PE, SLIP, CRS e INS) e nove genes ('gag, pol, and env, tat, rev, nef, vif, vpr, vpu, e por vezes um décimo tev, que consiste numa fusão de tat, env e rev), codificando 19 proteínas
Três destes genes, gag, pol e env, contêm a informação necessária para produzir as proteínas estruturais de novas partículas virais
por exemplo, o env codifica uma proteína denominada gp160 que é quebrada por uma protease celular de modo a formar gp120 e gp41
Os restantes seis genes, 'tat, rev, nef, vif, vpr, e vpu (ou vpx no caso do VIH-2), são genes reguladores para proteínas que controlam a capacidade do VIH em infectar céulas, produzir novas cópias de si mesmo (replicar-se) ou provoca a doença.
As duas proteínas Tat (p16 e p14) são trans-ativadores transcricionais do LTR, atuando ao ligar o elemento ARN do TAR
O TAR pode também ser processado em micro-ARNs que regulam os genes da apoptose ERCC1 e IER3
A proteína Rev (p19) está envolvida no encerramento dos ARN do núcleo e do citoplasma, ao ligar-se ao elemento de ARN RRE
A proteína Vif (p23) previne a acção da APOBEC3G (uma proteína celular que devide os híbridos de ADN:ARN e/ou interfere com a proteína Pol)
A proteína Vpr (p14) pára a divisão celular e G2/M
A proteína Nef (p27) infra-regula o CD4 (o maior recetor viral), assim como as moléculas MHC classe I e II
A proteína Vpu (p16) influencia a libertação de novas partículas virais a partir de células infectadas
As extremidades de cada cadeia de ARN do HIV contêm uma sequência de ARN denominada long terminal repeat (LTR)
As regiões no LTR atuam como interruptores que controlam a produção de novos vírus e podem ser ativadas pelas proteínas quer do VIH quer da célula anfitriã
O elemento Psi está envolvido no envelope do genoma viral e é reconhecido pelas proteínas Gag e Rev
O elemento SLIP está envolvido no deslocamento do quadro de leitura Gag-Pol, necessário para a produção de Pol funcional.
O termo tropismo viral refere-se ao tipo de células que determinado vírus infeta
O VIH pode infetar diversas células imunitárias, como os linfócitos T CD4, macrófagos e microgliócitos
A entrada do VIH-1 nos macrófagos e nos linfócitos CD4 é mediada através da interação das glicoproteínas do envelope do virião (gp120) com a molécula CD4 nas células-alvo, e ainda através de co-recetores de quimiocina.
As cadeias do VIH-1 que afectam os macrófagos (M-trópicas) usam os co-recetores de quimiocina CCR5 para entrar, sendo assim capazes de se replicarem em macrófagos e linfócitos T CD4
Este co-recetor CCR5 é usado por praticamente todos os tipos primários de VIH-1, independentemente do seu subtipo genético
Assim, os macrófagos desempenham um papel essencial em vários aspetos fundamentais da infeção por VIH, aparentando ser as primeiras células a ser infetadas e talvez a fonte de produção de VIH a partir do momento em que o doente perde as células CD4
Em amígdalas e adenoides de doentes infetados com VIH, os macrófagos fundem-se em células de grandes dimensões e vários núcleos que produzem grandes quantidades de partículas virais
As cadeias T-trópicas replicam-se tanto em linfócitos T CD4 como em macrófagos e usam para entrar o co-recetor de quimioquina CXCR4
Pensa-se que as cadeias VIH-1 de tropismo duplo sejam cadeias de VIH-1 em transição, e portanto capazes de usar como co-recetores de entrada tanto o CCR5 como o CXCR4
A quimioquina-alfa SDF-1, um ligante do CXCR4, suprime a replicação dos tipos T-trópicos
Consegue-o através da infra-regulação da expressão do CXCR4 na superfície destas células
O VIH que usa apenas o co-recetor CCR5 é denominado R5; o que usa apenas o CXCR4 é denominado X4; e o que usa ambos é denominado X4R5
No entanto, o uso do co-recetor por si só não explica o tropismo viral, já que nem todos os vírus R5 são capazes de usar o CCR5 em macrófagos de modo a dar origem a uma infeção bem sucedida e o VIH pode também infetar um subtipo de células dendríticas mieloides, que provavelmente constituem uma reserva que mantém a infeção quando a contagem de células CD4 desce para níveis extremamente baixos
Algumas pessoas são resistentes a determinadas estirpes de VIH.Por exemplo, pessoas com a mutação CCR5-Δ32 são resistentes a infeções com o vírus R5, uma vez que a mutação impede o VIH de se ligar ao seu co-recetor, reduzindo a sua capacidade de infetar células-alvo.
A relação sexual é o principal meio de transmissão do VIH
Tanto o VIH X4 como o R5 estão presentes no sémen que é transmitido entre o homem e o seu parceiro sexual
Os viriões podem assim infetar vários alvos celulares e disseminar-se por todo o organismo
No entanto, a existência de um processo de seleção faz com que através desta via seja predominante a transmissão do vírus R5
A forma como o processo seletivo funciona está ainda a ser investigada, mas um dos modelos propõe que os espermatozoides possam seletivamente transportar VIH R5, uma vez que na superfície possuem CCR3 e CCR5, mas não CXCR4, e que as células epiteliais genitais sequestram de forma preferencial vírus X4
Em pessoas infetadas com o subtipo HIV-1, muitas vezes verifica-se a troca de co-recetor durante a fase avançada da doença, e as variantes T-trópicas aparentam poder infetar diferentes linfócitos T através do CXCR4
Estas variantes replicam-se então de forma mais agressiva e com maior virulência, o que provoca a diminuição acentuada dos linfócitos T, o colapso do sistema imunitário e o aparecimento de infeções oportunistas, características da SIDA
Assim, durante o curso da infeção, a adaptação viral para passar a usar o CXCR4 em vez do CCR5 pode representar um passo fundamental na progressão para a SIDA
Vários estudos em indivíduos infetados com o subtipo B concluíram que 40 a 50% dos pacientes com SIDA podem apresentar vírus T-trópicos e, presume-se, fenótipos X4.
O VIH-2 é muito menos patogénico do que o VIH-1 e a sua ocorrência é mais restrita em termos globais
A adoção de "genes acessórios" pelo VIH-2 e o seu padrão promíscuo de utilização de coreceptores (incluindo a independência relativamente ao CD4) pode auxiliar o vírus na sua adaptação de forma a evitar fatores de restrição inatos presentes nas células anfitriãs
A capacidade do VIH-2 em se replicar nos seres humanos pode ter origem na capacidade de adaptação do vírus, de modo a ser capaz de usar processos celulares normais de forma a permitir a transmissão e a infeção produtiva
Uma das estratégias de sobrevivência de qualquer agente infecioso é não matar o seu hospedeiro, mas antes estabelecer uma relação de comensalismo entre organismos
Tendo conseguido obter baixa petogenicidade, ao longo do tempo irão sendo selecionadas as variantes mais eficazes na transmissão.
O VIH penetra nos macrófagos e nos linfócitos T CD4 através da adsorção de glicoproteínas na sua superfície para recetores na célula-alvo, seguida pela fusão do envelope viral com a membrana celular e pela libertação do capsídeo do VIH na célula.
A penetração na célula tem início com a interação do complexo envelope trímero (gp160) com o CD4 e um recetor de quimiocina na superfície da célula (geralmente o CCR5 ou CXCR4, embora sejam conhecidos outros)
A gp120 liga-se à integrina α4β7, ativando o LFA-1, a principal integrina envolvida no estabelecimento de sinapses virológicas, que facilita a disseminação eficiente do VIH-1 entre células
A gp160 contém domínios de ligação tanto para o CD4 como para os recetores de quimioquina.
O primeiro estágio na fusão envolve a união dos domínios de ligação CD4 da gp120 ao CD4
Uma vez ligada a gp120 com a proteína CD4, o complexo envelope atravessa uma alteração na estrutura, expondo os domínios de ligação de quimioquina da gp120 e permitindo-lhes interagir com o recetor-alvo de quimioquina
Isto permite uma ligação mais estável, o que permite ao peptídeo de fusão N-terminal gp41 penetrar na membrana celular
Em seguida, as sequências de repetição na gp41, HR1 e HR2 interagem entre si, provocando o colapso da porção extracelular da gp41 num hairpin
Esta estrutura circular aproxima o vírus da membrana celular, permitindo a fusão das suas membranas e consequente entrada do capsídeo viral.
Depois do VIH se ligar à célula-alvo, injeta nela o seu ARN e as suas diversas enzimas, incluindo a transcriptase reversa, integrase, ribonuclease e protease
O VIH pode infetar células dendríticas (CD) através do processo CD4-CCR5, embora possa também usar recetores de lectina tipo C
As células dendríticas são uma das primeiras células que o vírus encontra durante a trensmissão por via sexual
Atualmente, pensa-se que as CD desempenhem um papel importante na transmissão do VIH para os linfócitos, durante o momento em que o vírus é capturado na mucosa
Acredita-se que a presença da proteína FEZ-1, que ocorre naturalmente em neurónios, impeça que o VIH infecte as células.
Pouco depois do capsídeo viral penetrar na célula, uma enzima denominada transcriptase reversa liberta o genoma ARN de cadeia única das proteínas virais, e copia-o para uma molécula complementar de ADN
O processo de transcrição reversa é extremamente predisposto a erros e as mutações daí resultantes podem provocar resistência aos anti-virais ou permitir ao vírus evadir o sistema imunitário
A transcriptase reversa tem também atividade de ribonuclease, que degrada o ARN viral durante a síntese de ADN complementar, assim como atividade de ADN polimerase ADN-dependente, capaz de criar ADN de sentido positivo a partir do ADN complementar de sentido negativo
Juntos, o ADN complementar e o seu complemento forma um ADN viral de cadeia dupla que é assim transportado para o núcleo celular
A integração do ADN viral com o genoma das células anfitriãs é realizada por outra enzima viral, denominada integrase.
O ADN viral, agora integrado na célula, pode permanecer dormente durante a fase latente da infeção
De forma ao vírus poder ser produzido de forma ativa, têm que estar presentes determinados fatores de transcrição, o mais importante dos quais o NF-κB (factor nuclear kappa B), que é depois supra-regulado quando os linfócitos T são ativados.
Durante a replicação viral, o AND proviral integrado é transcrito para ARNm, que é depois reorganizado através de splicing em partes mais pequenas
Estas partes são exportadas do núcleo para o citoplasma, onde são transcritas para as proteínas reguladoras Tat (que incentiva a produção de novos vírus) e Rev
À medida que as proteínas Rev recém-formadas se acumulam no núcleo, vão-se ligando ao ARNm viral e permitem ao ARN que ainda não sofreu splicing abandonar o núcleo, onde de outra forma são retidos até sofrerem splicing.
Em cada partícula de VIH-1 estão encapsidados dois genomas ARN
Durante a infeção e replicação catalisadas pela transcriptase reversa, pode ocorrer recombinação entre estes dois genomas
A recombinação ocorre quando os genomas ARN+ de cadeia única são transcritos reversamente para formar ADN
Durante a transcrição reversa o novo ADN pode alternar diversas vezes entre as duas cópias do ARN viral
Esta forma de recombinação é denominada cópia-escolha
Os processos de recombinação podem ocorrer ao longo de todo o genoma, e entre 2 e 20 eventos por genoma em cada ciclo de replicação
Estes eventos podem alterar rapidamente a informação genética que é transmitida dos genomas progenitores para os descendentes.
A recombinação viral produz variação genética que é provável que contribua para a evolução da resistência à terapia antiviral
A recombinação pode também contribuir, em princípio, para vencer as defesas imunitárias do hospedeiro
No entanto, para que as vantagens adaptativas da variação genética ocorram, os dois genomas virais contidos em cada uma das partículas de vírus devem ter origem em diferentes vírus progenitores e de constituição genética distinta
Não se sabe ainda com que frequência este fenómeno ocorre em condições naturais.
Um estudo sugeriu que a alternância do modelo por parte da transcriptase reversa atua como processo de reparação das quebras no genoma ssARN
Outro estudo sugeriu que a recombinação é uma adaptação tendo em vista a reparação de danos nos genomas ARN
A variação na troca de fita pela transcriptase reversa poderia gerar uma cópia não danificada de ADN genómico a partir de duas cópias danificadas de genoma ssARN
Este ponto de vista dos benefícios da recombinação no VIH poderia explicar porque é que cada partícula de VIH contém dois genomas completos, em vez de apenas um
Além disso, no ponto de vista que sustenta que a recombinação no VIH é um processo de reparação está implícito que esse benefício possa ocorrer a cada ciclo de replicação, e que o benefício possa ser conseguido quer os genomas sejam ou não diferentes em termos genéticos.
A infeção por VIH-1 provoca um processo inflamatório contínuo e a produção de espécies reativas de oxigénio
Assim, o genoma do VIH pode ser vulnerável a danos de oxidação, incluindo quebras no ARN de fita única
No caso do VIH, e para todos os vírus de forma genérica, a infeção bem sucedida está dependente de superar as estratégias defensivas do hospedeiro, que normalmente incluem a produção de oxigénio reativo capaz de destruir genoma
Um estudo sugeriu que a recombinação por parte dos vírus é uma adaptação com o objetivo de reparar os danos no genoma, e que a variação na recombinação é um subproduto que pode trazer benefícios acrescidos.
O último passo do ciclo viral, a montagem dos viriões do novo VIH-1, tem início na membrana de plasma da célula anfitriã
A poliproteína Env (gp160) atravessa o retículo endoplasmático e é transportada para o complexo de Golgi, onde é dividida pela furina, dando origem às duas glicoproteínas do envelope do VIH, gp41 e gp120
Estas proteínas são transportadas para a membrana plasmática da célula anfitriã, na qual a gp41 fixa a gp120 à membrana da célula infetada
As poliproteínas Gag (p55) e Gag-Pol (p160) também interagem com a superfície interior da membrana plasmática, em conjunto com o ARN genómico do VIH, à medida que o virião em formação começa a despontar da célula anfitriã
Este novo virião encontra-se ainda imaturo, uma vez que as poliproteínas Gag precisam ainda de ser separadas em proteínas de matriz, capsídeo e nucleocapsídeo.Esta divisão é mediada pela protease viral e pode ser inibida por fármacos antirretrovirais da classe dos inibidores da protease
Finalmente, os vários componentes são montados de modo a produzir um virião de VIH amadurecido, que são os únicos capazes de infetar outras células.
O vírus HIV se replica em linfócitos T CD4+ ativos, porque estes expressam fatores necessários para transcrição reversa, integração e expressão do DNA viral
Como exemplo de um fator que interfere na expressão do DNA viral está o fator de transcrição pró-inflamatório NF-κB, cuja expressão é induzida após ativação de linfócitos T CD4+; tal fator tem um papel importante no início da transcrição da sequência de DNA viral e expressão das proteínas virais primárias.
Os dois primeiros processos não ocorrem nos linfócitos T CD4+ em repouso (que não foram ativados pela apresentação de um antígeno específico) infectados, caracterizando a latência pré-integração
Esse DNA viral extracromossomal (que não está integrado) permanece viável por semanas após a infecção, constituindo um reservatório por certo intervalo de tempo, uma vez que, se tais células forem ativadas subsequentemente à infecção, o DNA viral se integrará e poderá gerar novos vírus.
Quando ocorre a ativação dos linfócitos T CD4+, que podem já estar infectados com o vírus ou serem infectados posteriormente à sua ativação, há estimulo para a proliferação celular e, assim, é possível que ocorra a integração do DNA viral e replicação do HIV; porém este estado é transitório e, após um tempo, os linfócitos voltam à fase de repouso como células de memória
Com isso, proteínas virais deixam de ser expressas e o vírus entra no estado de latência pós-integração: deixa de se replicar, mas seu DNA continua integrado, formando o reservatório de HIV
Caso essas células voltem a ser ativadas, ocorrerá a reativação da replicação do HIV e da sua infecção.
Nos macrófagos, que também são células que não estão em divisão e são o segundo alvo principal do vírus, não ocorre o bloqueio da síntese e integração do provírus, sendo assim, estes não abrigam o HIV em latência pré-integração, mas podem abrigá-lo em latência pós-integração, na qual mesmo com o provírus não há formação de novas partículas virais.
O VIH difere de grande parte dos vírus na medida em que possui uma imensa variabilidade genética
Esta diversidade é resultado do seu rápido ciclo de replicação, capaz de gerar 10 viriões por dia; de uma elevada taxa de mutação, de cerca de 3 x 10 por nucleobase por ciclo de replicação; e das propriedades recombinativas da transcriptase reversa.
Este esquema complexo leva a que sejam produzidas diversas variantes de VIH por dia num paciente infetado com VIH
Esta variabilidade é agravada quando uma célula é simultaneamente infetada por duas ou mais estirpes de VIH
Quando ocorre infeção em simultâneo, o genoma dos viriões progenitores pode ser constituído por fitas de ARN de duas estirpes diferentes
Este virião híbrido infeta depois uma nova célula, onde se replicará
Enquanto isto acontece, a transcriptase reversa, ao alternar entre dois padrões diferentes de ARN, vai gerar uma nova sequência de ADN retroviral que é uma recombinação entre os dois genomas progenitores
Esta recombinação é mais óbvia quando ocorrer entre subtipos.
O vírus da imunodeficiência símia (VIS) evoluiu para diversas estirpes, classificadas em função da espécie do hospedeiro natural
Pensa-se que as estirpes de VIS dos géneros Chlorocebus (VISagm) e Cercocebus atys (VISsmm) tenham tido uma longa história evolutiva em paralelo com os seus hospedeiros
Estes hospedeiros adaptaram-se à presença do vírus, que está presente em grande quantidade no seu sangue mas espoleta apenas uma resposta imune moderada, não provoca o aparecimento da SIDA símia, e nem sofre as amplas mutações e recombinações típicas da infeção do VIH em seres humanos.
Em contraste, quando estas estirpes infetam espécies que não estão adaptadas ao VIS, os animais desenvolvem SIDA e o vírus gera diversidade genética semelhante à que é observada na infeção humana com o VIH.
O SIV em chimpanzés (VIScpz), o parente genético mais próximo do VIH-1, está associado a maior mortalidade e sintomas semelhantes à SIDA no seu hospedeiro natural
O VIScpz aparenta ter sido transmitido aos chimpanzés e à população humana há relativamente pouco tempo, pelo que os seus hospedeiros não estão ainda adaptados ao vírus
Este vírus também perdeu a função do gene Nef que está presente na maior parte dos VIS; sem esta função, é mais provável que ocorra a diminuição dos linfócitos T, levando à imunodeficiência.
Foram identificados três grupos de VIH-1 com base nas diferenças entre a região do envelope (env): M, N e O
O grupo M é o mais prevalente e é subdividido em oito subtipos (ou clados) com base no genoma completo, que são distintos em termos geográficos
Os mais prevalentes são os subtipos B (encontrados principalmente na Europa e América do Norte), A e D (encontrados principalmente em África), e C (encontrado principalmente em África e na Ásia)
Estes subtipos formam ramos na árvore filogénica que representam a linhagem do grupo M do VIH-1
A co-infeção com diferentes subtipos suscita formas recombinantes circulantes (FRC ou, em inglês, CRF)
Em 2000, o último ano em que foi feita uma análise da prevalência à escala global dos subtipos, 47,2% das infeções eram do subtipo C, 26,7% eram do subtipo A/CRF02_AG, 12,3% eram do subtipo B, 5,3% do subtipo D, 3,2% eram CRF_AE, e os restantes 5,3% eram constituídos por outros subtipos e formas recombinantes
Grande parte da investigação relativa ao VIH-1 está focada no subtipo B e poucos laboratórios se focam nos restantes subtipos
Tem sido colocada a hipótese de um outro grupo "P", com base num vírus isolado em 2009
A estirpe aparenta ser derivada do VIS do gorila (VISgor), isolada pela primeira vez em 2006.
Muitos seropositivos desconhecem que estão infetados com o vírus
Por exemplo, em 2001, menos de 1% da população urbana sexualmente ativa em África tinha sido testada, sendo esta percentagem ainda menor entre a população rural
No mesmo ano, só 0,5% das mulheres grávidas que tiveram uma consulta em áreas urbanas foram aconselhadas, examinadas ou receberam os resultados dos testes e, igualmente, esta percentagem é inferior em áreas rurais
Uma vez que os dadores de sangue podem não estar conscientes da sua infeção, o sangue doado é sistematicamente examinado em relação à presença de VIH.
O teste de VIH-1 é inicialmente feito através de um exame ELISA, que deteta a presença de anticorpos do VIH-1
Indivíduos com resultado não reativo ao primeiro exame são considerados seronegativos, até que se verifique nova exposição a um parceiro infetado
Indivíduos com resultado positivo são novamente testados
Se o resultado de ambos os testes é reativo, o indivíduo é classificado como duplamente reativo e submetido e exames de confirmação com testes complementares mais específicos (por exemplo, western blot ou, menos comum, imunofluorescência
Apenas os indivíduos que são duplamente reativos pelo ELISA e positivos por imunofluorescência ou reativos pelo western blot é que são considerados seropositivos e indicadores da presença de uma infeção com o VIH
Alguns indivíduos que são duplamente reativos ao ELISA, ocasionalmente têm resultados indeterminados com western blot, o que pode significar tanto uma resposta incompleta dos anticorpos ao VIH numa pessoa infetada, como reações não-específicas numa pessoa não infetada
Embora a imunofluorescência possa ser usada para confirmar a infeção nestes casos ambíguos, este ensaio não é amplamente usado
Regra geral, deve ser colhida uma segunda amostra mais de um mês depois da primeira, e novamente testadas as pessoas com resultados indeterminados de western blot
Embora seja muito menos comum, o exame com ácido nucleico pode auxiliar o diagnóstico em determinadas situações.
Os exames de VIH modernos são extremamente precisos
Um único exame apresenta resultados corretos em mais de 99% dos casos
Estima-se que a probabilidade da ocorrência de um resultado falso positivo no exame protocolar seja de apenas 1 em 250 000, numa população de baixo risco
É recomendado que, após uma exposição ao VIH, os exames sejam feitos de imediato, a seis semanas, a três meses e a seis meses.
Em 2017, dois pesquisadores da Stanford criaram a centrífuga de papel que pode revolucionar como infecções como malária e HIV são detectadas nos países em desenvolvimento.
Estão identificadas três principais vias de transmissão do VIH: através de relações sexuais desprotegidas; por contacto sanguíneo, sobretudo através de feridas expostas, partilha de seringas ou transfusão de sangue que não tenha sido rastreado; e de mãe para filho durante a gravidez, parto ou amamentação
A infeção por VIH não proporciona imunidade adquirida, pelo que é possível ser infetado diversas vezes com estirpes diferentes do vírus.
A maioria das infeções por VIH é adquirida através de relações sexuais desprotegidas
A transmissão por via sexual pode ocorrer quando as secreções sexuais infetadas de um dos parceiros entram em contacto com as membranas muscosas genitais, orais ou anais do outro
Em países desenvolvidos, o risco de transmissão da mulher para o homem é de 0,04% por ato, enquanto o risco da transmissão do homem para a mulher é de 0,08% por ato
Por várias razões, este risco é entre 4 a 10 vezes superior em países em desenvolvimento.
A utilização correta e consistente de preservativos de látex reduz o risco de transmissão do VIH por via sexual em cerca de 85%.
No entanto, a utilização de espermicida é capaz de aumentar a probabilidade de contágio.
Uma meta-análise de 27 estudos observacionais realizados até 1999 na África subsariana indicou que a circuncisão masculina reduz o risco de infeção por VIH
No entanto, uma revisão posterior indicou que a correlação entre a circuncisão e o VIH nestes estudos observacionais pode ter sido devido a factores de confusão
Além disso, foram levantadas preocupações relativas ao potencial de disseminação do VIH que as lâminas não esterilizadas contituem durante a circunsição em rituais
Foram posteriormente realizados outros ensaios, em África do Sul no Quénia, e no Uganda nos quais homens não circuncisados eram aleatoriamente escolhidos para ser circuncisados em condições estéreis, e os resultados comparados contra um grupo não circuncisado, e que mostraram reduções na transmissão do VIH entre heterossexuais de 60%, 53% e 51%, respetivamente
Posteriormente, um painel de especialistas convocado pela OMS e pelo Secretariado da UNAIDS recomendou que a circuncisão masculina fosse reconhecida enquanto intervenção complementar na reduzir o risco de uma infeção de VIH adquirida por contacto sexual heterossexual.
Regra geral, há o risco de transmissão de VIH quando sangue infetado entra em contacto com qualquer ferida exposta
Esta via de transmissão é responsável por grande parte dos casos em toxicodependentes, hemofílicos e receptores de transfusões de sangue ou produtos derivados do sangue (embora nos países desenvolvidos as transfusões sejam despistadas para a presença de VIH)
É também um motivo de preocupação em pessoas que recebam cuidados de saúde em regiões onde não sejam comuns as boas práticas de higiene no manuseio de equipamento de injeção, como a reutilização de agulhas em países sub-desenvolvidos
Indivíduos que realizem ou recebam tatuagem, piercings ou escarificações são também grupos de risco
Tem sido observado VIH em baixas concentrações em saliva, lágrimas e urina de indivíduos portadores; no entanto, não há qualquer caso registado de infeção através destas secreções e o risco potencial de transmissão é desprezível
A transmissão de VIH através do mosquito não é possível.
A transmissão do vírus de mãe para filho pode ocorrer durante a gravidez, no momento do parto ou através de amamentação
Na ausência de tratamento, a taxa de transmissão é de cerca de 25%
No entanto, caso estejam disponíveis tratamentos de combinação de antirretrovirais e a possibilidade de realizar uma cesariana, este risco pode ser reduzido para 1%
A partilha da tarefa de amamentação entre mães deve ser evitada, já que é uma das causas de transmissão.
Ao contrário de outros vírus, a infeção com VIH não proporciona imunidade contra novas infeções, sobretudo no caso de vírus geneticamente distantes
Têm sido relatados vários casos de infeções múltiplas inter- e intra-clado
As múltiplas infeções têm sido ainda associadas a uma progressão mais rápida da doença
As infeções múltiplas são divididas em duas categorias, dependendo do momento da aquisição da segunda estirpe
A "coinfeção" denomina duas estirpes que aparentam ter sido adquiridas em simultâneo, ou muito perto para se poder distinguir
A "reinfeção" ou "superinfeção" denomina a infeção com uma segunda estirpe num intervalo de tempo mensurável após a primeira
No caso do VIH, têm sido relatadas à escala global ambas as formas de infeção múltipla, tanto em infeções crónicas como agudas.
Não existe atualmente qualquer vacina ou cura para o VIH/SIDA
O único método de prevenção recomendado é evitar a exposição ao vírus
No entanto, acredita-se que um tratamento antirretrovírico denominado profilaxia pós-exposição (PPE) reduza o risco de infeção caso seja iniciado imediatamente após a exposição
O tratamento atual para a infeção com VIH consiste numa terapêutica antirretrovírica de alta eficácia (em inglês, HAART), introduzida em 1996
As opções terapêuticas atuais são compostas por três fármacos, pertencentes a pelo menos duas classes de agentes antirretrovirais
Regra geral, estas classes são dois nucleósidos inibidores da transcriptase reversa (NITR), associados a um não nucleósido inibidor da transcriptase reversa (NNITR) inibidor da protease (IP)
Uma vez que a progressão em crianças é mais rápida e menos previsível do que em adultos, são recomendados tratamentos mais agressivos
Em países desenvolvidos nos quais esteja disponível a terapêutica HAART, o médico faz a avaliação completa do paciente, medindo a carga viral, a velocidade de declínio do CD4 e a capacidade de resposta do paciente, usando estes dados para decidir quando recomendar o início do tratamento.
A terapêutica HAART permite a estabilização dos sintomas e da viremia, mas não cura o paciente nem alivia os sintomas
Uma vez interrompido o tratamento, os VIH-1 regressa aos níveis elevados anteriores
Além disso, seria necessário um prazo superior a toda uma vida para eliminar a infeção recorrendo apenas à terapêutica HAART
Apesar disso, muitos indivíduos infetados apresentam uma melhoria significativa em termos de saúde e qualidade de vida, o que tem proporcionado uma redução significativa da morbosidade e mortalidade associadas ao VIH em países desenvolvidos
A esperança média de vida de um indivíduo infetado por HIV é de 32 anos a partir da data de infeção, caso o tratamento seja iniciado quando a contagem de CD4 for 350/µL
Na ausência de terapêutica HAART, o tempo mediano para que uma infeção por VIH faça a progressão para SIDA é de cerca de nova a dez anos, enquanto que a estimativa mediana de sobrevivência depois de instalada a SIDA é de apenas 9,2 meses
No entanto, a terapêutica HAART por vezes não atinge resultados satisfatórios, sendo em algumas circunstâncias ineficaz em mais de metade dos casos
Isto deve-se a várias razões, entra as quais intolerância ou efeitos secundários da medicação, terapêuticas antirretrovirais anteriores ineficazes, ou infeção com uma estirpe resistente de VIH
No entanto, a não adesão ou desistência por parte do paciente ao longo de uma terapia antirretroviral são a principal causa de insucesso da terapia HAART
São várias as razões para a não adesão ou desistência da terapêutica HAART
A não adesão é motivada sobretudo pelo acesso deficiente a cuidados de saúde, apoios sociais inadequados, a presença de doenças psiquiátricas ou a toxicodependência
A desistência é motivada pela complexidade dos regimes HAART, em particular do número de comprimidos, da frequência das doses, da restrição alimentar ou ainda por outros motivos a par de efeitos secundários
Os efeitos secundários incluem lipodistrofia, dislipidemia, resistência à insulina, aumento de riscos cardiovasculares e doenças congénitas.
O momento preciso para iniciar o tratamento é ainda objeto de debate
É indiscutível que o tratamento deva ser iniciado antes da contagem de CD4 do paciente ser inferior a 200
A maior parte das recomendações nacionais indica que o tratamento deva ser iniciado mal a contagem seja inferior a 350, embora evidências de alguns estudos apontem para que seja iniciado ainda antes de ultrapassar os 350
Em países onde não estão disponíveis métodos para contagem de CD4, o tratamento deve ser iniciado em pacientes nos estágios III e IV, conforme definido pela OMS
Os fármacos antirretrovirais são dispendiosos, pelo que a maioria da população infetada a nível mundial não tem acesso ao tratamento de VIH/SIDA
A investigação para melhorar os tratamentos atuais contempla a diminuição dos efeitos secundários, a simplificação dos regimes para diminuir a desistência, e a determinação da melhor sequência de regimes de modo a gerir a resistência aos fármacos
No entanto, pensa-se que apenas a vacinação será capaz de travar a pandemia global, já que se trata da única solução de baixo custo e que não requer tratamentos diários, sendo assim capaz de ser financeiramente sustentável em países em desenvolvimento
No entanto, após mais de vinte anos de investigação, o VIH-1 continua a ser um candidato difícil para uma vacina
Apesar disso, pensa-se que uma região da sua superfície constitua um potencial alvo para a criação uma vacina.
A OMS e a UNAIDS estimam que a SIDA tenha sido responsável pela morte de mais de 25 milhões de pessoas desde que foi identificada em 1981, o que a torna numa das mais destrutivas pandemias na História desde que há registo
Apesar da melhoria no acesso a cuidados de saúde e a tratamentos antirretrovirais em muitas regiões do mundo, só em 2005 a SIDA provocou a morte estimada a 2,8 milhões de pessoas (entre 2,4 e 3,3 milhões), das quais mais de 570 000 eram crianças.
Em 2007, estimava-se que viviam com o VIH entre 30,6 e 36,1 milhões de pessoas
Só nesse ano, estima-se que o vírus tenha sido o responsável direto pela morte de cerca de 2,1 milhões de pessoas, das quais 330 000 eram crianças, e que tenham ocorrido 2,5 milhões de novas infeções.
A África subsariana é de longe a região mais afetada, na qual se estima que 21,6 a 27,4 milhões de pessoas vivam atualmente com o VIH
Dois milhões são crianças com idade inferior a quinze anos
Mais de 64% de todas as pessoas portadoras de VIH vivem na África subsariana, assim como mais de 75% de todas as mulheres portadoras do vírus
Em 2005 havia na região entre 10,6 e 13,6 milhões de órfãos em consequência da SIDA
A África do Sul tem o maior número de casos de VIH no mundo, seguida pela Nigéria
Nos 35 países com a maior prevalência de VIH, a esperança média de vida é de 48,3 anos, ou 6,5 anos a menos do que seria espectável sem a doença.
A introdução da terapêutica HAART reduziu de forma substancial a mortalidade relacionada com o VIH nas áreas onde exista o acesso generalizado a cuidados de saúde
No entanto, à medida que aumentou a esperança de vida de portadores de VIH em países desenvolvidos, aumentaram também a probabilidade de disseminação da doença e, de forma substancial, o número de portadores vivos.
A pesquisa sobre o HIV/AIDS inclui todas as pesquisas médicas que tentam prevenir, tratar ou curar HIV/AIDS, bem como pesquisas fundamentais sobre a natureza do HIV como agente infeccioso e da AIDS como a doença causada pelo HIV
Muitos governos e instituições de pesquisa participam de investigações científicas sobre o tema
Esta pesquisa inclui intervenções de saúde comportamental, como pesquisas sobre educação sexual e desenvolvimento de medicamentos, como pesquisa de microbicidas para doenças sexualmente transmissíveis, vacinas contra o HIV e medicamentos antirretrovirais
Outras áreas de pesquisa médica incluem os tópicos de profilaxia pré-exposição, profilaxia pós-exposição, circuncisão e efeitos acelerados do envelhecimento.
Após muitos anos de pesquisa, uma vacina contra o HIV não testada foi criada
Os anticorpos bi-específicos que visam tanto a superfície das células T como os epítopos virais podem impedir a entrada do vírus em células somáticas
Outro grupo utilizou a mesma tecnologia para desenvolver um anticorpo bi-específico que neutraliza as partículas virais através da reticulação de glicoproteínas de envelope.
(FIGURA B) Células cancerígenas evitam a apoptose e continuam a multiplicar-se de maneira desregulada.
Câncer  ou cancro , também conhecido como neoplasia maligna, é um grupo de doenças que envolvem o crescimento celular anormal, com potencial para invadir e espalhar-se para outras partes do corpo, além do local original
Há mais de cem diferentes cânceres conhecidos que afetam os seres humanos, mas nem todos os tumores são cancerosos (malignos); tumores benignos não se espalham pelo corpo
Sinais e sintomas possíveis incluem surgimento de uma massa cancerígena, sangramento anormal, tosse prolongada, perda de peso inexplicável, mudança nas funções intestinais, entre outros
Apesar de estes sintomas poderem indicar câncer, eles também podem ocorrer devido a outras doenças.
O uso do tabaco é a causa de cerca de 22% das mortes, evitáveis, por câncer
Outros 10% ocorrem devido à obesidade, uma dieta pobre, falta de atividade física e consumo de bebidas alcoólicas
Entre outros, estão certos tipos de infecções, exposição à radiação ionizante e poluentes ambientais
No mundo em desenvolvimento, cerca de 20% dos cânceres surgem devido a infecções, tais como hepatite B, hepatite C e vírus do papiloma humano (HPV)
Estes fatores atuam, pelo menos parcialmente, na alteração dos genes das células
Normalmente muitas dessas mudanças são necessárias para que o câncer se desenvolva
Entre 5% e 10% dos cânceres surgem por conta de defeitos genéticos hereditários
O câncer pode ser detectado através de certos sinais e sintomas ou por meio de testes de rastreio
Em seguida, geralmente é feita a investigação por imagens médicas e a confirmação pela biópsia
Os benefícios do rastreio do câncer de mama ainda são controversos, mas a detecção precoce através de mamografia é útil para o câncer do colo do útero e colorretal.
Muitos cânceres podem ser evitados ao: manter um peso ideal, comer muitos vegetais, frutas e grãos integrais, ser vacinado contra certas doenças infecciosas, não comer muita carne vermelha processada, evitar ingestão excessiva de álcool, de fumo e demasiada exposição à luz solar
O câncer é frequentemente tratado através da combinação de radioterapia, cirurgia, quimioterapia e terapia dirigida
A gestão da dor e dos sintomas é uma parte importante do tratamento
Os cuidados paliativos são particularmente importantes para os doentes com cânceres em estágios avançados
A chance de sobrevivência depende do tipo de câncer e da extensão da doença no início do tratamento
Em crianças menores de quinze anos no momento do diagnóstico a taxa de sobrevivência de cinco anos no mundo desenvolvido é, em média, de 81%
Nos Estados Unidos a taxa média de sobrevivência de cinco anos é de 66%.
Em 2012, cerca de 14,1 milhões de novos casos de câncer ocorreram globalmente (excluindo casos de câncer de pele que não seja melanoma)
A doença causou cerca de 8,2 milhões de mortes, ou 14,6% de todas as mortes humanas, além de um prejuízo anual de 2 trilhões de dólares na economia mundial (dados de 2015)
Os tipos mais comuns de câncer nos homens são de pulmão, próstata, colorretal e de estômago
Nas mulheres, os tipos mais comuns são o câncer de mama, colorretal, de pulmão e cervical
Se o câncer de pele que não for melanoma for incluído no total de novos casos anuais, ele representará cerca de 40% dos registros da doença
Em crianças, leucemia linfoide aguda e tumores cerebrais agudos são os mais comuns, exceto na África, onde o linfoma não Hodgkin ocorre com mais frequência
Em 2012, cerca de 165 mil crianças com menos de quinze anos de idade foram diagnosticadas com câncer
O risco de câncer aumenta significativamente com a idade e muitos cânceres ocorrem mais comumente em países desenvolvidos devido à mudança no estilo de vida e à chegada da terceira idade.


A palavra "Câncer" em português brasileiro é oriunda do latim cancer, em português: caranguejo, em referência à proliferação de células cancerosas no organismo (metástase), que se espalham pelo corpo de forma semelhante às patas e pinças do caranguejo que irradiam do seu cefalotórax
Em português europeu, o termo cancro é oriundo do latim cancru.
Quando o câncer começa, invariavelmente, não produz sintomas
Sinais e sintomas só aparecem quando a massa cancerígena continua a crescer ou forma úlceras e dependem do tipo e da localização do câncer
Alguns sintomas são específicos, sendo que muitos deles também ocorrem com frequência em indivíduos que têm outras patologias
O câncer é o novo "grande imitador", assim, não é incomum que pessoas diagnosticadas com câncer recebam patologia de outras doenças com sintomas semelhantes.
A massa do tumor (ou a ulceração) podem causar sintomas locais
Por exemplo, os efeitos da massa cancerígena no pulmão podem causar a obstrução do brônquio, o que resulta em tosse ou pneumonia; se ocorrer no pulmão pode causar hemorragia, fazendo com que o paciente passe a tossir sangue; o câncer de esôfago pode causar o estreitamento do esôfago, o que torna o ato de engolir difícil ou doloroso; nos intestinos a hemorragia causa anemia ou hemorragia retal; o câncer colorretal pode levar ao estreitamento ou bloqueio do intestino, o que altera as funções intestinais; na bexiga a ulceração causa a presença de sangue na urina; no útero, a hemorragia vaginal
A massa inicial é geralmente indolor, porém em estádios avançados podem ocorrer dores localizadas
Alguns tipos de câncer podem causar acumulação de líquido dentro do peito ou no abdômen.
Os sintomas gerais ocorrem devido a efeitos distantes do câncer que não estão relacionados à propagação metastática, o que pode incluir: perda involuntária de peso, febre, cansaço excessivo e alterações na pele
A doença de Hodgkin, leucemias e câncer de fígado ou rins podem causar uma febre de origem desconhecida persistente.
Alguns tipos de câncer podem causar grupos específicos de sintomas sistêmicos, denominados fenômenos para-neoplásicos, como o aparecimento de miastenia grave na timoma ou hipocratismo digital no câncer de pulmão.
O câncer pode se espalhar a partir do seu local original de propagação através da disseminação linfática para os linfonodos regionais, ou pelo sangue para locais distantes, processo conhecido como metástase
Quando o câncer se espalha por uma rota sanguínea, normalmente se espalha por todo o corpo
No entanto, "sementes" de câncer crescem em determinados locais
Os sintomas de cânceres metastáticos dependem da localização do tumor e podem incluir linfadenopatia, hepatomegalia ou esplenomegalia, dor ou fratura dos ossos afetados, além de sintomas neurológicos.
A grande maioria dos cânceres, cerca de 90-95% dos casos, ocorre devido a fatores ambientais
Os 5-10% restantes são devido à hereditariedade genética
Os fatores ambientais englobam qualquer causa que não seja herdada geneticamente, como o estilo de vida, nível econômico e fatores comportamentais, e não apenas a poluição
Entre os principais fatores ambientais que contribuem para a morte por câncer estão o tabagismo (25-30%), maus hábitos alimentares e obesidade (30-35%), além de infecções (15-20%), radiação (tanto ionizante e não ionizante, até 10%), estresse, sedentarismo e poluentes ambientais.
É praticamente impossível determinar a causa de um câncer em dada pessoa, uma vez que a maioria dos cânceres têm várias causas possíveis
Por exemplo, se um fumador desenvolver câncer de pulmão, é provável que a doença tenha sido causada pelo tabagismo; mas visto que qualquer pessoa apresenta uma pequena probabilidade de desenvolver câncer de pulmão, como resultado da poluição do ar ou da radiação, há uma pequena probabilidade de esse câncer ter sido causado por outros fatores
Apesar de muito raramente poderem ocorrer transmissões durante a gravidez e em alguns doadores de órgãos, o câncer geralmente não é uma doença transmissível.
A exposição a determinadas substâncias tem sido associada a tipos específicos de câncer
Estas substâncias são denominadas cancerígenas
O tabagismo, por exemplo, é a causa de 90% dos casos de câncer de pulmão, podendo ser também a causa de câncer de laringe, cabeça e pescoço, estômago, bexiga, rins, esôfago e pâncreas
O fumo do tabaco contém mais de 50 agentes cancerígenos conhecidos, incluindo nitrosaminas e hidrocarbonetos aromáticos policíclicos
O tabaco é responsável por cerca de uma em cada três mortes por câncer no mundo desenvolvido e cerca de uma em cada cinco mortes em todo o mundo
As taxas de mortalidade por câncer de pulmão nos Estados Unidos têm espelhado padrões, com o aumento de fumantes seguido por aumentos dramáticos nas taxas de mortalidade por câncer de pulmão
No entanto, a diminuição nas taxas de tabagismo desde a década de 1950 levou a decréscimos nas taxas de mortalidade por câncer de pulmão em homens desde os anos 1990.
Na Europa Ocidental, 10% dos cânceres em homens e 3% de todos os cânceres em mulheres são atribuídos à exposição ao álcool, especialmente em casos de câncer do fígado e do trato digestivo
Acredita-se que o câncer relacionado à exposição a substâncias no local de trabalho possa representar entre 2% e 20% de todos os casos
Todos os anos, pelo menos 200 mil pessoas morrem de câncer no mundo em casos relacionados a seus locais de trabalho
Milhões de trabalhadores correm o risco de desenvolver a doença, como câncer de pulmão e mesotelioma, por inalação do fumo do tabaco ou de fibras de amianto no trabalho, ou leucemia por exposição ao benzeno.
Os maus hábitos alimentares, o sedentarismo e a obesidade estão relacionados com 30% a 35% das mortes por câncer
O excesso de peso corporal nos Estados Unidos está associado ao desenvolvimento de muitos tipos de câncer e é um fator relevante entre 14% e 20% de todas as mortes por câncer
Do mesmo modo, um estudo do Reino Unido, que incluiu dados de mais de 5 milhões de pessoas, apresentou que um maior índice de massa corporal (IMC) está relacionado a pelo menos dez tipos de câncer e é responsável por cerca de 12 mil casos anuais da doença no país
Acredita-se que o sedentarismo possa contribuir para o risco de câncer, não só através do seu efeito sobre o peso corporal, mas também através de efeitos negativos sobre o sistema endócrino e imunológico
Mais da metade do efeito da dieta é devido a supernutrição (comer demais), ao invés da pouca ingestão de legumes ou outros alimentos saudáveis.
Alguns alimentos específicos estão ligados a cânceres específicos
Uma dieta rica em sal está ligada ao câncer gástrico
A aflatoxina B1, que frequentemente contamina alimentos, provoca o câncer de fígado
A mastigação de noz de areca provoca câncer oral
As diferenças de práticas alimentares podem explicar em parte as diferenças de incidência de câncer em diferentes países
Por exemplo, o câncer gástrico é mais comum no Japão, devido à dieta de alto teor salino da população local, enquanto o câncer de cólon é mais comum nos Estados Unidos
Imigrantes também desenvolvem maior risco em seu novo país, muitas vezes dentro de uma geração, sugerindo um vínculo substancial entre dieta e câncer.
Em todo o mundo aproximadamente 18% das mortes por câncer estão relacionadas com doenças infecciosas
Esta proporção varia em diferentes regiões do mundo de um máximo de 25% na África para menos de 10% no mundo desenvolvido
Os vírus são agentes cancerígenos infecciosos usuais, mas bactérias e parasitas cancerosos também podem ter efeito.
Os vírus que podem causar câncer são chamados de oncovírus
Estes incluem o papilomavírus humano (carcinoma cervical), o vírus de Epstein-Barr, o herpesvírus (sarcoma de Kaposi), a hepatite B e a hepatite C (carcinoma hepatocelular) e o vírus linfotrópico da célula T humana (leucemia de células T)
A infecção bacteriana também pode aumentar o risco de câncer, como visto no carcinoma gástrico induzido por Helicobacter pylori
Entre as infecções parasitárias fortemente associadas ao câncer estão a Schistosoma haematobium' (carcinoma de células escamosas da bexiga) e os vermes do fígado, como Opisthorchis viverrini e Clonorchis sinensis (colangiocarcinoma).
Até 10% dos cânceres invasivos estão relacionadas com a exposição à radiação, incluindo tanto a radiação ultravioleta quanto a radiação não ionizante
Além disso, a grande maioria dos cânceres não invasivos são cânceres da pele que não são melanomas causados ​​por radiação ultravioleta não ionizante, a maior parte proveniente da luz solar
Fontes de radiação ionizante incluem imagens médicas e gás radônio.
A radiação ionizante não é um mutagênico particularmente forte
A exposição residencial ao radônio, por exemplo, tem riscos de câncer semelhantes ao do tabagismo passivo
A radiação é uma fonte mais potente de câncer quando é combinada com outros agentes causadores da doença, como a exposição a radônio, além de tabaco
A radiação pode causar câncer na maioria das partes do corpo, em todos os animais e em qualquer idade
Crianças e adolescentes têm duas vezes mais probabilidade de desenvolver leucemia induzida por radiação que adultos; a exposição à radiação antes do nascimento tem dez vezes mais efeito.
O uso médico da radiação ionizante é uma pequena, mas crescente, fonte de cânceres induzidos por radiação
A radiação ionizante pode ser utilizada para tratar outros tipos de cânceres, mas esta pode, em alguns casos, induzir a uma segunda forma da doença
Também é utilizada em alguns tipos de imagens médicas.
A exposição prolongada à radiação ultravioleta do Sol pode conduzir a melanoma e outras malignidades de pele
Evidências estabelecem a radiação ultravioleta, em particular a onda média não ionizante UV, como a causa da maior parte dos cânceres da pele não melanoma, que são as mais formas comuns de câncer no mundo.
A radiofrequência não ionizante a partir de celulares, transmissão de energia elétrica e de outras fontes semelhantes tem sido descrita como um possível agente cancerígeno pela Agência Internacional de Pesquisa em Câncer da Organização Mundial da Saúde
No entanto, estudos não encontraram uma ligação consistente entre a radiação do telefone celular e o aumento do risco de câncer.
A grande maioria dos cânceres não são hereditários ("cânceres esporádicos")
Cânceres hereditários são causados ​​principalmente por um defeito genético herdado
Menos do que 0,3% da população é portadora de uma mutação genética que tem um grande efeito no risco de câncer e esta causa menos do que 3-10% de todos os casos de câncer no mundo
Por exemplo, certas mutações hereditárias nos genes BRCA1 e BRCA2 ampliam em 75% o risco de câncer da mama, câncer de ovário e de câncer colorretal hereditário sem polipose (que está presente em cerca de 3% das pessoas com câncer colorretal).
Algumas substâncias causam câncer, principalmente através de seus efeitos físicos, em vez de químicos, sobre as células
Um exemplo proeminente disto é a prolongada exposição ao amianto, um composto que ocorre naturalmente em fibras minerais
Ele é uma das principais causas de mesotelioma, um câncer da membrana serosa que envolve os pulmões
Outras substâncias nesta categoria são wollastonita, paligorsquite, lã de vidro e lã mineral, que têm efeitos semelhantes
Materiais particulados não fibrosos que causam câncer incluem o pó metálico de cobalto e níquel e o dióxido de silício (quartzo, cristobalita e tridimita)
Normalmente, agentes cancerígenos físicos devem ficar no interior do corpo (tal como por meio de inalação de pedaços minúsculos) e requerem anos de exposição para desenvolver câncer.
É relativamente raro que traumas físicos resultem em câncer
Alegações de que ossos quebrados acabam por facilitar o desenvolvimento de câncer ósseo, por exemplo, nunca foram provadas
Da mesma forma, traumas físicos não são aceitos como uma das causas para o câncer de colo do útero, de mama ou no cérebro
Um mecanismo aceito é o contato frequente, a longo prazo, de objetos quentes com o corpo
É possível que repetidas queimaduras na mesma parte do corpo possam produzir câncer de pele, especialmente se substâncias químicas cancerígenas também estiverem presentes
Beber chá muito quente pode produzir câncer do esôfago
De um modo geral, acredita-se que o câncer surge através de um câncer preexistente que é estimulado durante o processo de reparação do trauma, ao invés de o câncer ser causado diretamente pelo trauma
No entanto, repetidas lesões nos mesmos tecidos podem promover uma proliferação celular excessiva, o que poderia, então, aumentar as chances de uma mutação cancerosa.
É controverso se inflamações crônicas podem causar mutações diretamente
Reconhece-se, no entanto, que a inflamação pode contribuir para a proliferação, a sobrevivência, a angiogênese e a migração de células cancerosas por influenciar o microambiente em torno dos tumores
Além disso, os oncogenes são conhecidos por surgirem em um microambiente inflamatório pró-tumorigênico.
Alguns hormônios desempenham um papel importante no desenvolvimento de câncer através da promoção da proliferação de células
Os fatores de crescimento semelhante à insulina e as suas proteínas de ligação desempenham um papel fundamental na proliferação, diferenciação e apoptose de células cancerosas,, sugerindo um possível envolvimento na carcinogênese.
Hormônios são agentes importantes em cânceres relacionados ao sexo, como o câncer de mama, do endométrio, da próstata, do ovário e do testículo, além do câncer de tireoide e ósseo
Por exemplo, as filhas de mulheres que têm câncer de mama têm níveis significativamente mais elevados de estrogênio e progesterona do que as filhas de mulheres sem câncer da mama
Estes níveis hormonais elevados podem explicar por que essas mulheres têm maior risco de desenvolver câncer de mama, mesmo na ausência de um gene deste tipo de câncer
Da mesma forma, os homens de ascendência africana têm níveis significativamente mais elevados de testosterona do que os homens de ascendência europeia, além de ter um nível correspondentemente muito maior de câncer de próstata, enquanto que homens de ascendência asiática têm níveis mais baixos de câncer de próstata.
Outros fatores que também são relevantes: pessoas obesas têm níveis mais elevados de alguns hormônios associados ao câncer e uma taxa mais elevada de certos cânceres
As mulheres que fazem terapia de reposição hormonal têm um maior risco de desenvolver cânceres associados a esses hormônios
Por outro lado, pessoas que se exercitam muito mais do que a média têm menores níveis desses hormônios e menor risco de desenvolver câncer
O osteossarcoma pode ser promovido por hormônios de crescimento.
Teratomas são crescimentos descontrolados de células, que geralmente são compostos de vários tecidos, como cabelos, músculos e ossos, ocorrendo com maior frequência nos ovários (mulheres) e nos testículos (homens)
Quando esses teratomas são malignos, eles são chamados de teratocarcinomas, sendo considerados um tipo de câncer.
Nesse tipo de câncer, o tumor não é causado por uma mutação genética, mas sim pelo ambiente externo da célula
Através de experimentos, sendo o mais famoso realizado com camundongos, observou-se que se uma massa de células é colocada no interior de um blastocisto de camundongo, ela vai se integrar ao blastocisto, perder sua malignidade e se dividir normalmente; caso contrário, se ela for colocada em uma outra região, isso pode levar à formação do teratocarcinoma, tornando-se um tumor maligno.
Alguns tipos de tumores podem ocorrer devido a uma deficiência na comunicação entre células
Essa comunicação é responsável por evitar a divisão celular descontrolada que pode dar origem ao tumor
Alguns estudos mostraram que tumores podem ser causados por alteração na estrutura de um tecido e que esses tumores podem ser suprimidos restaurando o ambiente do tecido apropriado.
Esse defeito na comunicação celular pode causar metástases, pois assim como as células embrionárias, as células tumorais não costumam ficar paradas, elas migram e formam colônias, podendo se espalhar por todo o corpo
Uma das proteínas que tem um importante papel na comunicação célula-célula é a caderina, pois ela é responsável pela correta separação das células para formar os tecidos durante a divisão celular, em que as células formam fronteiras e se segregam dentro dos tecidos por meio da alteração de suas forças de ligação
Quando ocorre metástase, essa propriedade se perde, os níveis de caderina ficam abaixo do normal e a força de ligação à matriz extracelular e a outros tipos de células se torna maior do que as forças de coesão que mantêm o tecido junto
Como resultado, as células se tornam capazes de se espalhar para outros tecidos.
O câncer colorretal é um exemplo em que o tumor é formado pelo defeito na comunicação célula-célula
Sabe-se que a adesão célula-célula desempenha um importante papel na manutenção da homeostase do tecido epitelial; uma desorganização dessa adesão influencia no desenvolvimento da carcinogênese, nesse caso no epitélio do reto
Essa adesão, como dito anteriormente, é favorecida pela caderina; no caso do epitélio retal, é a E-caderina quem exerce esse papel
Durante o processo de formação do câncer é observada uma expressão diminuída da E-caderina ou sua translocação da membrana plasmática para o citoplasma, causando uma desorganização da adesão célula-célula
Essa desorganização da adesão célula-célula pode ser mediada por diversos fatores, como por exemplo a endocitose de E-caderina ou a clivagem do domínio extracelular da E-caderina, resultando na E-caderina solúvel e na liberação do domínio intracelular para o citoplasma
Essa redução na expressão de E-caderina vai indicar um aumento na invasividade tumoral, sendo um tumor mais maligno, e também está correlacionada a um aumento na probabilidade de metástases e na mortalidade do paciente
Também foi descoberta uma relação entre as vias de sinalização celular envolvendo proteínas quinases (PKA) e GTPases, que são responsáveis por regular a organização do citoesqueleto de actina e das junções intercelulares, onde a E-caderina cumpre seu papel.
Em outros casos, pode ocorrer um defeito nas vias parácrinas
Nesses casos, células tumorais vão reativar vias parácrinas que são usadas durante o desenvolvimento
Sabe-se, por exemplo, que muitos tumores secretam o fator parácrino Sonic hedgehog (Shh)
Shh não age nas células tumorais, mas nas células estromais, fazendo com que elas produzam fatores que suportam as células tumorais
Se a via do Shh é bloqueada, o tumor regride
Se isso não ocorrer, o tumor vai progredir.
Foram descobertos três modelos básicos para explicar o envolvimento da via do Shh na formação de tumores
O primeiro tipo consiste em tumores que contêm mutações nas vias de ativação do Shh e que são independentes da ligação de Shh
O segundo tipo é autócrino e dependente da ligação ao Shh, o que significa que tanto a produção quanto a resposta de Shh são realizadas pelas mesmas células tumorais
Por fim, no terceiro tipo, os tumores são parácrinos e dependentes da ligação ao Shh, nesse caso o Shh produzido pelas células tumorais é recebido pelo estroma, que vai ativar outras vias de sinalização de volta ao tumor, promovendo seu crescimento.
A maioria dos cânceres são inicialmente reconhecidos por causa de seus sintomas e sinais ou através de exames
Nenhum dos dois leva a um diagnóstico definitivo, que geralmente requer a opinião de um patologista
Pessoas com suspeita de câncer são investigadas com exames médicos
Estes geralmente incluem exames de sangue, radiografia, tomografia computadorizada, endoscopia, entre outros.
Os cânceres são uma grande família de doenças que envolvem o crescimento celular anormal, com potencial para invadir e se espalhar para outras partes do corpo
Eles formam um subconjunto de neoplasias
A neoplasia ou tumor é um grupo de células que foi submetido a um crescimento não regulado e, muitas vezes, forma uma massa, mas pode ser distribuído de forma difusa.
Todas as células tumorais mostram as seis características de câncer
Estas são características que as células cancerosas precisam ter para produzir um tumor maligno
Elas incluem:
A progressão das células normais para células que podem formar uma massa detectável até o surgimento do câncer definitivo é um processo que envolve vários passos conhecidos como "progressão maligna".
Nos Estados Unidos e em outros países desenvolvidos, o câncer é responsável por cerca de 25% de todas as mortes
Anualmente, 0,5% da população é diagnosticada com câncer
As estatísticas abaixo são para adultos nos Estados Unidos e variam consideravelmente em outros países:
O câncer também ocorre em crianças jovens e adolescentes, mas é raro
Alguns estudos concluíram que cânceres pediátricos, especialmente leucemia, estão em uma tendência de aumento de incidência.
A idade do pico de incidência de câncer em crianças ocorre durante o primeiro ano de vida
Leucemia (geralmente leucemia linfoblástica aguda) é a forma maligna infantil mais comum (trinta por cento), seguida pelos do sistema nervoso central e neuroblastoma
Também são presentes o tumor de Wilms, linfomas, retinoblastoma, osteossarcoma e sarcoma de Ewing.
A suspeita de câncer pode ocorrer por razões diversas, mas o diagnóstico definitivo da maioria dos casos malignos deve ser confirmado através de exame histológico das células cancerosas por um patologista
O tecido pode ser obtido através de uma biópsia ou cirurgia
Muitas biópsias (como aquelas da pele, mama ou fígado) podem ser feitas em um consultório médico
Biópsias em outros órgãos são realizadas sob anestesia e requerem cirurgia em uma sala de operação
O diagnóstico do tecido indica o tipo de célula que está proliferando, sua graduação histológica e outras características do tumor
Toda esta informação reunida é útil para avaliar o prognóstico do paciente e escolher o melhor tratamento
A citogenética e a imuno-histoquímica podem fornecer informações sobre o comportamento futuro do câncer (prognóstico) e melhor tratamento.
O câncer é fundamentalmente uma doença causada pela falha da regulação do crescimento de tecidos
Para que uma célula normal se transforme em uma célula cancerígena, os genes que regulam o crescimento e a diferenciação celular têm de ser alterados.
Os genes afetados são divididos em duas grandes categorias
Oncogenes são os genes que promovem a reprodução e o crescimento celular
Genes supressores de tumores são genes que inibem a divisão celular
A transformação maligna pode ocorrer através da formação de novos oncogenes, da sobre-expressão inadequada de oncogenes normais, ou pela sub-expressão ou desativação de genes supressores de tumores
Normalmente, alterações em vários genes são necessárias para transformar uma célula normal em uma célula cancerosa.
Alguns ambientes tornam mais susceptíveis o surgimento e a propagação dos erros genéticos
Tais ambientes podem incluir a presença de substâncias perturbadoras chamadas agentes cancerígenos, danos físicos repetidos, calor, radiações ionizantes ou hipoxia.
A transformação de células normais em câncer é semelhante a uma reação em cadeia causada ​​por erros iniciais, que criam erros progressivamente mais graves, permitindo que a célula escape dos controles que limitam o crescimento do tecido normal
Este cenário de "rebelião" torna-se uma indesejável sobrevivência do mais apto, onde as forças motrizes da evolução trabalham contra a concepção e a execução das ordens do corpo
Depois que o câncer começa a se desenvolver, este processo em curso, denominado "evolução clonal", impulsiona a progressão para estágios mais invasivos
A evolução clonal conduz à heterogeneidade intra-tumor, que complica o desenho de estratégias de tratamento eficazes.
As características desenvolvidas por cânceres são divididas em várias categorias
Seis categorias foram originalmente propostas em um artigo de 2000 chamado The Hallmarks of Cancer, de Douglas Hanahan e Robert Allan Weinberg: evasão de apoptose; a autossuficiência em sinais de crescimento; insensibilidade aos sinais anti-crescimento; sustentada angiogênese; potencial replicativo ilimitado; e metástase
Com base em trabalhos futuros, os mesmos autores acrescentaram mais duas categorias em 2011: a reprogramação do metabolismo energético e a evasão de destruição imune.
Classicamente, o câncer foi visto como um conjunto de doenças que são movidas por anormalidades genéticas progressivas que incluem mutações nos genes e oncogenes supressores de tumores e anormalidades cromossômicas
No entanto, tornou-se evidente que o câncer também é acionado por alterações epigenéticas.
Alterações epigenéticas referem-se a modificações funcionalmente relevantes do genoma que não envolvem uma alteração na sequência de nucleótidos
Exemplos de tais modificações estão em alterações na metilação do DNA (hipermetilação e hipometilação), modificação da histona e mudanças na arquitetura cromossômica (causadas pela expressão inapropriada de proteínas, tais como HMGA2 ou HMGA1)
Cada uma destas alterações epigenéticas servem para regular a expressão do gene, sem alterar a sequência de DNA subjacente
Estas alterações podem permanecer através de divisões celulares, passadas por várias gerações e podem ser consideradas epimutações (equivalentes a mutações).
Enquanto um grande número de alterações epigenéticas são encontradas em vários tipos de câncer, mudanças em genes de reparo causam a redução da expressão de proteínas de reparo do DNA, o que pode ser particularmente importante
Tais alterações podem ocorrer no início da progressão para o câncer e são uma causa provável da característica instabilidade genética de cânceres.
Deficiências da expressão das proteínas de reparação de DNA, devido a uma mutação herdada, podem causar um maior risco de desenvolvimento de câncer
Os indivíduos com uma deficiência hereditária em qualquer um dos 34 genes de reparo de DNA têm um maior risco de câncer, sendo que alguns defeitos podem causar uma chance de até 100% de desenvolver câncer (mutações em p53, por exemplo).
Cânceres surgem normalmente a partir de um conjunto de mutações e epimutações que conferem uma vantagem seletiva, levando a uma expansão clonal (ver Neoplasma)
Mutações, no entanto, podem não ser tão frequentes em cânceres como as alterações epigenéticas
Um câncer de mama ou cólon comum pode ter cerca de 60 a 70 mutações que alteram a proteína, das quais cerca de três ou quatro podem ser mutações "definitivas", enquanto que os demais podem ser mutações "passageiras".
A metástase é a propagação do câncer para outros locais do corpo
Os novos tumores são chamados de tumores metastáticos, enquanto a massa original é chamada de tumor primário
Quase todos os tipos de câncer podem ter metástase
A maioria das mortes por câncer ocorrem devido a propagação do câncer, a partir do seu local inicial, para outros órgãos.
A metástase é muito comum nos últimos estágios do câncer e pode ocorrer através do sistema circulatório, do sistema linfático, ou de ambos
Os passos típicos da metástase são a invasão local, o intravasamento para o sangue ou a linfa, a circulação através do corpo, o extravasamento para o novo tecido, a proliferação e a angiogênese
Diferentes tipos de cânceres tendem a ter metástase para órgãos específicos, mas no geral os lugares mais comuns para metástases ocorrerem são pulmões, fígado, cérebro e ossos.
Existem muitas opções de tratamento para o câncer, como cirurgia, quimioterapia, radioterapia, terapia hormonal, terapia-alvo e cuidados paliativos
A escolha dos tratamentos que serão utilizados depende do tipo, localização e estágio do câncer, bem como da saúde e dos desejos do paciente
O objetivo do tratamento pode ser curativo ou não curativo.
A quimioterapia é o tratamento do câncer com uma ou mais drogas anti-neoplásicas citotóxicas (agentes quimioterápicos), como parte de um regime normalizado
O termo engloba uma grande variedade de diferentes fármacos anticancerígenos, que são divididos em categorias amplas, tais como agentes alquilantes e anti-metabólitos
Os agentes quimioterápicos tradicionais atuam matando as células que se dividem muito rapidamente, uma das principais propriedades da maioria das células cancerosas.
A terapia-alvo é uma forma de quimioterapia que tem como alvo as diferenças moleculares específicas entre o câncer e as células normais
As terapias direcionadas bloqueiam a molécula de receptor de estrogênio, o que inibe o crescimento de câncer de mama, por exemplo
Outro exemplo comum é a classe de inibidores de Bcr-Abl, que são utilizados para o tratamento de leucemia mielóide crônica (LMC)
Atualmente, não são orientados para câncer de mama, mieloma múltiplo, linfoma, câncer de próstata, melanoma e outros tipos de cânceres.
A eficácia da quimioterapia depende do tipo e do estágio do câncer
Em combinação com a cirurgia, a quimioterapia tem se revelado útil em diferentes tipos de câncer, como da mama, colorretal, do pâncreas, osteossarcoma, testicular, do ovário e em certos tipos de câncer de pulmão
A eficácia global varia entre a cura de alguns tipos de câncer, como algumas leucemias, e a ineficácia completa, como em alguns tumores cerebrais, ou ainda pode ser simplesmente desnecessária em outros, como na maioria dos cânceres de pele que não são melanomas.
A radioterapia envolve o uso de radiação ionizante para tentar curar ou melhorar os sintomas da doença
Ela funciona ao danificar o DNA do tecido canceroso, o que conduz à morte celular
Para poupar tecidos normais (tais como pele ou órgãos pelos quais a radiação precisa passar para tratar o tumor), feixes de radiação são lançados a partir de vários ângulos de exposição e se cruzam no tumor, proporcionando uma dose absorvida muito maior na massa cancerosa do que no tecido saudável do entorno
Tal como acontece com a quimioterapia, cânceres diferentes respondem de maneiras diferentes à terapia de radiação.
A radioterapia é usada em cerca de metade de todos os casos e a radiação pode ser tanto de fontes internas, na forma de braquiterapia, ou de fontes de radiação externa
A radiação de raios-x é geralmente de baixa energia para o tratamento de cânceres da pele, enquanto que feixes de raios-x com graus mais elevados de energia são usados ​​no tratamento de cânceres que se desenvolveram dentro do corpo
A radiação é tipicamente utilizada em associação com cirurgias e/ou quimioterapia, mas para certos tipos de câncer, tais como na cabeça e no pescoço, pode ser utilizada isoladamente
Para casos de metástases ósseas dolorosas, a radioterapia provou-se eficaz para cerca de 70% dos pacientes.
A cirurgia é o principal método de tratamento de cânceres sólidos mais isolados e pode desempenhar um papel relevante no tratamento paliativo e no prolongamento da sobrevivência do paciente
É tipicamente uma parte importante do diagnóstico definitivo e do estadiamento do tumor, visto que biópsias são geralmente necessárias
A cirurgia de câncer localizado normalmente tenta remover toda a massa, em certos casos, juntamente com os nódulos linfáticos na área
Para alguns tipos de câncer a cirurgia elimina a doença por completo.
Os cuidados paliativos se referem ao tratamento que tenta fazer com que o paciente se sinta melhor e podem ou não pode ser combinados com uma tentativa de tratar o câncer
Os cuidados paliativos incluem medidas para reduzir o sofrimento físico, emocional, espiritual e psicossocial vivido por pessoas com câncer
Ao contrário do tratamento que visa matar diretamente as células cancerosas, o principal objetivo dos cuidados paliativos é melhorar a qualidade de vida da pessoa
Pessoas em todas as fases do tratamento de câncer devem ter algum tipo de cuidado paliativo para proporcionar conforto
Em alguns casos, as organizações profissionais de especialidades médicas recomendam que as pessoas e os médicos respondam ao câncer apenas com cuidados paliativos e não com a terapia dirigida a cura.
Os cuidados paliativos são muitas vezes confundidos com a chamada "unidade de cuidados paliativos", que é aplicada em pacientes terminais
Os cuidados paliativos na verdade tentam ajudar a pessoa a lidar com as necessidades imediatas e aumentar o seu conforto
Várias organizações médicas recomendam cuidados paliativos logo no início do diagnóstico para pessoas cujo câncer produz sintomas angustiantes (como dor, falta de ar, fadiga e náuseas) ou que precisam de ajuda para lidar com a sua doença
Em pessoas que têm a doença metastática quando diagnosticadas pela primeira vez, os oncologistas devem considerar iniciar os cuidados paliativos imediatamente
Além disso, um oncologista deve considerar um tratamento paliativo em qualquer pessoa que tiver uma estimativa de menos de 12 meses de vida, mesmo se continuar com o tratamento agressivo.
Várias terapias que utilizam a imunoterapia, que são estimulantes que ajudam o sistema imunológico a combater o câncer através do uso de substâncias modificadoras da resposta biológica, entraram em uso a partir de 1997 e continuam a ser uma área de pesquisa muito ativa.
A imunoterapia pode ser classificada em "ativa" e "passiva", de acordo com as substâncias utilizadas
Na imunoterapia ativa, substâncias estimulantes e restauradores das defesas do corpo são administradas com a finalidade de intensificar a resistência do organismo ao crescimento do tumor
Na imunoterapia passiva, anticorpos antitumorais são administrados para proporcionar uma maior capacidade imunológica de combate ao câncer
No entanto, a imunoterapia ainda é uma alternativa experimental, sendo que resultados mais conclusivos sobre sua eficácia e aplicabilidade clínica devem ser obtidos antes do seu uso em larga escala.
Tratamentos complementares e alternativos para o câncer são um grupo diverso de sistemas, práticas e produtos de assistência médica que não fazem parte da medicina convencional
A "medicina complementar" refere-se a métodos e substâncias utilizadas juntamente com a medicina convencional, enquanto que a "medicina alternativa" refere-se a compostos utilizados em substituição de métodos convencionais
Medicamentos complementares e alternativos para o câncer não foram rigorosamente estudados ou testados
Alguns tratamentos alternativos têm sido investigados e mostraram-se ineficazes, mas ainda continuam a ser comercializados e promovidos.
Foi observado que as células cancerosas eram de muitas maneiras reversões para células embrionárias, sendo assim foi hipotetizado que células cancerígenas deveriam reverter para a normalidade se elas fossem estimuladas a se diferenciarem.
No trabalho realizado por Sachs descobriu-se que certas leucemias podiam ser controladas fazendo com que suas células se diferenciassem e não se proliferassem
Uma dessas leucemias, APL, é causada por uma recombinação somática criando um novo fator de transcrição, cujas partes é um receptor de ácido retinoico
A expressão desse fator de transcrição em progenitores neutrófilos faz com que a célula se torne maligna
O tratamento de pacientes com APL usando ácido retinoico trans causa a remissão do APL em mais de 90% dos casos, desde que o ácido retinoico adicional seja capaz de afetar a diferenciação das células leucêmicas em neutrófilos normais.
O câncer tem uma reputação de ser uma doença mortal
Como um todo, cerca de metade das pessoas que recebem tratamento para câncer invasivo (excluindo o carcinomas e câncer de pele não melanoma) morrem em decorrência da doença ou do tratamento
A sobrevivência é pior no mundo em desenvolvimento, em parte porque os tipos de cânceres mais comuns nessas regiões são mais difíceis de tratar do que aqueles associados com o estilo de vida de países desenvolvidos
No entanto, as taxas de sobrevivência variam dramaticamente de acordo com o tipo de câncer e com o estágio de desenvolvimento da doença no momento em que ela é diagnosticada
Após o câncer ter metástase ou se propagar para além do seu local original, o prognóstico normalmente torna-se muito pior.
Aqueles que sobrevivem a um câncer têm cerca de duas vezes mais risco de desenvolver um segundo câncer primário em relação à taxa registrada naqueles que nunca foram diagnosticados com a doença
Acredita-se que o aumento do risco deve-se, principalmente, aos mesmos fatores de risco que produziram o primeiro câncer, em parte por conta do tratamento oferecido e a um melhor cumprimento de triagem.
Prever a sobrevivência de curto e longo prazo é difícil e depende de muitos fatores
Os fatores mais importantes são o tipo específico de câncer e a idade e a saúde geral do paciente
As pessoas que são frágeis, com muitos outros problemas de saúde, têm taxas de sobrevivência mais baixas do que as pessoas saudáveis
É improvável que centenários sobrevivam por mais de cinco anos após o diagnóstico, mesmo se o tratamento for bem sucedido
As pessoas que relatam uma maior qualidade de vida tendem a sobreviver mais tempo
As pessoas com baixa qualidade de vida podem ser afetadas por um transtorno depressivo maior e por outras complicações do tratamento contra o câncer e/ou a progressão da doença
Além disso, os pacientes com pior prognóstico podem relatar uma menor qualidade de vida, porque eles percebem corretamente que a sua condição médica pode ser fatal.
Pessoas com câncer, mesmo aquelas que caminham por conta própria, têm um risco aumentado de coágulos sanguíneos nas veias
A utilização de heparina parece melhorar a sobrevivência e diminuir o risco de formação de coágulos sanguíneos.
A prevenção é definida como uma série de medidas ativas que podem diminuir o risco de desenvolvimento de câncer
A grande maioria dos casos de câncer ocorrem devido a fatores de risco ambientais e muitos, se não todos, são escolhas de estilo de vida controláveis
Assim, o câncer é considerado uma doença em grande parte evitável
Entre 70% e 90% dos cânceres comuns são devidos a fatores ambientais e, portanto, possivelmente evitáveis.
Mais de 30% das mortes por câncer poderia ser prevenida evitando-se fatores de risco, como tabagismo, excesso de peso/obesidade, dieta insuficiente, sedentarismo, alcoolismo, doenças sexualmente transmissíveis e poluição do ar
No entanto, nem todas as causas ambientais são controláveis, tais como a ocorrência natural de radiação
Ademais, alguns tipos de câncer são causados por doenças genéticas hereditárias e, assim, não é possível evitar todos os casos da doença.
Enquanto muitas recomendações dietéticas têm sido propostas para reduzir o risco de câncer, a evidência para apoiá-las não é definitiva
Os fatores dietéticos primários que aumentam o risco são a obesidade e o consumo de álcool; uma dieta pobre em frutas e legumes e rica em carne vermelha também foi apontada, mas não confirmada
Um estudo de 2014 não encontrou uma relação entre consumo de frutas e vegetais e o câncer
O consumo de café está associado a um risco reduzido de câncer de fígado
Estudos têm relacionado o consumo excessivo de carne vermelha ou processada com o aumento do risco de câncer de mama, câncer de cólon e câncer de pâncreas, um fenômeno que poderia ocorrer devido à presença de substâncias cancerígenas em carnes cozidas em altas temperaturas
Isto foi confirmado em 2015 pela Agência Internacional de Pesquisa em Câncer, da Organização Mundial da Saúde (OMS), que determinou que a ingestão de carne processada (por exemplo, bacon, presunto, cachorros-quentes, salsichas) e, em menor grau, carne vermelha, foi associada a alguns tipos de câncer.
Recomendações dietéticas para a prevenção do câncer geralmente incluem uma maior ênfase em legumes, frutas, grãos integrais e peixes, além de se evitar o consumo de carne processada e vermelha (carne de vaca, porco, cordeiro), gorduras animais e carboidratos refinados.
O conceito de que medicamentos podem ser utilizados para prevenir o câncer é atraente e evidências apoiam a sua utilização em algumas circunstâncias definidas
Na população em geral, anti-inflamatórios não esteroides (AINEs) reduzem o risco de câncer colorretal, no entanto, devido aos efeitos secundários cardiovasculares e gastrointestinais, eles causam danos globais quando utilizados para a prevenção
A aspirina também reduz o risco de morte por câncer em cerca de 7%
Inibidores seletivos de COX-2 podem diminuir a taxa de formação de pólipos em pessoas com polipose adenomatosa familiar, no entanto estão associados com os mesmos efeitos adversos dos AINEs
A utilização diária de tamoxifeno ou raloxifeno tem sido demonstrada como eficaz na redução do risco de desenvolver câncer da mama em mulheres com alto risco
O benefício contra danos por inibidor da 5-alfarredutase, tal como finasterida, ainda não foi confirmado.
As vitaminas não foram provadas como eficazes na prevenção de câncer, embora os níveis sanguíneos de vitamina D estejam correlacionados com um risco aumentado do câncer
A hipótese de que esta relação é causal e que suplementação com vitamina D causa algum grau de proteção ainda não foi comprovada
A suplementação com beta-caroteno aumenta as taxas de câncer de pulmão em pessoas com alto risco
A suplementação com ácido fólico não previne o câncer de cólon e pode aumentar pólipos do cólon
Não está claro se a suplementação com selênio tem algum efeito.
Foram desenvolvidas vacinas que previnem a infecção por alguns vírus cancerígenos
A vacina contra hepatite B (Gardasil e Cervarix) diminui o risco de desenvolvimento de câncer cervical
A vacina contra o HPV previne a infecção pelo vírus da hepatite B e, consequentemente, diminui o risco de câncer de fígado
A administração de vacinas de papilomavírus humano e da hepatite B é recomendada quando tais recursos estão disponíveis.
Ao contrário de um diagnóstico motivado por sinais e sintomas médicos, o rastreio do câncer envolve esforços para encontrar a doença depois de ter sido formada, mas antes de apresentar quaisquer sintomas perceptíveis
O rastreio pode envolver exames físicos, de sangue, de urina, ou imagiologia médica.
O rastreio do câncer não está atualmente disponível para muitos tipos da doença e, mesmo quando tais testes estão disponíveis, eles podem não ser recomendados para todos os pacientes
A triagem universal ou o rastreio em massa envolve o rastreio de toda uma população, enquanto a triagem prescritiva analisa apenas os pacientes que conhecidamente têm maior risco de desenvolver a doença, tais como pessoas com histórico familiar de casos de câncer
Vários fatores são considerados para determinar se os benefícios do rastreio superam os riscos e os custos de triagem.
O rastreio do câncer do colo do útero é recomendado em mulheres de até 65 anos de idade que sejam sexualmente ativas e que tenham cérvix
O rastreio do câncer colorretal é indicado através de testes de sangue oculto nas fezes, sigmoidoscopia ou colonoscopia desde os 50 anos até os 75 anos de idade
Não há evidências suficientes para recomendar ou desaconselhar o rastreamento dos cânceres de pele, oral, de pulmão, ou de próstata em homens com menos de 75 anos de idade.
A mamografia para detecção do câncer de mama é recomendada a cada dois anos para mulheres entre 50 e 74 anos de idade
No entanto, uma análise de 2011 da Colaboração Cochrane chegou a conclusões ligeiramente diferentes em relação à triagem do câncer de mama, ao afirmar que a mamografia de rotina pode ser mais prejudicial do que benéfica.
Testes genéticos são recomendados para pessoas com alto risco de desenvolver determinados tipos de câncer
Portadores de tais mutações podem, em seguida aos exames genéticos, passarem a ser alvo de vigilância médica, de quimioprevenção ou de cirurgias preventivas para reduzir o risco de desenvolver a doença no futuro.
Em 2008, cerca de 12,7 milhões de casos de câncer foram diagnosticados (excluindo câncer de pele não melanoma e outros cânceres não invasivos) e em 2010 cerca de 7,98 milhões de pessoas morreram por causa da doença
O câncer causa aproximadamente 13% de todas as mortes anuais, sendo os tipos mais comuns: câncer de pulmão (1,4 milhão de mortes); câncer do estômago (740 mil mortes); câncer de fígado (700 mil mortes); câncer colorretal (610 mil mortes); e câncer da mama (460 mil mortes)
Este câncer invasivo é a principal causa de morte no mundo desenvolvido e a segunda principal causa de morte no mundo em desenvolvimento
Mais de metade dos casos ocorrem no mundo em desenvolvimento.
Foram registradas 5,8 milhões de mortes por câncer em 1990 e as taxas têm aumentado, principalmente devido a uma população mais longeva e por mudanças no estilo de vida no mundo em desenvolvimento
O fator de risco mais importante para o desenvolvimento de câncer é a velhice
Embora seja possível que o câncer surja em qualquer idade, a maioria das pessoas que são diagnosticadas com câncer invasivo tem em torno de 65 anos de idade
De acordo com o pesquisador Robert A
Weinberg: "Se vivêssemos tempo suficiente, mais cedo ou mais tarde todos nós teríamos câncer." A associação entre o envelhecimento e o câncer é atribuída a imunossenescência, erros acumulados no DNA ao longo da vida e alterações relacionadas com a idade no sistema endócrino
O efeito da envelhecimento sobre o câncer é complexo, com uma série de fatores, tais como danos no DNA.
Alguns tipos de câncer de crescimento lento são particularmente comuns
Estudos de autópsias na Europa e na Ásia têm mostrado que até 36% das pessoas não foram diagnosticadas com câncer de tireoide, aparentemente inofensivo, no momento da sua morte e que 80% dos homens desenvolvem câncer de próstata aos 80 anos.
Os três tipos de cânceres mais comuns na infância são leucemia (34%), tumores cerebrais (23%) e linfomas (12%)
Nos Estados Unidos o câncer afeta cerca de 1 em 285 crianças
As taxas de câncer infantil aumentaram 0,6% por ano no período entre 1975 e 2002 nos Estados Unidos e de 1,1% por ano entre 1978 e 1997 na Europa
As mortes por câncer infantil diminuíram pela metade desde 1975 nos Estados Unidos.
Em 2016, morreram em Portugal 27.900 pessoas vítimas de cancro, mais 3% do que no ano anterior
O cancro do pulmão foi o que mais matou, seguido do carcinoma do cólon e do reto, o da mama e o da próstata.
O câncer tem existido por toda a história da humanidade
O mais antigo registro escrito sobre o câncer é de cerca de 1600 aC, no Papiro de Edwin Smith do Egito Antigo e que descreve o câncer de mama
Hipócrates (cerca de 460 aC - 370 aC ) descreveu vários tipos de câncer, referindo-se a eles com a palavra grega καρκίνος karkinos (caranguejo ou lagostas)
Este nome vem da aparência da superfície de corte de um tumor maligno sólido, com "as veias esticadas por todos os lados como o animal caranguejo tem seus pés, de onde deriva seu nome"
Cláudio Galeno afirmou que "o câncer da mama é assim chamado por causa da semelhança imaginária de um caranguejo, em vista dos prolongamentos laterais do tumor e as veias dilatadas adjacentes." Aulo Cornélio Celso (cerca de 25 aC - 50 dC) traduziu karkinos para o latim cancer, que também significa caranguejo, e recomendou a cirurgia como tratamento
Galeno (século II dC) discordava do uso de cirurgia e recomendava purgantes
Estas recomendações em grande parte permaneceram por mil anos.
Nos séculos XV, XVI e XVII, tornou-se aceitável que os médicos dissecassem corpos para descobrir a causa da morte
O professor alemão Wilhelm Fabry acreditava que o câncer de mama era causado por um coágulo de leite em um duto mamário
O professor holandês Franciscus Sylvius, um seguidor de Descartes, acreditava que toda doença era o resultado de processos químicos e que o fluido linfático ácido era a causa do câncer
Seu contemporâneo Nicolaes Tulp acreditava que o câncer era um veneno que se espalhava lentamente e concluiu que era contagioso.
O médico John Hill descreveu o rapé de tabaco como a causa de câncer de nariz em 1761
Em 1775 o cirurgião britânico Percivall Pott escreveu um relatório onde dizia que um tipo específico de câncer no escroto era uma doença comum entre limpadores de chaminés
Com o uso generalizado do microscópio, no século XVIII, foi descoberto que o "veneno câncer" se espalhava a partir do tumor primário através dos gânglios linfáticos para outros locais do corpo ("metástase")
Este ponto de vista da doença foi formulado pela primeira vez pelo cirurgião britânico Campbell De Morgan entre 1871 e 1874.
Como o câncer é uma classe de doenças, é improvável que algum dia haverá uma "cura universal", visto que não haverá um único tratamento para todos os diferentes tipos de cânceres
Inibidores da angiogênese, outrora pensados como um potencial tratamento eficaz e aplicável a muitos tipos de cânceres, não têm mostrado a eficácia esperada no tratamento
É mais provável que os inibidores da angiogênese e outros terapêuticos para o câncer sejam utilizados em combinação com outros tratamentos complementares para reduzir a morbidade e a mortalidade da doença.
Tratamentos experimentais para o câncer são terapias que estão sendo estudadas para testar sua eficácia
Tipicamente, tais terapias são estudadas em ensaios clínicos para comparar o tratamento proposto com o melhor tratamento existente
Eles podem ser tratamentos inteiramente novos ou tratamentos que têm sido usados ​​com êxito em um determinado tipo de câncer e que agora estão sendo testados em outro tipo
Novos tratamentos estão sendo desenvolvidos, assim como novos testes de diagnóstico, para direcionar os medicamentos certos para os pacientes certos, com base na biologia individual de cada pessoa.
A melhor compreensão da biologia molecular e da biologia celular, devido à investigação do câncer, levou a uma série de novos tratamentos para a doença desde que o então Presidente dos Estados Unidos, Richard Nixon, declarou a "guerra contra o câncer", em 1971
Desde então, os Estados Unidos gastaram mais de 200 bilhões de dólares em pesquisas sobre a doença, incluindo recursos dos setores público e privado
Durante esse período, o país viu uma redução de 5% na taxa de mortalidade do câncer (ajustado ao tamanho e idade da população) entre 1950 e 2005.
A disputa pelos recursos financeiros que são necessários para conduzir experimentos científicos sobre o câncer tende a suprimir a criatividade, a cooperação e a assunção de riscos dos pesquisadores, justamente por favorecer pesquisas de baixo risco financeiro que focam em pequenos avanços incrementais, ao invés de pesquisas realmente inovadoras que possam descobrir terapias novas e radicalmente melhores para o tratamento da doença
Outras consequências da alta competitividade por recursos é o número substancial de publicações científicas cujos resultados não podem ser replicados, além de incentivos perversos no financiamento da investigação que acabam por estimular as instituições beneficiárias a crescer sem fazer investimentos suficientes em seu próprio corpo docente e/ou em suas instalações físicas.
Apesar de outras doenças (como a insuficiência cardíaca) poderem ter um prognóstico mais grave do que a maioria dos cânceres, esta é tema de medo generalizado e de tabus
O eufemismo "depois de uma longa batalha" ainda é comumente usado, refletindo um estigma em relação à doença
Essa crença profunda de que o câncer é necessariamente uma doença difícil ou mortal se reflete nos sistemas escolhidos pela sociedade para compilar estatísticas: as formas mais comuns de câncer — o câncer de pele não melanoma representa cerca de um terço de todos os casos de câncer no mundo, mas com pouca evidência de mortes — são excluídas das estatísticas de câncer especificamente porque são facilmente tratáveis e com alto índice de cura.
O câncer é uma doença que deve ser "combatida" para acabar com a "rebelião" do corpo; metáforas militares (metáforas de guerra) são particularmente comuns nas descrição de sintomas e patologias do câncer, levando a estigmatização do paciente, enfatizando o estado precário de saúde do paciente em relação a tomar ações imediatas e decisivas sobre o ocorrido, ou seja, levando o paciente a fazer sacrifícios para eliminar a ameaça à vida, em vez de incentivar a confiança nos tratamentos ou no auxílio de outrem e desencadeando a atribuição de culpa ao paciente
As metáforas militares também ajudam a racionalizar os tratamentos mais radicais e destrutivos.
Na década de 1970, ocorreu um tratamento alternativo para um câncer relativamente popular através de psicoterapia especializada, com base na ideia de que o câncer era causado por uma má atitude
Dizia-se que pessoas com uma "personalidade cancerígena" (depressivas, reprimidas, com auto-aversão e com medo de expressar suas emoções) manifestavam o câncer através do desejo subconsciente
O tratamento baseava-se em alterar a perspectiva do paciente sobre a vida e assim curar o câncer
​​Entre outros efeitos, esta crença permitia que a sociedade culpasse a vítima por ser "causadora" da doença ou ter "impedido" sua cura (por ser infeliz)
Além disso, este método aumentava a ansiedade dos pacientes, pois eles acreditavam erroneamente que as emoções naturais de tristeza, raiva ou medo encurtavam a vida
A ideia foi execrada pela escritora ativista Susan Sontag, que publicou o livro "Doença como Metáfora" (em inglês: Illness as Metaphor) enquanto se recuperava de um câncer da mama em 1978
​​Embora esta ideia atualmente seja considerada absurda, ela persiste, em parte, como uma forma reduzida de uma crença generalizada, mas incorreta, de que, deliberadamente, cultivar o hábito do "pensamento positivo" irá aumentar a sobrevida das pessoas
Esta noção é particularmente forte na cultura do câncer de mama.
Em 2007, os custos globais de câncer nos Estados Unidos - incluindo o tratamento e as despesas da mortalidade indiretas (como a perda de produtividade no trabalho) - foram estimados em 226,8 bilhões de dólares
Em 2009, 32% dos hispânicos e 10% das crianças de até 17 anos não tinham plano de saúde; "minorias étnicas são substancialmente mais propensas a serem diagnosticadas com câncer em um estágio avançado, quando o tratamento pode ser mais extenso e mais caro."
A Europa gasta cerca de 100 bilhões de euros por ano com pacientes cancerígenos, de acordo com um estudo sobre o impacto econômico da doença na região - divulgado no Congresso da Sociedade Europeia de Oncologia Médica de 2012, realizado em Viena, na Áustria.
A cada ano, o câncer absorve aproximadamente 2 trilhões de dólares da economia mundial, em termos de perda de produção e custos de tratamentos, o que equivale a cerca de 1,5% do produto interno bruto (PIB) global (dados de 2015).
A oncologia veterinária, que concentra-se principalmente em cães e gatos, é uma especialidade crescente nos países desenvolvidos e pode oferecer aos animais as principais formas de tratamento dado a humanos, tais como cirurgias e radioterapia.
Os tipos comuns de câncer diferem, mas a incidência da doença parece ser tão elevada em animais de estimação quanto em seres humanos
Animais, geralmente roedores, são frequentemente utilizados em pesquisas sobre câncer
Ademais, estudos de cânceres naturais registrados em animais de maior porte podem beneficiar na investigação do câncer humano.
Em animais não humanos, foram detectados alguns tipos de cânceres transmissíveis, onde a doença se espalha entre os indivíduos através das próprias células tumorais
Este fenômeno é visto em cães com sarcoma de Sticker, também conhecido como tumor venéreo transmissível canino, bem como em tumores faciais em diabos-da-tasmânia.
 Tedros Adhanom
Organização Mundial da  ou de  Saúde (em inglês: World Health Organization - WHO) é uma agência especializada em saúde, fundada em 7 de abril de 1948 e subordinada à Organização das Nações Unidas
Sua sede é em Genebra, na Suíça
O diretor-geral é, desde julho de 2017, o etíope Tedros Adhanom.
A OMS tem suas origens nas guerras do fim do século XIX (México, Crimeia)
Após a Primeira Guerra Mundial, a SDN criou seu comitê de higiene, que foi o embrião da OMS.
Segundo sua constituição, a OMS tem por objetivo desenvolver ao máximo possível o nível de saúde de todos os povos
A saúde sendo definida nesse mesmo documento como um «estado de completo bem-estar físico, mental e social e não consistindo somente da ausência de uma doença ou enfermidade.»
O Brasil tem participação fundamental na história da Organização Mundial da Saúde, criada pela ONU para elevar os padrões mundiais de saúde
A proposta de criação da OMS foi de autoria dos delegados do Brasil, que propuseram o estabelecimento de um "organismo internacional de saúde pública de alcance mundial"
Desde então, Brasil e a OMS desenvolvem intensa cooperação.


Além de coordenar os esforços internacionais para controlar surtos de doenças, como a malária, a tuberculose, a OMS também patrocina programas para prevenir e tratar tais doenças
A OMS apoia o desenvolvimento e distribuição de vacinas seguras e eficazes, diagnósticos farmacêuticos e medicamentos, como por meio do Programa Ampliado de Imunização
Depois de mais de duas décadas de luta contra a varíola, a OMS declarou em 1980 que a doença havia sido erradicada
A primeira doença na história a ser erradicada pelo esforço humano
A OMS tem como objetivo erradicar a pólio entre os próximos anos.
A OMS supervisiona a implementação do Regulamento Sanitário Internacional, e publica uma série de classificações médicas, incluindo a Classificação Estatística Internacional de Doenças (CID), a Classificação Internacional de Funcionalidade, a Incapacidade e Saúde (CIF) e a Classificação Internacional de Intervenções em Saúde (ICHI)
A OMS publica regularmente um Relatório Mundial da Saúde, incluindo uma avaliação de especialistas sobre a saúde global.
Além disso, a OMS realiza diversas campanhas de saúde - por exemplo, para aumentar o consumo de frutas e vegetais em todo o mundo e desencoraja o uso do tabaco
Cada ano, a organização escolhe o Dia Mundial da Saúde.
OMS realiza a pesquisa em áreas sobre doenças transmissíveis, a doenças não-transmissíveis, a doenças tropicais, e outras áreas, bem como melhorar o acesso à pesquisa em saúde e a literatura em países em desenvolvimento, como através da rede HINARI
A organização conta com a experiência de muitos cientistas de renome mundial, como o Comitê de Especialistas da OMS sobre Padronização Biológica, o Comitê de Especialistas da OMS para a Hanseníase e o Grupo de Estudos sobre Educação Interprofissional & Prática Colaborativa.
A OMS faz várias pesquisas em diversos países, em uma delas entrevistou 308 mil pessoas com 18 anos, 81.000 pessoas com idade entre 18-50 anos de 70 países, conhecido como Study on Global Ageing and Adult Health (SAGE) e a WHO Quality of Life Instrument (WHOQOL).
A OMS também trabalhou em iniciativas globais como a Global Initiative for Emergency and Essential Surgical Care a Guidelines for Essential Trauma Care focado no acesso das pessoas às cirurgias
Safe Surgery Saves Lives sobre a segurança do paciente em tratamento cirúrgico.
A Constituição da OMS afirma que seu objetivo "é a realização para todas as pessoas do mais alto nível possível de saúde." A bandeira possui o Bordão de Asclépio como um símbolo para a cura.
A Organização Mundial de Saúde (OMS) é uma das agências originais das Nações Unidas, sendo que sua constituição formal entrou em vigor no primeiro Dia Mundial da Saúde, (7 de abril de 1948), quando foi ratificada pelo 26º Estado-Membro
Jawaharlal Nehru, um grande lutador pela liberdade da Índia, deu um parecer para começar a OMS
Antes dessas operações, bem como as restantes atividades da Organização Mundial de Saúde da Liga das Nações, estavam sob o controle de uma Comissão Provisória após uma Conferência Internacional de Saúde no verão de 1946
A transferência foi autorizada por uma resolução da Assembleia Geral das Nações Unidas
O serviço epidemiológico dos franceses da Office International d'Hygiène Publique foi incorporado à Comissão Interina da Organização Mundial de Saúde em 1 de janeiro de 1947.
A OMS é composta por 194 Estados-membros, onde se incluem todos os Estados Membros da ONU exceto o Liechtenstein e inclui dois não-membros da ONU, Niue e as Ilhas Cook
Os territórios que não são Estados-membros da ONU podem tornar-se Membros Associados (com acesso total à informação, mas com participação e direito de voto limitados) se assim for aprovado em assembleia: Porto Rico e Tokelau são Membros Associados
Existe também o estatuto de Observador; alguns exemplos incluem a Palestina (um Observador da ONU), a Santa Sé, a Ordem Soberana e Militar de Malta, o Vaticano (um observador não-membro da ONU), Taipé Chinesa (uma delegação convidada) e Taiwan.
Os Estados-membro da OMS nomeiam delegações para a Assembleia Geral da Saúde Mundial, que é o corpo decisor supremo
Todos os Estados-membros da ONU são elegíveis para pertencer à OMS e, de acordo com o afirmado no website da OMS, "Podem ser admitidos outros países como membros sempre que a sua aplicação seja aprovada por uma maioria simples de votos na Assembleia Geral da Saúde Mundial".
A Assembleia Geral da OMS reúne-se anualmente em Maio
Para além da nomeação do Director-Geral a cada cinco anos, a Assembleia analisa as políticas de financiamento da Organização e revê e aprova o orçamento proposto
A Assembleia elege 34 membros, tecnicamente qualificados na área da saúde, para a Direcção Executiva durante um mandato de três anos
As principais funções desta direcção serão as de levar a cabo as decisões e regras da Assembleia, de aconselhá-la e, de uma forma geral, auxiliar e facilitar a sua missão.
A OMS é financiada por contribuições dos Estados-membros e doadores vários
Nos últimos anos, o trabalho da OMS tem envolvido de forma crescente a colaboração com entidades externas; existem actualmente cerca de 80 parcerias com organizações não-governamentais e indústria farmacêutica, bem como com fundações como a Fundação Bill e Melinda Gates e a Fundação Rockefeller
Com efeito, as contribuições voluntárias para a OMS por governos locais e nacionais, fundações e ONGs, outras organizações da ONU e o próprio sector privado excedem actualmente as contribuições estabelecidas (quotas) pelos 193 Estados-membros.
Além dos Estados Observadores e entidades listadas acima, os observadores de organizações a Cruz Vermelha e da Federação Internacional da Cruz Vermelha entraram em "relações oficiais" com a OMS e são convidados como observadores
Na Assembleia Mundial da Saúde eles atuam como representantes, igual aos de outros países.
Que cumpra os seus objectivos através das seguintes funções essenciais:
Estas funções básicas estão descritas no Décimo Primeiro Programa Geral de Trabalho, que estabelece o quadro para o programa de trabalho, orçamento, recursos e resultados em toda a organização
Intitulado "Empreender para a Saúde", o programa abrange o período de dez anos, de 2006 a 2015.
Ásia é o maior dos continentes, tanto em área como em população
Abrange um terço das partes sólidas da superfície da Terra e é responsável por abrigar quase três quintos da população mundial
A Ásia faz fronteira no lado ocidental com a África e com a Europa, e no lado oriental com o oceano Pacífico, a Oceania e, em menor proporção, com a América do Norte, pelo Estreito de Bering
O ponto extremo setentrional do continente está localizado no oceano Glacial Ártico
Mas na parte meridional, a Ásia chega ao seu final na região mais quente dos trópicos, nas imediações da linha do equador
Na Ásia são encontradas algumas das montanhas mais altas do mundo; os rios mais extensos; os maiores desertos, planícies e planaltos; as selvas e florestas mais densas
A altitude máxima e a mínima está localizada na Ásia
O monte Everest, a altitude máxima do planeta, está localizada a 8 848 m acima do nível do mar; ao longo da linha fronteiriça da República Democrática Federal do Nepal com a região autônoma chinesa do Tibete
O litoral do mar Morto, a planície de menor altitude do mundo, estão localizadas a 396 m abaixo do nível do mar, na região fronteiriça do Estado de Israel com o Reino Hashemita da Jordânia.
Dos 55 países são encontradas algumas das maiores e menores nações do mundo, tanto em área como em população
A Federação Russa, cuja parte europeia corresponde a um quarto de seu território, tem três quartos de território na parte asiática, sendo duas vezes maior que os Estados Unidos e o Canadá juntos
Mas três nações asiáticas — Reino do Barém, República de Singapura e República das Maldivas — juntas corresponderiam à extensão territorial da ilha de Marajó
A população da República Popular da China ou da República da Índia é maior do que as populações dos continentes norte-americano e sul-americano somadas
Porém, aproximadamente dois terços dos países da Ásia tem uma população pequena em relação à da Região Metropolitana de São Paulo
O povo é enormemente diferente em árvores genealógicas, práticas ou comportamentos habituais, idiomas, crenças de religião o modus vivendi
A civilização asiática teve início há mais de 4 000 anos, muito antes de começar no mundo ocidental, em termos de atividades econômicas, manifestações culturais e desenvolvimento da ciência
O povo da Ásia fundou as cidades mais antigas, estabeleceu os sistemas de leis mais antigos e criou a figura dos agricultores e comerciantes mais antigos
Os cidadãos da Ásia foram os inventores da escrita e criaram as primeiras literaturas
Os fundadores de todas as religiões mais relevantes do mundo foram asiáticos: Buda, Confúcio, Jesus Cristo e Maomé
Os asiáticos também foram os inventores do papel, da pólvora, da bússola e do tipo móvel.
As nações asiáticas têm vários sistemas de governo
Os comunistas são responsáveis pelo governo da China e de alguns outros países
Os monarcas governam os reinos da Arábia Saudita e a Tailândia, por exemplo
Os xeques são os controladores do Reino do Barém, do Estado do Catar e dos Emirados Árabes Unidos
Dos países da Ásia que são seguidores dos princípios da democracia, podemos citar Israel e Japão
Líderes das forças armadas passaram a exercer o controle de muitas nações da Ásia em períodos de conturbação
Os sultões de nove estados malaios ocupam a função no cargo de chefe supremo da nação
A população asiática é muito diversificada quanto tudo o que se refere ao continente
Durante o século XVI, a economia asiática declinou-se, enquanto o mundo ocidental teve rápido progresso
As nações do Oeste da Europa foram os conquistadores da parte predominante da Ásia dos século XVI até o século XIX
A economia defasada entre o continente asiático e o mundo ocidental teve aumento ainda mais na época da colonização vinda da Europa
Os cidadãos da Europa e dos Estados Unidos foram responsáveis pelo desenvolvimento do sistema industrial e tiveram o início da utilização de máquinas e de outros recursos na atividade agrícola
Isto tornou possível a criação de novos empregos, o aumento produtivo, e a melhoria do nível de vida
Mas a maior parte dos países da Ásia não se desenvolveram industrialmente
Continuaram sendo países de economia baseada na agricultura, e seus agricultores empregavam na utilização de ferramentas, manuais e métodos nada modernos
Ao mesmo tempo, a explosão populacional — que ainda está a ocorrer — aumentou de modo incrível a população asiática como do mundo ocidental
Mais e mais produtos alimentícios, ocupações empregatícias, instituições de ensino, além de outras coisas básicas, tornavam-se necessidade de acordo com o aumento populacional
O mundo ocidental, por causa do desenvolvimento de sua economia, teve mais recursos do que o continente asiático para enfrentar os problemas que foram as consequências da explosão demográfica.
Quase toda a Ásia colonial teve sua independência conquistada em meados do século XX
A partir de então, muitos cidadãos da Ásia têm trabalhado para ter o padrão de vida elevado, incentivando as atividades industrial, a agrícola, e diminuindo o crescimento da população
As disputas políticas já dificultaram essa tarefa
Após a Segunda Guerra Mundial (1939-1945),o continente asiático foi convertido no centro das lutas entre países que adotam o comunismo como sistema de governo e países que utilizam o capitalismo como sistema econômico
Na maioria dos países da Ásia, a luta começou, quando os comunistas tiveram o desejo de ocupar o poder executivo do novo país independente
Fora disso, outras disputas que não se relacionam com os políticos do comunismo foram provocadores de brigas entre diversos grupos no continente asiático
Sendo assim, a Ásia, quase de modo ininterrupto, enfrenta conflitos militares e civis e ameaças bélicas enquanto tenta a solução de todos os problemas.


O termo "Ásia" foi recebido pela língua portuguesa através do latim, a partir do grego antigo Ασία
O primeiro registro do topônimo é encontrado em Heródoto: em cerca de 440 a.C., aquele historiador grego mencionava a uma divisão do mundo em três partes, cujos nomes referiam-se a personagens da mitologia grega: a Europa, em homenagem à ninfa oceânida ou à filha de Agenor; a Líbia (que é como os gregos antigos chamavam a África), em homenagem à mãe de Agenor; e a Ásia (Ασία), em homenagem a outra ninfa oceânica, mais conhecida como Clímene
À época, o termo Ásia servia para designar a atual Ásia Menor (Anatólia) ou, por oposição ao mundo grego ou egípcio, o Império Aquemênida
O termo Ασία, por sua vez, pode ser derivado do acádio (w)aṣû(m), que significa "subir", "sair", com respeito ao nascer do sol.
Outra explicação para a etimologia refere-se a Homero, que menciona na Ilíada um certo Ásio, aliado dos troianos e filho de Hírtaco
O nome "Ásio" proviria de Assuwa, uma confederação de Estados do século XIV a.C
localizada no oeste da Anatólia e cujo nome teria origem no hitita assu, que significa "bom".
O gentílico de "Ásia" é asiático (ou asiano, asiânico, ásio).
A história da Ásia pode ser entendida como a história coletiva de várias regiões litorâneas distintas - o leste asiático, a Ásia meridional e o Oriente Médio - ligadas pela estepe eurasiática no interior do continente
Cidades, depois Estados e impérios surgiram naquelas áreas.
A periferia costeira foi o berço de algumas das civilizações mais antigas do mundo
Cada uma daquelas regiões desenvolveu uma civilização ao longo de vales férteis de rios
As civilizações da Mesopotâmia, do vale do Indo e da China tinham muito em comum e provavelmente trocaram tecnologia e ideias, como a matemática e a roda
Outros avanços, como a escrita, desenvolveram-se independentemente em cada região.
A estepe era habitada por nômades a cavalo que, a partir das estepes centrais, alcançavam qualquer parte do continente asiático
A primeira expansão conhecida das estepes para a costa foi a dos indo-europeus, que levaram sua família linguística ao Oriente Médio, à Índia e às fronteiras da China
A parte norte do continente, correspondente à Sibéria, permaneceu inacessível aos nômades, devido a suas densas florestas e à tundra, e manteve-se pouco habitada.
A estepe central e a periferia são separadas por cordilheiras e desertos
O Cáucaso, os Himalaias, o deserto de Karakum e o deserto de Gobi representavam barreiras que os cavaleiros das estepes ultrapassavam com dificuldade
Embora os habitantes das cidades fossem mais avançados tecnológica e culturalmente, havia pouco que pudessem fazer para defender-se militarmente das hordas a cavalo provenientes das estepes
Entretanto, os nômades que conquistaram Estados na China, Índia e Oriente Médio terminaram por adaptar-se e integrar-se às sociedades locais, culturalmente mais fortes.
Muitas grandes civilizações e culturas existiram no continente asiático
O Judaísmo e o Cristianismo foram fundados na Palestina
A cultura da antiga Israel foi estabelecida no segundo milênio a.C
Alexandre, o Grande, conquistou o território que vai da atual Turquia ao subcontinente indiano no século IV a.C
O Império Romano posteriormente controlaria partes da Ásia ocidental
Sucederam-se na Pérsia as dinastias aquemênida, selêucida, parta e sassânida
Muitas civilizações antigas foram influenciadas pela Rota da Seda, que ligava a China, a Índia, o Oriente Médio e a Europa
O hinduísmo e o budismo, que tiveram início na Índia, também foram uma influência importante no sul e no leste da Ásia.
O Califado islâmico e outros Estados muçulmanos tomaram o Oriente Médio a partir do século VII e posteriormente se expandiram para o subcontinente indiano e para a Insulíndia
As Cruzadas, tentativas da Europa cristã de retomar dos muçulmanos a Terra Santa, sucederam-se a partir do século XII
O Império Mongol conquistou boa parte da Ásia no século XIII, estendendo-se da China à Europa
O Império Russo começou a expandir-se em direção à Ásia no século XVII, até controlar a Sibéria e a maior parte da Ásia Central em fins do século XIX
O Império Otomano controlou a Turquia e o Oriente Médio a partir do século XVI
No século XVII, os manchus conquistaram a China e estabeleceram a dinastia Qing, que declinou no século XIX e foi derrubada em 1912.
Diversas potências europeias apossaram-se de partes da Ásia, como a Índia britânica, a Indochina francesa e Macau e Goa, que estiveram sob controle português
No século XIX, decorreu o chamado "Grande Jogo" entre o Império Russo e o Império Britânico, uma disputa pelo controle da Ásia Central
No século XX, o Japão expandiu-se para a China, a Coreia e o sudeste asiático durante a Segunda Guerra Mundial
Após o conflito, muitos países do continente tornaram-se independentes das potências europeias
Durante a Guerra Fria, a porção norte da Ásia era comunista, controlada pela União Soviética e pela República Popular da China, enquanto que os aliados ocidentais formaram pactos como CENTO e SEATO
Representantes dos blocos capitalista e comunista enfrentaram-se em confrontos como a Guerra da Coreia, a Guerra do Vietnã e a invasão soviética do Afeganistão
O conflito árabe-israelense dominou a maior parte da história recente do Oriente Médio
O colapso da União Soviética, em 1991, deu origem a vários países independentes na Ásia Central.
A área do continente asiático é superior a 44,5 milhões de quilômetros quadrados, correspondentes a quase um terço de todas as terras emersas do nosso planeta
Só no continente moram aproximadamente 4 000 milhões  de habitantes, número que supera quase 50% da população do mundo, como resultado da densidade demográfica fora do comum e superior a 70 habitantes por quilômetro quadrado.
Essa vasta área territorial é atravessada por três paralelos: no ponto extremo setentrional, em território russo, pelo Círculo Polar Ártico; na parte meridional, pelo Trópico de Câncer; e, no centro do território arquipelágico indonésio, pela linha do Equador.
Localizada quase totalmente no hemisfério setentrional, com somente uma porção dos territórios insulares do sul indonésio ocupando o hemisfério meridional, o continente asiático torna-se extenso de 10 graus de latitude ao sul da linha do Equador a 80 graus de latitude ao norte dessa mesma linha divisória
Distribuindo-se por inteiro pelo hemisfério leste, torna-se extenso de 25 para além de 180 graus de longitude a leste do Meridiano de Greenwich.
Por ser composto de uma grande extensão continental da parte setentrional para a parte meridional, a Ásia preenche espaço de todas as áreas de clima do hemisfério setentrional: equatorial, tropical, temperada e polar
Tornando-se extenso com grandiosidade também da parte oriental para a parte ocidental, é atravessada por 11 fusos horários.
Faz fronteira no lado setentrional, com o oceano Glacial Ártico; no lado meridional, com o oceano Índico; no lado oriental, com o oceano Pacífico; e no lado ocidental, com os montes Urais, com o rio Ural e com os mares Cáspio, com o Negro, com o Mediterrâneo e com o Vermelho.
O continente asiático é, desse modo, o maior de todos, onde se podem ser encontradas as mais diversos panoramas paisagísticos e tipologias de clima, como também diversidade de etnias e padronizações de desenvolvimento da economia.
A Ásia apresenta características contrastantes: enormes terras baixas de aluvião e de litoral e grandes formações planálticas com cordilheiras muito altas, que se tornam extensas por uma vasta área centro-meridional, entre os territórios nacionais turco e indonésio
Isso tudo faz do continente asiático o único com aproximadamente 1 0000 metros de cota altimétrica média
As montanhas de maior altitude estão localizadas na cordilheira do Himalaia, mas existem outras que se espalham por toda a área territorial, situando-se no continente asiático as 18 montanhas mais altas do mundo.
O relevo asiático é caracterizado pela apresentação de seus contrastes de extremidade altimétrica:
Algumas regiões banhadas pelas águas salgadas do oceano Pacífico fazem parte do Círculo de Fogo, ou seja, por causa de sua formação geológica ocorrida há pouco tempo estão sujeitas a erupções vulcânicas e a abalos sísmicos
É o caso do arquipélago japonês e da Indonésia.
Algumas formações planálticas são altíssimas e são intercaladas às cadeias de montanhas, como é o caso do Pamir e do Tibete, contrastando com outros de maior antiguidade, de menores altitudes, como os da Armênia, do Decã.
As planícies de rios da Ásia são revestidas com depósito aluvial trazido pelos acidentes geográficos fluviais que as percorrem e que se dirigem de modo principal para as águas salgadas dos oceanos Índico e Pacífico
As principais planícies de rios são a Indo-gangética (Índia), a Mesopotâmica (Iraque), a Siberiana (Rússia) e as dos rios Yang-tsé (China) e Mekong (Vietnã).
A Ásia projeta, dirigindo-se aos oceanos adjacentes, várias porções peninsulares, sendo as mais relevantes a da Anatólia, a Arábica, a Hindustânica, a da Indochina e a da Coreia.
A vasta extensão territorial e, portanto, as diferenças de latitude, a presença alternada de áreas baixas e elevadas, a grande influência das massas de ar e ainda a continentalidade e a maritimidade trazem para o continente grande variedade de tipos de clima e, consequentemente, de formações vegetais.
Nas terras situadas no extremo norte predomina o clima polar, que vai se tornando mais ameno em direção ao sul
O centro do continente, por situar-se distante de influências marítimas e, em parte, devido à altitude do relevo, que bloqueia a passagem dos ventos oceânicos, é dominado pelo clima temperado continental, que alterna verões de elevadas temperaturas com invernos muito frios
Já o temperado oceânico, ocupando grandes extensões do continente, sofre variações em função da altitude do relevo, da latitude e da interioridade.
Mais para o sul, à retaguarda das grandes cordilheiras, que impedem a passagem dos ventos úmidos do oceano, encontram-se vastas extensões dominadas por clima semi-árido e clima árido, formando uma extensa faixa de desertos
A Ásia abriga a maioria dos desertos existentes na Terra: da Arábia (Arábia Saudita), da Síria, de Thal (Paquistão), do Thar (ou Grande Deserto Indiano), de Lut (ou deserto do Irã), de Gobi (Mongólia), de Taklamakan (China), Caracum (Turcomenistão), Carmânia (Irã), da Judeia (Israel), de Negueve (Israel).
No litoral da Ásia Ocidental surge uma faixa estreita de clima do tipo mediterrânico, enquanto nos arquipélagos do sul do continente, nas proximidades do Equador, aparecem climas de tipo quente: equatorial e tropical.
Entre todos os tipos de clima da Ásia, no entanto, o que mais diretamente influi nas condições de vida locais, sobretudo orientando as atividades agrícolas, é o tropical de monções
Abrangendo as regiões mais populosas do continente, estende-se pelas planícies costeiras da Índia e do sudeste e leste da China, com violentas chuvas durante o verão
Caracteriza-se pela atividade dos ventos, conhecidos como monções, que sopram do Índico e do Pacífico para o continente durante o verão, e do interior da Ásia para esses oceanos durante o inverno.
A ocorrência de monções se deve ao fato de que as terras continentais aquecem-se e esfriam mais rapidamente do que as águas oceãnicas
Durante o verão, o interior da Ásia, ao esquentar-se, forma uma área de baixa pressão, que contrasta com as altas pressões dos oceanos, provocando o deslocamento de ventos úmidos do mar para terra
Esses ventos são as monções de verão
No inverno, ocorre o inverso: os oceanos estão mais quentes do que o continente, formando áreas de baixa pressão e atraindo os ventos continentais
São as monções de inverno.
As regiões montanhosas, independentemente de sua localização geográfica, apresentam temperaturas muito baixas, em razão da altitude.
Tanto as chuvas abundantes da região influenciada pelos climas equatorial e tropical quanto a grande quantidade de neve derretida das altas montanhas favorecem a existência de grandes rios, que correm em quase todas as direções do continente asiático
Podemos destacar:
A Ásia apresenta poucos lagos, embora de grande extensão, como o Baikal e o Balkhash, localizados na Rússia
Se os lagos existem em pequeno número, os mares asiáticos aparecem com muito mais destaque: mar Vermelho, que limita as costas africanas e asiáticas; Mar da Arábia; a sudeste, mar da China Meridional, mar da China Oriental, Mar de Andamã e mar Amarelo; os mares da Indonésia: de Java, de Timor, de Banda, de Celebes; a nordeste, os mares de Okhotsk, do Japão e de Bering
No limite com a Europa, aparece o maior mar fechado do mundo, o mar Cáspio.
Como as formações vegetais dependem do tipo de solo e principalmente do clima, a Ásia apresenta muitas variedades vegetais, ainda que parcialmente destruídas ou alteradas pela milenar ocupação humana.
No extremo norte do continente, junto ao pólo, não há condições para a existência de vegetação, porém mais ao sul, na planície Siberiana, começam a surgir formações de tundra
Ainda rumo ao sul, à medida que o clima polar se torna menos intenso e o frio se estende por um número menor de meses, aparece a vasta região da taiga, quase integralmente pertencente à Rússia.
O maior destaque, entretanto, está nas estepes, que ocupam grandes extensões da Ásia Central, aparecendo em áreas de clima temperado continental.
Os arquipélagos situados na Ásia Meridional apresentam-se recobertos por florestas equatoriais e tropicais, não muito diferentes das que existem na Amazônia brasileira
Essas formações podem ser observadas também no centro-sul, onde igualmente se verifica a presença de savanas, em que a vegetação herbácea é dominante, apresentando arbustos e árvores em associações pouco densas, como o jângal na Índia.
Registra-se ainda a ocorrência de florestas temperadas em extensões consideráveis no Extremo Oriente e de vegetação xerófita nas áreas desérticas ou semi-áridas do continente.
Considerando que uma região geográfica é uma área mais ou menos definida, caracterizada por determinados aspectos físicos e humanos, seria possível encontrar dezenas delas no continente e até mesmo algumas em um mesmo país
Por esse motivo, e para facilitar o estudo e a compreensão das características e dos problemas políticos e sociais de um continente tão vasto, vamos simplificar sua divisão estudando-o através de seis grandes regiões geográficas
São elas: o Oriente Médio, o subcontinente indiano, o sudeste asiático, o centro-leste, o Extremo Oriente e a parte asiática da Comunidade de Estados Independentes.
Essa área, que se estende desde a Turquia até o Afeganistão, apresenta como característica física dominante o predomínio do clima seco, o que resulta na existência de desertos
Como característica populacional, destaca-se a ocupação por brancos e uma das densidades demográficas mais baixas do continente.
O Oriente Médio reúne 16 países independentes, muito importantes pelas notáveis reservas de petróleo que alguns possuem e por sua posição estratégica, já que essa região é o elo de ligação entre Europa, Ásia e África
É uma área constantemente agitada por conflitos de origens diversas: o antagonismo histórico entre esses países; a grande mescla de seitas e religiões (islamismo, cristianismo, judaísmo); os sistemas político-econômicos vigentes, levando ao alinhamento com os Estados Unidos ou com a Rússia.
Apesar de todas essas diferenças, há muitas semelhanças, principalmente em nível econômico: os países são todos subdesenvolvidos (à exceção de Israel, Catar e Emirados Árabes Unidos) e neles a atividade industrial de transformação é bastante escassa, predominando pequenas indústrias têxteis e alimentares
A agricultura é praticada nas poucas regiões onde não ocorrem desertos
Os principais produtos agrícolas são trigo, cevada, milho, arroz e cítricos, cultivados sobretudo na Turquia, Síria, Líbano, Israel e Iraque
A pecuária restringe-se ao pastoreio nômade de camelos, cabras e ovelhas.
O grande destaque econômico do Oriente Médio, em nível internacional, é a exploração do petróleo, que tem sido responsável pela entrada de lucros fabulosos nos países produtores
Os lucros do petróleo, entretanto, pouco têm contribuído para atenuar o elevado grau de subdesenvolvimento da maior parte dos países dessa área, acentuando, ao contrário, a enorme disparidade na distribuição de renda.
Em 1960, Arábia Saudita, Iraque, Irã, Cuaite e Venezuela criaram a Organização dos Países Exportadores de Petróleo (OPEP), à qual se filiaram durante as décadas de 1960 e 1970: Catar e Abu Dabi (um dos Emirados Árabes Unidos), Indonésia (país da Insulíndia), Equador, Líbia, Argélia, Nigéria e Gabão
Liderada pelos países árabes, a OPEP tem como objetivo controlar o preço do petróleo
Em 1973, essa organização multiplicou o preço do barril de petróleo, provocando uma série de desajustes econômicos nos países importadores, que ficou conhecida como crise do petróleo
Diversos desses países passaram a explorar jazidas até então consideradas não-rentáveis e desenvolveram fontes alternativas de energia
Em virtude disso, a OPEP foi obrigada mais tarde a reduzir o preço do barril de petróleo, cujo consumo retraiu.
A maior parte do Oriente Médio é ocupada pelos países árabes
Localizados na Península Arábica e vizinhanças, são nações fundamentalmente agropastoris, caso do Iêmen, enquanto na Arábia Saudita, Cuaite, Emirados Árabes Unidos, Iraque, Omã, Catar e Barém o petróleo é a grande riqueza nacional, impondo uma paisagem de torres e oleodutos onde durante séculos houve apenas um deserto sem proveito econômico.
Há ainda o Líbano e a Síria, países cuja agricultura e indústria são mais desenvolvidas, muito embora o Líbano, arrasado por conflitos intermináveis, sobreviva com grandes dificuldades
A Jordânia difere de todos por sua atividade mineradora caracterizada pela exploração de fosfato e mármore.
Entre os países não-árabes, há Israel, a nação mais industrializada e desenvolvida do Oriente Médio, além de três grandes Estados - Turquia, Irã e Afeganistão
A indústria turca está se desenvolvendo rapidamente, graças aos incentivos governamentais e às riquezas minerais do país, como carvão, ferro, manganês, crômio e cobre
A economia iraniana baseia-se principalmente na extração e comercialização do petróleo, enquanto a agropecuária é a base econômica do Afeganistão.
No sul da Ásia encontra-se a grande Península Hindustânica, que avança sobre o Oceano Índico
Apresentando a Cordilheira do Himalaia ao norte, o relevo da região é dominado pelo vasto Planalto do Decã, e, entre este e as montanhas, pela grande Planície Indo-gangética, percorrida pelo Indo e pelo Ganges, rios de grande volume de água
A região é tipicamente tropical e os verões são marcados pela chegada dos ventos monçônicos.
Índia, Paquistão e Bangladesh são os países centrais da região; em meio à Cordilheira do Himalaia, localizam-se ainda os pequenos reinos do Nepal e do Butão
A sudeste da Índia está Sri Lanka, país antigamente conhecido como Ceilão, e a sudoeste, o arquipélago das Maldivas.
Aproximadamente metade do território da Índia é recoberto por plantações de arroz, que se beneficiam do clima monçônico; cultivam-se em grande escala também trigo e milho, além de algodão, chá, juta e outros produtos
A pecuária, apesar do enorme rebanho bovino, não tem grande importância econômica.
Em termos mineralógicos, a Índia possui grandes depósitos de ferro, além de produzir a maior parte do petróleo que consome
Possui ainda abundantes reservas de carvão, mica, manganês, alumínio e outras de menor importância.
Dentre os países asiáticos, é dos que apresentam maior grau de industrialização, dispondo de algumas grandes áreas industriais, como a região de Bombaim, Calcutá, no leste, a de Punjab-Nova Délhi, no norte, e a Madras, no sul
Os ramos industriais mais importantes são o têxtil, o alimentar, o mecânico, o siderúrgico e o químico.
Além disso, a Índia domina a energia nuclear, possuindo tecnologia para a fabricação de bombas atômicas
Também na área dos satélites artificiais, esse país alcançou grandes progressos, tendo já lançado seu primeiro satélite de comunicações.
A população indiana é extremamente pobre: três quartos vivem em condições precárias de alimentação, saúde, educação e habitação.
Com mais de 700 habitantes por quilômetro quadrado, Bangladesh assemelha-se à Índia por suas baixas condições de vida
Não é muito melhor a situação do Paquistão, pois embora tenha densidade demográfica sensivelmente menor que a de seus vizinhos, dispõe de áreas relativamente reduzidas para a atividade agrícola e pastoril, que constitui a atividade econômica da maior parte dos habitantes.
Sri Lanka, com contrastes sociais menos chocantes, é uma república que apóia sua economia no cultivo de chá, arroz, borracha e coco e, naturalmente, na pesca
As Maldivas possuem uma economia precária, baseada principalmente na prática rudimentar da pesca e na extração do óleo de copra (amêndoa de coco seca).
Os países montanhosos - Nepal e Butão - enfrentam o problema do isolamento, determinado pelas elevadas altitudes do relevo e particularidades climáticas, que dificultam a construção e a manutenção de estradas, e também pela falta de acesso ao oceano
Nestes pequenos países, pratica-se a agricultura nas poucas áreas em que isso é possível, além de criarem-se animais
Mais da metade da população é analfabeta e os hábitos e costumes tradicionais das tribos regem a vida de quase todos os habitantes.
Em todos os países do centro-sul asiático a população rural é dominante, embora existam algumas grandes cidades, sobretudo na Índia, onde a atividade industrial é diversificada e o nível de informação e politização dos habitantes é bem mais avançado
As maiores cidades da região são Calcutá, Bombaim, Madras, Nova Délhi (Índia), Karachi (Paquistão) e Daca (Bangladesh).
Esta região é formada por nove países independentes: Myanmar (Birmânia), Tailândia, Laos, Vietnã, Camboja, Malásia e Singapura - localizados na península da Indochina - e Indonésia, Brunei, Filipinas e Timor-Leste - que constituem o arquipélago da Insulíndia
A Malásia tem uma parte de seu território localizada na península da Indochina e outra na ilha de Bornéu, cuja maior parte pertence à Indonésia
Brunei localiza-se inteiramente nessa ilha.
O principal destaque econômico do sudeste asiático é a exploração de minérios para exportação, principalmente na Indonésia e na Malásia
A Indonésia, membro da OPEP, é um dos grandes exportadores mundiais de petróleo (Bornéu) e minerais metálicos, com destaque para estanho, ferro, bauxita e ouro
Brunei, sultanato localizado na ilha de Bornéu, depende basicamente da exportação de petróleo.
Apesar de ser rico em minérios, o sudeste asiático apresenta uma indústria pouco desenvolvida devido à falta de capital para ser aplicado em serviços de infraestrutura
As principais indústrias são de processamento de matérias-primas para exportação, como as manufaturas têxteis na Indochina e as usinas de açúcar na Indonésia
Singapura constitui exceção à fraca industrialização da região
Essa pequena ilha é um dos "tigres asiáticos", países de industrialização recente e crescimento acentuado
A indústria malaia e tailandesa também está expandindo, mas as demais economias continuam dependendo basicamente de atividades agrícolas.
A par de atividades de subsistência, em que se destaca o cultivo do arroz a agricultura dessa região asiática, também oferece produtos tropicais, cultivados em regime de plantation, uma herança de colonização europeia
Voltando principalmente à exportação, esse ramo da economia emprega a maior parte da população ativa
As principais culturas para exportação são a da borracha na Malásia, no Myanmar e na Indonésia; de chá, na Indonésia; além do arroz - cultivado em terraços nas vertentes das montanhas -, que é exportando pela Tailândia, Vietnã e Indonésia.
As principais cidades da região são: Jacarta (Indonésia), Manila (Filipinas) e Bangcoc (Tailândia), cujas áreas metropolitanas abrigam mais de cinco milhões de habitantes.
Essa região do globo tem-se caracterizado por diversos problemas políticos, desde sucessivos golpes de Estado a longas e sangrentas guerras envolvendo o confronto entre capitalismo e socialismo, como a ocorrida no Vietnã (1960-1975)
A diversidade de grupos étnicos, o grande número de religiões professadas e os níveis de vida extremamente diferenciados são fatores que concorrem para tornar essa região ainda mais conturbada.
Possuindo o terceiro maior território do mundo e abrigando mais de um bilhão (mil milhões) de pessoas - cerca de 20% de toda a humanidade -, a China adquire grande destaque no mundo
Entretanto, devido ao fato de a maior parte de seu território ser ocupada por desertos e montanhas, a população chinesa fica quase toda concentrada no lado oriental do país, única região que pode ser plenamente aproveitada.
A atividade econômica que emprega maior número de trabalhadores é a agricultura, cuja principal meta é a alimentação da imensa população
Essa atividade se desenvolve através de um sistema comunitário, em que o Estado empresta a terra e fornece os meios para a produção (máquinas, ferramentas, adubos etc.)
A China destaca-se mundialmente na produção de arroz, trigo, soja e outros gêneros, cultivados principalmente no vale do Yang-tsé-kiang
Também na criação de animais (suínos, ovinos e bovinos), esse país se coloca entre os cinco maiores produtores mundiais.
A China possui abundantes reservas minerais e um considerável potencial hidráulico e petrolífero, o que, aliado ao fato de sua mão-de-obra ser muito barata e sua população numerosa, fornece condições para o desenvolvimento da indústria, ainda que ela seja estatizada e se volte quase exclusivamente para o mercado interno
A produção visa basicamente fornecer artigos considerados necessários, sem preocupação com acabamento de luxo e, por isso, sempre ao alcance dos operários e camponeses.
O país conta ainda com um grande parque de indústrias de base, essenciais aos empreendimentos estatais
As principais áreas industriais localizam-se nas proximidades de grandes centros urbanos da China Oriental, como Xangai e Pequim, ou em áreas novas, como a Manchúria.
A China não apresenta um grau de desenvolvimento semelhante ao das grandes potências mundiais, mas é uma nação em que a distribuição de renda e de bens é menos desequilibrada
O padrão de vida de todos é relativamente igual e praticamente não existem a miséria pessoal e suas inúmeras consequências.
A partir de 1984, o governo chinês passou a promover a entrada de investimentos estrangeiros no país, que se retraíram, em 1989, com a repressão às maiores liberdades políticas.
Formosa, ou Taiwan, tornou-se um país independente da China em 1949, por ocasião do término da revolução comunista chinesa
De estrutura capitalista, o país contou com a ajuda de capitais provenientes dos Estados Unidos e do Japão e projetou-se economicamente no plano agrícola e industrial, graças à abundância de recursos minerais e mão-de-obra barata.
A Formosa é um dos países conhecidos como "tigres asiáticos", da mesma forma que Hong Kong, colônia britânica que foi reanexada à China em 1997, funcionando como região administrativa especial.
A Mongólia ocupa a parte mais central do território asiático
Localizada entre a China e a União Soviética, foi por muito tempo motivo de rivalidade entre esses países
Atualmente é alinhada ao bloco soviético
A população do país é bastante reduzida em relação a seu extenso território, que apresenta vários obstáculos naturais ao desenvolvimento econômico
Sua atividade principal é a agropecuária e sua principal cidade é a capital, Ulan Bator.
O Japão é um Estado monárquico, altamente desenvolvido e industrializado, situado a leste do continente asiático, em pleno Oceano Pacífico, e constituído por mais de três mil ilhas, embora apenas as quatro mais extensas sejam economicamente importantes.
Sua área total é pouco maior que a do estado do Maranhão, mas detém uma grande população absoluta (127 milhões de habitantes em 2007) e uma alta densidade demográfica (337 habitantes por quilômetro quadrado)
Essa aglomeração populacional torna-se ainda mais grave ao se constatar que apenas um quinto do território japonês pode ser habitado, já que o restante é ocupado por altas montanhas
Por outro lado, o crescimento vegetativo do Japão é quase nulo, pois as taxas de natalidade apenas compensam as de mortalidade.
Integrante do Primeiro Mundo, portanto, capitalista e desenvolvido, o Japão apresenta, entre outras, as seguintes características: renda per capita bastante alta; moradia, saúde e educação de bom nível, acessíveis a todos; agricultura, indústria e rede de serviços tecnologicamente avançadas.
O desenvolvimento e a prosperidade japonesa, sobretudo após o término da Segunda Guerra Mundial, ocasião em que o país foi parcialmente destruído por bombardeios, constituem um verdadeiro milagre econômico, na opinião de especialistas do setor
Para tanto, contribuíram os seguintes fatores: ajuda militar e financeira dos Estados Unidos, através do Plano Marshall; adoção de uma política de rigoroso controle populacional; prioridade à educação e ao domínio da tecnologia; produção voltada à exportação
A partir da década de 1950, o Japão atingiu um estágio de grande desenvolvimento e é hoje uma das maiores potências mundiais.
Embora disponha de poucas matérias-primas e quase nenhum combustível, o país é bem servido de hidreletricidade
Hoje é o primeiro produtor mundial de navios, o segundo de automóveis e o terceiro de aço e de alumínio, e seus produtos elétricos e eletrônicos, como rádios, televisores, calculadoras e inúmeros outros, encontram-se disseminados por todo o mundo.
Devido ao alto grau de industrialização do Japão, a maior parte de seus habitantes vive no meio urbano, sendo que a Região Metropolitana de Tóquio possui mais de 37 milhões de habitantes, o que torna a aglomeração de Tóquio, independentemente de como se define, como a área urbana mais populosa do mundo; em âmbito nacional, é seguida por Osaka, Nagóia, Yokohama e Quioto.
Localizadas na Península da Coreia, estão a República Popular Democrática da Coreia (Coreia do Norte) e a República da Coreia (Coreia do Sul), que até 1948 formavam um único país
A divisão em dois estados foi decorrente da ocupação do território por soviéticos, no norte, e norte-americanos, no sul, por ocasião do término da Segunda Guerra Mundial.
Desde a separação, a Coreia do Norte é socialista, com uma economia pobre e subdesenvolvida e a Coreia do Sul, capitalista, sendo um país desenvolvido, com valores muito elevados de IDH (15.º a nível mundial em 2011) e de PIB (PPC) per capita (27.º a nível mundial em 2011, segundo o FMI e 29.º segundo o Banco Mundial  e a CIA, com uma economia com grandes apostas nos serviços e na alta tecnologia
A Coreia do Norte continua essencialmente agrícola, com uma economia subdesenvolvida, com destaque para o cultivo do arroz e do trigo, mas a Coreia do Sul — que, assim como Singapura, Formosa e Hong Kong, é um dos "tigres asiáticos" — alcançou grande desenvolvimento industrial na década de 1980.
As diferenças entre as bandeiras das duas Coreias são as seguintes:
A parte asiática da Comunidade de Estados Independentes, embora corresponda, aproximadamente, a quatro quintos do território administrado por essa organização internacional, tem modesta importância econômica, se comparada à parte europeia.
Devido principalmente à hostilidade do meio natural - desertos, grandes áreas geladas ao norte e altas montanhas ao sul - essa região não apresenta condições ideais para a agropecuária
Mesmo assim, nos limites com a Europa, cultiva-se trigo e milho; a sudoeste, nas estepes próximas aos mares Cáspio e Aral, criam-se extensivamente carneiros e cabras e cultivam-se algodão e frutas, e nas áreas mais frias da Sibéria criam-se renas.
A partir da revolução socialista de 1917 e, particularmente, após o final da Segunda Guerra Mundial, essa região conhecida como a ex-União Soviética passou a ser mais valorizada, devido, principalmente, à abundância de suas riquezas minerais
Graças a essa característica, passou a abrigar basicamente indústrias pesadas, localizadas em alguns centros da Sibéria e do Cazaquistão
Pode ser citada ainda a cidade de Vladivostok, localizada na extremidade oriental, que, além de ser importante ponto estratégico, centraliza inúmeras indústrias diferenciadas.
O continente asiático ocupa um espaço que corresponde a cerca de um terço de todas as terras do planeta, sendo, portanto, maior que a extensão somada de todas as Américas, ou da Europa com a África
Nessas terras vivem mais de três milhares de milhões de habitantes, ou seja, mais da metade da população mundial, resultando numa densidade demográfica de 70 habitantes por quilômetro quadrado, aproximadamente três vezes maior que a densidade média da Terra.
Embora muito numerosa, a população asiática é mal distribuída: nas planícies, sobretudo as irrigadas pelas monções, e nas grandes cidades, as densidades demográficas são altíssimas, enquanto nas regiões desérticas, montanhosas e geladas, e mesmo em áreas de climas muito quentes, a população apresenta-se rarefeita
Países como China, Índia, Indonésia, Japão, Paquistão e Bangladesh estão entre os mais populosos da Terra, enquanto outros, como a Mongólia ou mesmo trechos setentrionais da Rússia, apresentam as mais baixas densidades demográficas do planeta.
Um fator que agrava o problema da má distribuição demográfica são as altas taxas de natalidade e a tendência à concentração urbana, características de todos os países subdesenvolvidos, como é o caso da maioria das nações asiáticas
Apenas alguns poucos países conseguiram sucesso em suas campanhas de planejamento familiar, reduzindo-se o crescimento populacional na China e praticamente estancando-o no Japão.
Em outros casos, a situação continua alarmante; é o que ocorre, por exemplo, com a Índia, onde a cada ano a população apresenta um crescimento vegetativo de 2,1%
Isso representa anualmente cerca de 14 milhões de crianças à espera de formação e, futuramente, de emprego
Na prática, isso se mostra economicamente impossível, o que torna ainda mais agudo o subdesenvolvimento desse e de outros países asiáticos.
Outro aspecto grave do crescimento populacional muito elevado é que ele costuma ocorrer nas áreas mais populosas, acentuando ainda mais o contraste com os vazios demográficos
Atualmente, em uma área que equivale a um quarto do território asiático, vivem 90% dos habitantes do continente, enquanto nada menos que dois quintos do território são praticamente desabitados, abrigando apenas 3% ou 4% da população total
Uma das principais razões desse fenõmeno é a urbanização.
De maneira geral, as regiões que apresentam condições naturais satisfatórias são as que abrigam os maiores aglomerados populacionais; aquelas que apresentam obstáculos naturais à fixação humana, tais como a grande altitude do relevo, o clima muito frio e a aridez do solo, permanecem pouco habitadas.
A Terra assiste a um extraordinário crescimento populacional, impulsionado, em grande parte, pelo formidável crescimento populacional asiático
Na tabela, fica claro que a contribuição dos países subdesenvolvidos é muito superior à dos desenvolvidos, daí a importância dos países asiáticos nesse processo.

Mumbai

Xangai

Karachi
Embora a maior parte da população asiática seja composta de povos de raça amarela, há também expressivo número de representantes dos outros troncos étnicos, o negro e o branco.
Os amarelos compõem a etnia dominante e distribuem-se pelas regiões da taiga e da tundra (ao norte), pelos planaltos da Ásia Central e sobretudo pelo leste e sudeste do continente, regiões asiáticas mais intensamente povoadas
Ocorrem grandes diferenças físicas, linguísticas e culturais entre esses povos (chineses, japoneses, coreanos, malaios, indonésios), mas sobretudo entre eles e os grupos mais isolados, como os quirguizes, mongóis e tibetanos.
Os brancos ou caucasoides predominam no sudeste do continente (Oriente Médio), onde são encontrados os árabes, os turcos, os israelenses, curdos, etc., e na Ásia Central, cujos países receberam grandes contingentes de população eslava (principalmente russos) ao serem incorporados à extinta União Soviética
Também na Índia e no Paquistão há um ramo étnico branco, mas seus representantes são bem amorenados.
Também, aparecem em menor número, distribuindo-se no sul da Índia e em ilhas do Oceano Índico
Pertencem ao grupo drávida, cuja influência é marcante na cultura hindu.
Rei Abdallah da Arábia Saudita.
Regine Velasquez, é uma cantora filipina.
Taro Aso, ex-primeiro-ministro do Japão.
Zhang Ziyi, uma atriz chinesa.
Em um continente que apresenta tão grande diversidade étnica e que registrou um longo período de dominação colonial em grande parte de seu território, é muito natural que se verifique grande diversidade de idiomas
Os principais, falados por mais de 100 milhões de pessoas, são: o mandarim (a língua mais falada do mundo), o árabe, o malaio-indonésio, o coreano, o japonês e, dentre as muitas línguas faladas na Índia, o hindi-urdu e o bengali
Entretanto, existem mais de uma centena de línguas ou dialetos em uso corrente em toda a Ásia.
A Ásia também abriga as grandes religiões da humanidade, tendo sido o berço de quase todas elas
22% dos asiáticos professam o hinduísmo cerca de 792 897 000, comum na Índia e arredores, e o budismo, comum em todo o Extremo Oriente com 9,1% cerca de 350 000 000 de seguidores, onde além dessa religião, são praticados o Cristianismo Católico e Ortodoxo com 135 000 000 e os protestantes com aproximadamente de 50 000 000 de seguidores, além das religiões chinesas, o confucionismo (China) e o xintoísmo (Japão)
O islamismo é outra religião bastante difundida na Ásia com cerca de 807 034 000 fazendo dela a maior religião em números absolutos de pessoas na Ásia , sobretudo no Oriente Médio, Turquestão, Índia e Insulíndia
Merece destaque ainda o judaísmo, centralizado em Israel.

Existem ainda alguns territórios sem estatuto de dependência, pertencentes a outros países localizados noutros continentes, mas que no entanto se situam na Ásia.
As diferenças e semelhanças entre os países asiáticos fazem com que a regionalização do continente possa ser feita em cinco grandes conjuntos:
Outra divisão possível, em grandes áreas geográfico-culturais, é a seguinte:
Em 2007, a maior economia nacional na Ásia, em termos de produto interno bruto (PIB), é a da China, seguida da Índia e do Japão
No final dos anos 1990 e início do século XXI, as economias chinesa e indiana têm crescido rapidamente, a taxas médias anuais de mais de 8%.
Entretanto, pelo critério do PIB nominal (calculado pela taxa de câmbio), a China ainda é a maior economia asiática e a segunda maior do mundo
O crescimento econômico da Ásia desde a Segunda Guerra Mundial até os anos 1990 concentrou-se em alguns poucos países da costa do Pacífico; recentemente, espalhou-se para outras regiões
Os principais blocos comerciais do continente são: Cooperação Econômica da Ásia-Pacífico (APEC), Reunião Econômica Ásia-Europa, Associação de Países do Sudeste Asiático (ASEAN), Acordos de Estreitamento das Relações Económicas e Comerciais (da China com Hong Kong e com Macau), Comunidade de Estados Independentes (CEI) e Associação Sul-asiática para Cooperação Regional (SAARC).
A Ásia conta com enormes reservas minerais, circunstância que tem facilitado seu recente desenvolvimento industrial
Entre os países produtores de minerais, merece destaque a China, rica principalmente em petróleo, carvão, ferro, chumbo, zinco e mercúrio, além de grandes jazidas de outros minerais.
Também a Índia é privilegiada por suas reservas de ferro, carvão, mica e manganês, além de sua grande produção de petróleo
Os países do sudeste asiático também são muito ricos em minérios, principalmente em estanho, níquel, zinco, ferro e petróleo, de que a Indonésia é grande exportadora.
O grande destaque fica, no entanto, com os países do Oriente Médio, que produzem mais de 30% do total do petróleo explorado em todo o mundo.
A atividade econômica mais difundida em todo o continente é a agricultura, ressaltando-se o cultivo do arroz em toda a vasta região atingida pelas monções
Mais ao norte, o trigo é intensamente cultivado; em áreas menos férteis, o solo é ainda aproveitado pára a produção de cevada, milho e outros cereais
Em todas essas culturas, a China sobressai, apresentando-se como um dos quatro maiores produtores mundiais.
Além dos cereais, merecem destaque os cultivos de fumo, chá, juta, algodão, pimenta e borracha
Na China e Japão cultiva-se também a amoreira, cujas folhas servem de alimento ao bicho-da-seda
Dos casulos desse animal são extraídos fios com que se fazem tecidos muito apreciados em todo o mundo.
A pecuária é outra atividade muito comum no continente
A China é grande produtora de animais de pequeno porte, sendo o primeiro produtor mundial de suínos, o terceiro de ovinos e o quinto de bovinos
A Índia, por sua vez, possui o maior rebanho bovino do mundo, o qual, no entanto, não é aproveitado para a alimentação da população, a maioria seguidora do hinduísmo, religião que considera sagrados esses animais.
O Japão foi, durante muito tempo, o mais industrializado dos países asiáticos
Graças à maciça ajuda norte-americana após a Segunda Guerra Mundial e à adoção de uma série de medidas internas, seu desenvolvimento industrial fez-se em bases firmes, transformando o país, em pouco tempo, numa potência industrial.
Possuindo um parque industrial amplo e diversificado, o Japão se evidencia na produção de navios, automóveis e produtos elétricos e eletrônicos.
A região oriental da Rússia, embora economicamente menos importante que a parte europeia do país, abriga diversos centros de indústrias de base (no Cazaquistão), localizados próximo de áreas exploratórias de minério, como ferro e carvão.
Outro país que apresenta uma industrialização evoluída, apesar de ser subdesenvolvido, é a Índia, que utiliza sua produção agrícola e as riquezas minerais para prover suas indústrias têxteis, alimentícias, siderúrgicas e metalúrgicas
Esse país salienta-se ainda por ser um dos poucos do Terceiro Mundo a utilizar tecnologia avançada nas áreas de energia e de comunicações.
Na China, cuja industrialização foi implantada efetivamente após a revolução socialista de 1949, o parque industrial tem-se dedicado quase inteiramente à produção de itens essenciais ao mercado interno
Somente a partir de meados da década de 1970 a economia chinesa começou a voltar-se, ainda que lentamente para o exterior
Na década seguinte, a abertura econômica foi maior, mas, devido a problemas políticos internos, voltou a retrair-se em 1989, tornando-se, atualmente, a 2ª maior potência industrial do mundo e a maior da Ásia.
Destacam-se ainda os chamados "tigres asiáticos" - Coreia do Sul, República da China, Singapura e Hong Kong -, cujas taxas de crescimento econômico e industrial estão entre as mais elevadas do mundo
Sua produção visa, em geral, o mercado externo, o que lhes permite obter grandes saldos em suas balanças comerciais.
As outras regiões asiáticas (Oriente Médio, sudeste asiático, Mongólia, países do Oceano Índico) apresentam uma industrialização incipiente e pouco significativa.
A cultura da Ásia é o agregado artificial da herança de muitas nacionalidades, sociedades, religiões, e grupos étnicos na região, tradicionalmente chamada um continente de uma perspectiva central ocidental, da Ásia
A região ou "o continente" são mais comumente divididos em sub-regiões geográficas e culturais mais naturais, inclusive a Ásia Central, a Ásia Oriental, a Ásia Meridional ("o subcontinente indiano"), a Ásia Setentrional, a Ásia Ocidental e o Sudeste Asiático
Geograficamente, a Ásia não é um continente distinto; culturalmente, houve pouca unidade ou história comum de muitas das culturas e povos da Ásia.
A arte, a música, e a culinária, bem como a literatura, são partes importantes da cultura asiática
A filosofia oriental e a religião também desempenham um papel principal, com budismo, hinduísmo, taoísmo, confucionismo, islã, e cristianismo todos os papéis principais desempenham
Uma das partes mais complexas da cultura asiática é a relação entre culturas tradicionais e o mundo ocidental.
Na Ásia existem países desenvolvidos, como Japão, Coreia do Sul, Israel, Singapura ou Taiwan, que revelam níveis de prosperidade econômica e social comparáveis aos da Europa ou da América Anglo-Saxônica
Essas áreas, entretanto, pouco representam, se comparadas com muitos dos demais países, geralmente bastante pobres e violentamente atingidos pelo subdesenvolvimento
Mesmo aqueles exportadores de petróleo, que tiveram lucros fabulosos a partir do início da década de 1970, não escapam a essa característica.
Há inúmeros fatores que contribuem para que a Ásia exiba grande atraso e miséria
Entre eles, podem ser citados:
Além destes fatores histórico-culturais, também os de ordem natural dificultam o desenvolvimento econômico
O clima e relevo hostis são obstáculos ao aproveitamento agrícola de vastas extensões localizadas em áreas montanhosas, geladas ou desérticas, limitando as áreas cultiváveis do continente.
Para se avaliar a grande disparidade de riquezas entre os países asiáticos, vamos tomar dois exemplos: os países exportadores de petróleo do Oriente Médio e o Japão.
Todo o Oriente Médio caracteriza-se por apresentar populações extremamente pobres, em contraste com elites detentoras de imensas fortunas
A maior riqueza de quase todos os países dessa região é o petróleo, responsável nos últimos anos pelo seu rápido enriquecimento.
Entretanto, os tradicionais males do subdesenvolvimento não foram atenuados: em primeiro lugar, porque esses lucros beneficiam principalmente determinados grupos, e não os países como um todo; e em segundo, porque boa parte dos rendimentos cabe a poderosas companhias transnacionais norte-americanas ou europeias.
O Japão, por sua vez, sendo um país capitalista desenvolvido, destaca-se em diversas áreas, sobretudo no setor industrial, chegando a superar em muitos aspectos as conquistas norte-americanas e europeias
Esse grande avanço industrial e tecnológico reflete-se diretamente na qualidade de vida da população japonesa, cujo PIB per capita é bastante alto e o acesso a moradia, saúde e educação de bom nível é indiscriminado.

África

América

Antártida

Ásia

Europa

Oceania

América Central

América do Norte

América do Sul

Austrália

Eurafrásia

Eurásia

Magrebe · Norte · Centro · Sul · Ocidente · Oriente · Subsaariana

Norte  · Central   · Sul 
(Latina  · Anglo)

Central · Oriente   · Norte   · Sul   · Sudeste · Ocidente

Ocidente · Centro · Oriente · Norte · Sul


Australásia · Melanésia · Micronésia · Polinésia

Ártico · Antártida

Afeganistão · Arábia Saudita · Arménia · Azerbaijão · Bahrein · Bangladesh · Butão · Brunei · Cazaquistão · Camboja · República Popular da China · Chipre · Timor-Leste · Egito · Geórgia · Índia · Indonésia · Irã · Iraque · Israel · Japão · Jordânia · Coreia do Norte · Coreia do Sul · Kuwait · Quirguistão · Laos · Líbano · Malásia · Maldivas · Mongólia · Myanmar · Nepal · Omã · Paquistão · Filipinas · Qatar · Rússia · Singapura · Sri Lanka · Síria · Tajiquistão · República da China · Tailândia · Turquia · Turquemenistão · Emirados Árabes Unidos · Uzbequistão · Vietname · Iémen
Aceh · Adjara · Abcásia · Akrotiri e Dhekelia · Altai · Território Britânico do Oceano Índico · Buryatia · Ilha Christmas · Ilhas Cocos (Keeling) · Guangxi · Hong Kong · Mongólia Interior · Iraqi Kurdistan · Jacarta · Khakassia · Macau · Nagorno-Karabakh · Nakhchivan · Ningxia · Chipre do Norte · Palestina (Faixa de Gaza · Margem Ocidental) · Papua · Sakha · Ossétia do Sul · Tibet · Tuva · Papua Ocidental · Xinjiang · Yogyakarta
Afeganistão • Arábia Saudita • Armênia • Azerbaijão • Bahrein • Bangladesh • Butão • Brunei • Camboja • Cazaquistão • China • Chipre • Coreia do Norte • Coreia do Sul • Egito • Emirados Árabes Unidos • Filipinas • Geórgia • Iêmen • Índia • Indonésia • Irã • Iraque • Israel • Japão • Jordânia • Kuwait • Laos • Líbano • Malásia • Maldivas • Mianmar • Mongólia • Nepal • Omã • Paquistão • Catar •
A África é o terceiro continente mais extenso (depois da Ásia e da América) com cerca de 30 milhões de quilômetros quadrados, cobrindo 20,3 % da área total da terra firme do planeta
É o segundo continente mais populoso da Terra (atrás da Ásia) com cerca de um bilhão de pessoas (estimativa para 2005 ), representando cerca de um sétimo da população mundial, e 54 países independentes.
Apresenta grande diversidade étnica, cultural, social e política
Dos trinta países mais pobres do mundo (com mais problemas de subnutrição, analfabetismo, baixa expectativa de vida), pelo menos 21 são africanos
Apesar disso existem alguns países com um padrão de vida razoável, mas não existe nenhum país realmente desenvolvido na África
Maurícia e Seicheles têm uma qualidade de vida bastante razoável, como até a recente revolução também a Líbia
Ainda há outros países africanos com qualidade de vida e índices de desenvolvimento razoáveis, como a maior economia africana, a África do Sul (0,666) e outros países como Marrocos (0,628), Argélia (0,736), Tunísia (0,726), Cabo Verde (0,646),São Tomé e Príncipe (0,555), Congo (0,598) e Botswana (0,698)
A África costuma ser regionalizada de duas formas, a primeira forma valoriza a localização dos países e os dividem em cinco grupos, que são a África setentrional, a África Ocidental, a África central, a África Oriental e a África meridional
A segunda regionalização desse continente, que vem sendo muito utilizada, usa critérios étnicos e culturais (religião e etnias predominantes em cada região), é dividida em dois grandes grupos, a África Branca ou setentrional, formado pelos oito países da África do norte, mais a Mauritânia e o Saara Ocidental, e a África Negra ou subsaariana, formada pelos outros 44 países do continente.


Afri era o nome de vários povos que se fixaram perto de Cartago no Norte de África
O seu nome é geralmente relacionado com os fenícios como afar, que significa "poeira", embora uma teoria de 1981, tenha afirmado que o nome também deriva de uma palavra de berbere, ifri, palavra que significa "caverna", em referência à gruta onde residiam.
No tempo dos romanos, Cartago passou a ser a capital da Província de África, que incluiu também a parte costeira da moderna Líbia
Os romanos utilizaram o sufixo "-ca" denotando "país ou território"
Mais tarde, o reino muçulmano de Ifríquia, actualmente Tunísia, também preservou o nome.
Outras etimologias têm sido apontadas como originárias para a antiga denominação "África":
A África sempre despertou o interesse dos europeus pelo ar misterioso e exótico e por guardar elementos bem diferentes daqueles com os quais eles estavam acostumados
Até mesmo o norte do continente,conhecido há mais tempo, apresentava civilizações com hábitos e costumes muito particulares aos olhos ocidentais
Exemplo disso foi a civilização egípcia, que demonstrou o poder e a capacidade intelectual dos povos africanos.
O homem passou a estar presente na África durante os primeiros anos da era quaternária ou os últimos anos da era terciária
A maioria dos restos de hominídeos fósseis que os arqueólogos encontraram — australopitecos, Homo habilis, Homo erectus, Homo helderbegensis, homens de Neandertal e de Cro-Magnon — em lugares diferenciados da África é a demonstração de que essa parte do mundo é importante no processo evolutivo da espécie humana e indica, até, a possível busca das origens do homem nesse continente
As semelhanças comparáveis da história da arte que vai entre o paleolítico e o neolítico são iguais às das demais áreas dos continentes europeu e asiático, com diferenças focadas em regiões então desenvolvidas
A maioria das zonas do interior do continente, meio postas em isolamento, em contraposição ao litoral, ficaram permanentes em estágios do período paleolítico, apesar de a neolitização processada ter início em 10000 a.C., com uma diversidade de graus acelerados.
O Norte da África é a região mais antiga do mundo
A civilização egípcia floresceu e inter-relacionou-se com as demais áreas culturais do mundo mediterrâneo, motivos pelas quais essa região foi estreitamente vinculada, há milhares de séculos, depois que a civilização ocidental foi geralmente desenvolvida
As colônias pertencentes à Fenícia, Cartago, a romanização, os vândalos aí fixados e o Império Bizantino influente são os fatores pelos quais foi deixada no litoral mediterrâneo da África uma essência da cultura que posteriormente os árabes assimilaram e modificaram
Na civilização árabe foi encontrado um campo de importância em que foi expandida e consolidada a cultura muçulmana no Norte da África
O Islã foi estendido pelo Sudão, pelo Saara e pelo litoral leste
Nessa região, o Islã é a religião pela qual foram sendo seguidas as rotas de comércio do interior da África (escravos, ouro, penas de avestruz) e estabelecidos encraves marítimos (especiarias, seda) no oceano Índico.
Simultaneamente, na África negra foram conhecidos vários impérios e estados que aí floresceram
Estes impérios e estados nasceram de grandes clãs e tribos submetidos a um só soberano poderoso com características próprias do feudalismo e da guerra
Entre esses impérios de maior importância figuram o de Aksum, na Etiópia, que teve sua chegada ao apogeu no século XIII; o de Gana, que desenvolveu-se do século V ao século XI e os estados muçulmanos que o sucederam foram o de Mali (do século XIII ao século XV) e o de Songhai (do século XV ao século XVI); o reino Abomey do Benim (século XVII); e a confederação zulu do sudeste africano (século XIX).
Durante o século XV os exploradores vindos da Europa chegaram primeiro ao litoral da África Ocidental
O estímulo dado a essa exploração foi uma forma de buscar novos caminhos para as Índias, após o comércio ser fechado por parte dos turcos no leste do Mar Mediterrâneo
Os colonizadores de Portugal, da Espanha, da França, da Inglaterra e dos Países Baixos foram os competidores do novo caminho, estabelecendo no litoral feitorias e portos de embarque para, principalmente, comercializar escravos
Concomitantemente, foram realizadas as primeiras viagens científicas que adentraram o interior do continente: Charles-Jacques Poncet na Abissínia, em 1700; James Bruce em 1770, procurando o local onde nasce o Nilo; Friedrich Konrad Hornermann viajando no deserto da Líbia sobre a garupa de um camelo, em 1798; Henry Morton Stanley e David Livingstone na bacia do Congo, em 1879.
A partir do século XIX, as potências europeias interessadas política e economicamente representavam estímulo para que o interior da África seja penetrado e colonizado
As potências europeias desejavam a criação de impérios que fossem estendidos de litoral a litoral, mas isso fez com que o Reino Unido (pelo qual foi conseguida a ocupação de uma faixa de norte a sul, do Egito à África do Sul, além de demais zonas colonizadas no golfo da Guiné), a França (que estabeleceu-se no noroeste da África, em parte do equador africano e em Madagascar) e, em quantidade pequena, Portugal (Angola, Moçambique, Guiné e uma diversidade de ilhas estratégicas), Alemanha (Togo, Tanganica e Camarões), Bélgica (Congo Belga), Itália (Líbia, Etiópia e Somália) e Espanha (parte do Marrocos, Saara Ocidental e encraves na Guiné) brigassem entre si
A partilha da África foi formalmente consumada na Conferência de Berlim de 1884-1885, na qual firmou-se o princípio da ocupação efetiva como forma de legitimar as colônias empossadas.
Devido ao regime colonial estabelecido no continente, foram destruídas e modificadas as estruturas sociais, econômicas, políticas e religiosas da maioria do território da África negra
As colônias que proclamaram sua independência, processo emancipatório que se iniciou após a Segunda Guerra Mundial e se concluiu principalmente de 1960 até 1975, tiveram que enfrentar problemas graves de integração nacional, resultantes das fronteiras arbitrárias herdadas do sistema colonial, além da pobreza prevalecente no continente e o rápido crescimento da população africana, mais elevado do que o número de alimentos produzidos
Acresce que econômica e politicamente dependem em boa parte das antigas metrópoles, que a sua administração se caracteriza geralmente por ineficiência e corrupção, e que a persistente divisão étnica e religiosa leva a conflitos de vária ordem
Estes e outros fa(c)tores são as principais barreiras que impedem que os novos países se desenvolvam
Os seus governos, muitas vezes com características de ditadurasmilitares ou de um presidencialismo autoritário, são frequentemente impecilhos em vez de motores do desenvolvimento
Nalguns casos têm tendência à adoção de políticas concebidas para garantir a libertação dos países das potências estrangeiras
A cooperação entre países africanos, ensaiada para facilitar a solução dos seus problemas, deu origem a uma diversidade de organizações supranacionais que se baseiam-se na ideia do pan-africanismo, ou a totalidade dos povos africanos unidos em torno dos interesses comuns
A organização de maior importância é a Organização da Unidade Africana (OUA).
A África está separada da Europa pelo mar Mediterrâneo e liga-se à Ásia na sua extremidade nordeste pelo istmo de Suez
O continente é o único que se estende pelo hemisfério norte e hemisfério sul, atravessado pela linha do equador e o meridiano de Greenwich
No entanto, a África ocupa uma única placa tectônica, ao contrário da Europa que partilha com a Ásia a placa Euro-asiática.
Do seu ponto mais a norte, Ras ben Sakka, em Marrocos, à latitude 37°21'N, até ao ponto mais a sul, o cabo das Agulhas na África do Sul, à latitude 34°51'15" S, há uma distância de aproximadamente 8 000 km
Do ponto mais ocidental de África, o Cabo Verde, no Senegal, à longitude 17°33'22"W, até Ras Hafun na Somália, à longitude 51°27'52" E, são cerca de 7 400 km.
Para além do mar Mediterrâneo, a norte, a África é banhada pelo oceano Atlântico na sua costa ocidental e pelo oceano Índico do lado oriental
O comprimento da linha de costa é de 26 000 km.
A área territorial da África é de pouco mais de 30 milhões de quilômetros quadrados, já que é o terceiro continente mais extenso do mundo
A África é atravessada por três grandes paralelos terrestres de leste para oeste: Linha do Equador, Trópico de Câncer e Trópico de Capricórnio, além do Meridiano de Greenwich, no sentido norte-sul
A África tem cinco diferentes fusos horários.
O relevo da África é, em sua maioria, formada por planaltos
É apresentada pelo continente uma altitude média de mais de 750 metros
As formas de relevo que ocupam todas as regiões centro e oeste são planaltos que se erodiram com intensidade
As rochas mais antigas constituem os planaltos
E os planaltos, propriamente ditos, tem como limites os grandes escarpamentos.
São contornadas pelos planaltos as depressões cujos rios atravessam, nas quais também são encontrados lagos e bacias hidrográficas de maior extensão, das quais podemos citar os rios Nilo, Congo, Chade, Níger, Zambeze, Limpopo, Cubango e Orange
Ao longo do litoral, estão situadas as planícies costeiras, por vezes com muita vastidão, como as planícies do Níger e do Congo.
No leste da África são encontradas um de seus aspectos físicos que mais se destacam: uma falha geológica que se estende no sentido norte-sul, o Grande Vale do Rift, em que são sucedidas montanhas, algumas que no passado geológico eram meros vulcões e depressões de maior extensão
É nessa região que estão localizados os maiores lagos do continente, cujas altas montanhas circundam-os, de mencionar o Kilimanjaro (5 895 m), o monte Quênia (5 199 m) e o Ruwenzori (5 109 m).
Podem ser destacados ainda dois grandes conjuntos formados pela elevação de terras, um na parte setentrional e outro na parte meridional do continente:
Dando por completo uma visão do relevo da África, é possível a observação do fato de existir antigos maciços montanhosos em pontos diferenciados do continente: o da Etiópia, que se formou desde erupções de vulcão, o de Fouta Djalon e o de Hoggar, além de muitos outros.
Os principais acidentes geográficos litorâneos são o golfo da Guiné no Atlântico Sul; e o estreito de Gibraltar, do Oceano Atlântico até o mar Mediterrâneo
Na parte oriental do continente está localizada a península da Somália, aquilo que os geógrafos também a chamam de Chifre da África no Brasil ou "Corno de África" em Portugal, e o golfo de Aden, cujo acidente geográfico que forma o golfo, propriamente dito, são as águas do oceano Índico
O golfo de Aden tem como limites a península Arábica, que é pertencente à Ásia
Na parte meridional, está localizado o cabo da Boa Esperança.
Na África não existem muitas ilhas adjacentes
No Atlântico, estão localizadas a Região Autónoma da Madeira, ilhas Canárias, São Tomé e Príncipe e de Cabo Verde
No oceano Índico é encontrada uma ilha de maior extensão, Madagáscar, e outras pequenas que são os arquipélagos denominados Comores, Maurício e Seychelles.
Na África existem quatro tipos climáticos
São eles: equatorial, tropical, desértico e mediterrâneo.
O clima equatorial é de calor e umidade o ano inteiro
A parte abrangida pelo clima equatorial é a região centro-ocidental do continente; o clima tropical é quente com carência de chuvas no invernos
A parte dominada pelo clima é a quase a totalidade das terras africanas, entre o centro e o sul, com inclusão da ilha de Madagascar; a parte compreendida pelo clima desértico é uma grande área extensa da África, que acompanha os desertos do Saara e de Calaari; finalmente, as áreas de manifestação do clima mediterrâneo são pequenos trechos da extremidade setentrional e da extremidade meridional do continente
A apresentação térmica do clima de deserto é de temperaturas elevadas com a umidade dos invernos.
A quantidade de chuvas que caem na África é a causa principal dos muitos diferenciais que existem entre as paisagens africanas
A ocorrência das chuvas é abundante na região cortada pela linha do equador, mas tem insignificância nas áreas próximas ao Trópico de Câncer, onde está localizado o deserto do Saara, e do Trópico de Capricórnio, região pela qual o Calaari tem uma área extensa
Os desertos se localizam no interior do território africano e a área de ocupação dos desertos é definida a muitas partes do continente.
Na África existem rios de maior extensão e volume, porque se localizam em regiões próximas aos trópicos e à linha do equador
O rio mais importante do continente é o Nilo, o segundo maior em extensão do mundo (depois do Solimões-Amazonas)
Tem um comprimento de mais de 6 500 km
Sua nascente é próxima ao lago Vitória, cuja área percorrida é o nordeste africano e o Nilo é afluente do mar Mediterrâneo
A bacia hidrográfica que é formada pelo rio principal e seus afluentes tem uma área de superior a três milhões de quilômetros quadrados
O vale do Nilo, resulta da união entre o Nilo Branco e o Nilo Azul
O solo apresentado pelo vale do Nilo é de extrema fertilidade
A atividade econômica principal do vale do Nilo é a agricultura
As grandes civilizações egípcia e de Meroé, na Antiguidade, tiveram existência em parte devido ao fato de ocorrer cheias que se repetem a cada ano.
Além do Nilo, entre os demais rios de importância para a África estão o Congo, o Níger e o Zambeze
De menor extensão, mas iguais em relevância, incluem o Senegal, o Orange, o Limpopo e o Zaire.
No que diz respeito aos lagos, na África existem alguns de extensão e profundidade, os muitos que se localizam na parte oriental do continente, como o Vitória, o Rodolfo e o Tanganica; a profundidade do Tanganica, propriamente dito, é superior a 1500 metros
A grande falha geológica, onde foram alojados os Grandes Lagos Africanos, é muito evidenciada enfaticamente pelo lago Tanganica
O lago mais extenso da região centro-ocidental é o Chade.
Nas áreas de clima equatorial existe uma abundância de chuvas o ano todo; devido à pluviosidade, a vegetação que domina o continente é a floresta equatorial
Nas partes setentrional e meridional dessa faixa, onde há umidade de verão, constatamos o aparecimento das savanas, que são o tipo de vegetação constituinte de maior abundância no continente
As áreas que são circundadas por essa região são zonas que podem contar com a amenidade das temperaturas, pouca chuva e a acentuação das estações secas, como o Sahel.
Ao longo do litoral do mar Mediterrâneo e da África do Sul, é destacada aquilo que os geógrafos e climatólogos a chamam de vegetação mediterrânea
A formação da vegetação mediterrânea é arbustiva e de gramíneas
Na parte meridional do continente, a província florística do Cabo tem relevância.
Como os africanos têm consciência ecológica da preservação de parte significativa de sua vegetação, na África são conservadas ainda numerosas espécies de sua fauna: na floresta equatorial abrigam-se, de maneira principal, aves e macacos; nas savanas e estepes estão reunidos antílopes, zebras, girafas, leões, leopardos, elefantes, avestruzes e geralmente animais maiores.
Não é fácil fazer o agrupamento dos países da África em conjuntos que apresentem homogeneidade
Mas, para facilitar o estudo, o continente pode ser dividido em cinco regiões principais: Norte da África, África Ocidental, África Centro-ocidental, África Centro-oriental e África Meridional.
O Norte da África, aquilo que os geógrafos também chamam de África Setentrional e de África do Norte, é a maior região do continente em extensão territorial, que comporta três subdivisões: os países do Maghreb, os países do Saara e o vale do Nilo.
A palavra maghreb é da língua árabe tem o significado de "poente do Sol", ou seja, o ocidente
Os países que compõem o Maghreb são Marrocos, a Argélia, a Tunísia, a Mauritânia e a Líbia
Na paisagem, os acidentes geográficos que mais destacam o Maghreb são a cadeia do Atlas, junto ao mar Mediterrâneo, e o gigantesco deserto do Saara onde ambos os trechos são distintos: um pelas quais as dunas arenosas dominam, aquilo que os geógrafos e habitantes locais conhecem por Erg, e outro com muitas pedras, que se chama Hamadas.
A região do Magrebe tem um clima clima mediterrânico na encosta setentrional da cordilheira do Atlas e um clima desértico na parte setentrional dessa cordilheira
A distribuição da população é desigual: a densidade demográfica é grande em áreas de maior umidade e, de modo natural, tem escassez nas áreas de deserto, onde a maioria da população é formada pelos árabes e pelos berberes, que são adeptos do islamismo.
Devido às condições naturais que não favorecem as lavouras, a agropecuária se desenvolve muito pouco, apesar do seu emprego para muitos trabalhadores em atividade que moram nesses países
Merecem destaque a agricultura mediterrânea, em que são cultivados vinhas, oliveiras, cítricos e tâmaras
É praticada a pecuária extensiva nas áreas de clima semiárido e a pecuária que se desloca sem destino próprio no deserto.
Como têm muitos minérios que são destinados à exportação, o alcance feito pelos países do Maghreb foi a implantação de uma diversidade de centros industriais destacados, como Argel, Túnis, Orã, Casablanca, Rabat, Fez e Marrakesh, que são algumas das cidades africanas de maior população e beleza.
Os principais produtos econômicos da Argélia são o petróleo e o gás natural, sendo que o país também faz parte da OPEP como membro desta organização internacional
Marrocos e Tunísia exportam muito fosfatos, que serve como matéria-prima para a indústria que fabrica fertilizantes.
A vastidão do deserto do Saara tem extensão por uma diversidade de países, mas é a característica natural da qual fazem parte a Mauritânia, o Mali, o Níger, o Chade e a Líbia na mesma sub-região
O solo árido e o predominante clima desértico não são favoráveis às atividades econômicas; a possibilidade de agricultura só existem juntamente aos oásis e em trechos de pouco comprimento do litoral
Mas as riquezas mineiras apresentadas pelo subsolo são a expressividade das reservas de petróleo, gás natural, ferro e urânio.
Mesmo com o encontro do Egito com o Sudão no deserto do Saara, o rio Nilo ali presente pode ser agrupado em outra sub-região
Como os rios Nilo Branco e Nilo Azul formam o famoso acidente geográfico fluvial, é atravessada pelo Nilo a totalidade do território desses países, cujo rio proporciona a melhoria das condições vitais para seu povo.
O solo apresentado pelo vale do Nilo é de extrema fertilidade, no qual é praticada com intensidade a agricultura
Consequentemente desse fato, a população do Egito e Sudão é muito maior no deserto do Saara
O Cairo é, por exemplo, a maior cidade da África em população e uma das mais populosas do mundo, com mais de 11 milhões de habitantes.
De menor expressão no Sudão, a indústria egípcia é de maior desenvolvimento e diversidade, das quais podem ser citadas as indústrias siderúrgica, a elétrica e a têxtil, assim como as de produto químicos e alimentícios
Também no subsolo do Egito e do Sudão são encontradas reservas de petróleo e gás natural, além de ferro, fosfato e potássio.
A África Ocidental está localizada entre o deserto do Saara e o golfo da Guiné e nela são abrangidos 17 países independentes (ver lista de países, abaixo).
Devido ao fato de se localizar entre o deserto e o golfo, o clima da região é do tipo equatorial, e a vegetação é formada por savanas na parte setentrional e florestas na parte meridional, onde chove bastante.
A densidade demográfica da África Ocidental é menor nas regiões sob influência do Saara e maior no sul
A Nigéria alberga cerca de 60% de sua população.
A principal atividade econômica é a agricultura, alternada entre a agricultura de subsistência e a plantação de produtos que se destinam à exportação, como o café, cacau, amendoim, banana e outros.
O fato de a África Ocidental chegar à industrialização, que está se expandindo, é dependente dos capitais estrangeiros
Os países de maior desenvolvimento no setor são: Nigéria, Costa do Marfim e Senegal.
Os países agrupados por essa região são quatro: República Centro-Africana, República do Congo, República Democrática do Congo e Angola
Está localizada na porção equatorial do continente, que faz limite com o Atlântico a oeste e com altas escarpas montanhosas e grandes falhamentos a leste, sendo verificados, no resto do território, os planaltos e planícies alternadas cujos rios caudalosos atravessam
A região tem um clima de calor e umidade nos países da extremidade norte, sendo verificadas as presentes florestas equatoriais
O clima predominante na extremidade sul da África Ocidental é o tropical, tendo como ecossistema as savanas.
A população dessa região é menos densa cujo grupo étnico principal são os negros que fazem parte majoritariamente do grupo banto
Os países mais populosos da África Central são Zaire e Angola.
É semelhante a agricultura da África Central em relação à agricultura da África Ocidental
A importância da exploração mineral é maior para o Zaire e Angola, onde são encontradas jazidas de cobre, cobalto, manganês e ferro
O extrativismo vegetal, notadamente de madeira, é responsável pelo reforçamento da economia regional.
Como na quase totalidade do continente, há poucas indústrias, mas os lençóis petrolíferos descobertos na faixa litorânea e o grande potencial hidrelétrico que esses países possuem têm como vantagem o oferecimento do progresso esperado.
A África Oriental compreende a área que vai da bacia hidrográfica do rio Congo até as águas do mar Vermelho e do oceano Índico
Os países que são agrupados pela África Oriental são no total dez: Eritreia, Etiópia, Djibuti, Somália, Quênia, Tanzânia, Uganda, Ruanda, Burundi e Seychelles
Como a diversidade da paisagem é muito grande, é verificada, em meio à quantidade menor de planícies e da elevação dos planaltos , os ali presentes maciços montanhosos, grandes falhamentos, a grande quantidade de vulcões e lagos
O clima predominante é o tropical, com atenuação das temperaturas pela altitude
A variação de um quadro oferecido pela vegetação é formada pelas florestas equatoriais, pelas savanas, pelas estepes e pelas formações características de áreas desérticas.
As etnias da África Oriental não têm homogeneidade: na península da Somália, aquilo que os geógrafos a conhecem como "Chifre da África" no Brasil ou "Corno de África" em Portugal apenas porque tem a peculiaridade desse formato, a predominância da população tem como grupo étnico os negros do grupo banto, enquanto em outras áreas são encontrados expressivamente a quantidade de camitas, árabes, indianos e europeus
O contingente que é habitante da zona rural é numericamente maior do que a população das cidades; a cidades mais populosas da África Oriental são Nairóbi, Mogadíscio e Adis-Abeba.
Na África Oriental, a economia que tem como base a agricultura, que se organiza principalmente de acordo com o sistema de plantation, é dedicada aos produtos exportados que são o café e o algodão
A escassez de recursos minerais é limitada em jazidas menores de ouro, platina, cobre, estanho e tungstênio
Também na África Oriental a vantagem que ainda não foi atingida pela industrialização representa um grau de satisfação ao fato de que a economia se desenvolva.
Uma das regiões de maior pobreza e onde ocorrem mais conflitos é a África Centro-oriental
Seu povo teve crises de seca e fome (Somália e Etiópia) e conflitos entre etnias em que morreram 800 mil hutus e tutsis em Ruanda e Burundi.
A África Meridional, cuja linha imaginária do Trópico de Capricórnio atravessa, está dividida em doze países
No relevo da África Meridional são predominantes os planaltos cujas baixas altitudes da faixa litorânea circundam
Correspondendo ao clima, que tem variação entre a umidade do tropical e o desértico (na região do Calaari), fazendo a passagem, pelo mediterrâneo, é encontrada uma vegetação que também tem diversidade, em que é verificada a savanas ali presentes, estepes e até mesmo florestas (em conjunto com o litoral do oceano Índico).
O ponto vantajoso das reservas de minério é que sustentam de maneira principal a economia da África Meridional
Merecem ser destacados os principais produtos econômicos do extrativismo mineral da África do Sul, que são o ouro, os diamantes, o crômio e o manganês) e da Zâmbia, que são o cobre e o cobalto
Como atividades que geram dinheiro podem ser citadas ainda a agricultura, onde os camponeses produzem alimentos de clima mediterrâneo como vinhas, oliveiras e frutas e alimentos de clima tropical como cana-de-açúcar, café, fumo e algodão, além dos pecuaristas criarem extensivamente os bois.
No território sul-africano, que é o país que tem mais indústrias no continente, a concentração das indústrias está localizada nas regiões metropolitanas de Joanesburgo, Cidade do Cabo e Durban
Na África do Sul, o regime político que oficializou a segregação racial foi apartheid
Através desse regime, por 15,5% da população, que são os brancos, foi dominado o país até 1994
Desde a instituição do apartheid, brancos e não-brancos tiveram relações socialmente muito desiguais.
O Estado namibiano, que proclamou sua independência em 1990, fazia parte da África do Sul num período de 70 anos
Depois que a Alemanha colonizou de maneira original a Namíbia, foi elevado à categoria de colônia da África do Sul depois da Primeira Guerra Mundial
O primeiro governante que a população da Namíbia elegeu após a proclamação da independência foi Sam Nujoma, que liderava o movimento guerrilheiro num período de 30 anos.
A África limita-se a norte com o mar Mediterrâneo, a sul com aconfluência dos oceanos Atlântico e Índico, a Este com a Ásia e o oceano Índico e a oeste com o oceano Atlântico.
No oceano Índico encontra-se Madagáscar, a maior ilha da África, separada do continente pelo canal de Moçambique.
O continente Africano tem aproximadamente 30 270 000 km², sendo o terceiro continente mais extenso atrás da Ásia e da América: No sentido este-oeste tem 7400 km, pouco menos que a extensão norte-sul que é de aproximadamente 8000 km.
O extremo Norte encontra-se no Ras ben Sakka na Tunísia à latitude 37° 21' Norte e extremo Sul no cabo das Agulhas na África do Sul a latitude 34° 51' S
O extremo Leste encontra-se no Ras Hafun na Somália, à longitude 51° 27' E
O extremo oceânico no Cabo Verde no Senegal à longitude 17°33′22″ W.
África é o terceiro continente em extensão territorial, e o segundo continente mais populoso (atrás da Ásia) com cerca de um bilhão de pessoas (estimativa para 2005 ), representando cerca de um sétimo da população do mundo, cifra que lhe confere uma densidade demográfica de cerca de 30 habitantes por quilômetro quadrado.
Essa pequena ocupação demográfica encontra explicações nos seguintes fatores:
A população africana caracteriza-se também pela distribuição irregular
O vale do Nilo, por exemplo, possui densidade demográfica de 500 hab./km, enquanto os desertos e as florestas são praticamente despovoados
Outros pontos de alta densidade são o golfo da Guiné, as áreas férteis em torno do lago Vitória e alguns trechos no extremo norte e no extremo sul do continente
As regiões das savanas, de maneira geral, são áreas de densidades demográficas médias.
Poucos países africanos apresentam população urbana numericamente superior à rural; entre os que se enquadram nesse caso estão Argélia, Líbia e Tunísia.
A quase totalidade dos países africanos exibe características típicas do subdesenvolvimento: elevadas taxas de natalidade e de mortalidade, bem expectativa de vida muito baixa
Resulta desses fatores a preponderância de jovens na população, que, além de apresentarem menor produtividade, requisitam grandes investimentos em educação e nível de emprego.
Em correspondência com os diferentes ramos étnico-culturais, encontram-se na África três religiões principais: o Islão, que se manifesta sobretudo na África Branca, mas é também professado por numerosos povos negros; o cristianismo, religião levada por missionários e professada em pontos esparsos do continente; e as religiões tradicionais africanas centradas no animismo, seguido em toda a África Negra
Esta última corrente religiosa, na verdade, abrange grande número de seitas politeístas, que possuem em comum a crença na força e na influência dos elementos da natureza sobre o destino dos homens.
Da mesma forma que as religiões, existem inúmeras línguas no continente: várias línguas de origem africana e os idiomas introduzidos pelos colonizadores, utilizados até hoje
Os principais são: árabe, inglês, francês, português, espanhol e africâner, língua oriunda do neerlandês, falada pelos descendentes de neerlandeses, alemães e franceses da África do Sul e da Namíbia.
Cinco dos países de África foram parte do Império Português e usam a língua portuguesa como oficial (ver PALOP)
Em Cabo Verde, Guiné-Bissau e São Tomé e Príncipe ainda são falados crioulos de base portuguesa.
Predefinição:Lista das maiores áreas metropolitanas da África
A maior parte da população africana é constituída por diferentes povos negros, mas há expressiva quantidade de brancos, que vivem principalmente na porção setentrional do continente, ao norte do deserto do Saara, por isso mesmo denominada "África Branca"
São principalmente árabes e berberes, mas incluem também os tuaregues; aparecem ainda, embora em menor quantidade, judeus e descendentes de europeus.
A sul do Saara estende-se a chamada "África Negra", povoada por grande variedade de grupos negroides que se diferenciam entre si por diferenças culturais, como as religiões que professam e a grande diversidade de línguas que falam
Os grupos mais importantes são:
Além dos negros, encontramos na África os malgaxes, povo de origem malaia que habita a ilha de Madagáscar, os indianos trazidos pelos colonizadores ingleses e portugueses para a África Oriental, além de um pequeno número de imigrantes chineses e de origem europeia.
Existe no mundo uma diversidade de regiões que a fome atinge
A fome é a causa de morte para milhares de pessoas anualmente
Os principais focos são Haiti, Indochina, Índia e Bangladesh
Mas não há outro lugar onde ocorre a disseminação do problema a não ser na África
Apesar disso, a fome atinge com dureza trinta países, em primeiro lugar, principalmente aqueles que se localizam nas áreas adjacentes do deserto do Saara
Por esse motivo, com alguma frequência a associação da fome está relacionada com o clima árido e as precipitações irregulares
O clima adverso, porém, apenas faz a amplitude da miséria da maioria dos cidadãos africanos, que vivem numa posição inferior à linha da pobreza e às péssimas condições de que podem sobreviver
Outros fazem a contribuição para a composição desse quadro dramático.
Para o profundo entendimento de tudo aquilo que causou a fome na África é importante é a volta no tempo à época em que foi colonizada, quando os europeus introduziram o sistema de plantation para realizar a produção de gêneros que se destinam à exportação, tornando reduzida a área de cultivos de subsistência (milho, sorgo, mandioca, etc.)
A maioria dos países africanos exportadores, por valores flutuantes, matérias-primas para os países ricos e que fazem a importação, a preços caríssimos, alimentos para suas populações que passam fome.
Com a agricultura extensiva, o homem derruba as matas e em seus limites ocorre o avanço do deserto
A produção necessária para exportar não permite que seja praticado o sistema de descansar a terra, que se esgota com rapidez e mesmo assim o fato de utilizar fertilizantes é de difícil recuperação
Geralmente, dessa forma, houve a diminuição da produtividade agrícola em muitos países africanos
O fato de introduzir a pecuária extensiva, em consequência da pecuária nômade, que se pratica de maneira tradicional no continente, também é causadora de danos às paisagens africanas, pois ocorre a morte dos rebanhos com as pastagens que se reduziram, sendo que a fome os atinge, igualmente à população.
Outro problema é o descompasso existente entre o enorme crescimento populacional e o reduzido crescimento, ou mesmo estagnação, da agropecuária
Apesar das elevadas taxas de mortalidade infantil e geral, da ineficácia dos serviços de saúde e das numerosas doenças, a população africana cresce em níveis muito altos
A todos esses problemas é preciso acrescentar outro, ainda mais marcante: as guerras
A colonização da África impõs divisões políticas que nunca coincidiram com as divisões tribais e, atualmente, guerras entre tribos agravam ainda mais a fome e a mortalidade no continente.
Quando o problema torna-se agudo demais, é comum organizarem-se campanhas nos países mais ricos
Essas campanhas, no entanto, conseguem apenas atenuar o problema, pois atacam as suas consequências e não as suas causas
Além disso, nem todos os recursos provenientes dessas campanhas chegam a seu destino, pois a rede de transportes e demais serviços de infraestrutura extremamente precários fazem com que parte dos alimentos enviados não alcance as populações mais isoladas.
Em nenhuma outra parte do mundo a questão racial assumiu questões tão graves como na África do Sul
Embora os negros, mestiços e indianos constituam 86% da população, eram os brancos que detinham todo o poder político, e somente eles gozavam de direitos civis.
A origem desse sistema, denominado apartheid, data de 1911, quando os africânderes (descendentes de agricultores holandeses que emigraram para a África do Sul) e os britânicos estabeleceram uma série de leis para consolidar seu domínio sobre os negros
Em 1948, a política de segregação racial foi oficializada, criando direitos e zonas residenciais para brancos, negros, asiáticos e mestiços.
Na década de 1950, foi fundado o Congresso Nacional Africano (CNA), entidade negra contrária à segregação racial na África do Sul
Em 1960, o CNA foi declarado ilegal e seu líder Nelson Mandela, condenado à prisão perpétua
De 1958 a 1976, a política do apartheid se fortaleceu com a criação dos bantustões, apesar dos protestos da maioria negra.
Diante de tal situação, cresceram o descontentamento e a revolta na maioria subjugada pelos brancos; os choques tornaram-se frequentes e violentos; e as manifestações de protesto eram decorrência natural desse quadro injusto
A comunidade internacional usou algumas formas de pressão contra o governo sul-africano, especialmente no âmbito diplomático e econômico, no sentido de fazê-lo abolir a instituição do apartheid.
A atual divisão política da África somente se configurou nas décadas de 1960 e 1970
Durante séculos, o continente foi explorado pelas potências europeias - Reino Unido, França, Portugal, Espanha, Bélgica, Itália e Alemanha -, que o dividiram em zonas de influência adequadas aos seus interesses
Ao conseguirem a independência, os países africanos tiveram de se moldar às fronteiras definidas pelos colonizadores
Estas, por um lado, separavam de modo artificial grupos humanos pertencentes às mesmas tribos, falantes dos mesmos dialetos e praticantes dos mesmos costumes e submetia-os, por outro lado, à influência de valores europeus.
Em muitos desses novos países, após a independência, houve inevitáveis revoltas separatistas e golpes de Estado que terminaram por instaurar ditaduras
Seguindo diretrizes capitalistas ou socialistas, os governos assim constituídos distinguiam-se sempre pela perseguição política, que chegava a culminar em torturas e massacres dos opositores.
Em grande parte dos casos, a independência política não foi total, pois geralmente os novos países mantiveram laços econômicos com as ex-metrópoles e, durante a Guerra Fria, alguns ligaram-se às grandes potências (Estados Unidos e extinta União Soviética) em busca de assistência militar e econômica.
De tudo isso resulta a existência de muitos focos de conflito no continente
Em alguns casos trata-se de lutas de caráter político: grupos que pretendem conquistar o poder se confrontam com os que detêm o domínio da região
Em outros, o motivo principal é o separatismo, originado pela artificialidade das fronteiras coloniais herdadas.
Abaixo indicam-se as principais regiões da África e os países que as compõem.
Há ainda territórios pertencentes a países (ou territórios dependentes) de outros continentes, não constituindo portanto dependências:
A África é o continente mais pobre do mundo, onde estão quase dois terços dos portadores do vírus HIV do planeta, a continuidade dos conflitos armados, o avanço de epidemias e o agravamento da miséria põem em causa o seu desenvolvimento
Algumas nações alcançaram relativa estabilidade política, como é o caso da África do Sul, que possui sozinha um quinto do PIB de toda a África.
Distinguindo-se pelas elevadas taxas de natalidade e de mortalidade e pela baixa expectativa de vida e abrigando uma população jovem, a África caracteriza-se pelo subdesenvolvimento
Aparecendo ao mesmo tempo como causa e consequência desse panorama, os setores econômicos em que os países africanos apresentam algum destaque constituem herança do seu passado colonial: o extrativismo e a agricultura - setores em que são baixos os investimentos e o custo da mão-de-obra - cuja produção é destinada a abastecer o mercado externo.
A África detém grandes reservas minerais, destacando-se o ouro e os diamantes da África do Sul, do Zaire e de Gana, que respondem pela maior parte da produção mundial
É igualmente rica em fontes energéticas como petróleo e gás natural, explorados principalmente na Nigéria, no Gabão, na Líbia, na Argélia e no Egito.
O subsolo africano fornece também em abundância os seguintes minerais: antimônio (África do Sul), fosfatos (Marrocos, grande produtor mundial), manganês (Gabão e África do Sul), cobre (Zâmbia e Zaire), urânio (África do Sul e Gabão).
Apesar da diversidade de minerais encontrada em seu subsolo, a África revela-se um continente pobre, o que é explicado pelo fato de a exploração das riquezas minerais estar a cargo de companhias europeias ou norte-americanas
Estas, ao se instalarem, implantam na região uma infraestrutura - equipamentos, técnicas e meios de transporte - visando exclusivamente à extração e exportação das riquezas em estado bruto para os países industrializados, de modo que a maior parte dos lucros provenientes desse setor acaba se encaminhando para fora do continente.
A caça, a pesca e a coleta de produtos naturais ainda constituem importantes fontes de renda para a grande parcela da população africana
No extrativismo animal, figuram em primeiro plano o comércio de couro e de peles em Burkina Faso, Botsuana e Djibuti, e o de marfim na África do Sul, Congo, Moçambique e Gabão
O extrativismo vegetal fornece como principais produtos: madeiras, resinas e especiarias, nos países cobertos parcialmente pela floresta equatorial; óleo de palmeira, no Benim e na Costa do Marfim; tâmaras, nos países desérticos.
A agricultura do continente africano apresenta-se sob duas formas: a de subsistência e a comercial
A primeira é rudimentar, itinerante e extensiva - planta-se em grandes extensões de terra, que são cultivadas anos seguidos, até ocorrer o esgotamento do solo
Em seguida, busca-se outra área, em que se repete o mesmo processo
Trata-se de um sistema pouco produtivo, cujas colheitas abastecem, em geral, apenas os próprios agricultores
Como principais produtos de cultivo citam-se inhame, mandioca, milho, sorgo, batata e arroz.
A forma comercial de agricultura está representada pela plantation, sistema introduzido pelos europeus no período colonial; baseia-se na monocultura de gêneros tropicais em grandes extensões de terra, com produção voltada para o mercado externo
Muitas vezes as propriedades encontram-se sob o comando de grandes empresas agroindustriais, que encaminham os artigos agrícolas para o processamento industrial
Enquadram-se nesse caso o algodão e a borracha, bem como o cacau, o café e o amendoim.
Devido às condições naturais pouco propícias à criação de gado bovino, a África tem na pecuária uma atividade econômica de limitado alcance, em geral praticada de forma nômade ou extensiva
O maior destaque é para a criação de ovelhas na África do Sul e na Etiópia, além de pequenos rebanhos conduzidos por nômades nas regiões de estepes
Nos países situados ao norte do Saara, criam-se camelos e dromedários, animais de grande porte utilizados como meio de transporte
Nessa região, os rebanhos caprino e ovino também são significativos.
A incipiente industrialização do continente, por sua vez, está restrita a alguns pontos do território
Iniciou-se tardiamente, após o processo de descolonização, motivo pelo qual as indústrias africanas levam grande desvantagem em relação ao setor industrial altamente desenvolvido de países do Primeiro Mundo, ou mesmo de Terceiro Mundo, mas industrializados, como o Brasil
Esse distanciamento agrava-se dia a dia com o permanente aprimoramento industrial e tecnológico dos países desenvolvidos.
Toda a sua estrutura econômica é extremamente frágil e dependente, fato que se torna mais evidente no setor industrial: a escassez de capitais, a falta de mão-de-obra técnica especializada e a insuficiência dos meios de transporte, aliados ao baixo poder aquisitivo da população, compõem um quadro nada propício ao desenvolvimento econômico
Mesmo a grande variedade de matérias-primas, sobretudo minerais, que poderia ser utilizada para promover a indústria africana, é destinada basicamente ao mercado externo.
Atuando nesse panorama, as modestas indústrias africanas dedicam-se, em geral, ao beneficiamento de matérias-primas, como madeiras, óleos comestíveis, açúcar e algodão, ou ao beneficiamento de minérios para exportação.
Atraídas pelo baixo preço da mão-de-obra, da energia elétrica e das matérias-primas, muitas indústrias de origem europeia e norte-americana instalaram-se no continente, onde produzem a custo reduzidos artigos cuja exportação lhes possibilita altas margens de lucro.
As indústrias têxteis e alimentares, voltadas para o mercado interno, encontram-se em todos os países do continente, enquanto na África do Sul, no Egito e na República Democrática do Congo estão instaladas as principais indústrias de base (siderúrgicas, metalúrgicas, usinas hidrelétricas etc.) Essa circunstância justifica o fato de a África do Sul e o Egito serem os países mais industrializados do continente.
O sistema de transportes, bastante precário, constitui um entrave ao desenvolvimento industrial
Implantado pelos colonizadores, tinha como principal finalidade possibilitar o escoamento de matérias-primas e gêneros agrícolas para os portos marítimos, de onde os produtos seguiam para as metrópoles
Por isso, hoje a África ressente-se da falta de uma rede rodoviária e ferroviária que interligue eficazmente suas regiões.
A cultura da África reflete a sua antiga história e é tão diversificada como foi o seu ambiente natural ao longo dos milénios
A África é o território terrestre habitado há mais tempo, e supõe-se que foi neste continente que a espécie tenha surgido
Os mais antigos fósseis de hominídeos encontrados na África (Tanzânia e Quênia) têm cerca de cinco milhões de anos
O Egito foi provavelmente o primeiro Estado a constituir-se na África, há cerca de 5000 anos, mas muitos outros reinos ou cidades-estados se foram sucedendo neste continente, ao longo dos séculos (por exemplo, Axum, o Grande Zimbabwe)
Para além disso, a África foi, desde a antiguidade, procurada por povos doutros continentes, que buscavam as suas riquezas.
O continente africano cobre uma área de cerca de 30 milhões de quilômetros quadrados, um quinto da área terrestre da Terra, e possui mais de 50 países
Suas características geográficas são diversas e variam de tropical úmido ou floresta tropical, com chuvas de 250 a 380 centímetros a desertos
O monte Kilimanjaro (5895 metros de altitude) permanece coberto de neve durante todo o ano enquanto o Saara é o maior e mais quente deserto da Terra
A África possui uma vegetação diversa, variando de savana, arbustos de deserto e uma variedade de vegetação crescente nas montanhas bem como nas florestas tropicais e tropófilas.
Como a natureza, os atuais 800 milhões de habitantes da África evoluíram um ambiente cultural cheio de contrastes e que possui várias dimensões
As pessoas através do continente possuem diferenças marcantes sob qualquer comparação: falam um vasto número de diferentes línguas, praticam diferentes religiões, vivem em uma variedade de tipos de habitações e se envolvem em um amplo leque de atividades econômicas.
Elikia M'Bokolo, "África Negra: História e Civilizações", tomo I, "Até ao Século XVIII, Lisboa: Vulgata, 2003; tomo II, "Do século XIX aos nossos dias", Lisboa: Edições Colibri, 2007

África

América

Antártida

Ásia

Europa

Oceania

América Central

América do Norte

América do Sul

Austrália

Eurafrásia

Eurásia

Magrebe · Norte · Centro · Sul · Ocidente · Oriente · Subsaariana

Norte  · Central   · Sul 
(Latina  · Anglo)

Central · Oriente   · Norte   · Sul   · Sudeste · Ocidente

Ocidente · Centro · Oriente · Norte · Sul


Australásia · Melanésia · Micronésia · Polinésia

Ártico · Antártida

Negro pode referir-se a:
 Rio Negro
 Black
 Noir
Ásia é o maior dos continentes, tanto em área como em população
Abrange um terço das partes sólidas da superfície da Terra e é responsável por abrigar quase três quintos da população mundial
A Ásia faz fronteira no lado ocidental com a África e com a Europa, e no lado oriental com o oceano Pacífico, a Oceania e, em menor proporção, com a América do Norte, pelo Estreito de Bering
O ponto extremo setentrional do continente está localizado no oceano Glacial Ártico
Mas na parte meridional, a Ásia chega ao seu final na região mais quente dos trópicos, nas imediações da linha do equador
Na Ásia são encontradas algumas das montanhas mais altas do mundo; os rios mais extensos; os maiores desertos, planícies e planaltos; as selvas e florestas mais densas
A altitude máxima e a mínima está localizada na Ásia
O monte Everest, a altitude máxima do planeta, está localizada a 8 848 m acima do nível do mar; ao longo da linha fronteiriça da República Democrática Federal do Nepal com a região autônoma chinesa do Tibete
O litoral do mar Morto, a planície de menor altitude do mundo, estão localizadas a 396 m abaixo do nível do mar, na região fronteiriça do Estado de Israel com o Reino Hashemita da Jordânia.
Dos 55 países são encontradas algumas das maiores e menores nações do mundo, tanto em área como em população
A Federação Russa, cuja parte europeia corresponde a um quarto de seu território, tem três quartos de território na parte asiática, sendo duas vezes maior que os Estados Unidos e o Canadá juntos
Mas três nações asiáticas — Reino do Barém, República de Singapura e República das Maldivas — juntas corresponderiam à extensão territorial da ilha de Marajó
A população da República Popular da China ou da República da Índia é maior do que as populações dos continentes norte-americano e sul-americano somadas
Porém, aproximadamente dois terços dos países da Ásia tem uma população pequena em relação à da Região Metropolitana de São Paulo
O povo é enormemente diferente em árvores genealógicas, práticas ou comportamentos habituais, idiomas, crenças de religião o modus vivendi
A civilização asiática teve início há mais de 4 000 anos, muito antes de começar no mundo ocidental, em termos de atividades econômicas, manifestações culturais e desenvolvimento da ciência
O povo da Ásia fundou as cidades mais antigas, estabeleceu os sistemas de leis mais antigos e criou a figura dos agricultores e comerciantes mais antigos
Os cidadãos da Ásia foram os inventores da escrita e criaram as primeiras literaturas
Os fundadores de todas as religiões mais relevantes do mundo foram asiáticos: Buda, Confúcio, Jesus Cristo e Maomé
Os asiáticos também foram os inventores do papel, da pólvora, da bússola e do tipo móvel.
As nações asiáticas têm vários sistemas de governo
Os comunistas são responsáveis pelo governo da China e de alguns outros países
Os monarcas governam os reinos da Arábia Saudita e a Tailândia, por exemplo
Os xeques são os controladores do Reino do Barém, do Estado do Catar e dos Emirados Árabes Unidos
Dos países da Ásia que são seguidores dos princípios da democracia, podemos citar Israel e Japão
Líderes das forças armadas passaram a exercer o controle de muitas nações da Ásia em períodos de conturbação
Os sultões de nove estados malaios ocupam a função no cargo de chefe supremo da nação
A população asiática é muito diversificada quanto tudo o que se refere ao continente
Durante o século XVI, a economia asiática declinou-se, enquanto o mundo ocidental teve rápido progresso
As nações do Oeste da Europa foram os conquistadores da parte predominante da Ásia dos século XVI até o século XIX
A economia defasada entre o continente asiático e o mundo ocidental teve aumento ainda mais na época da colonização vinda da Europa
Os cidadãos da Europa e dos Estados Unidos foram responsáveis pelo desenvolvimento do sistema industrial e tiveram o início da utilização de máquinas e de outros recursos na atividade agrícola
Isto tornou possível a criação de novos empregos, o aumento produtivo, e a melhoria do nível de vida
Mas a maior parte dos países da Ásia não se desenvolveram industrialmente
Continuaram sendo países de economia baseada na agricultura, e seus agricultores empregavam na utilização de ferramentas, manuais e métodos nada modernos
Ao mesmo tempo, a explosão populacional — que ainda está a ocorrer — aumentou de modo incrível a população asiática como do mundo ocidental
Mais e mais produtos alimentícios, ocupações empregatícias, instituições de ensino, além de outras coisas básicas, tornavam-se necessidade de acordo com o aumento populacional
O mundo ocidental, por causa do desenvolvimento de sua economia, teve mais recursos do que o continente asiático para enfrentar os problemas que foram as consequências da explosão demográfica.
Quase toda a Ásia colonial teve sua independência conquistada em meados do século XX
A partir de então, muitos cidadãos da Ásia têm trabalhado para ter o padrão de vida elevado, incentivando as atividades industrial, a agrícola, e diminuindo o crescimento da população
As disputas políticas já dificultaram essa tarefa
Após a Segunda Guerra Mundial (1939-1945),o continente asiático foi convertido no centro das lutas entre países que adotam o comunismo como sistema de governo e países que utilizam o capitalismo como sistema econômico
Na maioria dos países da Ásia, a luta começou, quando os comunistas tiveram o desejo de ocupar o poder executivo do novo país independente
Fora disso, outras disputas que não se relacionam com os políticos do comunismo foram provocadores de brigas entre diversos grupos no continente asiático
Sendo assim, a Ásia, quase de modo ininterrupto, enfrenta conflitos militares e civis e ameaças bélicas enquanto tenta a solução de todos os problemas.


O termo "Ásia" foi recebido pela língua portuguesa através do latim, a partir do grego antigo Ασία
O primeiro registro do topônimo é encontrado em Heródoto: em cerca de 440 a.C., aquele historiador grego mencionava a uma divisão do mundo em três partes, cujos nomes referiam-se a personagens da mitologia grega: a Europa, em homenagem à ninfa oceânida ou à filha de Agenor; a Líbia (que é como os gregos antigos chamavam a África), em homenagem à mãe de Agenor; e a Ásia (Ασία), em homenagem a outra ninfa oceânica, mais conhecida como Clímene
À época, o termo Ásia servia para designar a atual Ásia Menor (Anatólia) ou, por oposição ao mundo grego ou egípcio, o Império Aquemênida
O termo Ασία, por sua vez, pode ser derivado do acádio (w)aṣû(m), que significa "subir", "sair", com respeito ao nascer do sol.
Outra explicação para a etimologia refere-se a Homero, que menciona na Ilíada um certo Ásio, aliado dos troianos e filho de Hírtaco
O nome "Ásio" proviria de Assuwa, uma confederação de Estados do século XIV a.C
localizada no oeste da Anatólia e cujo nome teria origem no hitita assu, que significa "bom".
O gentílico de "Ásia" é asiático (ou asiano, asiânico, ásio).
A história da Ásia pode ser entendida como a história coletiva de várias regiões litorâneas distintas - o leste asiático, a Ásia meridional e o Oriente Médio - ligadas pela estepe eurasiática no interior do continente
Cidades, depois Estados e impérios surgiram naquelas áreas.
A periferia costeira foi o berço de algumas das civilizações mais antigas do mundo
Cada uma daquelas regiões desenvolveu uma civilização ao longo de vales férteis de rios
As civilizações da Mesopotâmia, do vale do Indo e da China tinham muito em comum e provavelmente trocaram tecnologia e ideias, como a matemática e a roda
Outros avanços, como a escrita, desenvolveram-se independentemente em cada região.
A estepe era habitada por nômades a cavalo que, a partir das estepes centrais, alcançavam qualquer parte do continente asiático
A primeira expansão conhecida das estepes para a costa foi a dos indo-europeus, que levaram sua família linguística ao Oriente Médio, à Índia e às fronteiras da China
A parte norte do continente, correspondente à Sibéria, permaneceu inacessível aos nômades, devido a suas densas florestas e à tundra, e manteve-se pouco habitada.
A estepe central e a periferia são separadas por cordilheiras e desertos
O Cáucaso, os Himalaias, o deserto de Karakum e o deserto de Gobi representavam barreiras que os cavaleiros das estepes ultrapassavam com dificuldade
Embora os habitantes das cidades fossem mais avançados tecnológica e culturalmente, havia pouco que pudessem fazer para defender-se militarmente das hordas a cavalo provenientes das estepes
Entretanto, os nômades que conquistaram Estados na China, Índia e Oriente Médio terminaram por adaptar-se e integrar-se às sociedades locais, culturalmente mais fortes.
Muitas grandes civilizações e culturas existiram no continente asiático
O Judaísmo e o Cristianismo foram fundados na Palestina
A cultura da antiga Israel foi estabelecida no segundo milênio a.C
Alexandre, o Grande, conquistou o território que vai da atual Turquia ao subcontinente indiano no século IV a.C
O Império Romano posteriormente controlaria partes da Ásia ocidental
Sucederam-se na Pérsia as dinastias aquemênida, selêucida, parta e sassânida
Muitas civilizações antigas foram influenciadas pela Rota da Seda, que ligava a China, a Índia, o Oriente Médio e a Europa
O hinduísmo e o budismo, que tiveram início na Índia, também foram uma influência importante no sul e no leste da Ásia.
O Califado islâmico e outros Estados muçulmanos tomaram o Oriente Médio a partir do século VII e posteriormente se expandiram para o subcontinente indiano e para a Insulíndia
As Cruzadas, tentativas da Europa cristã de retomar dos muçulmanos a Terra Santa, sucederam-se a partir do século XII
O Império Mongol conquistou boa parte da Ásia no século XIII, estendendo-se da China à Europa
O Império Russo começou a expandir-se em direção à Ásia no século XVII, até controlar a Sibéria e a maior parte da Ásia Central em fins do século XIX
O Império Otomano controlou a Turquia e o Oriente Médio a partir do século XVI
No século XVII, os manchus conquistaram a China e estabeleceram a dinastia Qing, que declinou no século XIX e foi derrubada em 1912.
Diversas potências europeias apossaram-se de partes da Ásia, como a Índia britânica, a Indochina francesa e Macau e Goa, que estiveram sob controle português
No século XIX, decorreu o chamado "Grande Jogo" entre o Império Russo e o Império Britânico, uma disputa pelo controle da Ásia Central
No século XX, o Japão expandiu-se para a China, a Coreia e o sudeste asiático durante a Segunda Guerra Mundial
Após o conflito, muitos países do continente tornaram-se independentes das potências europeias
Durante a Guerra Fria, a porção norte da Ásia era comunista, controlada pela União Soviética e pela República Popular da China, enquanto que os aliados ocidentais formaram pactos como CENTO e SEATO
Representantes dos blocos capitalista e comunista enfrentaram-se em confrontos como a Guerra da Coreia, a Guerra do Vietnã e a invasão soviética do Afeganistão
O conflito árabe-israelense dominou a maior parte da história recente do Oriente Médio
O colapso da União Soviética, em 1991, deu origem a vários países independentes na Ásia Central.
A área do continente asiático é superior a 44,5 milhões de quilômetros quadrados, correspondentes a quase um terço de todas as terras emersas do nosso planeta
Só no continente moram aproximadamente 4 000 milhões  de habitantes, número que supera quase 50% da população do mundo, como resultado da densidade demográfica fora do comum e superior a 70 habitantes por quilômetro quadrado.
Essa vasta área territorial é atravessada por três paralelos: no ponto extremo setentrional, em território russo, pelo Círculo Polar Ártico; na parte meridional, pelo Trópico de Câncer; e, no centro do território arquipelágico indonésio, pela linha do Equador.
Localizada quase totalmente no hemisfério setentrional, com somente uma porção dos territórios insulares do sul indonésio ocupando o hemisfério meridional, o continente asiático torna-se extenso de 10 graus de latitude ao sul da linha do Equador a 80 graus de latitude ao norte dessa mesma linha divisória
Distribuindo-se por inteiro pelo hemisfério leste, torna-se extenso de 25 para além de 180 graus de longitude a leste do Meridiano de Greenwich.
Por ser composto de uma grande extensão continental da parte setentrional para a parte meridional, a Ásia preenche espaço de todas as áreas de clima do hemisfério setentrional: equatorial, tropical, temperada e polar
Tornando-se extenso com grandiosidade também da parte oriental para a parte ocidental, é atravessada por 11 fusos horários.
Faz fronteira no lado setentrional, com o oceano Glacial Ártico; no lado meridional, com o oceano Índico; no lado oriental, com o oceano Pacífico; e no lado ocidental, com os montes Urais, com o rio Ural e com os mares Cáspio, com o Negro, com o Mediterrâneo e com o Vermelho.
O continente asiático é, desse modo, o maior de todos, onde se podem ser encontradas as mais diversos panoramas paisagísticos e tipologias de clima, como também diversidade de etnias e padronizações de desenvolvimento da economia.
A Ásia apresenta características contrastantes: enormes terras baixas de aluvião e de litoral e grandes formações planálticas com cordilheiras muito altas, que se tornam extensas por uma vasta área centro-meridional, entre os territórios nacionais turco e indonésio
Isso tudo faz do continente asiático o único com aproximadamente 1 0000 metros de cota altimétrica média
As montanhas de maior altitude estão localizadas na cordilheira do Himalaia, mas existem outras que se espalham por toda a área territorial, situando-se no continente asiático as 18 montanhas mais altas do mundo.
O relevo asiático é caracterizado pela apresentação de seus contrastes de extremidade altimétrica:
Algumas regiões banhadas pelas águas salgadas do oceano Pacífico fazem parte do Círculo de Fogo, ou seja, por causa de sua formação geológica ocorrida há pouco tempo estão sujeitas a erupções vulcânicas e a abalos sísmicos
É o caso do arquipélago japonês e da Indonésia.
Algumas formações planálticas são altíssimas e são intercaladas às cadeias de montanhas, como é o caso do Pamir e do Tibete, contrastando com outros de maior antiguidade, de menores altitudes, como os da Armênia, do Decã.
As planícies de rios da Ásia são revestidas com depósito aluvial trazido pelos acidentes geográficos fluviais que as percorrem e que se dirigem de modo principal para as águas salgadas dos oceanos Índico e Pacífico
As principais planícies de rios são a Indo-gangética (Índia), a Mesopotâmica (Iraque), a Siberiana (Rússia) e as dos rios Yang-tsé (China) e Mekong (Vietnã).
A Ásia projeta, dirigindo-se aos oceanos adjacentes, várias porções peninsulares, sendo as mais relevantes a da Anatólia, a Arábica, a Hindustânica, a da Indochina e a da Coreia.
A vasta extensão territorial e, portanto, as diferenças de latitude, a presença alternada de áreas baixas e elevadas, a grande influência das massas de ar e ainda a continentalidade e a maritimidade trazem para o continente grande variedade de tipos de clima e, consequentemente, de formações vegetais.
Nas terras situadas no extremo norte predomina o clima polar, que vai se tornando mais ameno em direção ao sul
O centro do continente, por situar-se distante de influências marítimas e, em parte, devido à altitude do relevo, que bloqueia a passagem dos ventos oceânicos, é dominado pelo clima temperado continental, que alterna verões de elevadas temperaturas com invernos muito frios
Já o temperado oceânico, ocupando grandes extensões do continente, sofre variações em função da altitude do relevo, da latitude e da interioridade.
Mais para o sul, à retaguarda das grandes cordilheiras, que impedem a passagem dos ventos úmidos do oceano, encontram-se vastas extensões dominadas por clima semi-árido e clima árido, formando uma extensa faixa de desertos
A Ásia abriga a maioria dos desertos existentes na Terra: da Arábia (Arábia Saudita), da Síria, de Thal (Paquistão), do Thar (ou Grande Deserto Indiano), de Lut (ou deserto do Irã), de Gobi (Mongólia), de Taklamakan (China), Caracum (Turcomenistão), Carmânia (Irã), da Judeia (Israel), de Negueve (Israel).
No litoral da Ásia Ocidental surge uma faixa estreita de clima do tipo mediterrânico, enquanto nos arquipélagos do sul do continente, nas proximidades do Equador, aparecem climas de tipo quente: equatorial e tropical.
Entre todos os tipos de clima da Ásia, no entanto, o que mais diretamente influi nas condições de vida locais, sobretudo orientando as atividades agrícolas, é o tropical de monções
Abrangendo as regiões mais populosas do continente, estende-se pelas planícies costeiras da Índia e do sudeste e leste da China, com violentas chuvas durante o verão
Caracteriza-se pela atividade dos ventos, conhecidos como monções, que sopram do Índico e do Pacífico para o continente durante o verão, e do interior da Ásia para esses oceanos durante o inverno.
A ocorrência de monções se deve ao fato de que as terras continentais aquecem-se e esfriam mais rapidamente do que as águas oceãnicas
Durante o verão, o interior da Ásia, ao esquentar-se, forma uma área de baixa pressão, que contrasta com as altas pressões dos oceanos, provocando o deslocamento de ventos úmidos do mar para terra
Esses ventos são as monções de verão
No inverno, ocorre o inverso: os oceanos estão mais quentes do que o continente, formando áreas de baixa pressão e atraindo os ventos continentais
São as monções de inverno.
As regiões montanhosas, independentemente de sua localização geográfica, apresentam temperaturas muito baixas, em razão da altitude.
Tanto as chuvas abundantes da região influenciada pelos climas equatorial e tropical quanto a grande quantidade de neve derretida das altas montanhas favorecem a existência de grandes rios, que correm em quase todas as direções do continente asiático
Podemos destacar:
A Ásia apresenta poucos lagos, embora de grande extensão, como o Baikal e o Balkhash, localizados na Rússia
Se os lagos existem em pequeno número, os mares asiáticos aparecem com muito mais destaque: mar Vermelho, que limita as costas africanas e asiáticas; Mar da Arábia; a sudeste, mar da China Meridional, mar da China Oriental, Mar de Andamã e mar Amarelo; os mares da Indonésia: de Java, de Timor, de Banda, de Celebes; a nordeste, os mares de Okhotsk, do Japão e de Bering
No limite com a Europa, aparece o maior mar fechado do mundo, o mar Cáspio.
Como as formações vegetais dependem do tipo de solo e principalmente do clima, a Ásia apresenta muitas variedades vegetais, ainda que parcialmente destruídas ou alteradas pela milenar ocupação humana.
No extremo norte do continente, junto ao pólo, não há condições para a existência de vegetação, porém mais ao sul, na planície Siberiana, começam a surgir formações de tundra
Ainda rumo ao sul, à medida que o clima polar se torna menos intenso e o frio se estende por um número menor de meses, aparece a vasta região da taiga, quase integralmente pertencente à Rússia.
O maior destaque, entretanto, está nas estepes, que ocupam grandes extensões da Ásia Central, aparecendo em áreas de clima temperado continental.
Os arquipélagos situados na Ásia Meridional apresentam-se recobertos por florestas equatoriais e tropicais, não muito diferentes das que existem na Amazônia brasileira
Essas formações podem ser observadas também no centro-sul, onde igualmente se verifica a presença de savanas, em que a vegetação herbácea é dominante, apresentando arbustos e árvores em associações pouco densas, como o jângal na Índia.
Registra-se ainda a ocorrência de florestas temperadas em extensões consideráveis no Extremo Oriente e de vegetação xerófita nas áreas desérticas ou semi-áridas do continente.
Considerando que uma região geográfica é uma área mais ou menos definida, caracterizada por determinados aspectos físicos e humanos, seria possível encontrar dezenas delas no continente e até mesmo algumas em um mesmo país
Por esse motivo, e para facilitar o estudo e a compreensão das características e dos problemas políticos e sociais de um continente tão vasto, vamos simplificar sua divisão estudando-o através de seis grandes regiões geográficas
São elas: o Oriente Médio, o subcontinente indiano, o sudeste asiático, o centro-leste, o Extremo Oriente e a parte asiática da Comunidade de Estados Independentes.
Essa área, que se estende desde a Turquia até o Afeganistão, apresenta como característica física dominante o predomínio do clima seco, o que resulta na existência de desertos
Como característica populacional, destaca-se a ocupação por brancos e uma das densidades demográficas mais baixas do continente.
O Oriente Médio reúne 16 países independentes, muito importantes pelas notáveis reservas de petróleo que alguns possuem e por sua posição estratégica, já que essa região é o elo de ligação entre Europa, Ásia e África
É uma área constantemente agitada por conflitos de origens diversas: o antagonismo histórico entre esses países; a grande mescla de seitas e religiões (islamismo, cristianismo, judaísmo); os sistemas político-econômicos vigentes, levando ao alinhamento com os Estados Unidos ou com a Rússia.
Apesar de todas essas diferenças, há muitas semelhanças, principalmente em nível econômico: os países são todos subdesenvolvidos (à exceção de Israel, Catar e Emirados Árabes Unidos) e neles a atividade industrial de transformação é bastante escassa, predominando pequenas indústrias têxteis e alimentares
A agricultura é praticada nas poucas regiões onde não ocorrem desertos
Os principais produtos agrícolas são trigo, cevada, milho, arroz e cítricos, cultivados sobretudo na Turquia, Síria, Líbano, Israel e Iraque
A pecuária restringe-se ao pastoreio nômade de camelos, cabras e ovelhas.
O grande destaque econômico do Oriente Médio, em nível internacional, é a exploração do petróleo, que tem sido responsável pela entrada de lucros fabulosos nos países produtores
Os lucros do petróleo, entretanto, pouco têm contribuído para atenuar o elevado grau de subdesenvolvimento da maior parte dos países dessa área, acentuando, ao contrário, a enorme disparidade na distribuição de renda.
Em 1960, Arábia Saudita, Iraque, Irã, Cuaite e Venezuela criaram a Organização dos Países Exportadores de Petróleo (OPEP), à qual se filiaram durante as décadas de 1960 e 1970: Catar e Abu Dabi (um dos Emirados Árabes Unidos), Indonésia (país da Insulíndia), Equador, Líbia, Argélia, Nigéria e Gabão
Liderada pelos países árabes, a OPEP tem como objetivo controlar o preço do petróleo
Em 1973, essa organização multiplicou o preço do barril de petróleo, provocando uma série de desajustes econômicos nos países importadores, que ficou conhecida como crise do petróleo
Diversos desses países passaram a explorar jazidas até então consideradas não-rentáveis e desenvolveram fontes alternativas de energia
Em virtude disso, a OPEP foi obrigada mais tarde a reduzir o preço do barril de petróleo, cujo consumo retraiu.
A maior parte do Oriente Médio é ocupada pelos países árabes
Localizados na Península Arábica e vizinhanças, são nações fundamentalmente agropastoris, caso do Iêmen, enquanto na Arábia Saudita, Cuaite, Emirados Árabes Unidos, Iraque, Omã, Catar e Barém o petróleo é a grande riqueza nacional, impondo uma paisagem de torres e oleodutos onde durante séculos houve apenas um deserto sem proveito econômico.
Há ainda o Líbano e a Síria, países cuja agricultura e indústria são mais desenvolvidas, muito embora o Líbano, arrasado por conflitos intermináveis, sobreviva com grandes dificuldades
A Jordânia difere de todos por sua atividade mineradora caracterizada pela exploração de fosfato e mármore.
Entre os países não-árabes, há Israel, a nação mais industrializada e desenvolvida do Oriente Médio, além de três grandes Estados - Turquia, Irã e Afeganistão
A indústria turca está se desenvolvendo rapidamente, graças aos incentivos governamentais e às riquezas minerais do país, como carvão, ferro, manganês, crômio e cobre
A economia iraniana baseia-se principalmente na extração e comercialização do petróleo, enquanto a agropecuária é a base econômica do Afeganistão.
No sul da Ásia encontra-se a grande Península Hindustânica, que avança sobre o Oceano Índico
Apresentando a Cordilheira do Himalaia ao norte, o relevo da região é dominado pelo vasto Planalto do Decã, e, entre este e as montanhas, pela grande Planície Indo-gangética, percorrida pelo Indo e pelo Ganges, rios de grande volume de água
A região é tipicamente tropical e os verões são marcados pela chegada dos ventos monçônicos.
Índia, Paquistão e Bangladesh são os países centrais da região; em meio à Cordilheira do Himalaia, localizam-se ainda os pequenos reinos do Nepal e do Butão
A sudeste da Índia está Sri Lanka, país antigamente conhecido como Ceilão, e a sudoeste, o arquipélago das Maldivas.
Aproximadamente metade do território da Índia é recoberto por plantações de arroz, que se beneficiam do clima monçônico; cultivam-se em grande escala também trigo e milho, além de algodão, chá, juta e outros produtos
A pecuária, apesar do enorme rebanho bovino, não tem grande importância econômica.
Em termos mineralógicos, a Índia possui grandes depósitos de ferro, além de produzir a maior parte do petróleo que consome
Possui ainda abundantes reservas de carvão, mica, manganês, alumínio e outras de menor importância.
Dentre os países asiáticos, é dos que apresentam maior grau de industrialização, dispondo de algumas grandes áreas industriais, como a região de Bombaim, Calcutá, no leste, a de Punjab-Nova Délhi, no norte, e a Madras, no sul
Os ramos industriais mais importantes são o têxtil, o alimentar, o mecânico, o siderúrgico e o químico.
Além disso, a Índia domina a energia nuclear, possuindo tecnologia para a fabricação de bombas atômicas
Também na área dos satélites artificiais, esse país alcançou grandes progressos, tendo já lançado seu primeiro satélite de comunicações.
A população indiana é extremamente pobre: três quartos vivem em condições precárias de alimentação, saúde, educação e habitação.
Com mais de 700 habitantes por quilômetro quadrado, Bangladesh assemelha-se à Índia por suas baixas condições de vida
Não é muito melhor a situação do Paquistão, pois embora tenha densidade demográfica sensivelmente menor que a de seus vizinhos, dispõe de áreas relativamente reduzidas para a atividade agrícola e pastoril, que constitui a atividade econômica da maior parte dos habitantes.
Sri Lanka, com contrastes sociais menos chocantes, é uma república que apóia sua economia no cultivo de chá, arroz, borracha e coco e, naturalmente, na pesca
As Maldivas possuem uma economia precária, baseada principalmente na prática rudimentar da pesca e na extração do óleo de copra (amêndoa de coco seca).
Os países montanhosos - Nepal e Butão - enfrentam o problema do isolamento, determinado pelas elevadas altitudes do relevo e particularidades climáticas, que dificultam a construção e a manutenção de estradas, e também pela falta de acesso ao oceano
Nestes pequenos países, pratica-se a agricultura nas poucas áreas em que isso é possível, além de criarem-se animais
Mais da metade da população é analfabeta e os hábitos e costumes tradicionais das tribos regem a vida de quase todos os habitantes.
Em todos os países do centro-sul asiático a população rural é dominante, embora existam algumas grandes cidades, sobretudo na Índia, onde a atividade industrial é diversificada e o nível de informação e politização dos habitantes é bem mais avançado
As maiores cidades da região são Calcutá, Bombaim, Madras, Nova Délhi (Índia), Karachi (Paquistão) e Daca (Bangladesh).
Esta região é formada por nove países independentes: Myanmar (Birmânia), Tailândia, Laos, Vietnã, Camboja, Malásia e Singapura - localizados na península da Indochina - e Indonésia, Brunei, Filipinas e Timor-Leste - que constituem o arquipélago da Insulíndia
A Malásia tem uma parte de seu território localizada na península da Indochina e outra na ilha de Bornéu, cuja maior parte pertence à Indonésia
Brunei localiza-se inteiramente nessa ilha.
O principal destaque econômico do sudeste asiático é a exploração de minérios para exportação, principalmente na Indonésia e na Malásia
A Indonésia, membro da OPEP, é um dos grandes exportadores mundiais de petróleo (Bornéu) e minerais metálicos, com destaque para estanho, ferro, bauxita e ouro
Brunei, sultanato localizado na ilha de Bornéu, depende basicamente da exportação de petróleo.
Apesar de ser rico em minérios, o sudeste asiático apresenta uma indústria pouco desenvolvida devido à falta de capital para ser aplicado em serviços de infraestrutura
As principais indústrias são de processamento de matérias-primas para exportação, como as manufaturas têxteis na Indochina e as usinas de açúcar na Indonésia
Singapura constitui exceção à fraca industrialização da região
Essa pequena ilha é um dos "tigres asiáticos", países de industrialização recente e crescimento acentuado
A indústria malaia e tailandesa também está expandindo, mas as demais economias continuam dependendo basicamente de atividades agrícolas.
A par de atividades de subsistência, em que se destaca o cultivo do arroz a agricultura dessa região asiática, também oferece produtos tropicais, cultivados em regime de plantation, uma herança de colonização europeia
Voltando principalmente à exportação, esse ramo da economia emprega a maior parte da população ativa
As principais culturas para exportação são a da borracha na Malásia, no Myanmar e na Indonésia; de chá, na Indonésia; além do arroz - cultivado em terraços nas vertentes das montanhas -, que é exportando pela Tailândia, Vietnã e Indonésia.
As principais cidades da região são: Jacarta (Indonésia), Manila (Filipinas) e Bangcoc (Tailândia), cujas áreas metropolitanas abrigam mais de cinco milhões de habitantes.
Essa região do globo tem-se caracterizado por diversos problemas políticos, desde sucessivos golpes de Estado a longas e sangrentas guerras envolvendo o confronto entre capitalismo e socialismo, como a ocorrida no Vietnã (1960-1975)
A diversidade de grupos étnicos, o grande número de religiões professadas e os níveis de vida extremamente diferenciados são fatores que concorrem para tornar essa região ainda mais conturbada.
Possuindo o terceiro maior território do mundo e abrigando mais de um bilhão (mil milhões) de pessoas - cerca de 20% de toda a humanidade -, a China adquire grande destaque no mundo
Entretanto, devido ao fato de a maior parte de seu território ser ocupada por desertos e montanhas, a população chinesa fica quase toda concentrada no lado oriental do país, única região que pode ser plenamente aproveitada.
A atividade econômica que emprega maior número de trabalhadores é a agricultura, cuja principal meta é a alimentação da imensa população
Essa atividade se desenvolve através de um sistema comunitário, em que o Estado empresta a terra e fornece os meios para a produção (máquinas, ferramentas, adubos etc.)
A China destaca-se mundialmente na produção de arroz, trigo, soja e outros gêneros, cultivados principalmente no vale do Yang-tsé-kiang
Também na criação de animais (suínos, ovinos e bovinos), esse país se coloca entre os cinco maiores produtores mundiais.
A China possui abundantes reservas minerais e um considerável potencial hidráulico e petrolífero, o que, aliado ao fato de sua mão-de-obra ser muito barata e sua população numerosa, fornece condições para o desenvolvimento da indústria, ainda que ela seja estatizada e se volte quase exclusivamente para o mercado interno
A produção visa basicamente fornecer artigos considerados necessários, sem preocupação com acabamento de luxo e, por isso, sempre ao alcance dos operários e camponeses.
O país conta ainda com um grande parque de indústrias de base, essenciais aos empreendimentos estatais
As principais áreas industriais localizam-se nas proximidades de grandes centros urbanos da China Oriental, como Xangai e Pequim, ou em áreas novas, como a Manchúria.
A China não apresenta um grau de desenvolvimento semelhante ao das grandes potências mundiais, mas é uma nação em que a distribuição de renda e de bens é menos desequilibrada
O padrão de vida de todos é relativamente igual e praticamente não existem a miséria pessoal e suas inúmeras consequências.
A partir de 1984, o governo chinês passou a promover a entrada de investimentos estrangeiros no país, que se retraíram, em 1989, com a repressão às maiores liberdades políticas.
Formosa, ou Taiwan, tornou-se um país independente da China em 1949, por ocasião do término da revolução comunista chinesa
De estrutura capitalista, o país contou com a ajuda de capitais provenientes dos Estados Unidos e do Japão e projetou-se economicamente no plano agrícola e industrial, graças à abundância de recursos minerais e mão-de-obra barata.
A Formosa é um dos países conhecidos como "tigres asiáticos", da mesma forma que Hong Kong, colônia britânica que foi reanexada à China em 1997, funcionando como região administrativa especial.
A Mongólia ocupa a parte mais central do território asiático
Localizada entre a China e a União Soviética, foi por muito tempo motivo de rivalidade entre esses países
Atualmente é alinhada ao bloco soviético
A população do país é bastante reduzida em relação a seu extenso território, que apresenta vários obstáculos naturais ao desenvolvimento econômico
Sua atividade principal é a agropecuária e sua principal cidade é a capital, Ulan Bator.
O Japão é um Estado monárquico, altamente desenvolvido e industrializado, situado a leste do continente asiático, em pleno Oceano Pacífico, e constituído por mais de três mil ilhas, embora apenas as quatro mais extensas sejam economicamente importantes.
Sua área total é pouco maior que a do estado do Maranhão, mas detém uma grande população absoluta (127 milhões de habitantes em 2007) e uma alta densidade demográfica (337 habitantes por quilômetro quadrado)
Essa aglomeração populacional torna-se ainda mais grave ao se constatar que apenas um quinto do território japonês pode ser habitado, já que o restante é ocupado por altas montanhas
Por outro lado, o crescimento vegetativo do Japão é quase nulo, pois as taxas de natalidade apenas compensam as de mortalidade.
Integrante do Primeiro Mundo, portanto, capitalista e desenvolvido, o Japão apresenta, entre outras, as seguintes características: renda per capita bastante alta; moradia, saúde e educação de bom nível, acessíveis a todos; agricultura, indústria e rede de serviços tecnologicamente avançadas.
O desenvolvimento e a prosperidade japonesa, sobretudo após o término da Segunda Guerra Mundial, ocasião em que o país foi parcialmente destruído por bombardeios, constituem um verdadeiro milagre econômico, na opinião de especialistas do setor
Para tanto, contribuíram os seguintes fatores: ajuda militar e financeira dos Estados Unidos, através do Plano Marshall; adoção de uma política de rigoroso controle populacional; prioridade à educação e ao domínio da tecnologia; produção voltada à exportação
A partir da década de 1950, o Japão atingiu um estágio de grande desenvolvimento e é hoje uma das maiores potências mundiais.
Embora disponha de poucas matérias-primas e quase nenhum combustível, o país é bem servido de hidreletricidade
Hoje é o primeiro produtor mundial de navios, o segundo de automóveis e o terceiro de aço e de alumínio, e seus produtos elétricos e eletrônicos, como rádios, televisores, calculadoras e inúmeros outros, encontram-se disseminados por todo o mundo.
Devido ao alto grau de industrialização do Japão, a maior parte de seus habitantes vive no meio urbano, sendo que a Região Metropolitana de Tóquio possui mais de 37 milhões de habitantes, o que torna a aglomeração de Tóquio, independentemente de como se define, como a área urbana mais populosa do mundo; em âmbito nacional, é seguida por Osaka, Nagóia, Yokohama e Quioto.
Localizadas na Península da Coreia, estão a República Popular Democrática da Coreia (Coreia do Norte) e a República da Coreia (Coreia do Sul), que até 1948 formavam um único país
A divisão em dois estados foi decorrente da ocupação do território por soviéticos, no norte, e norte-americanos, no sul, por ocasião do término da Segunda Guerra Mundial.
Desde a separação, a Coreia do Norte é socialista, com uma economia pobre e subdesenvolvida e a Coreia do Sul, capitalista, sendo um país desenvolvido, com valores muito elevados de IDH (15.º a nível mundial em 2011) e de PIB (PPC) per capita (27.º a nível mundial em 2011, segundo o FMI e 29.º segundo o Banco Mundial  e a CIA, com uma economia com grandes apostas nos serviços e na alta tecnologia
A Coreia do Norte continua essencialmente agrícola, com uma economia subdesenvolvida, com destaque para o cultivo do arroz e do trigo, mas a Coreia do Sul — que, assim como Singapura, Formosa e Hong Kong, é um dos "tigres asiáticos" — alcançou grande desenvolvimento industrial na década de 1980.
As diferenças entre as bandeiras das duas Coreias são as seguintes:
A parte asiática da Comunidade de Estados Independentes, embora corresponda, aproximadamente, a quatro quintos do território administrado por essa organização internacional, tem modesta importância econômica, se comparada à parte europeia.
Devido principalmente à hostilidade do meio natural - desertos, grandes áreas geladas ao norte e altas montanhas ao sul - essa região não apresenta condições ideais para a agropecuária
Mesmo assim, nos limites com a Europa, cultiva-se trigo e milho; a sudoeste, nas estepes próximas aos mares Cáspio e Aral, criam-se extensivamente carneiros e cabras e cultivam-se algodão e frutas, e nas áreas mais frias da Sibéria criam-se renas.
A partir da revolução socialista de 1917 e, particularmente, após o final da Segunda Guerra Mundial, essa região conhecida como a ex-União Soviética passou a ser mais valorizada, devido, principalmente, à abundância de suas riquezas minerais
Graças a essa característica, passou a abrigar basicamente indústrias pesadas, localizadas em alguns centros da Sibéria e do Cazaquistão
Pode ser citada ainda a cidade de Vladivostok, localizada na extremidade oriental, que, além de ser importante ponto estratégico, centraliza inúmeras indústrias diferenciadas.
O continente asiático ocupa um espaço que corresponde a cerca de um terço de todas as terras do planeta, sendo, portanto, maior que a extensão somada de todas as Américas, ou da Europa com a África
Nessas terras vivem mais de três milhares de milhões de habitantes, ou seja, mais da metade da população mundial, resultando numa densidade demográfica de 70 habitantes por quilômetro quadrado, aproximadamente três vezes maior que a densidade média da Terra.
Embora muito numerosa, a população asiática é mal distribuída: nas planícies, sobretudo as irrigadas pelas monções, e nas grandes cidades, as densidades demográficas são altíssimas, enquanto nas regiões desérticas, montanhosas e geladas, e mesmo em áreas de climas muito quentes, a população apresenta-se rarefeita
Países como China, Índia, Indonésia, Japão, Paquistão e Bangladesh estão entre os mais populosos da Terra, enquanto outros, como a Mongólia ou mesmo trechos setentrionais da Rússia, apresentam as mais baixas densidades demográficas do planeta.
Um fator que agrava o problema da má distribuição demográfica são as altas taxas de natalidade e a tendência à concentração urbana, características de todos os países subdesenvolvidos, como é o caso da maioria das nações asiáticas
Apenas alguns poucos países conseguiram sucesso em suas campanhas de planejamento familiar, reduzindo-se o crescimento populacional na China e praticamente estancando-o no Japão.
Em outros casos, a situação continua alarmante; é o que ocorre, por exemplo, com a Índia, onde a cada ano a população apresenta um crescimento vegetativo de 2,1%
Isso representa anualmente cerca de 14 milhões de crianças à espera de formação e, futuramente, de emprego
Na prática, isso se mostra economicamente impossível, o que torna ainda mais agudo o subdesenvolvimento desse e de outros países asiáticos.
Outro aspecto grave do crescimento populacional muito elevado é que ele costuma ocorrer nas áreas mais populosas, acentuando ainda mais o contraste com os vazios demográficos
Atualmente, em uma área que equivale a um quarto do território asiático, vivem 90% dos habitantes do continente, enquanto nada menos que dois quintos do território são praticamente desabitados, abrigando apenas 3% ou 4% da população total
Uma das principais razões desse fenõmeno é a urbanização.
De maneira geral, as regiões que apresentam condições naturais satisfatórias são as que abrigam os maiores aglomerados populacionais; aquelas que apresentam obstáculos naturais à fixação humana, tais como a grande altitude do relevo, o clima muito frio e a aridez do solo, permanecem pouco habitadas.
A Terra assiste a um extraordinário crescimento populacional, impulsionado, em grande parte, pelo formidável crescimento populacional asiático
Na tabela, fica claro que a contribuição dos países subdesenvolvidos é muito superior à dos desenvolvidos, daí a importância dos países asiáticos nesse processo.

Mumbai

Xangai

Karachi
Embora a maior parte da população asiática seja composta de povos de raça amarela, há também expressivo número de representantes dos outros troncos étnicos, o negro e o branco.
Os amarelos compõem a etnia dominante e distribuem-se pelas regiões da taiga e da tundra (ao norte), pelos planaltos da Ásia Central e sobretudo pelo leste e sudeste do continente, regiões asiáticas mais intensamente povoadas
Ocorrem grandes diferenças físicas, linguísticas e culturais entre esses povos (chineses, japoneses, coreanos, malaios, indonésios), mas sobretudo entre eles e os grupos mais isolados, como os quirguizes, mongóis e tibetanos.
Os brancos ou caucasoides predominam no sudeste do continente (Oriente Médio), onde são encontrados os árabes, os turcos, os israelenses, curdos, etc., e na Ásia Central, cujos países receberam grandes contingentes de população eslava (principalmente russos) ao serem incorporados à extinta União Soviética
Também na Índia e no Paquistão há um ramo étnico branco, mas seus representantes são bem amorenados.
Também, aparecem em menor número, distribuindo-se no sul da Índia e em ilhas do Oceano Índico
Pertencem ao grupo drávida, cuja influência é marcante na cultura hindu.
Rei Abdallah da Arábia Saudita.
Regine Velasquez, é uma cantora filipina.
Taro Aso, ex-primeiro-ministro do Japão.
Zhang Ziyi, uma atriz chinesa.
Em um continente que apresenta tão grande diversidade étnica e que registrou um longo período de dominação colonial em grande parte de seu território, é muito natural que se verifique grande diversidade de idiomas
Os principais, falados por mais de 100 milhões de pessoas, são: o mandarim (a língua mais falada do mundo), o árabe, o malaio-indonésio, o coreano, o japonês e, dentre as muitas línguas faladas na Índia, o hindi-urdu e o bengali
Entretanto, existem mais de uma centena de línguas ou dialetos em uso corrente em toda a Ásia.
A Ásia também abriga as grandes religiões da humanidade, tendo sido o berço de quase todas elas
22% dos asiáticos professam o hinduísmo cerca de 792 897 000, comum na Índia e arredores, e o budismo, comum em todo o Extremo Oriente com 9,1% cerca de 350 000 000 de seguidores, onde além dessa religião, são praticados o Cristianismo Católico e Ortodoxo com 135 000 000 e os protestantes com aproximadamente de 50 000 000 de seguidores, além das religiões chinesas, o confucionismo (China) e o xintoísmo (Japão)
O islamismo é outra religião bastante difundida na Ásia com cerca de 807 034 000 fazendo dela a maior religião em números absolutos de pessoas na Ásia , sobretudo no Oriente Médio, Turquestão, Índia e Insulíndia
Merece destaque ainda o judaísmo, centralizado em Israel.

Existem ainda alguns territórios sem estatuto de dependência, pertencentes a outros países localizados noutros continentes, mas que no entanto se situam na Ásia.
As diferenças e semelhanças entre os países asiáticos fazem com que a regionalização do continente possa ser feita em cinco grandes conjuntos:
Outra divisão possível, em grandes áreas geográfico-culturais, é a seguinte:
Em 2007, a maior economia nacional na Ásia, em termos de produto interno bruto (PIB), é a da China, seguida da Índia e do Japão
No final dos anos 1990 e início do século XXI, as economias chinesa e indiana têm crescido rapidamente, a taxas médias anuais de mais de 8%.
Entretanto, pelo critério do PIB nominal (calculado pela taxa de câmbio), a China ainda é a maior economia asiática e a segunda maior do mundo
O crescimento econômico da Ásia desde a Segunda Guerra Mundial até os anos 1990 concentrou-se em alguns poucos países da costa do Pacífico; recentemente, espalhou-se para outras regiões
Os principais blocos comerciais do continente são: Cooperação Econômica da Ásia-Pacífico (APEC), Reunião Econômica Ásia-Europa, Associação de Países do Sudeste Asiático (ASEAN), Acordos de Estreitamento das Relações Económicas e Comerciais (da China com Hong Kong e com Macau), Comunidade de Estados Independentes (CEI) e Associação Sul-asiática para Cooperação Regional (SAARC).
A Ásia conta com enormes reservas minerais, circunstância que tem facilitado seu recente desenvolvimento industrial
Entre os países produtores de minerais, merece destaque a China, rica principalmente em petróleo, carvão, ferro, chumbo, zinco e mercúrio, além de grandes jazidas de outros minerais.
Também a Índia é privilegiada por suas reservas de ferro, carvão, mica e manganês, além de sua grande produção de petróleo
Os países do sudeste asiático também são muito ricos em minérios, principalmente em estanho, níquel, zinco, ferro e petróleo, de que a Indonésia é grande exportadora.
O grande destaque fica, no entanto, com os países do Oriente Médio, que produzem mais de 30% do total do petróleo explorado em todo o mundo.
A atividade econômica mais difundida em todo o continente é a agricultura, ressaltando-se o cultivo do arroz em toda a vasta região atingida pelas monções
Mais ao norte, o trigo é intensamente cultivado; em áreas menos férteis, o solo é ainda aproveitado pára a produção de cevada, milho e outros cereais
Em todas essas culturas, a China sobressai, apresentando-se como um dos quatro maiores produtores mundiais.
Além dos cereais, merecem destaque os cultivos de fumo, chá, juta, algodão, pimenta e borracha
Na China e Japão cultiva-se também a amoreira, cujas folhas servem de alimento ao bicho-da-seda
Dos casulos desse animal são extraídos fios com que se fazem tecidos muito apreciados em todo o mundo.
A pecuária é outra atividade muito comum no continente
A China é grande produtora de animais de pequeno porte, sendo o primeiro produtor mundial de suínos, o terceiro de ovinos e o quinto de bovinos
A Índia, por sua vez, possui o maior rebanho bovino do mundo, o qual, no entanto, não é aproveitado para a alimentação da população, a maioria seguidora do hinduísmo, religião que considera sagrados esses animais.
O Japão foi, durante muito tempo, o mais industrializado dos países asiáticos
Graças à maciça ajuda norte-americana após a Segunda Guerra Mundial e à adoção de uma série de medidas internas, seu desenvolvimento industrial fez-se em bases firmes, transformando o país, em pouco tempo, numa potência industrial.
Possuindo um parque industrial amplo e diversificado, o Japão se evidencia na produção de navios, automóveis e produtos elétricos e eletrônicos.
A região oriental da Rússia, embora economicamente menos importante que a parte europeia do país, abriga diversos centros de indústrias de base (no Cazaquistão), localizados próximo de áreas exploratórias de minério, como ferro e carvão.
Outro país que apresenta uma industrialização evoluída, apesar de ser subdesenvolvido, é a Índia, que utiliza sua produção agrícola e as riquezas minerais para prover suas indústrias têxteis, alimentícias, siderúrgicas e metalúrgicas
Esse país salienta-se ainda por ser um dos poucos do Terceiro Mundo a utilizar tecnologia avançada nas áreas de energia e de comunicações.
Na China, cuja industrialização foi implantada efetivamente após a revolução socialista de 1949, o parque industrial tem-se dedicado quase inteiramente à produção de itens essenciais ao mercado interno
Somente a partir de meados da década de 1970 a economia chinesa começou a voltar-se, ainda que lentamente para o exterior
Na década seguinte, a abertura econômica foi maior, mas, devido a problemas políticos internos, voltou a retrair-se em 1989, tornando-se, atualmente, a 2ª maior potência industrial do mundo e a maior da Ásia.
Destacam-se ainda os chamados "tigres asiáticos" - Coreia do Sul, República da China, Singapura e Hong Kong -, cujas taxas de crescimento econômico e industrial estão entre as mais elevadas do mundo
Sua produção visa, em geral, o mercado externo, o que lhes permite obter grandes saldos em suas balanças comerciais.
As outras regiões asiáticas (Oriente Médio, sudeste asiático, Mongólia, países do Oceano Índico) apresentam uma industrialização incipiente e pouco significativa.
A cultura da Ásia é o agregado artificial da herança de muitas nacionalidades, sociedades, religiões, e grupos étnicos na região, tradicionalmente chamada um continente de uma perspectiva central ocidental, da Ásia
A região ou "o continente" são mais comumente divididos em sub-regiões geográficas e culturais mais naturais, inclusive a Ásia Central, a Ásia Oriental, a Ásia Meridional ("o subcontinente indiano"), a Ásia Setentrional, a Ásia Ocidental e o Sudeste Asiático
Geograficamente, a Ásia não é um continente distinto; culturalmente, houve pouca unidade ou história comum de muitas das culturas e povos da Ásia.
A arte, a música, e a culinária, bem como a literatura, são partes importantes da cultura asiática
A filosofia oriental e a religião também desempenham um papel principal, com budismo, hinduísmo, taoísmo, confucionismo, islã, e cristianismo todos os papéis principais desempenham
Uma das partes mais complexas da cultura asiática é a relação entre culturas tradicionais e o mundo ocidental.
Na Ásia existem países desenvolvidos, como Japão, Coreia do Sul, Israel, Singapura ou Taiwan, que revelam níveis de prosperidade econômica e social comparáveis aos da Europa ou da América Anglo-Saxônica
Essas áreas, entretanto, pouco representam, se comparadas com muitos dos demais países, geralmente bastante pobres e violentamente atingidos pelo subdesenvolvimento
Mesmo aqueles exportadores de petróleo, que tiveram lucros fabulosos a partir do início da década de 1970, não escapam a essa característica.
Há inúmeros fatores que contribuem para que a Ásia exiba grande atraso e miséria
Entre eles, podem ser citados:
Além destes fatores histórico-culturais, também os de ordem natural dificultam o desenvolvimento econômico
O clima e relevo hostis são obstáculos ao aproveitamento agrícola de vastas extensões localizadas em áreas montanhosas, geladas ou desérticas, limitando as áreas cultiváveis do continente.
Para se avaliar a grande disparidade de riquezas entre os países asiáticos, vamos tomar dois exemplos: os países exportadores de petróleo do Oriente Médio e o Japão.
Todo o Oriente Médio caracteriza-se por apresentar populações extremamente pobres, em contraste com elites detentoras de imensas fortunas
A maior riqueza de quase todos os países dessa região é o petróleo, responsável nos últimos anos pelo seu rápido enriquecimento.
Entretanto, os tradicionais males do subdesenvolvimento não foram atenuados: em primeiro lugar, porque esses lucros beneficiam principalmente determinados grupos, e não os países como um todo; e em segundo, porque boa parte dos rendimentos cabe a poderosas companhias transnacionais norte-americanas ou europeias.
O Japão, por sua vez, sendo um país capitalista desenvolvido, destaca-se em diversas áreas, sobretudo no setor industrial, chegando a superar em muitos aspectos as conquistas norte-americanas e europeias
Esse grande avanço industrial e tecnológico reflete-se diretamente na qualidade de vida da população japonesa, cujo PIB per capita é bastante alto e o acesso a moradia, saúde e educação de bom nível é indiscriminado.

África

América

Antártida

Ásia

Europa

Oceania

América Central

América do Norte

América do Sul

Austrália

Eurafrásia

Eurásia

Magrebe · Norte · Centro · Sul · Ocidente · Oriente · Subsaariana

Norte  · Central   · Sul 
(Latina  · Anglo)

Central · Oriente   · Norte   · Sul   · Sudeste · Ocidente

Ocidente · Centro · Oriente · Norte · Sul


Australásia · Melanésia · Micronésia · Polinésia

Ártico · Antártida

Afeganistão · Arábia Saudita · Arménia · Azerbaijão · Bahrein · Bangladesh · Butão · Brunei · Cazaquistão · Camboja · República Popular da China · Chipre · Timor-Leste · Egito · Geórgia · Índia · Indonésia · Irã · Iraque · Israel · Japão · Jordânia · Coreia do Norte · Coreia do Sul · Kuwait · Quirguistão · Laos · Líbano · Malásia · Maldivas · Mongólia · Myanmar · Nepal · Omã · Paquistão · Filipinas · Qatar · Rússia · Singapura · Sri Lanka · Síria · Tajiquistão · República da China · Tailândia · Turquia · Turquemenistão · Emirados Árabes Unidos · Uzbequistão · Vietname · Iémen
Aceh · Adjara · Abcásia · Akrotiri e Dhekelia · Altai · Território Britânico do Oceano Índico · Buryatia · Ilha Christmas · Ilhas Cocos (Keeling) · Guangxi · Hong Kong · Mongólia Interior · Iraqi Kurdistan · Jacarta · Khakassia · Macau · Nagorno-Karabakh · Nakhchivan · Ningxia · Chipre do Norte · Palestina (Faixa de Gaza · Margem Ocidental) · Papua · Sakha · Ossétia do Sul · Tibet · Tuva · Papua Ocidental · Xinjiang · Yogyakarta
Afeganistão • Arábia Saudita • Armênia • Azerbaijão • Bahrein • Bangladesh • Butão • Brunei • Camboja • Cazaquistão • China • Chipre • Coreia do Norte • Coreia do Sul • Egito • Emirados Árabes Unidos • Filipinas • Geórgia • Iêmen • Índia • Indonésia • Irã • Iraque • Israel • Japão • Jordânia • Kuwait • Laos • Líbano • Malásia • Maldivas • Mianmar • Mongólia • Nepal • Omã • Paquistão • Catar •
A Europa é, por convenção, um dos seis continentes do mundo
Compreendendo a península ocidental da Eurásia, a Europa geralmente divide-se da Ásia a leste pela divisória de águas dos montes Urais, o rio Ural, o mar Cáspio, o Cáucaso, e o mar Negro a sudeste
A Europa é limitada pelo oceano Glacial Ártico e outros corpos de água no norte, pelo oceano Atlântico a oeste, pelo mar Mediterrâneo ao sul, e pelo mar Negro e por vias navegáveis interligadas ao sudeste
No entanto, as fronteiras para a Europa, um conceito que remonta à Antiguidade clássica, são um tanto arbitrárias, visto que o termo "Europa" pode referir-se a uma distinção cultural e política ou geográfica.
A Europa é o segundo menor continente em superfície do mundo, cobrindo cerca de 10 180 000 km² ou 2% da superfície da Terra e cerca de 6,8% da área acima do nível do mar
Dos cerca de 50 países da Europa, a Rússia é o maior tanto em área quanto em população (sendo que a Rússia se estende por dois continentes, a Europa e a Ásia) e o Vaticano é o menor
A Europa é o quarto continente mais populoso do mundo, após a Ásia, a África e a(s) América(s), com 740 milhões de habitantes em 2015, cerca de 11% da população mundial naquele ano, isto é, a cada 100 pessoas no mundo neste período, 11 viviam no continente
No entanto, de acordo com a Organização das Nações Unidas (estimativa média), o peso europeu pode cair para cerca de 7% em 2050
Em 1900, por exemplo, a população europeia representava 25% da população mundial (ou seja, a cada 4 habitantes do mundo naquele ano, 1 vivia dentro dos limites do continente).
A Europa, nomeadamente a Grécia Antiga, é considerada o berço da cultura ocidental
Tendo desempenhado um papel preponderante na cena mundial a partir do século XVI, especialmente após o início do colonialismo
Entre os séculos XVI e XX, as nações europeias controlaram em vários momentos as Américas, a maior parte da África, a Oceânia e grande parte da Ásia
Ambas as guerras mundiais foram em grande parte centradas na Europa, sendo considerado como o principal fator para um declínio do domínio da Europa Ocidental na política e economia mundial a partir de meados do século XX, com os Estados Unidos e a União Soviética ganhando maior protagonismo
Durante a Guerra Fria, a Europa estava dividida politicamente ao longo da Cortina de Ferro entre a Organização do Tratado do Atlântico Norte, a oeste, e o Pacto de Varsóvia, a leste
A vontade de evitar outra guerra acelerou o processo de integração europeia e levou à formação do Conselho Europeu e da União Europeia na Europa Ocidental, os quais, desde a queda do Muro de Berlim e do fim da União Soviética em 1991, têm vindo a expandir-se para o leste
A moeda da maior parte dos países da União Europeia, o euro, é mais comumente usada por europeus; O Acordo de Schengen aboliu controles de imigração fortes nas fronteiras de países membros da União Europeia
O hino à Alegria é o hino do Conselho Europeu e da União Europeia.


O uso do termo "Europa" desenvolveu-se gradualmente ao longo da história
Na antiguidade, o historiador grego Heródoto provavelmente em referência a mapas de Hecateu de Mileto embora sem o nomear explicitamente, descreve o mundo como tendo sido dividido em três continentes, sendo eles a Europa, a Ásia e a Líbia (África), com o Nilo e o rio Fásis formando de suas fronteiras, embora também afirme que alguns consideravam o rio Don, em vez do Fásis, como a fronteira entre Europa e Ásia
Flávio Josefo e o Livro dos Jubileus descrevem os continentes como as terras dadas por Noé aos seus três filhos, sendo a Europa definida entre as Colunas de Hércules no Estreito de Gibraltar, separando-a da África, e o rio Don, separando-o da Ásia.
A definição cultural da Europa como terras da cristandade latina consolidou-se no século VIII, significando um novo local cultural criado através da confluência de tradições germânicas e da cultura cristã-latina, definidas em parte, em contraste com o Islão e Império Bizantino, e limitado a norte pela Ibéria (no Cáucaso), Ilhas Britânicas, França, Alemanha ocidental cristianizada, e as regiões alpinas do norte e no centro da Itália
Esta divisão, tanto geográfica como cultural, foi utilizada até a Baixa Idade Média, quando foi desafiada pela Era dos descobrimentos
O problema da redefinição da Europa, finalmente foi resolvido em 1730 quando, em vez de canais, o geógrafo e cartógrafo sueco von Strahlenberg propôs os Montes Urais como a fronteira mais importante do leste, uma sugestão que foi aceita na Rússia e em toda a Europa.
A Europa está agora em geral, definida pelos geógrafos, como a península ocidental da Eurásia, com seus limites marcados por grandes massas de água para o norte, oeste e sul; limites da Europa para o Extremo Oriente são normalmente tomadas para os Urais, o rio Ural, e o Mar Cáspio, a sudeste, as montanhas do Cáucaso, o Mar Negro e nas vias que ligam o Mar Negro ao Mar Mediterrâneo.
Às vezes, a palavra "Europa" é utilizada de forma geopoliticamente limitada para se referir apenas à União Europeia ou, ainda mais exclusiva, a um núcleo cultural definido
Por outro lado, o Conselho da Europa tem 47 países membros, e apenas 28 estados-membros estão na UE
Além disso, pessoas que vivem em áreas insulares, como a Irlanda, o Reino Unido, no Atlântico Norte e Mediterrâneo e ilhas também na Escandinávia podem rotineiramente se referir a parte "continental" ou ao "continente" da Europa ou simplesmente como "o continente".
Mapa da Europa, mostrando as fronteiras geográficas mais utilizadas
(legenda: azul = países transcontinentais• verde = países historicamente europeus, mas fora das fronteiras europeias).


Na mitologia grega, Europa era uma princesa fenícia que Zeus sequestrou depois de assumir a forma de um touro branco deslumbrante
Ele a levou para a ilha de Creta, onde ela deu à luz Minos, Radamanto e Sarpedão
Para Homero, Europa (em grego: Εὐρώπη, Eurṓpē) era uma rainha mitológica de Creta e não uma designação geográfica
Mais tarde, o termo Europa foi usado para se referir ao centro-norte da Grécia, e em 500 a.C., seu significado foi estendido para as terras ao norte.
O nome Europa é de etimologia incerta
Uma teoria sugere que a palavra é derivada do grego εὐρύς (eurus), que significa "largo, amplo" e ὤψ/ὠπ-/ὀπτ- (ōps/ōp-/opt-) significa "olho, rosto, semblante", portanto Eurṓpē seria algo como "ampla contemplação"
Amplo era um epíteto da própria Terra na religião protoindo-europeia
Outra teoria sugere que o termo é baseado em uma palavra semita como o mesmo significado do acadiano erebu, algo como "para ir para baixo, pôr-se" (cf
Ocidente), um cognato do fenício ereb "noite; oeste" e do árabe do Magreb, do hebraico ma'ariv (ver Érebo, PIE *h1regʷos, "escuridão")
No entanto, M
L
West afirma que "fonologicamente, a correspondência entre o nome de Europa e qualquer forma da palavra semítica é muito pobre".
As principais línguas do mundo mais usam palavras derivadas de "Europa" para se referir ao "continente" (península)
O chinês, por exemplo, usa a palavra Ōuzhōu (歐洲); este termo também é usado para se referir à União Europeia nas relações diplomáticas em língua japonesa, apesar do termo katakana (ヨーロッパ, Yōroppa) ser mais comumente usado
No entanto, em algumas línguas turcas, o nome originalmente persa Frangistan (terra dos francos) é usado casualmente para se referir à grande parte da Europa, além de nomes oficiais, como Avrupa ou Evropa.
Os Homo erectus e os Neanderthalis habitavam a Europa bem antes do surgimento dos humanos modernos, os Homo sapiens
Os ossos dos primeiros europeus foram achados em Dmanisi, Geórgia, e datados de 1,8 milhões de anos
O primeiro aparecimento do povo anatomicamente moderno na Europa é datado de 35 000 a.C
Evidências de assentamentos permanentes datam do 7º milénio a.C
na Bulgária, Roménia e Grécia
O período neolítico chegou na Europa central no 6º milénio a.C
e em partes da Europa Setentrional no 5º e 4º milénio a.C
A civilização Tripiliana (5 508-2 750 a.C.) foi a primeira grande civilização da Europa e uma das primeiras do mundo; era localizada na Ucrânia moderna e também na Moldávia e Roménia
Foi provavelmente mais antiga que os Sumérios no Oriente Próximo, e tinha cidades com 15 000 habitantes que cobriam 450 hectares.
Começando no Neolítico, tem-se a civilização dos Camunos no Val Camonica, Itália, que deixou mais de 350 000 petróglifos, o maior sítio arqueológico da Europa.
Também conhecido como Idade do Cobre, o Calcolítico europeu foi um tempo de mudanças e confusão
O fato mais relevante foi a infiltração e invasão de imensas partes do território por povos originários da Ásia Central, considerado pelos principais historiadores como sendo os originais indo-europeus, mas há ainda diversas teorias em debate
Outro fenómeno foi a expansão do Megalitismo e o aparecimento da primeira significante estratificação económica e, relacionado a isso, as primeiras monarquias conhecidas da região dos Balcãs
A primeira civilização bem conhecida da Europa foi as dos Minoicos da ilha de Creta e depois os Micenas em adjacentes partes da Grécia, no começo do 2º milénio a.C.
Embora o uso do ferro fosse de conhecimento dos povos egeus por volta de 1 100 a.C., não chegou à Europa Central antes de 800 a.C., levando ao início da Cultura de Hallstatt, uma evolução da Idade do Ferro (que até então se encontrava na Cultura dos Campos de Urnas)
Provavelmente como subproduto desta superioridade tecnológica, pouco depois os indo-europeus consolidam claramente suas posições na Itália e na Península Ibérica, penetrando profundamente naquelas penínsulas (Roma foi fundada em 753 a.C.
Os gregos e romanos deixaram um legado na Europa que é evidente nos pensamentos, leis, mentes e línguas actuais
A Grécia Antiga foi uma união de cidades-estado, na qual uma primitiva forma de democracia se desenvolveu
Atenas foi sua cidade mais poderosa e desenvolvida, e um berço de ensinamento nos tempos de Péricles
Fóruns de cidadãos aconteciam e o policiamento do estado deu ordem ao aparecimento dos mais notáveis filósofos clássicos, como Sócrates, Platão e Aristóteles
Como rei do Reino Grego da Macedónia, as campanhas militares de Alexandre o Grande espalharam a cultura helénica até às nascentes do rio Indo.
Mas a República Romana, alicerçada pela vitória sobre Cartago nas Guerras Púnicas, estava crescendo na região
A sabedoria grega passada às instituições romanas, assim como a própria Atenas foi absorvida sob a bandeira do senado e do povo de Roma
Os romanos expandiram seu império desde a Arábia até a Bretanha
Em 44 a.C
quando atingiu o seu ápice, seu líder, Júlio César foi morto sob suspeitas de estar corrompendo a república para se tornar um ditador
Na sucessão, Otaviano usurpou as raízes do poder e dissolveu o senado romano
Quando proclamou o renascimento da república ele, de facto, transferiu o poder do senado romano quando república para um império, o Império Romano.
Quando o Imperador Constantino reconquistou Roma sob a bandeira da Cruz em 312, ele rapidamente editou o Édito de Milão em 313, declarando legal o cristianismo no Império Romano
Além disso, Constantino mudou oficialmente a capital do império, Roma, para a colónia grega de Bizâncio, que ele renomeou para Constantinopla ("Cidade de Constantino")
Em 395, Teodósio, que tornou o cristianismo religião oficial do Império Romano, iria ser o último imperador a comandar o Império Romano em toda a sua unidade, sendo depois o império dividido em duas partes: O Império Romano do Ocidente, centrado em Ravena, e o Império Romano do Oriente (depois referido como Império Bizantino) centrado em Constantinopla
A parte ocidental foi seguidamente atacada por tribos nómadas germânicas, e em 476 finalmente caiu sob a invasão dos Hérulos comandados por Odoacro.
A autoridade romana no Oeste entrou em colapso e as províncias ocidentais logo tornaram-se pedaços de reinos germânicos
Entretanto, a cidade de Roma, sob o comando da Igreja Católica Romana permaneceu como um centro de ensino, e fez muito para preservar o pensamento clássico romano na Europa Ocidental
Nesse meio-tempo, o imperador romano em Constantinopla, Justiniano I, conseguiu com sucesso, montar toda a lei romana no Corpo do Direito Civil (529–534)
Por todo o século VI, o Império Romano do Oriente esteve envolvido numa série de conflitos sangrentos, primeiro contra o Império Sassânida, depois contra o Califado Ortodoxo
Em 650, as províncias do Egito, Palestina e Síria foram perdidas para forças muçulmanas.
Na Europa Ocidental, uma estrutura política surgia: no vácuo do poder deixado pelo colapso de Roma, hierarquias locais foram construídas sob a união das pessoas nas terras que eram trabalhadas
Dízimos eram pagos ao senhor da terra e este senhor devia tributos ao príncipe regional
Os dízimos eram usados para financiar o estado e as guerras
Esse foi o sistema feudal, no qual novos príncipes e reis apareceram, no qual o maior deles foi o líder Franco Carlos Magno
Em 800, Carlos Magno, após as suas grandes conquistas territoriais, foi coroado Imperador dos Romanos ("Imperator Romanorum") pelo Papa Leão III, afirmando efectivamente o seu poder na Europa Ocidental
O reinado de Carlos Magno marcou o começo dum novo império germânico no oeste, o Sacro Império Romano
Para além das suas fronteiras novas forças estavam crescendo
A Rússia de Quieve estava delimitando o seu território, a Grande Morávia estava crescendo, enquanto os anglos e os saxões estavam confirmando as suas fronteiras.
O Renascimento foi um movimento cultural que afectou profundamente a vida intelectual europeia no seu período pré-moderno
Começando em Itália, e espalhando-se de norte a oeste, o renascimento durou aproximadamente 250 anos e a sua influência afectou a literatura, filosofia, arte, política, ciência, história, religião entre outros aspectos de indagação intelectual.
O italiano Francesco Petrarca (Francesco di Petracco), suposto primeiro legítimo humanista, escreveu na década de 1330: "Estou vivo agora, ainda que eu prefira ter nascido noutro tempo"
Ele era um entusiasta da antiguidade romana e grega
Nos séculos XV e XVI, o contínuo entusiasmo pela antiguidade clássica foi reforçado pela ideia de que a cultura herdada estava se dissipando e de que havia um conjunto de ideias e atitudes com que seria possível reconstruí-la
Matteo Palmieri escreveu em 1430: "Agora, com certeza, todo espírito pensante deve agradecer a Deus, porque a ele foi permitido nascer numa nova era"
O Renascimento fez nascer uma nova era em que aprender era muito importante.
Importantes precedentes políticos aconteceram neste período
O político Nicolau Maquiavel escreveu "O Príncipe" que influenciou o posterior absolutismo e a política pragmática
Também foram importantes os diversos líderes que governaram estados e usaram a arte da Renascença como sinal de seus poderes.
Durante esse período, a corrupção da Igreja Católica levou a uma dura reação, na Reforma Protestante
E ela ganhou muitos seguidores, especialmente entre príncipes e reis buscando um estado forte para acabar com a influência da igreja católica
Figuras como Martinho Lutero começaram a surgir, assim também como João Calvino com o seu Calvinismo que teve influência em muitos países e o rei Henrique VIII da Inglaterra que rompeu com a igreja católica e fundou a Igreja Anglicana
Essas divisões religiosas trouxeram uma onda de guerras inspiradas e conduzidas religiosamente, mas também pela ambição dos monarcas na Europa Ocidental que se tornavam cada vez mais centralizadas e poderosas.
A reforma protestante também levou a um forte movimento reformista na igreja católica chamado Contra-Reforma, que tinha como objectivo reduzir a corrupção, assim como aumentar e fortalecer o dogma católico
Um importante grupo da igreja católica que surgiu nessa época foram os Jesuítas, que ajudaram a manter a Europa Oriental na linha católica de pensamento
Mesmo assim, a igreja católica foi fortemente enfraquecida pela reforma e, grande parte do continente não estava mais sob sua influência e os reis nos países que continuaram no catolicismo começaram a anexar as terras da igreja para os seus próprios domínios.
As numerosas guerras não impediram que os novos estados explorassem e conquistassem largas porções do mundo, particularmente na Ásia (Sibéria) e a recém-descoberta América
No século XV, Portugal liderou a exploração geográfica, seguido pela Espanha no começo no século XVI
Eles foram os primeiros estados a fundar colónias/colônias na América e estações de troca nas costas da África e da Ásia, porém logo foram seguidos pela França, Inglaterra e Holanda
Em 1552, o czar Russo Ivan, o Terrível conquistou os dois maiores canatos tártaros, Cazã e Astracã, e a viagem de Yermak em 1580, que levou a anexação da Sibéria pela Rússia.
A expansão colonial prosseguiu-se nos anos seguintes (mesmo com alguns empecilhos, como a Revolução Americana e as guerras pela independência em muitas colónias americanas)
A Espanha controlou parte da América do Norte e grande parte da América Central e do Sul, as Caraíbas/o Caribe e Filipinas.; Portugal teve em suas mãos o Brasil e a maior parte dos territórios costeiros em África e na Ásia (Índia e pequenos territórios na China etc); Os britânicos comandavam a Austrália, Nova Zelândia, maior parte da Índia e grande parte da África e América do Norte; a França comandou partes do Canadá e da Índia (porém quase tudo foi perdido para os britânicos em 1763), a Indochina, grandes terras na África e Caribe; a Holanda ganhou as Índias Orientais (hoje Indonésia) e algumas ilhas nas Caraíbas/no Caribe; países como Alemanha, Bélgica, Itália e Rússia conquistaram colónias posteriormente.
Essa expansão ajudou a economia dos países que a fizeram
O comércio prosperou, por causa da menor estabilidade entre os impérios
No final do século XVI, a prata americana era responsável por 1/5 de todo o comércio da Espanha
Os países europeus travaram guerras que foram pagas através do dinheiro conseguido com a exploração das colónias/colônias
No entanto, os lucros com o tráfico de escravos e as plantações das Índias Ocidentais, a mais rentável das colônias britânicas naquele momento, representavam apenas 5% de toda a economia do Império Britânico no final do século XVIII, tempo da Revolução Industrial.
A partir do início deste período, o capitalismo substituía o feudalismo como principal forma de organização económica, ao menos no oeste da Europa
A expansão das fronteiras coloniais resultou numa Revolução Comercial
Nota-se no período o crescimento da ciência moderna e a aplicação de suas descobertas em melhorias tecnológicas, que culminaram com a revolução Industrial
Descobertas ibéricas do Novo Mundo, que começaram com a jornada de Cristóvão Colombo ao oeste com a busca de uma rota fácil para as Índias Orientais em 1492, foram logo adaptadas por explorações inglesas e francesas na América do Norte
Novas formas de comércio e a expansão dos horizontes fizeram necessária uma mudança no direito internacional.
A reforma protestante produziu efeitos profundos na unidade europeia
Não apenas dividindo as nações uma das outras pela sua orientação religiosa, mas alguns estados foram afectados internamente por lutas religiosas, fortemente encorajadas por seus inimigos externos
A França viveu essa situação no século XVI com uma série de conflitos, como as guerras religiosas na França, que culminaram no triunfo da Dinastia Bourbon
A Inglaterra preveniu-se desse facto/fato com a consolidação sob a Rainha Elizabeth do moderado Anglicanismo
Quase toda a parte da atual Alemanha estava dividida em inúmeros estados sob o comando teórico do Sacro Império Romano Germânico, que também estava dividido dentro do próprio governo
A única exceção a isso era a Comunidade Polaco-Lituana, uma união criada pela União de Lublin, expressando uma grande tolerância religiosa
Esse embate religioso aconteceu até à Guerra dos Trinta Anos quando o nacionalismo substituiu a religião como principal motor dos conflitos na europa.
A Guerra dos Trinta Anos aconteceu entre 1618 e 1648, principalmente no território da atual Alemanha, e envolveu as principais potências europeias
Começou como um conflito religioso entre Protestantes e Católicos no Sacro Império Romano Germânico, e gradualmente desenvolveu-se numa guerra geral, envolvendo boa parte da europa, por razões não necessariamente ligadas à religião
O maior impacto da guerra, na qual exércitos de mercenários foram largamente utilizados, foi a devastação de regiões inteiras na busca do exército inimigo
Episódios como a disseminação da fome e das doenças devastaram a população dos estados germânicos e, em menor grau, dos Países Baixos e da Itália, onde levaram à falência muito dos poderes regionais envolvidos
Entre um quarto e um terço da população alemã pereceu por causas diretamente ligadas à guerra ou ainda de doenças e miséria causadas pelo conflito armado
A guerra durou trinta anos, mas os conflitos que ela deu início ainda continuaram sem solução por muito tempo.
Depois da Paz de Vestfália, que permitiu aos países que eles escolhessem a sua orientação religiosa, o Absolutismo tornou-se o padrão do continente, enquanto a Inglaterra caminhava rumo ao liberalismo com a Guerra Civil Inglesa e a Revolução Gloriosa
Os conflitos militares na europa não acabaram, mas tiveram menos impacto na vida dos seus cidadãos
No noroeste, o Iluminismo deu a base filosófica para um novo ponto de vista na sociedade, e a contínua difusão da literatura foi possível com a invenção da prensa, criando novas formas de avanço do pensamento humano
Ainda, nesse segmento, a Comunidade Polaco-Lituana foi uma exceção, com a sua quase democrática "liberdade dourada".
A Europa Oriental era uma arena de conflito disputada pela Suécia, Comunidade Polaco-Lituana e Império Otomano
Nesse período observou-se um gradual declínio destes três poderes que foram eventualmente substituídos pelas novas monarquias absolutistas, Rússia, Prússia e Áustria
Na virada para o século XIX, eles tornaram-se as novas potências, dividindo a Polónia entre si, com Suécia e Turquia perdendo territórios substanciais para a Rússia e a Áustria respetivamente/respectivamente
Uma grande parte de judeus polacos/poloneses emigrou para a Europa Ocidental, fundando comunidades judaicas em lugares de onde foram expulsos durante a Idade Média.
A intervenção francesa na Guerra de Independência dos EUA levou o estado francês à falência
Depois de diversas tentativas falhas de uma reforma financeira, Luis XVI foi forçado a reavivar a Assembleia dos Estados Gerais, um corpo representativo do país feito pelas três classes do estado: o clero, os nobres e o povo
Os membros dos Estados-Gerais reuniram-se no Palácio de Versalhes em maio de 1789, mas o debate e a forma de votação que seria usada criaram um impasse
Veio junho, e o terceiro estado, associado a membros dos dois outros estados, declarou-se uma Assembleia Nacional e prometeu não se dissolver até que França tivesse uma constituição e criasse, em julho, uma Assembleia Nacional Constituinte
No mesmo tempo, os parisienses revoltaram-se, celebremente derrubando a prisão da Bastilha em 14 de julho de 1789.
Nesse tempo, a assembleia criou uma monarquia constitucional, e nos dois anos que se passaram várias leis foram criadas como a Declaração dos direitos do Homem e do Cidadão, a abolição do feudalismo e uma mudança fundamental das relações entre a França e Roma
No início, o rei continuou no trono ao longo dessas mudanças e gozou de uma popularidade razoável com o povo, mas a anti-realeza crescia com o perigo de uma invasão estrangeira
Então o rei, sem poderes, decidiu fugir com a sua família, mas ele foi reconhecido de volta a Paris
Em 12 de janeiro de 1793, sendo condenada a sua traição, ele foi executado.
Em 20 de setembro de 1792, a convenção nacional aboliu a monarquia e declarou a França uma república
Devido à iminência das guerras, a convenção nacional criou o Comitê de Salvação Pública controlado por Maximilien Robespierre do Partido dos Jacobinos, para atuar como executivo do país
Sob Robespierre o comitê iniciava o Reino do terror, no qual cerca de 40 000 pessoas foram executadas em Paris, na maioria nobres, apesar de, frequentemente, faltarem evidências
Por todo o país, insurreições contra-revolução foram brutalmente reprimidas
O regime foi posto abaixo no golpe de 9 Termidor (27 de Julho de 1794) e Robespierre foi executado
O regime que se seguiu acabou com o Terror e afrouxou a maioria das regras extremas de Robespierre.
Napoleão Bonaparte foi o general francês que mais obteve sucesso nas guerras da Revolução, tendo conquistado grandes porções da península Itálica e forçado os austríacos à paz
Em 1799, retornou do Egito e em 18 de Brumário (9 de Novembro) subjugou o governo, substituindo-o pelo seu Consulado, do qual tornou-se o primeiro Cônsul
Em 2 de Dezembro de 1804, depois duma tentativa de assassinato, ele coroou-se imperador
Em 1805, Napoleão planeou invadir a Grã-Bretanha, mas a recém-criada aliança entre britânicos, russos e austríacos (Terceira Coalizão) forçou-o a direcionar a atenção para o continente, quando ao mesmo tempo ele tinha falhado em desviar a Armada Superior Britânica para longe do Canal da Mancha, ocasionando uma decisiva derrota francesa na batalha de Trafalgar em 21 de outubro, e colocando um fim às suas esperanças de invadir a Grã-Bretanha
Em 2 de dezembro de 1805, Napoleão derrotou o exército austro-russo, numericamente superior, em Austerlitz, forçando a Áustria desistir da coalizão e levando à fragmentação do Sacro Império Romano Germânico
Em 1806, a Quarta coalizão foi formada; em 14 de Outubro Napoleão derrotou os prussianos na Batalha de Jena-Auerstedt, marchando através da Alemanha e derrotando os russos em 14 de junho de 1807 em Friedland
Os Tratados de Tilsit dividiram a Europa entre França e Rússia e criaram o Ducado de Varsóvia.
Em 12 de junho de 1812, Napoleão invadiu a Rússia com a sua Grande Armée de aproximadamente 700 000 soldados
Após as vitórias em Smolensk e Borodino, Napoleão ocupou Moscovo, apenas para encontrá-la queimada pelo exército russo em retirada
Assim, ele foi forçado a bater com seu exército em retirada
Na volta o seu exército foi arrasado pelos cossacos e sofreu de doenças, fome e com o rigoroso inverno russo
Apenas 20 000 soldados sobreviveram a essa campanha
Em 1813, começou o declínio de Napoleão, sendo derrotado pelo Exército das Sete Nações na Batalha de Leipzig em outubro de 1813
Ele foi forçado a abdicar depois da Campanha dos Seis Dias e a ocupação de Paris
Sob o Tratado de Fontainebleau ele foi exilado na Ilha de Elba
Retornou à França em 1 de março de 1815 e convocou um exército leal, mas foi compreensivelmente derrotado por forças britânicas e prussianas na Batalha de Waterloo em 18 de junho de 1815.
Depois da derrota da revolucionária França, outras grandes forças tentaram restaurar a situação existente antes de 1789
Em 1815, no Congresso de Viena, as maiores forças da Europa organizaram-se para produzir um pacífico equilíbrio de poder entre os impérios depois das Guerrras Napoleónicas (embora estivessem ocorrendo movimentos internos revolucionários) sob o sistema de Matternich
Entretanto, os seus esforços foram incapazes de parar a propagação de movimentos revolucionários: a classe média foi profundamente influenciada pelos ideais de democracia da Revolução Francesa, a revolução Industrial trouxe importantes mudanças sócio-económicas/econômicas, as classes baixas começaram a ser influenciadas pelas ideias socialistas, comunistas e anarquistas (especialmente unidas por Karl Marx no Manifesto Comunista), e a preferência dos novos capitalistas era o liberalismo.
Uma nova onda de instabilidade veio da formação de diversos movimentos nacionalistas (na Alemanha, Itália, Polônia, etc.), buscando uma unidade nacional e/ou liberação do domínio estrangeiro
Como resultado, o período entre 1815 e 1871 foi palco de um grande número de conflitos e guerras de independência
Napoleão III, sobrinho de Napoleão I, retornou do exílio na Inglaterra em 1848 para ser eleito pelo parlamento francês, como o então "Presidente-Príncipe" e num golpe de estado eleger-se imperador, aprovado depois pela grande maioria do eleitorado francês
Ele ajudou na unificação da Itália lutando contra o Império Austríaco e lutou a Guerra da Crimeia com a Inglaterra e o Império Otomano contra a Rússia
Seu império ruiu depois duma infame derrota para a Prússia, na qual ele foi capturado
A França então se tornou uma fraca república que recusava-se a negociar e foi derrotada pela Prússia em poucos meses
Em Versalhes, o Rei Guilherme I da Prússia foi proclamado Imperador da Alemanha e a Alemanha moderna nasceu
Mesmo que a maioria dos revolucionários tenha sido derrotada, muitos estados europeus tornaram-se monarquias constitucionais, e em 1871 Alemanha e Itália se desenvolveram em estados-nação
Foi no século XIX também que se observou o Império Britânico emergir como o primeiro poder global do mundo devido, em grande parte, à Revolução Industrial e a vitória nas Guerras Napoleónicas.
A paz iria apenas durar até que o Império Otomano declinasse suficientemente para se tornar alvo de outros
Isso incitou a Guerra da Crimeia em 1854, e começou um tenso período de pequenos conflitos entre as nações dominantes da Europa que deram o primeiro passo para a posterior Primeira Guerra Mundial
Isso mudou uma terceira vez com o fim de várias guerras que transformaram o Reino da Sardenha e o Reino da Prússia nas nações da Itália e da Alemanha, mudando significativamente o balanço do poder na Europa
A partir de 1870, a hegemonia Bismarquiana na Europa pôs a França em uma situação crítica
Ela devagar reconstruiu suas relações internacionais, buscando alianças com a Grã-Bretanha e Rússia, para controlar o crescente poder da Alemanha sobre a Europa
Desse modo, dois lados opostos se formaram na Europa, incrementando suas forças militares e suas alianças ano a ano.
A Revolução Industrial foi um período compreendido entre o fim do século XVIII e o começo do século XIX, no qual ocorreram grandes mudanças na agricultura, manufatura e transporte e foi produzido um profundo efeito socioeconómico/socioeconômico e cultural na Grã-Bretanha, que posteriormente se espalhou por toda a Europa, América do Norte, e depois para todo o mundo, num processo que ainda continua: a Industrialização
Na parte final dos anos de 1700 a economia baseada na força manual no Reino da Grã-Bretanha começou a ser substituída por outra dominada pela indústria e pelas máquinas
Começou com a mecanização das indústrias têxteis, o desenvolvimento de técnicas avançadas de produção de ferro e o aumento do uso de carvão refinado
A expansão do comércio foi possibilitada com a introdução de canais, rodovias e auto-estradas
A introdução das máquinas a vapor (abastecidas primeiramente com carvão) e maquinaria bruta (principalmente na manufatura têxtil) deram a base para grandes aumentos na capacidade produtiva inglesa
O desenvolvimento de máquinas de ferramentas nas duas primeiras décadas do século XIX facilitou a produção de mais máquinas para serem utilizadas noutras indústrias
Durante o século XIX, a industrialização se alastrou pelo resto da Europa Ocidental e América do Norte, afetando posteriormente grande parte do mundo.
Depois da relativa paz na maior parte do século XIX, a rivalidade entre as potências europeias explodiu em 1914, quando a Primeira Guerra Mundial começou
Mais de 60 milhões de soldados europeus foram mobilizados entre 1914 e 1918
De um lado estavam Alemanha, Áustria-Hungria, o Império Otomano e a Bulgária (Poderes Centrais/Tríplice Aliança), enquanto que no outro lado estavam a Sérvia e a Tríplice Entente – a elástica coligação entre França, Reino Unido e Rússia, que ganhou a participação da Itália em 1915 e dos Estados Unidos em 1917
Embora a Rússia tenha sido derrotada em 1917 (a guerra foi uma das maiores causas da Revolução Russa, levando à formação da comunista União Soviética), a Entente finalmente prevaleceu no outono de 1918.
No Tratado de Versalhes (1919) os vencedores impuseram severas condições à Alemanha e aos novos estados reconhecidos (tais como Polónia, Checoslováquia, Hungria, Áustria, Jugoslávia, Finlândia, Estónia, Letónia, Lituânia) criados na Europa Central a partir dos extintos impérios Alemão, Austro-Húngaro e Russo, supostamente na base da auto-definição
A maioria desses países entraria em guerras locais, sendo a maior delas a Guerra Polaco-Soviética (1919–1921)
Nas décadas seguintes, o medo do comunismo e a Grande Depressão (1929–1943) levaram grupos extremistas nacionalistas — sob a categoria do fascismo — na Itália (1922), Alemanha (1933), Espanha (depois da guerra civil, terminada em 1939) e em outros países como a Hungria.
Depois de aliar-se com a Itália de Mussolini no Pacto de Aço e assinar o pacto de não-agressão com a União Soviética, o ditador alemão Adolf Hitler começou a Segunda Guerra Mundial em 1 de Setembro de 1939 invadindo a Polónia, depois de uma expansão militar ocorrida no final da década de 1930
Após sucessos iniciais (principalmente a conquista do oeste da Polónia/Polônia, grande parte da Escandinávia, França e os Balcãs antes de 1941), as forças do Eixo começaram a enfraquecer-se em 1941
Os principais oponentes ideológicos de Hitler eram os comunistas da União Soviética, mas por causa da falha alemã em derrotar o Reino Unido e das falhas italianas no norte da África e no Mediterrâneo, as forças do Eixo se resumiram à Europa Ocidental, Escandinávia, além de ataques a África
O ataque feito posteriormente à União Soviética (que junto com a Alemanha dividiu a Europa central em 1939-1940) não foi feito com a força necessária
Apesar de um sucesso inicial, o exército alemão foi parado perto de Moscovo em dezembro de 1941.
Apenas no ano seguinte é que o avanço alemão seria parado e eles começariam a sofrer uma série de derrotas, como por exemplo, nas batalhas de Stalingrado e Kursk
Nesse ínterim, o Japão (aliado de Alemanha e Itália desde setembro de 1940) atacou os britânicos no Sudeste Asiático e os Estados Unidos no Havaí em 7 de Dezembro de 1941; a Alemanha e a Itália declararam guerra aos Estados Unidos em união com seu aliado
A guerra aumentou a tensão entre o Eixo (Alemanha, Itália e Japão) e os Aliados (Reino Unido, União Soviética e os Estados Unidos)
As forças Aliadas venceram no norte da África e invadiram a Itália em 1943, e a ocupada França em 1944
Na primavera de 1945, a Alemanha foi invadida pelo leste pela União Soviética e pelo oeste pelos Aliados; Hitler cometeu suicídio e a Alemanha se rendeu no começo de maio acabando com a guerra na Europa.
O período foi marcado também por um industrializado e planeado genocídio de mais de 11 milhões de pessoas, incluindo a maioria dos judeus da Europa e ciganos, assim como milhões de polacos e eslavos soviéticos
O sistema soviético de trabalho forçado, as expulsões da população da União Soviética e a grande fome da Ucrânia tiveram semelhante carga de mortes
Durante e depois da guerra, milhões de civis foram afetados pelas forçadas transferências da população.
A Primeira e especialmente a Segunda Guerra Mundial acabaram com a preponderante posição da Europa Ocidental
O mapa do continente foi redesenhado na Conferência de Yalta e dividido se tornou a principal zona de contenção na Guerra Fria entre dois blocos, os países ocidentais e o bloco Oriental
Os Estados Unidos e a Europa Ocidental (Reino Unido, França, Itália, Portugal, Países Baixos, Alemanha Ocidental, Noruega, etc.) estabeleceram a aliança da OTAN como proteção contra uma possível invasão soviética
Depois, a União Soviética e o Leste Europeu (Polónia, Checoslováquia, Hungria, Roménia, Bulgária e Alemanha Oriental) estabeleceram o Pacto de Varsóvia como proteção contra uma possível invasão dos Estados Unidos.
Na mesma época, a Europa Ocidental lentamente começou um processo de integração política e económica/econômica, desejando um continente unido e integrado para prevenir outra guerra
Esse processo resultou naturalmente no desenvolvimento de organizações como a União Europeia e o Conselho da Europa
O movimento Solidarność que aconteceu na década de 1980 enfraqueceu o governo comunista na Polônia, foi o começo do fim do domínio comunista na Europa Oriental e o declínio da União Soviética
O líder soviético Mikhail Gorbachev instituiu a Perestroika e a Glasnost, que enfraqueceram oficialmente a influência soviética na Europa Oriental
Os governos que davam suporte aos soviéticos entraram em colapso e a Alemanha Ocidental anexou a Oriental em 1990
Em 1991, a própria União Soviética ruiu, dividindo-se em 15 estados, com a Rússia tomando o lugar da União Soviética no Conselho de Segurança da ONU
Entretanto, a separação mais violenta aconteceu na Jugoslávia, nos Bálcãs
Quatro (Eslovénia, Croácia, Bósnia e Herzegóvina e Macedónia/Macedônia) das seis repúblicas jugoslavas declararam independência e para a maioria delas uma violenta guerra se seguiu, em algumas partes até 1995
Em 2006, Montenegro se separou e declarou independência, seguido por Kosovo, formalmente uma província autónoma/autônoma da Sérvia, em 2008, e descaracterizando completamente o antigo mapa da Jugoslávia/Iugoslávia
Na era pós-guerra fria, OTAN e a União Europeia foram gradualmente admitindo a maioria dos antigos estados membros do Pacto de Varsóvia.
Em 1992, o Tratado de Maastricht foi assinado pelos então membros da União Europeia
Isso transformou o "Projeto Europeu" de ser uma comunidade económica/econômica com certos aspectos políticos, numa união com uma intensa cooperação e prosperidade baseada numa união de soberanias nacionais
Em 1985, o Acordo de Schengen criou uma área sem fronteiras e sem controle de passaporte entre os estados que o assinaram.
Uma moeda comum para a maioria dos estados membros da União Europeia, o euro, foi estabelecida eletronicamente em 1999, oficialmente partilhando todas as moedas de cada participante com os outros
A nova moeda foi posta em circulação em 2002 e as velhas foram retiradas dos mercados
Apenas três países dos quinze estados membros decidiram não aderir ao euro (Reino Unido, Dinamarca e Suécia)
Em 2004, a UE deu ordem à sua maior expansão, admitindo 10 novos membros (oito dos quais antigos estados comunistas)
Outros dois ingressaram no grupo em 2007, num total de 27 nações.
Um tratado estabelecendo uma constituição para a UE foi assinado em Roma em 2004, com a intenção de substituir todos os antigos tratados com apenas um só documento
Entretanto, a sua ratificação nunca foi feita devido à rejeição de franceses e holandeses, via referendo
Em 2007, concordou-se em substituir aquela proposta com um novo tratado reformado, o Tratado de Lisboa, que iria entrar como uma emenda em vez de substituir os tratados existentes
Esse tratado foi assinado em 13 de dezembro de 2007 e entraria em vigor em janeiro de 2009, se ratificado até essa data
Isso daria à União Europeia seu primeiro presidente e ministro de relações exteriores.
Os países dos Bálcãs ,são aqueles que mais desejam fazer parte da União Europeia,sendo a Croácia o último país a entrar no bloco,em 1 de julho de 2010.Ao mesmo tempo que as negociações formais para a entrada da Albânia e República da Macedônia estão em desenvolvimento.
Fisiograficamente, a Europa é o componente noroeste da maior massa de terra do planeta, conhecida como a Eurásia, ou Eurafrásia: a Ásia ocupa a maior parte leste dessa porção de terra contínua e todos partilham uma plataforma continental comum
A fronteira oriental da Europa agora é comumente definida pelos montes Urais, na Rússia
O geógrafo do século I d.C
Estrabão, considerava o rio Don "Tanais" como o limite para o mar Negro, como diziam as primeiras fontes judaicas.
A fronteira sudeste com a Ásia não é universalmente definida, sendo que o rio Ural, ou, alternativamente, o rio Emba servem mais comummente como limites possíveis
O limite continua até ao mar Cáspio, a crista das montanhas do Cáucaso, ou, alternativamente, o rio Cura no Cáucaso, e o mar Negro, Bósforo, o mar de Mármara, o estreito de Dardanelos, o mar Egeu concluem o limite com a Ásia
O mar Mediterrâneo ao sul separa a Europa da África
A fronteira ocidental é o oceano Atlântico, a Islândia, embora mais perto da Gronelândia (América do Norte) do que da Europa continental, são geralmente incluídos na Europa.
Por causa das diferenças sócio-políticas e culturais, existem várias descrições de fronteira da Europa, sendo que em algumas fontes alguns territórios não estão incluídos na Europa, enquanto outras fontes incluem-nos
Por exemplo, os geógrafos da Rússia e de outros países pós-soviéticos geralmente incluem os Urais na Europa, incluindo o Cáucaso na Ásia
Da mesma forma, o Chipre é mais próximo da Anatólia (ou Ásia Menor), mas é muitas vezes considerado parte da Europa e atualmente é um estado membro da UE
Além disso, Malta já foi considerado uma ilha da África ao longo de vários séculos.
O relevo europeu mostra grande variação dentro de áreas relativamente pequenas
As regiões do sul são mais montanhosas, e enquanto se move a norte o terreno desce dos altos Alpes, Pirenéus e Cárpatos, através de planaltos montanhosos e baixas planícies do norte, que são vastas a leste
Esta planície estendida é conhecida como a Grande Planície Europeia, e em seu coração encontra-se a Planície do Norte da Alemanha
Um arco de terras altas, também existe ao longo da costa norte-ocidental, que começa na parte ocidental da ilha da Grã-Bretanha e da Irlanda, e continua ao longo da montanhosa coluna, com fiordes cortados, da Noruega.
Esta descrição é simplificada
Sub-regiões como a Península Ibérica e a península Itálica contêm suas próprias características complexas, como faz a própria Europa Central continental, onde o relevo contém muitos planaltos, vales de rios e bacias que complicam a tendência geral
Sub-regiões como a Islândia, a Grã-Bretanha e a Irlanda são casos especiais
A primeira é uma terra independente no oceano do norte, que é considerada como parte da Europa, enquanto as outras duas são zonas de montanha que outrora foram parte do continente até o nível do mar cortá-las da massa de terra principal.
O continente apresenta uma complexa rede hidrográfica, com grandes rios como o Volga, na Rússia, e o Danúbio, que atravessa territórios (ou delimita fronteiras) da Alemanha, Áustria, República Checa, Croácia, Hungria, Sérvia, Romênia, Bulgária e Ucrânia
O rio Volga é o maior rio da Europa
Começa no Lago Ládoga e atravessa no sentido norte-sul a região oeste da Rússia até desaguar no mar Cáspio.
Entre os lagos europeus destacam-se o mar Cáspio, localizado na divisa com a Ásia e que possui 371 mil km²; e o lago Ládoga, na Federação Russa, este último o maior localizado totalmente no continente, com 17 700 km² de área
Outros lagos extensos são o Onega, o Vener, o Saimaa, o Veter, entre outros.
A Europa encontra-se principalmente nas zonas de clima temperado, sendo submetido a correntes de ventos do oeste
O clima é mais ameno em comparação com outras áreas da mesma latitude de todo o mundo devido à influência da Corrente do Golfo
A Corrente do Golfo é o apelido de "aquecimento central da Europa", porque torna o clima da Europa mais quente e mais húmido do que seria de outra maneira
A Corrente do Golfo não só leva água quente à costa da Europa, mas também aquece os ventos que sopram de oeste em todo o continente do Oceano Atlântico.
Portanto, a temperatura média durante todo o ano de Nápoles, é de 16 °C (60,8 °F), enquanto ela fica a apenas 12 °C (53,6 °F), em Nova Iorque, que é quase na mesma latitude
Berlim, na Alemanha; Calgary, no Canadá, e Irkutsk, na parte asiática da Rússia, estão em torno da mesma latitude, as temperaturas de janeiro, em Berlim, são em média em torno de 8 °C (15 °F), mais elevadas do que aquelas registradas em Calgary, e são quase 22 °C (40 °F) mais elevadas do que as temperaturas médias em Irkutsk.
Desde o Renascimento, a Europa teve uma grande influência na cultura, economia e movimentos sociais no mundo
As invenções mais significativas tiveram origem no mundo ocidental, principalmente na Europa e nos Estados Unidos
Algumas questões atuais e passadas na demografia europeia incluíram emigração religiosa, relações raciais, imigração econômica, a taxa de natalidade decrescente e o envelhecimento da população.
Em alguns países, como a Irlanda e a Polónia, o acesso ao aborto é atualmente limitado
No passado, tais restrições e também as restrições sobre o controle artificial da natalidade eram comuns em toda a Europa
O aborto continua sendo ilegal na ilha de Malta, onde o catolicismo é a religião do Estado
Além disso, três países europeus (Países Baixos, Bélgica e Suíça) e a Comunidade Autónoma da Andaluzia (Espanha) têm permitido uma forma limitada de eutanásia voluntária para doentes terminais.
Em 2005, a população da Europa era estimada em 731 milhões de acordo com as Nações Unidas, que é um pouco mais do que um nono da população mundial
Um século antes, a Europa tinha quase um quarto da população mundial
A população da Europa cresceu no século XX passado, mas nas outras regiões do mundo (especialmente na África e na Ásia), a população tem crescido muito mais rapidamente
Dentre os continentes, a Europa tem uma densidade populacional relativamente alta, perdendo apenas para a Ásia
O país mais densamente povoado da Europa são os Países Baixos, terceiro no ranking mundial após a Coreia do Sul e Bangladesh
Pan e Pfeil (2004) contam 87 distintos "povos da Europa", dos quais 33 formam a maioria da população em pelo menos um Estado soberano, enquanto os 54 restantes constituem minorias étnicas.
Segundo a projeção de população da ONU, a população da Europa pode cair para cerca de 7% da população mundial até 2050, ou 653 milhões de pessoas (variante média, 556 a 777 milhões em baixa e alta variante, respetivamente/respectivamente)
Neste contexto, existem disparidades significativas entre regiões em relação às taxas de fertilidade
O número médio de filhos por mulher em idade reprodutiva é de 1,52
De acordo com algumas fontes, essa taxa é maior entre os europeus muçulmanos
A ONU prevê que o declínio contínuo da população de vastas áreas da Europa Oriental
A população da Rússia está diminuindo em pelo menos 700 mil pessoas a cada ano
O país tem hoje 13 mil aldeias desabitadas.
A Europa é o lar do maior número de migrantes de todas as regiões do mundo, em 70,6 milhões de pessoas, segundo um relatório da OIM
Em 2005, a UE teve um ganho líquido global de imigração de 1,8 milhão de pessoas, apesar de ter uma das maiores densidades populacionais do mundo
Isso representou quase 85% do crescimento populacional total da Europa
A União Europeia pretende abrir centros de emprego para trabalhadores migrantes legais da África.
Emigração da Europa começou com os colonos espanhóis e portugueses no século XVI, e com colonos franceses e ingleses no século XVII
Mas os números mantiveram-se relativamente pequenas até ondas de emigração em massa no século XIX, quando milhões de famílias pobres, deixaram a Europa.
Hoje, uma grande população de ascendência europeia é encontrada em todos os continentes
A ascendência europeia predomina na América do Norte e, em menor grau, na América do Sul (principalmente na Argentina, Chile, Uruguai e Centro-Sul do Brasil)
Além disso, a Austrália e a Nova Zelândia têm grandes populações de descendentes europeus
A África não tem países de maioria de descendentes de europeus, mas há minorias significativas, como a dos brancos sul-africanos
Na Ásia, as populações descendentes de europeus (mais especificamente russos) predominam no Ásia Setentrional.
As línguas europeias pertencem principalmente a três grupos de Línguas indo-europeias: as línguas românicas, derivadas do latim do Império Romano, as línguas germânicas, cujos ancestrais vieram de língua do sul da Escandinávia, e as línguas eslavas
Apesar de ter a maioria de seu vocabulário descendente de línguas românicas, o idioma Inglês é classificado como uma língua germânica.
As línguas românicas são faladas principalmente no sudoeste da Europa, bem como na Roménia e na Moldávia
As línguas germânicas são faladas no noroeste da Europa e algumas partes da Europa Central
As línguas eslavas são faladas na Europa Central, Oriental e sudeste da Europa.
Muitas outras línguas fora dos três grupos principais grupos existem na Europa
Outras línguas indo-europeias incluem o grupo do Báltico (ie, Letã e Lituana), o grupo Céltico (ie, Irlandês, Gaélico Escocês, Manês, Galês, Córnico e Bretão), Grego, Albanês, e Arménio
Um grupo diferente de línguas urálicas são o Estónio, Finlandês e Húngaro, falado nos respetivos/respectivos países, bem como em partes da Roménia, Rússia, Sérvia e Eslováquia.
Outras línguas não indo-europeias são o maltês (a única língua oficial semita da UE), o Basco, Geórgio, Azerbaijão, Turco no leste da Trácia Oriental e as línguas das nações minoritárias na Rússia.
O multilinguismo e a proteção das línguas regionais e minoritárias são objetivos políticos reconhecidos na Europa de hoje
A Convenção para a Proteção das Minorias Nacionais e a Carta Europeia das Línguas Regionais ou Minoritárias do Conselho da Europa estabelecem um quadro jurídico para os direitos linguísticos na Europa.
Historicamente, a religião na Europa tem tido uma grande influência na arte, cultura, filosofia e direito europeu
A religião maioritária na Europa é o cristianismo praticado por católicos, ortodoxos orientais e protestantes.
Na sequência, é o Islão, concentrado principalmente no sudeste (Bósnia e Herzegovina, Albânia, Kosovo, Cazaquistão, Chipre do Norte, Turquia e Azerbaijão), e o Budismo Tibetano ,que é majoritário na região russa da Kalmykia
As outras religiões, incluindo o Judaísmo e o Hinduísmo, são religiões minoritárias.
A Europa é um continente relativamente secular e tem o maior número e proporção de pessoas sem religião, agnósticas e ateias no mundo ocidental, com um número particularmente elevado de pessoas que se auto descrevem como não-religiosas na República Checa, Estónia, Suécia, Alemanha (Oeste) e França.

Uma união constituída por mais de uma dezena de países, que fazem transações comerciais utilizando uma moeda única - Euro - e cujos interesses são representados por instituições comuns
Essa nova Europa começou a ganhar corpo em dezembro de 1991, quando os 12 países-membros da União Europeia concluíram o Tratado de Maastricht, que objetivava a união política, económica/econômica e monetária dos participantes, sem fechar espaço para novas adesões.
Através desse acordo, Alemanha, Bélgica, Dinamarca, Espanha, França, Grécia, Irlanda, Itália, Luxemburgo, Países Baixos, Portugal e Reino Unido iniciaram a caminhada da integração europeia
Áustria, Finlândia e Suécia são uns dos mais novos membros e vários outros países já entraram com seu pedido de adesão.
A reunião na cidade neerlandensa de Maastricht - que, em dezembro de 1991, consolidou a formação da União Europeia - representou um capítulo de várias etapas, cujas iniciativas pioneiras surgiram logo após a Segunda Guerra Mundial.
A Comunidade Económica Europeia (CEE) ou Mercado Comum Europeu (MCE) foi o embrião da atual União Europeia (UE)
Seus países membros são: Alemanha, Áustria, Bélgica, Dinamarca, Espanha, Finlândia, França, Grécia, Irlanda, Itália, Luxemburgo, Países Baixos, Portugal, Reino Unido e Suécia.
Quando de sua formação, em 1957, a entidade era constituída apenas por Alemanha, Bélgica, França, Itália, Luxemburgo e Países Baixos
Em 1973, ingressaram a Dinamarca, a Irlanda e o Reino Unido; em 1981, a Grécia, e em 1986, Espanha e Portugal
Em 1995, a chamada Europa dos Doze cresceu ainda mais, ganhando a adesão de Áustria, Finlândia e Suécia.
A partir de 1994, os países-membros da Comunidade Económica Europeia, que adotou então o nome de União Europeia, se integrariam para formar um mercado único, em que seriam abolidos os sistemas alfandegários e as diferentes taxas de impostos, além das restrições ao comércio, serviços e à circulação de capitais
Isso significaria, entre outras coisas, que os habitantes da União Europeia teriam trânsito livre em todos os países-membros, inclusive para trabalho; os impostos seriam aos poucos unificados e haveria livre acesso às mercadorias e serviços de todos os países-membros dentro da comunidade.
Desde 1995, para facilitar a circulação de pessoas por alguns países da União Europeia, entrou em vigor um acordo entre Portugal, Espanha, França, Bélgica, Países Baixos, Luxemburgo e Alemanha para eliminar as barreiras alfandegárias e a obrigação da apresentação do passaporte entre esses países
Essa área recebeu o nome de Espaço Schengen, tirado da cidade luxemburguesa onde o acordo foi assinado.
No sentido da integração económica/econômica, outro passo importante seria a utilização de uma moeda comum
O ECU (European Currency Unity ou Unidade Monetária Europeia) circula, desde 1993, como padrão em operações financeiras e, apesar da discordância de alguns membros, pretendeu-se que, gradualmente, ele fosse adotado nas operações cotidianas até 1999, quando o euro entrou em vigor como moeda escritural e como moeda oficial desde 2002.
Todos os países que integram a União Europeia apresentam economia desenvolvida, ainda que existam diferenças extraordinárias entre eles, como entre Irlanda e Alemanha, por exemplo, ou Grécia e Dinamarca
A meta, no entanto, é reduzir esses contrastes, tornando a comunidade cada vez mais homogénea/homógena/homogênea.
Apesar das metas em comum, há divergências entre os países-membros da União Europeia e são frequentes os atritos e necessários os ajustes para garantir a execução de tais metas
O ano de 1994 foi de provas para a integridade da União Europeia, já que ocorreram, nos países, plebiscitos para ratificar seus objetivos e confirmar ou não a adesão à União.
Na Dinamarca e no Reino Unido, as opiniões estavam muito divididas, mas o apoio à comunidade prevaleceu
Na Noruega, entretanto, sua população decidiu não ingressar na União Europeia, apesar da solicitação de adesão feita anteriormente.
Os países europeus ocidentais estão vinculados a importantes organizações que agregam países de outros continentes, como a OTAN e a OCDE.
A Organização do Tratado do Atlântico Norte (OTAN), criada em 1949, tem caráter militar
Além de países europeus, inclui outros dois banhados pelo oceano Atlântico Norte: Canadá e Estados Unidos
Seu objetivo fundamental é a cooperação militar e a defesa de seus membros, no caso de agressâo internacional.
Com o fim da Guerra Fria, o papel da OTAN tem estado em segundo plano
A aliança assumiu um caráter preponderantemente político em 1990, desenvolvendo o papel de resolver crises localizadas
Vários países do Leste Europeu solicitaram o ingresso à OTAN.
A OCDE (Organização para a Cooperação e Desenvolvimento Económico) foi estabelecida em 1961 para promover bem-estar econômico e social entre seus membros e harmonizar a qualidade de vida nos países em desenvolvimento
Além de 18 países europeus, engloba também Austrália, Canadá, Japão, Nova Zelândia e Estados Unidos.
De acordo com definições diferentes, os territórios podem ser sujeitos a várias categorizações
Os 27 Estados Membros da União Europeia são altamente integrados economicamente e politicamente, a própria União Europeia faz parte da geografia política da Europa
A tabela abaixo mostra o esquema de sub-regiões geográficas utilizado pela Organização das Nações Unidas, ao lado do grupo regional publicado no CIA World Factbook.
Dentro dos referidos Estados existem várias regiões, desfrutando de ampla autonomia, bem como de vários países independentes de facto com reconhecimento internacional limitado ou reconhecido, nenhum deles é membro da ONU:
De acordo com os pontos de vista espacial e económico, podemos dividir o continente em: Europa Ocidental, Europa Setentrional, Europa Centro-Oriental e Europa Meridional
Sendo:
Como um continente, a economia da Europa é atualmente a maior do planeta e é a região mais rica como medido por ativos sob gestão, com mais de 32,7 trilhões de dólares em relação ao 27,1 trilhões de dólares da América do Norte
Tal como acontece com outros continentes, a Europa tem uma grande variação da riqueza entre os seus países
Os países mais ricos tendem a estar no Ocidente, enquanto algumas das economias do Leste ainda estão emergindo do colapso da União Soviética e da Iugoslávia.
A União Europeia, um organismo intergovernamental composto por 27 estados europeus, compreende o maior espaço económico/econômico único no mundo
Atualmente, para 16 países da UE, o euro é a moeda comum
Cinco países europeus classificam-se entre as dez maiores economias nacionais do mundo por PIB (PPC)
Isso inclui (classificação de acordo com a CIA): Alemanha (5), Reino Unido (6), Rússia (7), França (8) e Itália (10).
O capitalismo tem sido dominante no mundo ocidental desde o fim do feudalismo
Da Grã-Bretanha, que gradualmente se espalhou pela Europa
A Revolução Industrial começou na Europa, mais concretamente ao Reino Unido no final do século XVIII, e no século XIX impulsionou a industrialização da Europa ocidental
Economias foram interrompidas pela Primeira Guerra Mundial, mas até o início da Segunda Guerra Mundial já tinham se recuperado e estavam tendo que competir com a crescente força económica dos Estados Unidos
A Segunda Guerra Mundial, novamente, danificados muito as indústrias europeias.
Após a Segunda Guerra Mundial, a economia do Reino Unido estava em estado de ruína, e continuou a sofrer um relativo declínio econômico nas décadas seguintes
A Itália também estava em má condição económica/econômica, mas recuperou um elevado nível de crescimento na década de 1950
A Alemanha Ocidental recuperou-se rapidamente e dobrou a produção de níveis pré-guerra na década de 1950
A França também organizou um retorno notável a um crescimento rápido e a modernização e, mais tarde a Espanha, sob a liderança de Franco, também recuperou-se, e a nação obteve um enorme crescimento econômico sem precedentes no início da década de 1960, em que é chamado de milagre espanhol
A maioria dos estados da Europa Oriental ficou sob o controle da URSS e, portanto, eram membros do Conselho para Assistência Econômica Mútua (COMECON).
Os estados que mantiveram um sistema de livre mercado foram agraciados com uma grande quantidade de ajuda dos Estados Unidos ao abrigo do Plano Marshall
Os Estados ocidentais mudaram para ligar as suas economias em conjunto, fornecendo a base para a UE e o aumento do comércio transfronteiriço
Isso ajudou-os a desfrutar de uma rápida melhora de suas economias, enquanto os estados da COMECON estavam lutando em grande parte devido ao custo da Guerra Fria
Até 1990, a Comunidade Europeia foi ampliado de 6 para 12 membros fundadores
A ênfase na ressurreição da economia da Alemanha Ocidental levou a ultrapassagem do Reino Unido como a maior economia da Europa.
Com a queda do comunismo na Europa Oriental, em 1991, os estados do Leste tiveram de se adaptar a um sistema de mercado livre
Havia vários graus de sucesso com os países centro-europeus, como Polónia, Hungria e Eslovénia, que se adaptaram razoavelmente rápido, enquanto estados do Leste como a Ucrânia e a Rússia, estão levando muito mais tempo
A Europa Ocidental ajudou a Europa Oriental, formando laços ao nível da economia.
Após o Leste e o Oeste da Alemanha se reunirem em 1990, a economia da Alemanha Ocidental, apoiou a reconstrução da infra-estrutura da Alemanha Oriental
A Jugoslávia mostrou um atraso maior, sendo devastada pela guerra e em 2003 ainda havia muitas tropas de paz da e da OTAN no Kosovo, na República da Macedónia, na Bósnia e Herzegovina, sendo apenas a Eslovénia que conseguiu fazer algum progresso real.
Na mudança do milênio, a União Europeia dominou a economia da Europa, que inclui os cinco maiores economias europeias da época a Alemanha, Reino Unido, França, Itália e Espanha
Em 1999, 12 dos 15 membros da UE aderiram à Zona Euro substituindo suas antigas moedas nacionais pelo euro comum
Os três que optaram por permanecer fora da zona euro foram Reino Unido Dinamarca e Suécia.
A Zona Euro entrou em sua primeira recessão oficial no terceiro trimestre de 2008, os números oficiais confirmados em janeiro de 2009
A crise econômica do final dos anos 2000, que teve início nos Estados Unidos, propagou-se de forma rápida para a Europa e afetou grande parte da região
A taxa de desemprego oficial nos 16 países que usam o euro subiu para 9,5% em maio de 2009
Os jovens trabalhadores da Europa têm sido especialmente atingidos
No primeiro trimestre de 2009, a taxa de desemprego na UE-27 para pessoas entre 15-24 anos foi de 18,3%.
A cultura europeia pode ser melhor descrita como uma série de culturas sobrepostas e que envolve questões de Ocidente contra Oriente e Cristianismo contra Islão
Existem várias linhas de ruptura culturais através do continente e movimentos culturais inovadores discordam uns dos outros
De acordo com Andreas Kaplan, o continente Europeu pode ser definido como "diversidade cultural máxima a uma distância geográfica mínima"
Assim, uma "cultura comum europeia" ou "valores comuns europeus", é algo cuja definição é mais complexa do que parece.
Na Europa pratica-se uma considerável quantidade de modalidades desportivas
O desporto mais popular é o futebol, representado pela UEFA
O torneio mais importante de seleções é o Campeonato Europeu de Futebol, enquanto que o de clubes é a Liga dos Campeões da UEFA
Em relação ao Campeonato do Mundo de Futebol, em dez edições países europeus sediaram o evento e cinco seleções europeias já venceram o torneio.
Dependências da Coroa e Territórios Ultramarinos Britânicos: Acrotíri e Deceleia • Gibraltar • Guernsey • Jersey • Ilha de Man
Nação do Reino da Dinamarca: Ilhas Faroé
Região Autónoma da Finlândia: Åland
Regiões Autónomas de Portugal: Açores e Madeira
República Turca de Chipre do Norte • Transnístria • Abecásia • Ossétia do Sul • Alto Carabaque

África

América

Antártida

Ásia

Europa

Oceania

América Central

América do Norte

América do Sul

Austrália

Eurafrásia

Eurásia

Magrebe · Norte · Centro · Sul · Ocidente · Oriente · Subsaariana

Norte  · Central   · Sul 
(Latina  · Anglo)

Central · Oriente   · Norte   · Sul   · Sudeste · Ocidente

Ocidente · Centro · Oriente · Norte · Sul


Australásia · Melanésia · Micronésia · Polinésia

Ártico · Antártida

Albânia • Alemanha • Andorra • Armênia • Áustria • Azerbaijão • Bélgica • Bielorrússia • Bósnia e Herzegovina • Bulgária • Cazaquistão • Chipre • Croácia • Dinamarca • Eslováquia • Eslovênia • Espanha • Estônia • Finlândia • França • Geórgia • Grécia • Hungria • Irlanda • Islândia • Itália • Kosovo • Letônia • Liechtenstein • Lituânia • Luxemburgo • Macedônia • Malta • Moldávia • Mônaco • Montenegro • Noruega • Países Baixos • Polônia • Portugal • Reino Unido • República Checa • Romênia • Rússia • San Marino • Santa Sé • Sérvia • Suécia • Suíça • Turquia • Ucrânia
Anno Domini (expressão em latim que significa: "ano do Senhor"), também apresentado na sua forma abreviada A.D., é uma expressão utilizada para marcar os anos seguintes ao ano 1 do calendário mais comumente utilizado no Ocidente, designado como "Era Cristã" ou, ainda, como "Era Comum", sendo esta última a mais usada por evitar referências religiosas.


A abreviatura de Anno Domini é A.D
para designar depois de Cristo, logo também D.C ou d.C.
Segundo este critério, também se utiliza a abreviatura "a.C." para designar os anos antes de Cristo, logo A.C
ou a.C.
Esta era cronológica ("Era Cristã" ou "Era Comum"), que é globalmente adotada, mesmo em países de cultura maioritariamente não cristã, para efeitos de unanimidade de critérios em vários âmbitos, como o científico e comercial, foi organizada de forma a contar o suposto ano do nascimento de Cristo como ano 1, marcando uma linha divisória no tempo a partir de então
A contagem dos anos assemelha-se à ordem dos números inteiros (com a exceção de que não existiu um ano zero - pelo que o ano 1 a.C
foi imediatamente sucedido pelo ano 1 d.C.), pelo que também é comum referir os anos antes de Cristo por números inteiros negativos e os anos depois de Cristo por números inteiros positivos.
Utiliza-se, nesta forma de datação, os calendários Juliano e Gregoriano
O termo Anno Domini é, por vezes, substituído pela expressão mais formal e descritiva Anno Domini Nostri Iesu Christi ("Ano de Nosso Senhor Jesus Cristo")
É, por vezes, ainda substituído pela expressão na era da Graça
A forma de datação segundo o Anno Domini foi primeiramente utilizada na Europa Ocidental durante o século VIII
Portugal foi um dos últimos países a adotar o novo método, imposto pelo rei Dom João I, a 15 de Agosto de 1422, em substituição da "era de César"
A Espanha já o usava desde meados do século precedente.
Nem todos os países seguem o calendário ocidental: judeus e muçulmanos, por exemplo, organizam anos e meses de maneiras diferentes
Contudo, é o padrão internacional, sendo reconhecido por instituições internacionais como a Organização das Nações Unidas ou a União Postal Universal
Isso justifica-se tanto pelo peso da tradição ocidental quanto pelo facto de que o Calendário Gregoriano foi, durante muito tempo, considerado astronomicamente correto.
A datação Anno Domini só foi adotada na Europa Ocidental a partir do século VIII
Tal como os outros habitantes do Império Romano, os primeiros cristãos usavam diversos métodos para especificar os anos, inclusive no mesmo documento
Tal redundância tornou-se útil para os historiadores que puderam, assim, elaborar tabelas comparativas de reinados e outros períodos políticos, com dados de crónicas de diferentes regiões, sob os mesmos governantes.
Uma das formas mais comuns e mais antigas consistia na datação consular, que consistia em nomear os dois consules ordinarii que iniciavam o seu exercício a 1 de Janeiro do ano civil
Por vezes, a designação para o cargo de um dos cônsules, ou mesmo dos dois, podia não ocorrer até Novembro ou dezembro do ano precedente, pelo que, como as notícias levavam meses a chegar aos pontos mais afastados do Império, existem documentos em que o ano é definido como "depois do consulado de...".
Outro método de datação, raramente usado, consistia no anno urbis conditae, ou "no ano da fundação da Cidade" (abreviadamente, AUC), sendo "a Cidade" Roma
(Note-se que, apesar de ser uma confusão freqüente, a abreviatura AUC não significa exatamente ab urbe condita, que é o título da História de Roma escrita por Tito Lívio, e que se adoptou para nomear esta era)
A data da fundação de Roma era disputada entre os próprios romanos, mas os historiadores modernos adoptam, geralmente, a data proposta por Varrão, de 753 a.C..
No início do século V, o historiador ibero Orósio usava a era ab urbe condita
O papa Bonifácio IV, no início do século VII, terá sido o primeiro a utilizar, simultaneamente, esta forma de datação, e o Anno Domini, equivalendo a data de 607 = 1360 anno urbis conditae.
Outro sistema, menos usado do que é frequente pensar-se, consistia na indicação do ano de reinado de cada imperador romano
No início, Augusto indicava os anos do seu governo contando as vezes em que foi investido no cargo de cônsul, ou as vezes em que o Senado de Roma renovava os seus privilégios tribunícios, alimentando a ideia de que os seus poderes lhe eram legitimamente adjudicados por estes órgãos de poder e não pelo fato de aproveitar o culto da personalidade de que já gozava, além do número de legiões sob o seu controlo
Os seus sucessores seguiram tal prática até que a memória da República Romana se foi esbatendo (nos final do século II ou início do III), quando começaram a usar explicitamente o seu ano de reinado.
Também a pacificação de uma região por Augusto serviu como ponto de partida para um calendário
A Era Hispânica ou Era de César, que foi um calendário usado na Península Ibérica durante mais de um milênio, tinha como ano-base o ano da imposição de uma nova taxa regular de impostos sobre os Ibéricos por Augusto, o que foi um marco simbólico do início da Pax romana sobre as províncias da Hispânia; muito embora outro motivo para o surgimento deste calendário pudesse ter sido a renovação do acordo do Triunvirato, que confirmou a Augusto o poder sobre a Península.
Os ciclos de indicção (do latim indictio) consistiam em quinze anos (cada um igual a uma indicção) que marcavam um ciclo determinado por um imposto, contando-se os anos a partir da data em que este era pago
Jesus Cristo nasceu no quinto ano deste ciclo.
Tal sistema, usado na Gália, no Egipto até à conquista Islâmica, no Império Romano do Oriente até à sua queda em 1453 e ainda na Santa Sé durante parte da Idade Média.
Coexistiam, ainda vários sistemas locais de datação ou eras de alguma importância, tal como o ano de fundação de uma dada cidade, o ano de reinado dos imperadores persas e, mesmo, o ano de governo de um dado califa
Particularmente importantes foram a Era dos selêucidas (em uso até ao século VIII) e a Era de César (ou Era Hispânica).
Da mesma forma, na Europa, até ao século XVI, não existia unanimidade quanto ao primeiro dia do ano, não sendo consensual, exceto em Inglaterra, datá-lo no primeiro dia de Janeiro.
Os primeiros cristãos nomeavam cada ano usando, combinadas, as datações consulares, os anos de reinado imperial e a datação a partir da criação do mundo
A datação consular foi extinta quando o imperador Justiniano I deixou de nomear cônsules em meados do século VI
Pouco depois, tornava-se oficial a datação pelo ano de reinado imperial
O último cônsul a ser nomeado foi Anício Fausto Albino Basílio em 541
A Santa Sé manteve, entretanto, um contato regular, durante a Idade Média, com embaixadores do Império Bizantino, pelos quais sabia com alguma certeza qual o imperador no trono, apesar do número elevado de mortes súbitas e deposições que se sucediam.
O sistema do Anno Domini foi desenvolvido em Roma por um monge cita, Dionísio, o Exíguo, em 527, como resultado secundário do seu trabalho no cálculo da data da Páscoa cristã
Cronistas bizantinos, como Teófano, o Confessor, mantinham, entretanto, critérios judaico-cristãos para as datas referidas nas suas crónicas universais, como a datação a partir da suposta data da criação do mundo por graça divina, de acordo com cálculos efetuados por estudiosos cristãos nos primeiros cinco séculos da Era Cristã
Tais eras, por vezes designadas como Anno Mundi, "ano do Mundo" (de forma abreviada, AM), pelos acadêmicos atuais, nem sempre concordavam umas com as outras, existindo grandes discrepâncias
Nenhuma era de Anno Mundi dominava entre os vários estudiosos, ainda que a calculada por Eusébio de Cesareia, historiador na época de Constantino I
São Jerónimo, tradutor da Bíblia para o latim, foi um dos principais divulgadores no ocidente da era AM calculada por Eusébio
Outra era AM, especialmente adoptada no Oriente durante os primeiros séculos do Império Bizantino foi desenvolvida pelo monge Anino de Alexandria.
Os cálculos feitos pelo monge Dionísio, o Exíguo, para datar o nascimento de Jesus Cristo são, em geral, considerados incorretos pela maioria dos acadêmicos bíblicos, julgando-se que teria ocorrido entre 8 e 4 a.C.
Sabe-se que Jesus terá nascido antes da morte de Herodes, o Grande, no ano 4 a.C
- ano este que é determinado pelas informações dadas por Flávio Josefo quanto aos eclipses lunares ocorridos na Páscoa e aos acontecimentos que acompanharam a sua morte, tal como foi calculado por Kepler.
O primeiro historiador ou cronista a usar o Anno Domini como mecanismo de datação principal foi Victor de Tonnenna, escritor africano do século VII
Poucas gerações depois, o historiador anglo-saxão Beda, que conhecia bem o trabalho de Dionísio, voltou a usar o Anno Domini na sua Historia eclesiástica gentis Anglorum, ("História eclesiástica do povo inglês) terminada em 731
Foi nesta obra que se usou pela primeira vez o equivalente, em latim, de "antes de Cristo" (Ante Christum - A.C.), estabelecendo o padrão da não existência de ano zero - ainda que tenha usado o zero no seu computus, ou determinação da Páscoa cristã
Tanto Dionísio como Beda dataram o Anno Domini como sendo o momento da encarnação ou concepção de Jesus Cristo por Graça do Espírito Santo e não no seu nascimento, aproximadamente nove meses depois.
A implantação do novo sistema foi gradual, primeiro em Itália e depois no resto do mundo cristão
A região de Inglaterra foi uma das primeiras a adotar o Anno Domini, graças à influência dos missionários romanos, como se pode verificar em documentos do século VII
No continente Europeu, o Anno Domini foi a era de eleição de Alcuíno de Iorque, durante a Renascença Carolíngia
A adoção do novo sistema de datação por Carlos Magno e pelos seus sucessores está na origem do sucesso do mesmo nos séculos seguintes, até a época atual
Na Gália, o sistema só tornou-se vulgar a partir do ano 1000, o que justifica que os franceses usassem o termo millésime para designar os anos da era Cristã.
Fora do Império Carolíngio, a Hispânia continuava a seguir a Era Hispânica (ou "dos Césares"), que se iniciara em 38 a.C., até bem tarde na Idade Média
A Era dos Mártires, que numerava os anos a partir da ascensão ao trono de Diocleciano, em 284, e que marcava o início da última e mais severa perseguição aos cristãos manteve-se no Oriente, sendo ainda atualmente utilizada pelos cristãos coptas, bem como, durante muito tempo, pela Igreja Ortodoxa Etíope
Outro sistema recorria à datação a partir da data da crucificação de Jesus Cristo, que Hipólito, Lactâncio, Agostinho e Tertuliano situavam em 29 d.C., durante o consulado dos Gêmeos (Lúcio Rubélio Gêmino e Caio Fúfio Gêmino).
Ainda que o Anno Domini já fosse comum no século IX, a designação "antes de Cristo", ou outra equivalente só se tornou vulgar a partir do final do século XV.
O Papiro Ebers é um dos tratados médicos mais antigos e importantes que se conhece
Foi escrito no Antigo Egito e é datado de aproximadamente 1550 a.C.
Atualmente o papiro está em exibição na biblioteca da Universidade de Leipzig e foi batizado em homenagem ao monge alemão Georg Ebers, que os adquiriu em 1873.
O papiro contém mais de 700 fórmulas mágicas e remédios populares além de uma descrição precisa do sistema circulatório
Os egípcios mostram o grau de compreensão do o corpo humano, a sua estrutura, o trabalho dos vasos sanguíneos e do coração, anatomia e fisiologia, e magias de toxicologia.


Foi encontrado entre os restos de uma múmia, em um túmulo, próximo a Tebas
Foram encontrados dois papiros, ambos foram para as mãos do colecionador estadunidense Edwin Smith, em 1862, mais tarde, no inverno de 1872, um deles foi comprado pelo egiptólogo alemão Georg Ebers, que acabou tendo o seu nome.
Possui 20,25 metros de comprimento e 30 centímetros de largura
Está dividido em 110 colunas , de 20 a 22 linhas, subdivididas em 877 seções

Nota: esta página contém alguns caracteres especiais e é possível que a impressão não corresponda ao artigo original.
Coordenadas: 26° 2' N 29° 13' E

O Egito (AO 1945: Egipto) (em egípcio antigo: Kemet; em copta Ⲭⲏⲙⲓ, translit.: Kīmi; em árabe: مصر, translit.: ‎Miṣr, pronunciado: [mi̠sˤr], pronunciado em árabe egípcio: [mesˤɾ]; em árabe egípcio: مَصر, translit.: Maṣr, pronunciado: [mɑsˤɾ]), oficialmente República Árabe do Egito (em árabe: جمهورية مصر العربية, transl
Jumhūriyyat Miṣr al-ʿArabiyyah, em árabe egípcio: Gomhoreyyet Maṣr el-ʿArabeyya) é um país do nordeste da África, numa região predominantemente desértica, que inclui também a península do Sinai, na Ásia, o que o torna um Estado transcontinental
Com uma área de cerca de 1 001 450 km², o Egito limita-se a oeste com a Líbia, a sul com o Sudão e a leste com a Faixa de Gaza e Israel
O litoral norte é banhado pelo mar Mediterrâneo e o litoral oriental pelo mar Vermelho
A península do Sinai é banhada pelos golfos de Suez e de Acaba
A sua capital é a cidade do Cairo, a maior e mais populosa cidade do país e do continente africano
Os gentílicos para o país são "egípcio", "egipciano", "egipcíaco", "egiptano", "egiptanense", "egipcião", "egíptico" e "egiptino", embora as últimas sete formas raramente sejam usadas.
Com mais de 85 milhões de habitantes, o Egito é um dos países mais populosos da África e do Oriente Médio, sendo o 15.º mais populoso do mundo
A população está concentrada, sobretudo, às margens do rio Nilo, praticamente a única área não desértica do país, com cerca de 40 000 kmª; O da Líbia, a oeste, o Arábico ou Oriental, a leste, ambos parte do Saara, e o do Sinai, são pouco povoados
Cerca de metade da população egípcia vive nos centros urbanos, em especial no Cairo, em Alexandria e nas outras grandes cidades do delta do Nilo, de maior densidade demográfica.
O país possui uma das histórias mais longas entre todos os Estados modernos, tendo sido continuamente habitado desde o 10.º milênio a.C., Sua antiga civilização foi responsável pela construção de alguns dos monumentos mais famosos da humanidade, como as pirâmides de Gizé e a Grande Esfinge, tendo sido também uma das mais poderosas de seu tempo e uma das primeiras seis civilizações a surgir de forma independente no mundo
Suas ruínas antigas, como as de Mênfis, Tebas, bem como o templo de Karnak e o Vale dos Reis, abrigados na cidade de Luxor, são um foco importante de estudo arqueológico e interesse popular de todo o mundo.
O rico legado cultural do Egito, bem como suas atrações, como o mar Vermelho e os sítios arqueológicos, fizeram do turismo a parte vital da economia, empregando cerca de 12% da força de trabalho no país
A economia egípcia é uma das mais diversificadas na África, com setores como o turismo, a agricultura, indústria e serviços em níveis de produção quase iguais
O Egito é considerado uma potência média, com influência cultural, política e militar significativa no Norte da África, no Oriente Médio e no mundo muçulmano.


Um dos antigos nomes egípcios para o país, Kemet (kṃt), ou "terra negra" (de kem, "negro"), advém do solo fértil negro depositado pelas cheias do Nilo, distinto da "terra vermelha" (dechret, dšṛt) do deserto
O nome passou às formas kīmi e kīmə na fase copta da língua egípcia e aparece no grego primitivo como Χημία (Khēmía)
Outro nome era t3-mry ("terra da ribeira")
Os nomes do Alto e do Baixo Egito eram Ta-Sheme'aw (t3-šmˁw), "terra da junça", e Ta-Mehew (t3 mḥw) "terra do norte", respectivamente.
Miṣr, o nome árabe moderno e oficial para o país, é de origem semita, diretamente relacionado com outros termos semíticos para o Egito, como o hebraico מִצְרַיִם (Mizraim), literalmente "os dois estreitos" (referência ao Alto e Baixo Egitos)
A palavra possuía originalmente a conotação de "metrópole" ou "civilização" e também significa "país" ou "terra de fronteira".
O termo português "Egito" deriva do grego antigo Αίγυπτος (Aígyptos), por meio do latim Aegyptus, e já era registado no vernáculo no século XIII
A forma grega, por sua vez, advém do egípcio Ha-K-Phtah, "morada de Ptá", denominação de Mênfis, capital do Antigo Império.
Os vestígios de ocupação humana no vale do Nilo desde o paleolítico assumem a forma de artefatos e petróglifos em formações rochosas ao longo do rio e nos oásis
No décimo milénio a.C., uma cultura de caçadores-coletores e de pescadores substituiu outra, de moagem de grãos
Em torno de 8 000 a.C., mudanças climáticas ou o abuso de pastagens começou a ressequir as terras pastoris do Egito, de modo a formar o Saara
Povos tribais migraram para o Vale do Nilo, onde desenvolveram uma economia agrícola sedentária e uma sociedade mais centralizada.
Por volta de 6 000 a.C., a agricultura organizada e a construção de grandes edifícios havia surgido no Vale do Nilo
Durante o neolítico, diversas culturas pré-dinásticas desenvolveram-se de maneira independente no Alto e no Baixo Egito
A cultura Badariana e a sua sucessora, a Nacada, são consideradas as precursoras da civilização egípcia dinástica
O sítio mais antigo conhecido no Baixo Egito, Merimda, antecede os badarianos em cerca de setecentos anos
As comunidades do Baixo e do Alto Egito coexistiram por mais de dois mil anos, mantendo-se como culturas separadas, mas com contatos comerciais frequentes
Os primeiros exemplos de inscrições hieroglíficas egípcias apareceram no período pré-dinástico, em artefatos de cerâmica de Nacada III datados de cerca de 3 200 a.C.
Cerca de 3 150 a.C., o rei Menés (ou Narmer) fundou um reino unificado e estabeleceu a primeira de uma sequência de dinastias que governaria o Egito pelos três milênios seguintes
Posteriormente, os egípcios passaram a referir-se a seu país unificado com o termo tawy, "duas terras" e, em seguida, kemet (kīmi, em copta), "terra negra"
A cultura egípcia floresceu durante este longo período e manteve traços distintos na religião, arte, língua e costumes
Às duas primeiras dinastias do Egito unificado seguiram-se o período do Antigo Império (c
2 700-2 200 a.C.), famoso pelas pirâmides, em especial a pirâmide de Djoser (III Dinastia) e as pirâmides de Gizé (IV Dinastia).
O Primeiro Período Intermédio foi uma época de distúrbios que durou cerca de 150 anos
Mas as cheias mais vigorosas do Nilo e a estabilização do governo trouxeram prosperidade ao país no Médio Império (c
2 040 a.C.), que atingiu o zénite durante o reinado do faraó Amenemés III
Um segundo período de desunião prenunciou a chegada da primeira dinastia estrangeira a governar o Egito, a dos hicsos
Estes invasores tomaram grande parte do Baixo Egito por volta de 1 650 a.C
e fundaram uma nova capital, em Aváris
Foram expulsos por uma força do Alto Egito chefiada por Amósis, quem fundou a XVIII Dinastia e transferiu a capital de Mênfis para Tebas.
O Novo Império (c
1 550-1 070 a.C.) teve início com a XVIII Dinastia e marcou a ascensão do Egito como potência internacional que, no seu auge, se expandiu para o sul até Jebel Barkal, na Núbia, e incluía partes do Levante, no leste
Alguns dos faraós mais conhecidos pertencem a este período, como Ramsés I, Ramsés II, Aquenáton e sua mulher Nefertiti, Tutankhamon e Ramsés III
A primeira expressão do monoteísmo é desta época, com o atonismo
O país foi posteriormente invadido por líbios, núbios e assírios, mas terminou por expulsá-los a todos
A XXX Dinastia foi a última de origem nativa a governar o país durante a era dos faraós
O último faraó nativo, Nectanebo II, foi derrotado pelos persas aqueménidas em 343 a.C..
O Reino Ptolomaico foi um poderoso estado helenístico, que se estendia do sul da Síria, a leste, a Cirene, a oeste, e ao sul da fronteira com a Núbia
A cidade de Alexandria tornou-se a capital e o centro cultural e comercial do reino grego
Para obter o reconhecimento da população egípcia nativa, os governantes ptolomaicos chamavam a si mesmos de sucessores dos faraós
Os ptolomaicos assumiram as tradições egípcias, retratavam-se em monumentos públicos e vestiam-se ao estilo egípcio, além de participarem da vida religiosa local.
O último governante da dinastia ptolomaica foi Cleópatra VII, que cometeu suicídio após o enterro de seu amante romano Marco Antônio, que tinha morrido em seus braços (de uma facada auto-infligida), depois de Otaviano ter capturado Alexandria e suas forças de mercenários fugirem.
Os ptolomaicos enfrentaram rebeliões dos egípcios nativos, muitas vezes causadas ​​por um regime indesejado, e se envolveram em guerras externas e civis que levaram à queda do reino e sua anexação pelo Império Romano
No entanto, a cultura helenística continuou a prosperar no Egito logo após a conquista muçulmana.
O cristianismo foi trazido ao Egito por São Marcos no primeiro século da era cristã
O reinado de Diocleciano marcou a transição entre os Impérios Romano e Bizantino no país, quando um grande número de cristãos foi perseguido
Naquela altura, o Novo Testamento foi traduzido para a língua egípcia
Após o Concílio de Calcedónia, em 451, uma Igreja Copta Egípcia foi firmemente estabelecida.
Os bizantinos recuperaram o controlo do país após uma breve invasão persa no início do século VII, mantendo-o até 639, quando o Egito foi tomado pelos árabes muçulmanos sunitas
Os egípcios começaram então a misturar a sua nova fé com crenças e práticas locais que sobreviveram através do cristianismo copta, o que deu origem a diversas ordens sufistas que existem até hoje
Os governantes muçulmanos eram nomeados pelo Califado islâmico e mantiveram o controle do país pelos seis séculos seguintes, inclusive durante o período em que o Egito foi a sede do Califado Fatímida
Com o fim da dinastia aiúbida, a casta militar turco-circassiana dos mamelucos tomou o poder em 1250 e continuou a governar até mesmo após a conquista do Egito pelos turcos otomanos em 1517.
A breve invasão francesa do Egito em 1798, chefiada por Napoleão Bonaparte, resultou num grande impacto no país e em sua cultura
Os egípcios foram expostos aos princípios da Revolução Francesa e tiveram a oportunidade de exercitar o auto-governo
À retirada francesa seguiu-se uma série de guerras civis entre os turcos otomanos, os mamelucos e mercenários albaneses, até que Mehmet Ali, de origem albanesa, tomou o controle do país e foi nomeado vice-rei do Egito pelos otomanos em 1805
Ali promoveu uma campanha de obras públicas modernizadoras, como projetos de irrigação e reformas agrícolas, bem como uma maior industrialização do país, tarefa continuada e ampliada por seu neto e sucessor, Ismail Paxá.
A Assembleia dos Delegados foi fundada em 1866 com funções consultivas e veio a influenciar de maneira importante as decisões do governo.
Embora vivenciasse um período de modernização, a má administração financeira do quediva Ismail Paxá e os enormes empréstimos contraídos com credores europeus - especialmente para a construção do Canal de Suez - deixaram o Egito à beira da falência e foi o pretexto ideal para as constantes ingerências dos governos do Reino Unido e da França no quedivato
Em 1879, pressionado interna e externamente, Ismael renunciou e seu filho, Teufique Paxá, assumiu o poder local
Em 1880, foi declarada a moratória nacional e, no ano seguinte, credores europeus assumiram a tutela do fisco e das finanças egípcias
A situação humilhante ampliou o descontentamento e a oposição ao regime Tawfik, e o desejo de se livrar da dominação estrangeira culminou na Revolucão Urabista, liderada pelo coronel nacionalista Ahmed Urabi
A revolta foi esmagada em 1882 pelas forças britânicas, que intervieram a pedido do próprio quediva colaboracionista
Embora o Império Britânico tivesse prometido uma evacuação rápida das suas tropas, elas ainda permaneceriam por 72 anos no Egito
Mesmo que formalmente continuasse sob domínio do Império Otomano, quem mandava no quedivato eram os Altos Comissários Gerais britânicos, que por igual acumulavam a função protocolar de cônsules gerais do Império Britânico no Egito
A ocupação colonial britânica semeou o incipiente sentimento nacionalista egípcio, que viu no Incidente de Dinshaway, em maio de 1906, seu episódio mais emblemático.
Embora surgissem os primeiros partidos políticos locais, a colonização se consolidaria oficialmente em 1914, quando os britânicos derrubaram o quediva Abbas II e declararam o Egito um protetorado militar
Hussein Kamil, tio de Abbas II, foi então nomeado sultão do Egito
Após a Primeira Guerra Mundial, Saad Zaghlul e o Partido Wafd lideraram o movimento nacionalista egípcio
Quando o Reino Unido ordenou o exílio de Zaghlul e seus correligionários para Malta em 1919, houve uma grande revolta popular, e as constantes rebeliões por todo o sultanato levaram Londres a conceder independência nominal ao Egito
Um sistema parlamentarista monárquico foi estabelecido e reconhecido pelos britânicos, na pessoa de Fuad I e promulgada uma nova constituição, embora o Reino Unido mantivesse a ocupação militar e controlasse as relações exteriores e as comunicações do país
De volta ao Egito, Saad Zaghlul foi eleito para o cargo de primeiro-ministro pelo voto popular, em 1924, mas renunciou no final desse ano
Novas eleições confirmaram outra vitória ao Wafd, mas o rei Fuad determinou o encerramento do parlamento e, em 1930, outorgou uma nova constituição ao Egito, que reforçava o poder da monarquia
Em 1936, foi assinado o tratado anglo-egípcio, pelo qual o Reino Unido se comprometia a defender o Egito e recebia o direito de manter tropas no canal de Suez
A continuidade da ingerência britânica no país e o aumento do envolvimento do rei do Egito na política desencadeou a Revolução de 1952, quando o Movimento dos Oficiais Livres derrubou militarmente o reinado de Rei Faruk, que abdicou em favor do seu filho Fuad.
Após a deposição de Faruk I, a monarquia egípcia continuou existindo formalmente, com Fuad II no trono, embora a Junta Militar tenha esvaziado de todos os poderes
O monarca ficou no trono por 18 meses até a república ser proclamada em 18 de junho de 1953, com o general Muhammad Nagib - número 1 do Conselho do Comando Revolucionário - tornando-se o primeiro presidente do Egito moderno
Os oficiais tentaram iniciar os trabalhos em conjunto com os políticos do país, mas surgiram os primeiros conflitos entre os militares no poder
Nagib era contrário ao afastamento dos civis e à ascensão dos militares nos negócios do governo e alertava para o perigo de uma nova ditadura, uma vez que muitos dos responsáveis pela corrupção do governo anterior continuavam em seus postos
Então com 51 anos, o general era mais velho que Nasser e gozava de boa reputação entre os oficiais mais novos, principalmente por ter sido um crítico feroz no período pré-revolucionário, conseguiu afastar o rival do centro de decisões
Em fevereiro de 1954, as tensões entre as correntes de Nagib e Nasser eclodiram um enfrentamento
Apoiado por oficiais revolucionários mais radicais, Gamal Nasser assumiu o controle do Estado
O presidente deposto tentou resistir, mas fracassou e foi condenado à prisão domiciliar perpétua
Comandado por Nasser, o Conselho de Comando da Revolução liderou o Egito entre novembro de 1954 e junho de 1956.
Em 23 de junho de 1956, Gamal Abdel Nasser assumiu oficialmente o poder como presidente do Egito, após um referendo sobre uma nova constituição e sobre a sua eleição presidencial
Com sua personalidade carismática que, junto às suas reformas sociais e econômicas bem-sucedidas, lhe proporcionaram grande apoio popular
Seu governo aboliu os partidos políticos, procedeu à reforma das estruturas agrárias, combateu o fundamentalismo islâmico e pôs em prática um processo de industrialização, do qual a construção a grande represa de Assuã era um dos projetos mais significativos
Para isso, nacionalizou o Canal de Suez, o que provocou uma grave crise internacional.
Apesar de se aproximar da União Soviética, Nasser incentivou uma política de solidariedade com outras nações africanas e asiáticas do Terceiro Mundo, afirmando-se como um dos principais líderes de movimentos não-alinhados, pan-arabista e anti-imperialista
Objetivando um socialismo adaptado à especificidade árabe e um primeiro passo em direção à unificação do mundo árabe, apostou em uma associação com a Síria, entre 1958 e 1961, que deu origem à República Árabe Unida
Em 1967, liderou o Egito na Guerra dos Seis Dias contra Israel, no qual os israelitas tomaram dos egípcios a Península do Sinai e a Faixa de Gaza
Em setembro de 1970, o general faleceu e foi sucedido por Anwar el Sadat.
Sucedeu-o Anwar Al Sadat, que distanciou seu país da União Soviética e o aproximou dos Estados Unidos
Promoveu uma reforma econômica chamada "Infitá" e suprimiu de maneira violenta tanto a oposição política quanto a religiosa
Em 1973, aproveitando de um feriado religioso judaico, forças do Egito e da Síria atacaram de surpresa Israel, na chamada Guerra de Outubro (ou do Yom Kippur)
Embora os israelenses tenham conservado em seu poder os territórios ocupados desde 1967, tanto o Egito quanto Israel consideravam-se vencedores do conflito de 19 dias
Em negociações secretas, Sadat buscava selar a paz com o governo israelense
Pressionado, o então premiê israelense Menachem Begin convidou o dirigente egípcio para uma visita surpresa a Jerusalém em novembro de 1977, um gesto que abriu definitivamente o caminho para os acordos de paz de Camp David, mediado pelo então presidente dos Estados Unidos Jimmy Carter
O tratado gerou a saída israelita da península do Sinai, em troca do Egito reconhecer o Estado de Israel
A iniciativa provocou enorme controvérsia no mundo árabe e provocou a expulsão do Egito da Liga Árabe
Sadat sequer chegou a ver completada a retirada das tropas israelenses do Sinai, pois foi assassinado em outubro de 1981 por fundamentalistas muçulmanos que o acusavam de "trair o mundo árabe com o acordo de paz"
Israel devolveu o Sinai aos egípcios em 1982 e os dois estados estabeleceram relações diplomáticas.
Com o assassinato de Anwar Sadat, assumiu o comando do Egito o vice-presidente Hosni Mubarak em 14 de novembro de 1981
Mubarak havia se destacado na Força Áerea egípcia pelo seu desempenho na guerra de Yom Kippur
Em 1995, ele sobreviveu a uma tentativa de assassinato durante uma visita à Etiópia
Por quase 24 anos, sempre se reelegeu por via de referendo popular como candidato único
Essa situação perdurou até 2005, quando houve a primeira eleição sob seu regime disputada por diversos candidatos
Mesmo assim, o ditador saiu vitorioso.
Inspirados nas manifestações insurrecionais ocorridas na Tunísia, milhares de egípcios foram as ruas em diversas cidades no país no dia 25 de janeiro de 2011 e iniciaram uma onda de protestos pedindo a saída do ditador do poder
A Praça Tahrir, no Cairo, transformou-se em um dos principais palco dos protestos, com milhares de pessoas desafiando o toque de recolher imposto pelo regime
Em 11 de fevereiro, Mubarak renunciou à presidência e passou o poder ao Exército, encerrando três décadas de governo autocrático.
Em 23 de junho de 2012, Mohamed Morsi, candidato da Irmandade Muçulmana, venceu o primeiro pleito presidencial pós-Mubarak, derrotando o opositor vinculado ao antigo ditador e se tornando o primeiro presidente civil eleito democraticamente no Egito
Mas seu governo foi marcado por muitas polêmicas com a oposição, que o acusou de impor uma nova Constituição sectária e forçar a "islamização" do Egito.
Depois de novas manifestações pró e anti-Morsi, no começo de julho, a oposição deu um ultimato de 24 horas a Morsi para que renunciasse, e o movimento Tamarod (rebelião, em árabe) pedia que o Exército tomasse uma posição clara "ao lado da vontade popular"
Os militares estipularam 48h para a classe política entrar em acordo e, em 3 de julho, depuseram Mohamed Morsi e suspenderam a Constituição
Violentos protestos contra o golpe se seguiram e tomaram conta das principais cidades do país, incluindo a capital Cairo.
Em 4 de julho de 2013, Adly Mansour, um juiz egípcio de 68 anos de idade foi empossado como presidente interino do país sobre o novo governo após a remoção de Morsi do governo
Em 18 de janeiro de 2014, o governo interino institucionalizou uma nova constituição nacional, após um referendo em que 98,1% dos eleitores foram favoráveis​​
A participação foi baixa, com uma participação de apenas 38,6% dos eleitores registrados, embora este índice tenha sido maior do que os 33% que votaram em um referendo durante o mandato de Morsi.
Uma eleição presidencial ocorreu entre 26 e 28 de maio de 2014, com apenas dois candidatos, o ex-Ministro da Defesa egípcio Abdel Fattah el-Sisi e Hamdeen Sabahi, da Corrente Popular Egípcia
As eleições aconteceram quase um ano após os protestos de junho de 2013 que levaram ao el-Sisi a depor o então presidente Mohamed Morsi
Os números oficiais mostraram que cerca de 25,5 milhões de pessoas participaram das eleições, ou 47,5% dos eleitores registrados, sendo que el-Sisi venceu com 23,7 milhões de votos (96,91% do total), dez milhões de votos a mais que o ex-presidente Mohamed Morsi (que recebeu 13 milhões a mais que o seu adversário no segundo turno das eleições presidenciais egípcias de 2012).
Com uma área de 1 001 450 km², o Egito é o 29º maior do mundo, um pouco maior do que o estado brasileiro do Mato Grosso e duas vezes o território da França
Entretanto, devido à aridez do clima do país, os centros urbanos estão concentrados ao longo do estreito vale do rio Nilo e no Delta do Nilo, razão pela qual 99% da população egípcia usam apenas 5,5% da área total.
As inundações do rio Nilo foram o fundamento da economia do país durante milênios
Tal fenômeno foi alterado pela construção da represa de Assuã, que apesar de controverso, e ter causado deslocamento massivo, trouxe benefícios para a agricultura, pois permitiu o cultivo de novas culturas como algodão e cana-de-açúcar, além de beneficiar as culturas tradicionais como trigo, arroz e milho, além disso a geração da energia hidrelétrica permitiu algum desenvolvimento industrial.
O Egito faz fronteira com a Líbia a oeste, o Sudão a sul e Israel e a Faixa de Gaza a nordeste
O país controla o canal de Suez, que liga o Mediterrâneo ao Mar Vermelho e, por conseguinte, ao oceano Índico.
Também pertence ao Egito a península do Sinai, na Ásia, a qual, ligada ao restante do país pelo istmo de Suez, caracteriza-o como um estado transcontinental.
Fora do vale do Nilo, a maior parte do território egípcio é composto por desertos sobretudo rochosos
Nas áreas de areia, os ventos criam dunas que podem ultrapassar 30 m de altura
O país inclui uma parte considerável do Deserto da Líbia, o qual faz parte do Saara, a "terra vermelha", como os chamavam os antigos egípcios, que protegia o reino dos faraós de ameaças a oeste
Os outros desertos são o Oriental ou Arábico, que ocupa a faixa entre a margem direita do Nilo e o Mar Vermelho, e o do Sinai, na península da Arábia.
Além da capital, Cairo, as outras cidades importantes do Egito são Alexandria, Almançora, Assuão, Assiut, El-Mahalla El-Kubra, Gizé, Hurghada, Luxor, Kom Ombo, Safaga, Porto Said, Sharm el Sheikh, Shubra El-Kheima, Suez e Zagazig
Os principais oásis são Bahariya, Dakhla (ou Dakhleh), Farafra, Kharga e Siuá (ou Siwa).
A grande bacia hidrográfica do país é a do Nilo, cujo curso total, com 6 696 km de extensão, é único a atravessar os desertos do NE africano até atingir o Mediterrâneo
A região do vale do Nilo, situada ao sul de Assuão, é quase desértica
A partir de Assuão, onde se localizam a primeira catarata e a grande represa do mesmo nome, o rio corre num leito estreito (2 a 10 km de largura), atingido sua largura máxima em Kom-Ombo (15Km)
Nessa região, o vale é ladeado por uma cadeia de colinas rochosas com altitude média de 300 m
A 5 km ao norte do Cairo, o rio divide-se em dois braços principais, formando um dos deltas mais férteis do mundo.
A precipitação é baixa no Egito, excepto nos meses de inverno nas regiões mais a norte
Ao sul do Cairo, a precipitação média é de apenas cerca de 2 a 5 mm ao ano, em intervalos de muitos anos
Numa faixa estreita do litoral norte, chega a 410 mm, concentrada principalmente entre Outubro e Março
As montanhas do Sinai e algumas cidades litorâneas ao norte, como Damieta, Baltim, Sidi Barrany e, mais raramente, Alexandria, vêem neve.
As temperaturas médias situam-se entre 27 e 32 °C no verão, chegando a 43 °C no litoral do mar Vermelho, e entre 13 e 21 °C no inverno
Um vento constante de noroeste ajuda a baixar a temperatura no litoral mediterrâneo
Outro vento, o Khamsin, sopra do sul na primavera, trazendo areia e poeira, e pode elevar a temperatura no deserto para mais de 38 °C.
A população egípcia é estimada em 81 milhões de habitantes (2008), e está quase toda (98%) concentrada no vale e no delta do Rio Nilo (Nahr-an-Nil), que representa 30% do total do território daquele país, havendo entretanto um importante núcleo populacional na cidade de Suez, situada junto ao Canal de Suez
É o segundo país mais populoso de África.
A esperança média de vida ao nascer é de 74,15 anos (estimativa de 2013), distribuída em 72,2 anos para os homens e 76,10 anos para as mulheres.
O árabe é a língua oficial; inglês e francês são utilizados por uma elite culta; o copta é utilizado pela minoria cristã em práticas religiosas; há minorias que falam idiomas bérberes, núbio ou oromo.
Cerca de 42% dos egípcios vivem em cidades
As mais populosas são o Cairo (a cidade mais populosa do continente africano com 6 789 000 habitantes, segundo dados de 1998) e Alexandria (3 328 000 habitantes)
Ao longo do século XX verificou-se uma migração das populações rurais para as cidades, o que se traduziu no surgimento nestas de problemas de saneamento básico, poluição e falta de habitações condignas.
A religião maioritária do Egito é o islã sunita, aproximadamente 90% da população
A maior minoria religiosa são os cristãos coptas (9% da população)
Outras minorias religiosas são os ortodoxos gregos e armênios, tanto católicos quanto protestantes.
Nesta zona viviam os judeus, ainda que em pequeno número, de importância econômica
Eles abandonaram o país em 1956, quando forças armadas de Israel, França e Grã-Bretanha atacaram o Egito.
Em 1992 começou uma campanha de violência armada, concentrado em Cairo e no Alto Egito, cujo principal objetivo era estabelecer um governo baseado em uma lei islâmica escrita
As principais vítimas da violência foram funcionários governamentais e turistas
A Organização de Direitos Humanos determinou que o governo egípcio parasse a discriminação contra as vítimas
As leis relativas à construção das igrejas e a prática aberta da religião têm recentemente diminuído, mas o importante trabalho de construção nas igrejas ainda requerem a permissão do governo.
A população egípcia é composta por diversas etnias, a maioria tem suas origens em um povo semítico-camítico; há uma minoria de beduínos, que mantém uma organização e práticas tribais e nômades na área desértica do país; o terceiro maior grupo étnico são os núbios, um povo africano estabelecido há milhares de anos no Alto Nilo
Há uma considerável herança étnica dos povos que passaram pelo território: romanos, gregos, turcos, circassianos, ingleses e franceses.
Os núbios são um grupo minoritário do país, oriundo de uma região corresponde ao sul do Egito e ao norte do Sudão
Quando as suas terras foram submergidas pelo Lago Nasser, tiveram que mudar-se para Kom Ombo
No século XIX fixaram-se no Egito comunidades estrangeiras compostas por gregos, italianos, britânicos e franceses; desde que se deu a independência do país, estas populações têm diminuído
A outrora ativa e influente comunidade judaica egípcia praticamente desapareceu; alguns judeus visitam o país em ocasiões religiosas.
O Egito tem a mais antiga tradição parlamentar contínua no mundo árabe
 Sua primeira assembleia popular foi criada em 1866
Foi licenciado pela ocupação britânica de 1882 - a potência ocupante permitiu apenas a existência de órgão consultivo
O nacionalismo egípcio antecedeu o seu homólogo árabe em muitas décadas, tendo raízes no século XIX, tornando-se o modo dominante de expressão de ativistas e intelectuais anti-coloniais egípcios até o início do século XX
Em 1923, no entanto, após a libertação colonial do país, uma nova constituição previa uma monarquia parlamentar.
O Egito é uma república desde 18 de junho de 1953
Atualmente, seu parlamento é bicameral, formado pela Assembleia do Povo (câmara baixa, com representantes eleitos para um mandato de 5 anos) e Conselho Shura (câmara alta, com representantes eleitos para um mandato de 6 anos)
– e as eleições acontecem em três etapas, divididas pelos "governorates" (Estados)
Em cada etapa, nove Estados são convocados às urnas
O resultado de cada consulta é divulgado exatamente uma semana depois de cada sufrágio
A Assembleia é composta por 454 membros, dos quais 444 eleitos a cada cinco anos (desde 1986, 400 deputados por listas de partidos e 44 como candidatos diretos sem partido) e dez são nomeados pelo chefe de Estado
O Conselho é o órgão legislativo formado por 210 membros, dos quais dois terços são eleitos e o terço restante nomeado pelo chefe de Estado.
Após a revolução Egípcia de 2011, durante o período da "Primavera Árabe", o governo de décadas do ditador Hosni Mubarak chegou ao fim e Mohamed Morsi tornou-se o primeiro chefe de Estado eleito democraticamente no país
No entanto, em 3 de julho de 2013, milhões de manifestantes saíram às ruas contra Morsi e formaram um dos maiores protestos da história do mundo
O general Abdul Fatah Khalil Al-Sisi, deu um golpe de Estado, suspendeu a Constituição e assumiu, frente aos militares, o comando do país
Uma "comissão", de 50 membros, foi formada para modificar a Constituição egípcia, que foi publicada mais tarde para votação pública e foi adotada oficialmente em 18 de janeiro de 2014
Em 2013, a Freedom House classificou os direitos políticos no Egito um país "parcialmente livre".
O Egito exerce uma grande influência política na África e no Médio Oriente e as suas instituições intelectuais e islâmicas estão no centro do desenvolvimento social e cultural da região
A sede da Liga Árabe encontra-se no Cairo; tradicionalmente, o secretário-geral da organização é egípcio.
O Egito foi o primeiro país árabe a estabelecer relações diplomáticas com Israel depois da assinatura dos acordos de Camp David, em 1978
O ex-vice-primeiro-ministro Boutros Boutros-Ghali foi secretário-geral das Nações Unidas entre 1992 e 1996.
As Forças Armadas do Egito têm tropas combinadas de cerca de 468.500 soldados na ativo, além 1.000.000 de reservistas
De acordo com o ex-presidente do Comitê de Relações Exteriores e Defesa do Knesset, Yuval Steinitz, a Força Aérea do Egito tem aproximadamente o mesmo número de aviões de guerra modernos que a Força Aérea de Israel e muito mais tanques, artilharia, baterias antiaéreas e navios de guerra do que as Forças de Defesa de Israel
Israel especula que o Egito é o segundo país da região com um satélite espião, o EgyptSat 1, além do EgyptSat 2, que foi lançado em 16 de abril de 2014
Os militares exercem muita influência na vida política nacional, assim como na economia e estão acima das leis que se aplicam aos outros setores da sociedade
Eles também gozam de considerável poder, prestígio e independência dentro do Estado e têm sido amplamente considerados parte do "Estado profundo" egípcio.
Os militares egípcios tem dezenas de fábricas de armas, bem como bens de consumo
O inventário das forças armadas do país inclui equipamentos de diferentes países ao redor do mundo
Equipamento da antiga União Soviética está sendo progressivamente substituídos por armas e equipamentos modernos de fabricação estadunidense, francesa e britânica, uma parcela significativa dos quais é construído sob licença no Egito, como o tanque M1 Abrams
A Marinha do Egito é a maior marinha da África, do Oriente Médio e do mundo árabe, além de ser a sétima maior do mundo por número de navios
Os Estados Unidos fornecem ao Egito uma ajuda militar anual, que em 2009 foi de 1,4 bilhão de dólares.
A Organização Egípcia para os Direitos Humanos é um dos órgãos mais antigos para a defesa dos direitos humanos no Egito
Em 2003, o governo criou o Conselho Nacional de Direitos Humanos
No entanto, o conselho recebeu graves críticas de ativistas locais, que afirmam que ele era apenas uma ferramenta de propaganda do governo para desculpar as suas próprias violações e para dar legitimidade às leis repressivas, como a Lei de Emergência.
O Pew Research Center classifica o Egito como o quinto pior país do mundo em liberdade religiosa
A Comissão dos Estados Unidos sobre Liberdade Religiosa Internacional, uma agência independente bipartidária do governo dos Estados Unidos, colocou o Egito em sua lista de observação para países que exigem um acompanhamento rigoroso, devido à natureza e extensão das violações das liberdades religiosas, com participação ou toleradas pelo governo
De acordo com uma pesquisa do Pew Center, em 2010 84% dos egípcios entrevistados apoiavam a pena de morte para aqueles que deixassem de seguir o islamismo; 77% apoiavam penalidades como aplicar chicotadas e cortar as mãos daqueles que furtarem e roubarem; e 82% apoiavam o apedrejamento de uma pessoa que comete adultério.
Os cristãos coptas enfrentam discriminação em vários níveis do governo, variando da representação desproporcional nos ministérios governamentais até leis que limitam a sua capacidade de construir ou reformar suas igrejas
A intolerância religiosa contra os bahá'ís e seitas muçulmanas não-ortodoxas, como sufis, xiitas e ahmadis, também continua a ser um problema.
Durante os confrontos entre a polícia e partidários do ex-presidente Mohamed Morsi, pelo menos 595 manifestantes civis foram mortos no Cairo em 14 de agosto de 2013, o pior assassinato em massa da história moderna egípcia.
O Egito é um dos países que praticam ativamente a pena de morte
As autoridades egípcias não fornecem dados sobre as condenações à morte e execuções, apesar de repetidos pedidos ao longo dos anos por organizações de direitos humanos
Os escritórios das Nações Unidas para os direitos humanos e várias ONGs expressaram um "alarme profundo" após um tribunal penal egípcio condenar 529 pessoas à morte em uma única audiência de 25 de março de 2014
Os condenados eram apoiadores do ex-presidente Mohamed Morsi
A sentença foi condenada como uma violação de direito internacional
Em maio de 2014, cerca de 16 mil pessoas (número que pode chegar a 40 mil de acordo com estimativas independentes), em sua maioria membros ou apoiadores da Irmandade Muçulmana, foram presos após o golpe, sendo a organização rotulada como terrorista pelo governo egípcio interino.
O Egito divide-se administrativamente em 27 províncias (mohafazat, em árabe); administradas por governadores nomeados pelo presidente:
A economia egípcia depende principalmente da agricultura, das telecomunicações, das exportações de petróleo e gás natural e da indústria do turismo; há também mais de três milhões de egípcios que trabalham no estrangeiro, principalmente na Arábia Saudita, no Golfo Pérsico e na Europa, e que mandam remessas de dinheiro para o país, além das receitas do Canal de Suez
A conclusão da Represa de Assuã em 1970, e o Lago Nasser que surgiu por conta disto, alteraram o lugar de honra do rio Nilo na agricultura e ecologia do país
A população em rápido crescimento, a terra arável limitada e a dependência do Nilo continuam a sobrecarregar os recursos e a economia.
O governo tem investido em comunicações e na infraestrutura física
O Egito recebe ajuda externa dos Estados Unidos desde 1979 (uma média de 2,2 bilhões de dólares anuais) e é o terceiro maior beneficiário de tais fundos de ajuda norte-americano após a Guerra do Iraque.
O país tem um mercado de energia desenvolvido com base em carvão, petróleo, gás natural e energia hidrelétrica
Depósitos de carvão consideráveis localizados no nordeste da península do Sinai são extraídos a uma taxa de cerca de 600.000 toneladas por ano
O petróleo e o gás são produzidos nas regiões do deserto ocidental, no Golfo de Suez e no Delta do Nilo
O Egito tem enormes reservas de gás, estimadas em 2.180 quilômetros cúbicos, que são exportadas para vários países.
As condições econômicas do país começaram a melhorar consideravelmente, depois de um período de estagnação, devido à adoção de políticas econômicas mais liberais por parte do governo, bem como por um aumento das receitas do turismo e um mercado de ações em alta
Em seu relatório anual, o Fundo Monetário Internacional (FMI) chegou a classificar o Egito como um dos melhores países do mundo a empreender reformas econômicas
O investimento estrangeiro direto (IED) no Egito aumentou consideravelmente antes da queda do regime de Hosni Mubarak, superando 6 bilhões de dólares em 2006, devido à liberalização e privatização
Desde a queda de Hosni Mubarak, durante a Revolução Egípcia de 2011, o país sofreu uma queda drástica no investimento e nas receitas geradas pelos turistas estrangeiros, seguido de uma queda de 60% em reservas cambiais, uma queda de 3% no crescimento e uma rápida desvalorização da libra egípcia.
Embora um dos principais obstáculos ainda enfrentados pela economia egípcia pelo limitado bem-estar social médio da população, muitos egípcios criticam seu governo para os preços mais elevados dos produtos básicos, enquanto seu padrão de vida e/ou poder de compra mantém-se relativamente estagnados
A corrupção política é frequentemente citada pela população como o principal impedimento para promover o crescimento econômico
No Índice de Percepção da Corrupção de 2013, o Egito ficou no 114º lugar entre os 177 países avaliados.
Estima-se que 2,7 milhões de egípcios no exterior contribuem ativamente para o desenvolvimento do seu país através de remessas (7,8 bilhões de dólares em 2009), bem como a circulação de capital humano e social e de investimento
As remessas, dinheiro ganho pelos egípcios que vivem no exterior e enviado para casa, atingiu um recorde de 21 bilhões de dólares em 2012, segundo o Banco Mundial.
A sociedade egípcia é moderadamente desigual em termos de distribuição de renda, sendo que estima-se que entre 35-40% da população do país ganhe menos do que o equivalente a 2 dólares por dia, enquanto apenas cerca de 2-3% pode ser considerada rica.
O turismo é um dos setores mais importantes da economia do país
Mais de 12,8 milhões de turistas visitaram o Egito em 2008, proporcionando uma receita de quase 11 bilhões de dólares
A indústria turística emprega cerca de 12% da força de trabalho local
A Necrópole de Gizé é o local mais emblemáticos do país
Ela também é o destino turístico mais popular do Egito desde a antiguidade e era popular no período helenístico, quando a Grande Pirâmide foi listada por Antípatro de Sídon como uma das Sete Maravilhas do Mundo, sendo a única delas que ainda existe.
O Egito tem uma grande variedade de praias situadas no Mediterrâneo e no Mar Vermelho, que se estendem por mais de 3 mil quilômetros
O Mar Vermelho tem águas calmas, recifes de corais coloridos, peixes raros e belas montanhas
As praias do Golfo de Aqaba também oferecem facilidades para a prática de esportes aquáticos
Safaga encabeça a zona do Mar Vermelho com sua bela localização no Golfo de Suez
Por último, mas não menos importante, Sharm el-Sheikh (ou Cidade da Paz), Hurghada, Luxor (conhecido como o maior museu ao ar livre do mundo), Dahab, Ras Sidr, Marsa Alam, Safaga e a costa norte do Mediterrâneo são os principais destinos do turismo de lazer.
O país é considerado um polo do turismo histórico, religioso, médico e de entretenimento
Para entrar no Egito, é necessário ter um passaporte válido e, na maioria dos casos, um visto
Além de cidadãos do Reino Unido e da União Europeia (UE), os cidadãos dos seguintes países podem obter vistos à chegada em qualquer um dos portos egípcios de entrada: Austrália, Canadá, Geórgia, Japão, Nova Zelândia, Noruega, Macedônia, Coreia do Sul, Rússia, Sérvia, Ucrânia e Estados Unidos
Os cidadãos do Reino Unido, UE e Estados Unidos podem viajar para os resorts de Sharm El Sheikh, Dahab, Nuweiba e Taba, para um máximo de 15 dias, sem precisarem requerer um visto antes de viajar.
A cultura egípcia tem seis mil anos de história registrada
O Antigo Egito esteve entre as primeiras civilizações complexas a surgirem no planeta e por milênios manteve uma cultura impressionante intrincada e estável que influenciou as culturas posteriores da Europa, Oriente Médio e outros países africanos
Depois da era faraônica, o próprio Egito ficou sob a influência do helenismo, do cristianismo e da cultura islâmica
Atualmente, muitos aspectos da cultura antiga do Egito existem na interação com os elementos mais recentes, incluindo a influência da cultura ocidental moderna, em si, com as raízes do Egito antigo.
A capital do país, a cidade do Cairo, é a maior cidade da África e é conhecida há séculos como um centro de cultura, aprendizado e comércio
O Egito tem o maior número de prêmios Nobel na África e no mundo árabe
Alguns políticos egípcios nascidos estiveram ou estão no comando de grandes organizações internacionais como Boutros Boutros-Ghali das Nações Unidas e Mohamed ElBaradei da AIEA.
O Egito é reconhecido por ser um criador de tendências culturais no mundo da língua e da cultura árabe contemporânea, influenciados fortemente pela literatura, música, cinema e televisão egípcia
O país ganhou um papel de liderança regional durante os anos de 1950 e 1960, o que deu um novo impulso duradouro para o estatuto da cultura egípcia no mundo árabe.
Na literatura médica, sintoma é qualquer alteração da percepção normal que uma pessoa tem de seu próprio corpo, do seu metabolismo, de suas sensações, podendo ou não consistir-se em um início de doença
Em psicopatologia, sintoma é todo relato do paciente acerca de sensações ou sofrimento de cunho subjetivo apresentado durante a entrevista médica
Por ser subjetivo, relaciona-se com tudo que não pode ser mensurado ou objetivamente observado, mas, naturalmente, não pode ser desprezado, pois trata-se de uma queixa válida do paciente.
Sintomas são frequentemente confundidos com sinais, que são as alterações percebidas ou medidas por outra pessoa, geralmente um profissional de saúde
A diferença entre sintoma e sinal é que o sinal é aquilo que pode ser percebido por outra pessoa sem o relato ou comunicação do paciente e o sintoma é a queixa relatada pelo paciente mas que só ele consegue perceber.
Sintomas são subjetivos, sujeitos à interpretação do próprio paciente
A variabilidade descritiva dos sintomas varia enormemente em função da cultura do paciente, assim como da valorização que cada pessoa dá às suas próprias percepções.
Quando de um atendimento de alguém por um profissional de saúde, compete ao profissional saber colher as informações necessárias ao pleno conhecimento das características dos sintomas.


Sintoma também pode ser entendido como sinônimo de índice
Na Semiótica, a ciência geral dos signos, índices e sintomas são signos em que a relação entre significado e significante não é arbitrária, mas sim determinada pela experiência vivenciada pelo interpretador ou pela contiguidade de fato entre dois elementos.
A identificação dos Sintomas faz-se essencialmente, pelo interrogatório do paciente, pois, sem seu relato ou qualquer outra forma de comunicação lúcida, é impossível conhecê-los
Em poucas áreas do conhecimento da saúde, como a Neonatologia, por exemplo, não ocorre a identificação dos sintomas, uma vez que o seu paciente, recém nascido, não se comunica de modo lúcido
A etimologia da palavra (Sintoma) vem do grego
'Sin' = junção e 'Tomo' = pedaços
Ou seja, a palavra sintoma tem a ver com juntar as peças de várias sinalizações orgânicas ou psíquicas, mediante um doença; assim como num quebra-cabeças.
A caracterização dos sintomas baseia-se em sete princípios ou componentes dos sintomas, a saber:
Cronologia, Localização Corporal, Qualidade, Quantidade, Circunstâncias, Fatores Agravantes ou atenuantes e Manifestações Associadas.

Areteu (em grego: Ἀρεταῖος), da Capadócia, é um dos mais notórios médicos da Grécia Antiga; no entanto, apenas alguns detalhes de sua vida são conhecidos
Existe alguma incerteza com relação à sua idade e país de origem, mas parece provável que exerceu a Medicina no século I, durante o reinado de Nero ou Vespasiano
É geralmente denominado "o Capadócio" (Καππάδοξ).


Areteu escreveu em grego jônico um tratado geral sobre doenças, que ainda existe, e é certamente uma das mais valiosas relíquias da antiguidade
O livro apresenta grande precisão nos detalhes dos sintomas, e no caráter do diagnóstico das doenças
Em seus anos de prática médica, empregou a maior parte do método de Hipócrates, mas deu menos atenção ao que tem sido denominado de "as ações naturais" do sistema; e, ao contrário da prática do Pai da Medicina, não hesitou em tentar neutralizá-las, quando elas lhe pareciam ser prejudiciais
Uma doença que ele descreveu mais tarde ficou conhecida como doença celíaca e é comum no mundo de hoje.
A explicação que ele dá para o tratamento de várias doenças indica um sistema simples e sagaz, e mais eficaz do que aqueles professos pelas antigas escolas de medicina da Grécia Antiga e de Roma
Ele frequentemente administrava laxantes; e não se opunha ao uso de entorpecentes; era muito menos avesso à sangria; e toda a sua Materia Medica era ampla e eficiente.
Pode-se afirmar geralmente que há poucos médicos da Antiguidade, desde o tempo de Hipócrates, que parecem ter sido menos influenciados pelo apego a qualquer conjunto peculiar de opiniões, e cujo relato dos fenômenos e tratamento da doença resistiu melhor ao teste da experiência subsequente
Areteu é colocado, por alguns escritores, entre os pneumatici, porque manteve as doutrinas que são peculiares a esta seita; outros escritores sistemáticos, porém, acham que ele é mais bem identificado com os ecléticos.
O trabalho de Areteu consiste de oito livros: dois De causis et signis acutorum morborum (Das causas e sinais das doenças agudas); dois De causis et signis diuturnorum morborum (Das causas e sinais de doenças crônicas), dois De curatione acutorum morborum (Da terapêutica das doenças agudas), e dois De curatione diuturnorum morborum (Da terapêutica das doenças crônicas)
Eles estão em um estado razoavelmente completo de preservação, embora alguns capítulos estejam perdidos.
O trabalho foi publicado pela primeira vez em uma tradução para o latim por Júnio Paulo Crasso (Giunio Paolo Grassi), Veneza, 1552, juntamente com Rufo Efésio
A primeira edição grega é a de Jacobo Goupilo, Paris, 1554, que é mais completa do que a versão latina de Crasso
Em 1723, uma edição principal em fólio foi publicada na editora de Clarendon, em Oxford, editada por John Wigan, contendo um texto melhorado, uma nova versão em latim, dissertações e notas didáticas, e um copioso índice escrito por Michel Maittaire
Em 1731, Herman Boerhaave publicou uma nova edição, na qual o texto e a versão em latim foram impressos anteriormente à edição de Wigan; esta edição contém anotações de Pierre Petit e de Daniel Wilhelm Triller
A edição de C
G
Kühn, Leipzig 1828, incluía o texto de Wigan, a versão em latim, dissertações, etc., juntamente com os comentários de Petit, as emendas de Triller, e o índice de Maittaire
Uma edição de Franz Zacharias Ermerins foi publicada em Utrecht em 1847.
Uma edição padrão mais recente foi publicada por Karl Hude (1860-1936) no Corpus medicorum graecorum (2ª edição, Berlim, Akademie-Verlag, 1958, online)
Os quatro livros De causis et signis já foram publicados em uma edição anotada bilíngue em grego e francês (Arétée de Cappadoce, Des causes et des signes des maladies aiguës et chroniques, tradução de R
T
H
Laennec, ed
e com
Mirko D
Grmek, pref
por Danielle Gourevitch, Genebra, 2000).
As opiniões médicas de Areteu foram discutidas por estudiosos como Johann Albert Fabricius, Albrecht von Haller e Kurt Sprengel
Areteu tem sido tratado, mais recentemente, em um par de curtas monografias:
Para a influência de Areteu sobre Giambattista Morgagni, o pai da anatomia patológica, veja:
 Grécia
 Chipre
 União Europeia
A língua grega (ελληνικά, IPA: [eliniˈka] ou ελληνική γλώσσα, AFI: [eliniˈki ˈɣlosa], lit
"língua helênica") é um ramo independente da família linguística indo-europeia
Natural do sul dos Bálcãs, oeste da Ásia Menor e a região em torno do mar Egeu, é o idioma indo-europeu a ter tido sua história documentada, abrangendo 34 gerações de registros escritos
Seu sistema de escrita foi o alfabeto grego durante a maior parte de sua história; outros sistemas, como o Linear B e o silabário cipriota também foram utilizados
O alfabeto grego surgiu a partir da escrita fenícia, e acabou dando origem, por sua vez, aos alfabetos latino, cirílico, copta, e diversos outros sistemas de escrita.
O idioma grego tem um lugar importante na história da Europa, do mundo ocidental e do cristianismo; o cânone da literatura grega antiga inclui obras de importância monumental, que influenciaram de maneira decisiva o cânone da literatura ocidental posterior; entre as obras de destaque estão poemas épicos como a Ilíada e a Odisseia
O grego também foi a língua na qual diversos dos textos fundamentais da filosofia ocidental, como os diálogos platônicos e as obras de Aristóteles, foram escritos; o Novo Testamento da Bíblia cristã foi escrito no grego koiné
Juntamente com os textos latinos e as tradições do mundo romano, o estudo dos textos gregos e das sociedades da Antiguidade foram a disciplina da História e Arqueologia Clássica.
O grego foi uma língua franca amplamente falada no mundo ao redor do mar Mediterrâneo, e até mesmo em outras partes, durante a Antiguidade Clássica, e viria a se tornar o idioma oficial do Império Bizantino
Em sua forma atual, o grego é a língua oficial da Grécia, uma das línguas oficiais de Chipre e uma das 23 línguas oficiais da União Europeia
É falado por pelo menos 13 milhões de pessoas atualmente, na Grécia, em Chipre e nas comunidades de expatriados em diversos países ao redor do mundo.
As raízes gregas frequentemente são usadas para formar novas palavras em outros idiomas, especialmente nos ramos da ciência e medicina; o grego e o latim são as fontes predominantes do vocabulário científico internacional
Mais de cinquenta mil palavras do inglês, por exemplo, têm origem no grego.


O grego moderno, língua oficial da Grécia, difere em muitas formas do grego antigo e é falado por cerca de 13,1 milhões de pessoas
Na Grécia, é falado por quase toda a população
Também é, juntamente com o turco, a língua oficial de Chipre, embora o uso oficial do turco tenha sido limitado pela República de Chipre desde a invasão turca de 1974
Devido à adesão da Grécia e de Chipre à União Europeia, o grego é, atualmente, uma de suas 24 línguas oficiais
Além disso, o grego é oficialmente reconhecido como uma língua minoritária em partes da Itália e Albânia, bem como na Armênia e Ucrânia, sem falar na diáspora grega em países europeus e americanos, bem como na Austrália
Essa diáspora é formada não apenas por descendentes de gregos da Grécia, como também de indivíduos nascidos das ondas de emigração que quase extinguiram as antigas comunidades gregas de lugares como Egito, Turquia, Bulgária etc.
A língua grega moderna - isto é, o falar inicialmente restrito a um certo estrato das populações da Grécia meridional, acrescido de componentes eruditos e elementos estrangeiros (principalmente franceses e ingleses) - só se tornou a língua oficial do país em 1976
Até esta data, a língua oficial era a chamada "catarévussa", o grego clássico, uma variante livresca decalcada do grego bizantino
O debate em torno da reforma linguística, que começou ainda em meados do século XIX, teve a cidade de Atenas por epicentro e o poeta Kostís Palamás como figura principal.
Os dialetos mais importantes eram os seguintes:
O alfabeto utilizado para escrever a língua grega teve o seu desenvolvimento por volta do século IX a.C., utilizando-se até aos nossos dias, tanto no grego moderno como também na Matemática, Astronomia, etc.
Anteriormente, o alfabeto grego (Ελληνικό αλφάβητο) foi escrito mediante um silabário, utilizado em Creta e zonas da Grécia continental como Micenas ou Pilos entre os séculos XVI a.C
e XII a.C
e conhecido como linear B
O Grego que reproduz parece uma versão primitiva dos dialectos arcado-cipriota e jónico-ático, dos quais provavelmente é antepassado, e é conhecido habitualmente como grego micênico.
Crê-se que o alfabeto grego deriva duma variante do semítico, introduzido na Grécia por mercadores fenícios
Dado que o alfabeto semítico não necessita de notar as vogais, ao contrário da língua grega e outras da família indo-europeia, como o latim e em consequência o português, os gregos adaptaram alguns símbolos fenícios sem valor fonético em grego para representar as vogais
Este facto pode considerar-se fundamental e tornou possível a transcrição fonética satisfatória das línguas Europeias.
As letras obsoletas desapareceram do alfabeto nos seus primeiros tempos, antes do denominado período clássico
Dado que a aparição das letras minúsculas é bastante posterior, não existem minúsculas medievais das ditas letras.
Originariamente existiram variantes do alfabeto grego, sendo as mais importantes a ocidental (Calcídica) e a oriental (Jónica)
A variante ocidental originou o alfabeto etrusco e daí o alfabeto romano
Atenas adoptou no ano 403 a.C
a variante oriental, dando lugar a que pouco depois desaparecessem as demais formas existentes do alfabeto
Já nesta época o grego escrevia-se da esquerda para a direita, enquanto que a princípio a maneira de o escrever era alternadamente da esquerda para a direita e da direita para a esquerda, de maneira que se começava pelo lado em que se tinha concluído a linha anterior, invertendo todos os caracteres em dito processo.
O factor inovador introduzido com o alfabeto grego são as vogais
As primeiras vogais foram Alfa, Épsilon, Iota, Ómicron e Upsilon
Se se contempla o processo de criação do alfabeto grego como resultado de um processo dinâmico baseado na adopção de vários alfabetos semíticos através do tempo, encontrando inclusive influências do linear-B, poder-se-ia dar uma explicação mais satisfatória da sua origem do que as teorias que postulam uma adaptação única de um alfabeto determinado num momento dado.
Alemão · Búlgaro · Checo · Croata · Dinamarquês · Eslovaco · Esloveno · Espanhol · Estoniano · Finlandês · Francês · Grego · Húngaro · Inglês · Irlandês · Italiano · Letão · Lituano · Maltês · Neerlandês · Polaco · Português · Romeno · Sueco
Cláudio Galeno ou Élio Galeno, em latim Claudius Galenus e grego Κλαύδιος Γαληνός, (Pérgamo, c
129 - provavelmente Sicília, ca
217), mais conhecido como Galeno de Pérgamo foi um proeminente médico e filósofo romano de origem grega, e provavelmente o mais talentoso médico investigativo do período romano
Suas teorias dominaram e influenciaram a ciência médica ocidental por mais de um milênio
Seus relatos de anatomia médica eram baseados em macacos, visto que a dissecação humana não era permitida no seu tempo  , mas foram insuperáveis até a descrição impressa e ilustrações de dissecções humanas por Andreas Vesalius em 1543

Desta forma Galeno é também um precursor da prática da Vivissecção e experimentação com animais.


A maioria de suas obras e seus estudos se perderam
Sabe-se, contudo, que Galeno investigou anatomia, fisiologia, patologia, sintomatologia e terapêutica
Foi o mais destacado médico de seu tempo e o primeiro que conduziu pesquisas fisiológicas.
Galeno fez muitas importantes descobertas, como distinguir as veias das artérias, o sangue venoso do arterial, propor pela primeira vez que o corpo fosse controlado pelo Cérebro, dando a distinção entre nervos sensoriais e motores, descobrindo que os rins processam a urina e demonstrando que a laringe é responsável pela voz.
A descrição feita por Galeno das atividades do coração, artérias e veias durou até que William Harvey estabelecesse que o sangue circula com o coração agindo como uma bomba em 1628
No século XIX, os estudantes de medicina ainda liam Galeno para aprender alguns conceitos
Galeno desenvolveu muitas experiências com ligações nervosas que apoiaram a teoria, ainda aceita hoje, de que o cérebro controla todos os movimentos dos músculos por meio do crânio e do sistema nervoso periférico.
Por volta de 170, Galeno realizou uma experiência que iria mudar o curso da medicina: demonstrou pela primeira vez que as artérias conduzem sangue e não ar, como até então se acreditava
No campo da anatomia, Galeno distinguiu ainda os ossos com e sem cavidade medular
Descreveu a caixa craniana e o sistema muscular
Pesquisou os nervos do crânio e reconheceu os raquidianos, os cervicais, os recorrentes e uma parte do sistema simpático
Galeno também foi o primeiro a demonstrar (baseado em experiências) que o rim é um órgão excretor de urina
Farmacologia também interessava Galeno.
Galeno também foi um conhecido cirurgião e muitos dos seus procedimentos e técnicas ousados demais para seu tempo só seriam usadas novamente alguns séculos depois, como por exemplo sua intervenção cirúrgica para correção da catarata.
Em vista das limitações técnicas (em especial limitações ópticas), Galeno inevitavelmente acabou cometendo erros
Não era possível ver o que se passava no interior dos órgãos
Seus dois maiores erros ocorreram em sua teoria da circulação e na sua idéia de que cada órgão realiza sua função própria devido a uma ação de forças que atuavam sobre os órgãos
Segundo Galeno, o sangue circulava devido ao impulso ou força atrativa cuja origem era a própria parede da artéria
Tal concepção foi estendida para todos os órgãos
O respeito pelas teorias de Galeno era tão grande que levou mais de quinze séculos para que sua teoria das forças fosse contestada (já que os médicos consideravam suas teorias infalíveis).
Foi graças à difusão da medicina árabe e ao médico inglês William Harvey que os erros de Galeno neste assunto foram corrigidos.
Galeno escreveu uma pequena obra chamada "O Melhor Médico é Também um Filósofo", e ele via a si próprio como sendo ambos, o que significava embasar a prática médica no aparente conhecimento teórico ou "filosofia", como era chamado em seu tempo
Galeno estava muito interessado na disputa entre as facções médicas racionalistas e empiristas, e sua utilização da observação direta, dissecação e vivissecção na formação médica e como forma de fundamentar a prática médica pode ser entendida como tendo considerado ambas as perspectivas e construído um fundamento mais complexo e mesclado que evitou problemas com cada posição.
Ele descreve seus primeiros anos de vida em "Sobre as moléstias da mente"
Nascido em setembro de 129 d.C., seu pai Élio Nicon foi um rico patrício, arquiteto e construtor com interesses ecléticos, incluindo filosofia, matemática, lógica, astronomia, agricultura e literatura
Galeno descreve seu pai como um "homem muito afável, justo, bom e benevolente"
Naquela época Pérgamo era um grande centro cultural e intelectual, notável por sua biblioteca (expandida por Eumenes II), só inferior à de Alexandria  e atraía tanto filósofos estoicos como platônicos, a quem Galeno foi apresentado aos 14 anos
Seus estudos também abrangeram cada um dos principais sistemas filosóficos da época, incluindo o aristotélico e o epicurista
Seu pai tinha planejado uma carreira tradicional para Galeno na filosofia ou na política e teve o cuidado de expô-lo a influências literárias e filosóficas
No entanto Galeno afirma que por volta de 145 seu pai teve um sonho em que deus Esculápio apareceu e ordenou a Nicon que seu filho estudasse medicina
Novamente, nenhuma despesa foi poupada e após sua inicial educação liberal, aos 16 começou a estudar no prestigiado santuário local ou Asclepeion, dedicado a Esculápio, o deus da medicina, como um θεραπευτής (auxiliar para tratamento ou atendente) por quatro anos
Lá, sofreu influências de homens como Aeschrion de Pérgamo, Stratonicus e Sátiro
Esses santuários funcionavam como spas ou sanatórios onde o doente vinha procurar ajuda do sacerdócio
O templo de Pérgamo era procurado avidamente pelos romanos em busca de uma cura
Foi também o refúgio de pessoas notáveis como Cláudio Charax, o historiador, Aélio Aristeides, o orador, Polemo, o sofista, e Cáspio Rufino, o cônsul.
Galeno iniciou seus estudos em filosofia e medicina por volta de 146 d.C
em Pérgamo, sua cidade natal
Após dois anos, achou que nada mais tinha a aprender e partiu para outros centros como Esmirna, Corinto e Alexandria a fim de se aperfeiçoar
Voltou para Pérgamo em 157, julgando terminada sua instrução
Passou, então, a ocupar o cargo de médico da escola de gladiadores, especializando-se em cirurgia e dietética.
Sendo Roma o centro do mundo àquela época, Galeno partiu para aquela cidade em 162
Galeno, que já havia ganho fama ao curar um milionário de nome Eudemo, torna-se ainda mais famoso
Tão famoso que se tornou médico particular do imperador romano Marco Aurélio
Suas conferências sobre medicina e higiene eram tão concorridas que Galeno as apresentava em um teatro
As aulas práticas que conduzia contemplavam vivissecção e necropsia
Permaneceu em Roma até 192, se afastando da cidade apenas por um curto período em que esteve no Oriente Médio
Ao fim da vida, retornou para Pérgamo.
Entre suas obras destacam-se:


O século XI começou em 1 de Janeiro de 1001 e terminou em 31 de Dezembro de 1100.


Durante o século XI a Europa se encontrava num regime feudalista com o início da Baixa Idade Média
Foi nesse século que pequenas cidades começaram a surgir e se popularizar, criando uma população urbana que mais tarde se tornaria a burguesia.
Houve também um aperfeiçoamento de técnicas agrícolas, como a introdução do arado de ferro e do rodízio de três campos, aumentando assim a quantidade de produção de alimento que em cosequência rendeu num aumento populacional
Com o renascimento urbano práticas comerciais como o artesanato foram impulsionadas.
Aos poucos a Europa começa a se modificar e os textos dessa também
Durante esse século a cultura medieval atinge seu apogeu
Obras escritas com ramo em teologia e filosofia começam a ser publicadas, há uma redescoberta de Aristóteles.
Abū ʿAlī al-Ḥusayn ibn ʿAbd Allāh ibn Sīnā (persa پورسينا Pur-e Sina - "filho de Sina"; Afshana, perto de Bucara, ca
980 — Hamadan, Irã, 1037), conhecido como Ibn Sīnā ou por seu nome latinizado Avicena, foi um polímata persa que escreveu tratados sobre variado conjunto de assuntos, dos quais aproximadamente 240 chegaram aos nossos dias
Em particular, 150 destes tratados se concentram em filosofia e 40 em medicina.
As suas obras mais famosas são o “Livro da Cura”, uma vasta enciclopédia filosófica e científica, e o “Cânone da Medicina”, que era o texto padrão em muitas universidades medievais, entre elas a Universidade de Montpellier e a Universidade Católica de Leuven, ainda em 1650
Ela apresenta um sistema completo de medicina em acordo com os princípios de Galeno e Hipócrates.
Suas demais obras incluem ainda escritos sobre filosofia, astronomia, alquimia, geografia, psicologia, teologia islâmica, lógica, matemática, física, além de poesia
Ele é considerado como o mais famoso e influente polímata da Era de Ouro Islâmica.


Avicena criou um extenso corpus literário durante a época geralmente conhecida como "Era de Ouro do Islão", na qual traduções de textos greco-romanos, persas e indianos foram extensivamente estudados
Textos greco-romanos (médio, neoplatônicos e aristotélicos da escola de Alcindi foram comentados, foram novamente editados e foram substancialmente desenvolvidos pelos intelectuais islâmicos, que também evoluíram a partir de sistemas matemáticos, astronômicos, de álgebra, trigonometria e medicina hindus e persas
A dinastia Samânida, na parte oriental da Pérsia, chamada de Coração e na Ásia Central e também a dinastia Búyida na parte ociental da Pérsia e do Iraque estimularam uma atmosfera propícia para o desenvolvimento cultural e acadêmico
Sob os Samânidas
Bucara rivalizava com Bagdá como a capital cultural do mundo islâmico.
O estudo do Corão e do Hadith floresceu neste ambiente
A filosofia (Fiqh) e a teologia (calam) também se desenvolveram, principalmente pelas mãos de Avicena e seus adversários
Al-Razi e Al-Farabi providenciaram a metodologia e o conhecimento necessário sobre medicina e filosofia
Avicena teve acesso às grandes bibliotecas de Balkh, Corásmia, Gorgan, Rey, Ispaã e Hamadã
Vários textos (como o 'Ahd with Bahmanyar) mostram que ele debateu pontos filosóficos com os grandes acadêmicos de seu tempo
Aruzi Samarqandi descreve como Avicena, antes de deixar Corásmia, conhecera Abu Rayhan Biruni (um famoso cientista e astrônomo), Abu Nasr Iraqi (um renomado matemático), Abu Sahl Masihi (um respeitado filósofo) e Abu al-Khayr Khammar (um importante médico).
A única fonte de informações para a primeira parte da vida de Avicena é a sua autobiografia, escrita por seu discípulo, Jūzjānī
Na falta de outras, é impossível ter certeza do quanto dela é verdadeiro
Já foi notado que ele usa sua autobiografia para avançar a sua teoria do conhecimento (de que é impossível para um indivíduo adquirir informações e compreender a ciência filosófica aristotélica sem ser um mestre) e já se questionou se a cronologia dos eventos descrita não está ajustada para se conformar de forma mais perfeita ao modelo aristotélico
Em outras palavras, se Avicena descreveu a si estudando na "ordem correta"
Porém, dada a ausência de quaisquer outras evidências, o relato deve ser tomado pelo literalmente.
Avicena teria nascido por volta de 980 d.C
perto de Bucara (atualmente no Uzbequistão, a capital dos Samânidas, uma dinastia persa na Ásia Central e no Grande Coração)
Sua mãe, chamada Setareh, era também de Bucara, enquanto que seu pai, Abdullah, seria um respeitado acadêmico Ismaili de Balkh, uma importante cidade do Império Samânida, no que é hoje a Província de Balkh, no Afeganistão
Seu pai foi, na época do nascimento de seu filho, o zelador das propriedades do samânida Nuh ibn Mansur
Ele educou seu filho cuidadosamente em Bucara e diz-se que não havia mais nada que ele não tivesse aprendido já aos dezoito anos.
De acordo com a sua autobiografia, Avicena já tinha memorizado todo o Corão aos dez anos
Ele aprendeu aritmética indiana de um verdureiro indiano e começou a aprender mais de um sábio errante que ganhava a vida curando os doentes e ensinando os jovens
Ele também estudou a Fiqh sob o acadêmico hanafi Ismail al-Zahid.
Ibn Sīnā escreveu extensivamente sobre a filosofia islâmica primitiva, especialmente nos temas de lógica, ética e metafísica
A maior parte de suas obras foram escritos em árabe, que era a linguagem científica ‘’de facto’’ na época no Oriente Médio, e algumas em persa.
Na Idade de ouro islâmica, por causa do sucesso de Avicena em reconciliar o neoplatonismo e o aristotelianismo juntamente com o calam, o “avicenismo” eventualmente se tornou a principal escola de filosofia islâmica já no século XII, com Avicena assumindo um papel de autoridade maior no assunto.
O “avicenismo” também teve influência na Europa medieval, particularmente as suas doutrinas sobre a alma e a distinção entre existência-essência, principalmente por causa dos debates e tentativas de censura que elas provocaram na Europa escolástica
Essa situação foi particularmente visível em Paris, onde o “avicenismo” foi proscrito em 1210
Mesmo assim, a sua psicologia e a sua teoria do conhecimento influenciaram William de Auvergne e Alberto Magno, enquanto que a sua metafísica teve impacto no pensamento de Tomás de Aquino.
A sua principal obra médica é o enciclopédico al-Qanun (ou "O Cânone da Medicina"), mais importante no seu tempo que a obra de Rasis ou de Galeno.
O Cânone foi iniciado em Gorgan, depois em Ray e completado em Hamadã e é o maior trabalho desenvolvido por Avicena, com cerca de um milhão de palavras
Essa obra foi muito bem-recebida pela comunidade científica e compreendia 5 livros (I- Generalidades, II- Matéria médica, III- Doenças da cabeça aos pés, IV- Doenças não específicas de órgãos, V- Drogas compostas)
A parte farmacêutica encontra-se nos livros II e V, que invocam, respectivamente, medicamentos simples e medicamentos compostos
O livro II divide-se em duas partes, a primeira acerca das propriedades das drogas (qualidades, virtudes e modos de conservação) e a segunda consiste numa lista de fármacos e as suas virtudes terapêuticas, ordenados alfabeticamente
Ambos os livros contêm uma lista extensa de medicamentos simples, tratados sobre venenos, uma seção acerca da preparação e manipulação de medicamentos e ainda uma longa lista de receitas e fórmulas medicinais
Muito dessa informação é proveniente em Dioscórides e Galeno, mas Avicena introduziu e argumentou grandes novidades, com drogas utilizadas por árabes, persas, indianos e gregos.
Seu Cânone foi traduzido posteriormente, no século XIII, para o latim por Gerardo de Cremona e posteriormente impresso e reimpresso por toda a Europa
Depois de Avicena e até o século XVIII, todo o trabalho farmacêutico na matéria médica foi influenciado pelo seu trabalho
Foi o livro de estudo adotado nas universidades de Montpellier e Louvain até 1650
Ficou conhecido como o príncipe dos médicos, por seu Cânone.
A vasta informação fornecida pelo o Al-Qanun, apelou a numerosos comentários e notas (até o século XIX)
Além do Al-Qanun, Ibn Sina escreveu cerca de 40 trabalhos médicos, a maioria preservados na forma de manuscritos.

Takwin • Pedra filosofal • Al-iksīr • Alambique • Atanor
Abu Ubaid Juzjani • Alhazen • Ali ibn Ridwan • Avicena • Ephraim ibn al-Za'faran • Ibn al-Wafid • Abdollah ibn Bukhtishu
Psicologia • Oftalmologia
O Canon da Medicina • Mapas de Anatomia dos árabes • O Livro da Cura • Livro dos Dez Tesouros do Olho • De Gradibus • Al-Tasrif • Zakhireye Khwarazmshahi • Adab al-Tabib ("Ética Prática do Médico")
Bimaristan • Nur al-Din Bimaristan • Al-'Adudi
Medicina antiga grega
Nadia Anjuman  · Wasef Bakhtari  · Raziq Faani  · Khalilullah Khalili  · Youssof Kohzad  · Massoud Nawabi  · Abdul Ali Mustaghni
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


Thomas Willis (Great Bedwyn, Wiltshire, 27 de Janeiro de 1621 — Londres, 11 de Novembro de 1675) foi um médico inglês que desempenhou um papel importante na história das ciências médicas e foi co-fundador da Royal Society (1662).
A sua carreira médica teve início em Westminster (Londres), e depois, de 1660 até à sua morte, na Universidade de Oxford, onde foi titular da cátedra de Filosofia natural
Foi um dos pioneiros da pesquisa neuroanatómica.


1679 (MDCLXXIX, na numeração romana) foi um ano comum do século XVII do actual Calendário Gregoriano, da Era de Cristo, e a sua letra dominical foi A (52 semanas), teve início a um domingo e terminou também a um domingo.
Ano comum com início ao domingo

Urina é um subproduto líquido do corpo, tipicamente estéril (na ausência de doenças), secretada pelos rins, depositada na bexiga e excretado pela uretra
O metabolismo celular gera vários subprodutos, muitos ricos em nitrogênio, que precisam ser eliminados da corrente sanguínea
Estes subprodutos são eventualmente expelidos do corpo em um processo conhecido como micção, o método primário para excretar do corpo substâncias químicas solúveis em água
Estas substâncias químicas podem ser analisadas por uranálise
É uma forma de limpar o organismo liberando gorduras,sais e outros.
Nos mamíferos, a urina é um fluido excretório resultante da filtragem do sangue nos rins
Nas aves e nos répteis é uma excreção sólida ou semi-sólida.
A urina é constituída pela filtração do plasma com posterior reabsorção dos nutrientes ainda presentes no mesmo, pelo túbulo proximal
A filtração é feita nos néfrons, que obtém uma parede, um tubo, que é chamado de túbulo, o qual é rodeado de vasos sanguíneos, que sugam os nutrientes que o organismo precisa, para depois ir para os ureteres, para a bexiga para ser armazenada, e passada para a uretra para finalmente ser expelida.


A urina humana, tal como a urina de outros animais, é composta por cerca de 3000 componentes, mas principalmente de água (95%, em média), e contém também cerca de 3% de ureia e de ácido úrico, sal e outras substâncias, sendo expelida durante o ato de urinar
O volume, a acidez e a concentração de sais na urina são regulados por hormonas, entre as quais figuram a hormona antidiurética e a aldosterona
Estas hormonas atuam nos rins para garantir que a água, os sais e o equilíbrio ácido-base (acidez ou alcalinidade do sangue e do fluido intersticial) do organismo se mantêm dentro de estreitos limites
Cerca de metade dos sólidos na urina humana são ureia, o principal produto da degradação do metabolismo das proteínas, e o resto inclui nitrogénio, cloretos, cetosteroides, fósforo, amónio, creatinina e ácido úrico
A presença na urina de açúcar, albumina, pigmentos biliares ou quantidades anormais de algumas substâncias, incluindo as constituintes habituais, é indicador de doenças
A urina é normalmente estéril quando é expelida e tem só um vago cheiro
O cheiro desagradável da urina deteriorada é devido à ação de bactérias que provocam a libertação de amoníaco.
Coordenadas: 21° 07' N 78° 18' E
Republic of India (inglês) República da Índia
Índia (em hindi: भारत, Bhārat, pronunciado: [ˈbʱaːrət̪]; em inglês: India, pronunciado: [ˈɪndiə]), oficialmente denominada República da Índia (em hindi: भारत गणराज्य, Bhārat Gaṇarājya; em inglês: Republic of India), é um país da Ásia Meridional
É o segundo país mais populoso, o sétimo maior em área geográfica e a democracia mais populosa do mundo
Delimitada ao sul pelo Oceano Índico, pelo mar da Arábia a oeste e pelo golfo de Bengala a leste, a Índia tem uma costa com 7 517 km de extensão
O país faz fronteira com Paquistão a oeste; China, Nepal e Butão ao norte e Bangladesh e Mianmar a leste
Os países insulares do Oceano Índico — Sri Lanka e Maldivas — estão localizados bem próximo da Índia.
Lar da Civilização do Vale do Indo, de rotas comerciais históricas e de vastos impérios, o subcontinente indiano é identificado por sua riqueza comercial e cultural de grande parte da sua longa história
Quatro grandes religiões — hinduísmo, budismo, jainismo e siquismo — originaram-se no país, enquanto o zoroastrismo, o judaísmo, o cristianismo e o islamismo chegaram no primeiro milênio d.C
e moldaram a diversidade cultural da região
Anexada gradualmente pela Companhia Britânica das Índias Orientais no início do século XVIII e colonizada pelo Império Britânico a partir de meados do século XIX, a Índia tornou-se uma nação independente em 1947, após uma luta social pela independência que foi marcada pela extensão da resistência não violenta.
A Índia é uma república composta por 28 estados e sete territórios da união, com um sistema de democracia parlamentar
O país é a sétima maior economia do mundo em Produto Interno Bruto (PIB) nominal, bem como a terceira maior do mundo em PIB medido em Paridade de Poder de Compra
As reformas econômicas feitas desde 1991 transformaram o país em uma das economias de mais rápido crescimento do mundo; no entanto, a Índia ainda sofre com altos níveis de pobreza, analfabetismo, violência de género, doenças e desnutrição
Uma sociedade pluralista, multilíngue e multiétnica, a Índia também é o lar de uma grande diversidade de animais selvagens e de habitats protegidos.


O nome Índia é derivado de Indus, que por sua vez é derivado da palavra Hindu, em persa antigo
Do sânscrito Sindhu, a denominação local histórica para o rio Indus
Os gregos clássicos referiam-se aos indianos como Indoi (Ινδοί), povos do Indus A Constituição da Índia e o uso comum em várias línguas indianas igualmente reconhecem Bharat como um nome oficial de igual status
Hindustão (ou Indostão), que é a palavra persa para a “terra do Hindus” e historicamente referida ao norte da Índia, é também usada ocasionalmente como um sinônimo para toda a Índia.
Os primeiros restos de humanos anatomicamente modernos encontrados na Ásia Meridional datam de aproximadamente 30 mil anos atrás
Sítios arqueológicos com arte rupestre do período Mesolítico foram encontrados em muitas partes do subcontinente indiano, como nos abrigos na Rocha de Bhimbetka, em Madia Pradexe
Por volta de 7 000 a.C., os primeiros assentamentos neolíticos conhecidos apareceram no subcontinente em locais como Mergar e outros no Paquistão ocidental
Estes locais gradualmente desenvolveram a Civilização do Vale do Indo, a primeira cultura urbana da Ásia Meridional; essa civilização floresceu entre 2 500 e 1 900 a.C
no Paquistão e na região oeste da Índia
Centrada em torno de cidades como Moenjodaro, Harapa, Dolavira e Kalibangan, e contando com variadas formas de subsistência, a cultura desenvolveu uma produção robusta de artesanatos e um amplo comércio.
Durante o período de 2000-500 a.C, culturas de muitas regiões do subcontinente fizeram a transição do Calcolítico para a Idade do Ferro
Os Vedas, as escrituras mais antigas do hinduísmo, foram compostas durante esse período e os historiadores têm conectado os textos à cultura védica, localizada na região do Panjabe e na planície Indo-Gangética
A maioria dos historiadores também considera que este período abrangeu várias ondas migratórias indo-arianas no subcontinente, de norte a oeste
O sistema de castas, que criou uma hierarquia de sacerdotes, guerreiros e camponeses livres, mas excluiu os povos indígenas ao rotular suas ocupações como "impuras", surgiu durante este período
Sobre o planalto do Decão, evidências arqueológicas deste período sugerem a existência de um estágio patriarcal de organização política
No sul da Índia, uma progressão para a vida sedentária é indicada pelo grande número de monumentos megalíticos que datam deste período, bem como por vestígios de agricultura, tanques de irrigação e de tradições de artesanato.
No período védico, por volta do século V a.C., as pequenas tribos do planalto do Ganges e de regiões do noroeste haviam se consolidado em 16 grandes oligarquias e monarquias que eram conhecidas como os mahajanapadas
A urbanização crescente e as ortodoxias desta época também criaram os movimentos de reforma religiosa do budismo e do jainismo, sendo que ambos se tornaram religiões independentes
O budismo, com base nos ensinamentos de Gautama Buda, atraiu seguidores de todas as classes sociais, com exceção da classe média; as narrações da vida de Buda foram fundamentais para o início do registro da história indiana
O jainismo entrou em destaque na mesma época durante a vida de seu "Grande Herói", Mahavira
Em uma época de crescente riqueza urbana, ambas as religiões levantaram a renúncia aos bens materiais como um ideal e estabeleceram mosteiros de longa duração
Politicamente, por volta do século III a.C., o Reino de Mágada tinha anexado ou reduzido outros Estados para emergir como o Império Máuria
Já se acreditou que esse império controlou a maior parte do subcontinente com exceção do extremo sul, mas agora acredita-se que as suas regiões centrais eram separadas por grandes áreas autônomas
Os reis máurias são conhecidos tanto pela construção do seu império e determinação na gestão da vida pública, quanto pela renúncia de Asoca, o Grande (r
273–232 a.C.) do militarismo e de sua promoção do darma budista.
A literatura sangam, escrita em tâmil, revela que entre 200 a.C
e 200 d.C
o sul da península estava sendo governado pelas dinastias Cheras, Cholas e Pandias, que comercializavam extensivamente com o Império Romano e com o Sudoeste e o Sudeste da Ásia
Nesse período o território do país também se tornou parte da Rota da Seda, uma rede de rotas comerciais que ligava o Extremo Oriente à Europa
Por essas estradas os comerciantes indianos vendiam tecidos e especiarias para mercados da Ásia Central, enquanto monges e peregrinos budistas vinham da China, até o período das Grandes Navegações, quando ligações comerciais marítimas foram criadas entre o Ocidente e o Oriente
No norte da Índia, o hinduísmo afirmou controle patriarcal familiar, o que levou ao aumento da subordinação das mulheres
Até os séculos IV e V, o Império Gupta havia criado um complexo sistema fiscal e de administração nos grandes planaltos do Ganges, que se tornou um modelo para reinos indianos posteriores
Sob os governos dos Guptas, um hinduísmo renovado baseado na devoção ao invés da gestão ritualística começou a se estabelecer
A renovação se refletiu em um florescimento da escultura e da arquitetura, que encontrou patronos entre uma elite urbana
A literatura sânscrita clássica floresceu e ciência, astronomia, medicina e matemática indianas tiveram avanços significativos.
A idade medieval indiana, de 600 a 1200 d.C., é definida por reinos regionais e pela diversidade cultural
Quando o imperador Harxa (r
606–647) de Canauje, que governou grande parte da Planície do Ganges de 606 a 647 d.C., tentou expandir seu território para o sul, ele foi derrotado pelo governante Chaluca do Decão
Seu sucessor, na tentativa de expandir para o leste, foi derrotado pelo rei Pala de Bengala
Quando os Chalucas tentaram se expandir para o sul, eles foram derrotados pelos Palavas, que por sua vez se opunham aos Pandias e aos Cholas, de ainda mais ao sul
Nenhum governante desse período foi capaz de criar um império unificado e os territórios sob seu controle geralmente não passavam muito além de sua região central
Durante este tempo, povos de pastoreio cujas terras tinham sido liberadas para abrir caminho para a crescente economia agrícola foram acomodados dentro do sistema de castas, assim como as novas classes dominantes não tradicionais
O sistema de castas, consequentemente, começou a mostrar as diferenças regionais.
Nos séculos VI e VII, os primeiros hinos devocionais foram criados na língua tâmil
Eles foram imitados por toda a Índia e levaram ao ressurgimento do hinduísmo e ao desenvolvimento de todas as línguas modernas do subcontinente
A realeza indiana, grande e pequena, e os templos por ela frequentados, atraíram cidadãos em grande número para as principais cidades, que tornaram-se também importantes centros econômicos
Templos em cidades de vários tamanhos começaram a aparecer em todos os lugares ao mesmo tempo que a Índia passava por outra era de urbanização
Pelos séculos VIII e IX, os efeitos disso foram sentidos no Sudeste da Ásia, conforme os sistemas culturais e políticos do sul da Índia eram exportados para terras que se tornaram parte dos atuais Myanmar, Tailândia, Laos, Camboja, Vietnã, Malásia e Java (Indonésia)
Comerciantes, estudiosos e às vezes exércitos indianos envolveram-se nesta transmissão cultural; os asiáticos do sudeste do continente também tomaram a iniciativa e organizaram muitas peregrinações para os seminários indianos, além de terem traduzido os textos budistas e hindus para os seus respectivos idiomas.
Após o século X, clãs nômades muçulmanos do centro da Ásia usaram cavalaria de guerra e organizaram vastos exércitos unidos pela etnia e religião para invadir repetidamente as planícies do noroeste da Ásia Austral, levando à criação do islâmico Sultanato de Déli em 1206
O sultanato controlou grande parte do norte da Índia e fez muitas incursões ao sul do subcontinente
Embora tenha sido perturbador para as elites indianas, o sultanato deixou a vasta população não muçulmana sujeita às suas próprias leis e costumes
Ao repelir repetidamente os invasores mongóis no século XIII, o sultanato salvou a Índia da devastação experimentada pela Ásia Central e Ocidental, criando o cenário para séculos de migração de soldados, homens instruídos, místicos, comerciantes, artistas e artesãos que vinham em fuga daquelas regiões para o subcontinente indiano, criando assim uma cultura indo-islâmica sincrética no norte do país
A invasão do sultanato e o enfraquecimento dos reinos da região do sul da Índia abriram o caminho ao Reino de Bisnaga
Abraçando uma forte tradição xivaísta e construído sobre a tecnologia militar do sultanato, o império passou a controlar a maior parte da Índia peninsular e foi influente na sociedade do sul do país por muito tempo.
No início do século XVI, o norte da Índia, na época sob domínio principalmente muçulmano, caiu novamente para a superioridade da mobilidade e do poder de fogo de uma nova geração de guerreiros da Ásia Central
O subsequente Império Mogol não erradicou as sociedades locais que passou a governar, mas as equilibrou e pacificou através de novas práticas administrativas e de elites dominantes diversas e inclusivas, levando a uma lei mais sistemática, centralizada e uniforme por todo o império
Evitando sua identidade tribal e islâmica, especialmente durante o governo de Acbar, o Grande (r
1556–1605), os mogóis uniram seus reinos distantes através da lealdade, expressa através de uma cultura influenciada pela Pérsia e de um imperador que tinha importância quase divina
As políticas econômicas do Estado Mogol tiravam a maior parte das receitas do império do setor agrícola e determinavam que os impostos deviam ser pagos em moedas de prata oficiais, o que causou a entrada de camponeses e artesãos em mercados maiores
A relativa paz mantida pelo império durante grande parte do século XVII foi um dos fatores que ajudaram na expansão econômica da Índia nesse período, o que resultou em investimentos maiores em pintura, além de obras literárias, têxteis e de arquitetura
Novos grupos sociais homogêneos no norte e no oeste da Índia, como os maratas, os rajaputes e os siques, ganharam ambições militares e de governo durante o domínio mogol, que, através da colaboração ou da adversidade, deu-lhes reconhecimento e experiência militar
A expansão do comércio durante o governo mogol deu origem à novas elites comerciais e políticas ao longo das costas do sul e do leste do país
À medida que o império se desintegrou, muitas dessas elites foram capazes de manter seus negócios sob controle.
Em 1498 o navegador português Vasco da Gama chega a Calecute, na costa ocidental do subcontinente indiano, o marco inicial de uma relação luso-indiana que duraria cerca de 500 anos
Em 1510, o explorador português Afonso de Albuquerque amplia os territórios portugueses com a conquista de Goa, que rapidamente se tornaria a capital do Estado Português da Índia (uma entidade política parte do Império Português)
A Índia Portuguesa, como a colônia lusitana também era conhecida, inicialmente abrangia todos os territórios conquistados pelos portugueses no Oceano Índico, mas depois ficou restrita à Costa do Malabar, em territórios como Goa, Damão, Diu, Ilha de Angediva, Dadrá e Nagar-Aveli, Simbor e Gogolá
No início do século XVIII, com a linha entre a dominação comercial e política cada vez mais tênue, uma série de empresas comerciais europeias, como a Companhia Britânica das Índias Orientais, haviam estabelecido postos nas regiões costeiras do país
O controle dos mares, maiores recursos, treinamento militar e tecnologia mais avançados levaram a Companhia Britânica das Índias Orientais a flexionar cada vez mais a sua força militar e tornar isso atraente para uma parcela da elite indiana; esses dois fatores foram cruciais para permitir que a Companhia Britânica ganhasse o controle sobre a região de Bengala em 1765 e marginalizasse as outras empresas europeias concorrentes O acesso maior às riquezas da Bengala e o subsequente aumento da força e do tamanho de seu exército permitiram à Companhia das Índias Orientais anexar ou subjugar a maior parte do subcontinente indiano durante os anos 1820
A Índia então parou de exportar bens manufaturados e, em vez disso, passou a abastecer o Império Britânico com matérias-primas
Esse momento é considerado por muitos historiadores o início do período colonial no país
Por esta altura, com seu poder econômico severamente restringido pelo parlamento britânico, a Companhia começou a entrar mais conscientemente em áreas não econômicas, como educação, reforma social e cultura.
Os historiadores consideram que a era contemporânea da Índia começou em algum momento entre 1848 e 1885
A nomeação, em 1848, de James Broun-Ramsay, Lord Dalhousie, como governador-geral do Companhia das Índias Orientais preparou o palco para alterações essenciais na transição do país para um Estado moderno
Estas mudanças incluíram a consolidação e a demarcação da soberania, a vigilância da população e a educação dos cidadãos
Mudanças tecnológicas — como as ferrovias, os canais e o telégrafo — foram introduzidas no país não muito tempo depois de sua introdução na Europa
No entanto, a insatisfação com a Companhia também cresceu durante este período e definiu a Revolta dos Sipais, em 1857
Alimentada por diversos ressentimentos e percepções entre a população, como as invasivas reformas sociais ao estilo britânico, altos impostos sobre propriedades e o tratamento sumário de alguns príncipes e fazendeiros ricos, a revolta abalou muitas regiões do norte e do centro da Índia e sacudiu os alicerces do governo da Companhia
Embora a rebelião tenha sido reprimida em 1858, ela levou à dissolução da Companhia das Índias Orientais e a administração da Índia passou a ser exercida diretamente pelo governo britânico
Além de proclamarem um Estado unitário e um sistema parlamentarista limitado, inspirado pelo parlamento britânico, os novos governantes também protegeram príncipes e aristocratas como uma salvaguarda contra uma possível agitação feudal futura
Nas décadas seguintes, a vida pública emergiu gradualmente em toda a Índia, levando à fundação do partido Congresso Nacional Indiano, em 1885.
A corrida tecnológica e a comercialização da agricultura na segunda metade do século XIX foi marcada por muitos contratempos econômicos — muitos pequenos produtores tornaram-se dependentes dos caprichos de mercados distantes
Houve um aumento no número de grandes crises de fome e, apesar dos riscos do desenvolvimento de uma infraestrutura suportada pelos contribuintes indianos, pouco emprego industrial foi gerado para a população
Houve também efeitos salutares: cultivos comerciais, especialmente na região recém-canalizada do Punjabe, levaram a um aumento da produção de comida para o consumo interno
A rede ferroviária, desde o alívio da crise de fome, ajudou a reduzir o custo dos bens móveis e auxiliou a nascente indústria indiana.
Após a Primeira Guerra Mundial, onde alguns milhares de indianos serviram, um novo período começou
Ele foi marcado por reformas britânicas, mas também por uma legislação mais repressiva; pelas reivindicações cada vez mais estridentes da população indiana por independência e pelo começo de um movimento não violento de não cooperação, do qual Mohandas Karamchand Gandhi se tornaria o líder e símbolo de resistência
Durante os anos 1930, uma lenta reforma legislativa foi promulgada pelos britânicos e o Congresso Nacional Indiano saiu vitorioso nas eleições seguintes
A década posterior foi cheia de crises: a participação indiana na Segunda Guerra Mundial, o impulso final do Congresso para a não cooperação com os britânicos e uma onda de nacionalismo muçulmano
Todos foram coroados com o advento da independência em 1947, mas ao custo de uma sangrenta divisão do subcontinente em dois Estados: Índia e Paquistão.
Vital para a autoimagem da Índia como uma nação independente foi a sua constituição, concluída em 1950, que colocou no lugar da antiga colônia britânica uma república secular e democrática
Nos 60 anos seguintes, a Índia teve um resultado misto de sucessos e fracassos
Manteve-se uma democracia com liberdades civis, uma Suprema Corte ativista e uma imprensa, em grande parte, independente
A liberalização econômica, que teve início na década de 1990, criou uma grande classe média urbana e transformou a Índia em uma das economias de mais rápido crescimento no mundo, o que aumentou a influência geopolítica do país
Filmes, músicas e ensinamentos espirituais indianos desempenham um papel cada vez maior na cultura mundial
No entanto, o país também tem sido oprimido por uma pobreza aparentemente inflexível, tanto no meio rural quanto no urbano; pela violência religiosa e entre castas; por grupos insurgentes de inspiração maoista chamados naxalitas; e pelo separatismo em Jammu e Caxemira e no Nordeste da Índia
O país tem disputas territoriais não resolvidas com a China, que se deterioraram até a guerra sino-indiana de 1962; e com o vizinho Paquistão, em guerras travadas em 1947, 1965, 1971 e 1999
A rivalidade nuclear entre a Índia e o Paquistão veio à tona em 1998
As liberdades democráticas sustentadas da Índia são únicas entre as novas nações do mundo; no entanto, apesar de seus sucessos econômicos recentes, a liberdade de sua população desfavorecida continua a ser um objetivo a ser alcançado.
A Índia ocupa a maior parte do subcontinente indiano, encontrando-se por cima da placa indiana, uma placa tectônica que faz parte da placa indo-australiana
Os processos geológicos que definiram a atual situação geográfica da Índia começaram há 75 milhões de anos, quando o subcontinente indiano, então parte do sul do supercontinente Gondwana, começou a se mover para nordeste através do que posteriormente se converteria no Oceano Índico
A colisão superior do subcontinente com a placa euro-asiática e a subducção debaixo dela deram lugar à cordilheira do Himalaia, o sistema montanhoso mais alto do planeta, que atualmente é a fronteira da Índia a norte e a noroeste
O antigo leito marinho que emergiu imediatamente ao sul do Himalaia fez com que o movimento da placa criasse uma grande depressão, que foi sendo levada pouco a pouco por sedimentos propagados por rios, o que atualmente constitui a planície Indo-Gangética
A oeste desta planície encontra-se o deserto do Thar, separado pela cordilheira Avarali.
A placa original indiana corresponde hoje ao subcontinente indiano, sendo também a parte mais antiga e estável da Índia, que se estende desde o norte, com as cordilheiras Satpura e Vindhya no centro
Estas cordilheiras paralelas vão desde a costa do mar Arábico, no estado de Gujarat, até o planalto de Chota Nagpur, no estado de Jharkhand
No sul, o planalto do Decão contém à esquerda e à direita os Gates Ocidentais e Orientais; o planalto contém as formações rochosas mais antigas do território, algumas com mais de um bilhão de anos de idade
Os pontos extremos do país se localizam a 6° 43' e 39° 26 'de latitude norte e 68°7' e 89°25' de longitude leste.
A Índia tem 7 517 quilômetros de litoral; destes, 5 423 pertencem ao subcontinente indiano e 2 094 pertencem aos arquipélagos de Andamão e Nicobar e Laquedivas
A costa indiana tem 43% de praias arenosas, 11% de costas rochosas (incluindo falésias) e 46% de marismas ou costas pantanosas
Os principais rios têm sua origem na cordilheira Himalaia, como o Ganges e o Brahmaputra, que desembocam no golfo de Bengala
Entre os afluentes mais importantes do Ganges encontram-se os rios Yamuna e o Kosi, cuja pendente extremamente baixa provoca inundações catastróficas quase todos os anos
Os rios peninsulares mais importantes cujas pendentes evitam inundações são o Godavari, o Mahanadi, o Kaveri e o Krishna, que também desembocam no golfo de Bengala; e os rios Narmada e Tapti, que desembocam no mar Arábico
Na costa oeste, encontram-se também os pântanos do Rann de Kutch, enquanto no leste há a área protegida de Sundarbans, que a Índia divide com Bangladesh
A Índia possui dois arquipélagos: Laquedivas, atóis de corais na costa sudoeste indiana, e as ilhas de Andamão e Nicobar, cadeias de ilhas vulcânicas no mar de Andamão.
O clima indiano é fortemente influenciado pelo Himalaia e pelo deserto do Thar, os quais favorecem o desenvolvimento das monções
O Himalaia barra a entrada de ventos catabáticos frios, vindos da Ásia Central, mantendo a maior parte do subcontinente indiano mais quente do que a maioria das localidades que se localizam em latitudes similares.
O deserto do Thar desempenha um papel crucial para atrair ventos de monção carregados de umidade desde o sudoeste, os quais entre junho e outubro proporcionam a maioria das precipitações do país
As zonas climáticas principais que predominam em território indiano são o tropical úmido, tropical semiúmido e o subtropical úmido.
O território indiano se encontra dentro da biorregião himalaia, que apresenta grande biodiversidade
Acolhendo 7,6% de todos os mamíferos, 12,6% de todas as aves, 6,2% de todas os répteis, 4,4% de todos os anfíbios, 11,7% de todos os peixes e 6% de todas as espermatófitas do mundo, a Índia é um dos dezoito países megadiversos
Em muitas regiões indianas existem altos níveis de endemismo; em geral, 33% das espécies indianas são endêmicas.
Os bosques da Índia variam de florestas úmidas nas ilhas de Andamão, Gates Ocidentais e noroeste indiano, até florestas temperadas de coníferas do Himalaia
Entre esses extremos encontram-se os bosques caducifólios da Índia Oriental; o bosque caducifólio no centro-sul e o bosque xerófito do Decão central e a planície ocidental do Ganges
Estima-se que menos de 12% da massa da Índia Continental esteja coberta por densos bosques.
Muitas espécies da Índia são descendentes de táxons originários de Gondwana, do qual a placa tectônica indiana se separou
O movimento posterior da placa do subcontinente indiano e a sua colisão com a massa de terra da Laurásia deu início a um intercâmbio massivo das espécies
Entretanto, o vulcanismo e as mudanças climáticas registradas há vinte milhões de anos provocaram uma extinção em massa de espécies originárias de Gondwana
A partir de então, mamíferos ingressaram ao subcontinente a partir da Ásia por meio de dois passos zoogeográficos em ambos os lados emergentes do Himalaia
Em consequência, apenas 12,6% dos mamíferos e 4,6% das aves são espécies endêmicas, em contraste com 45,8% dos répteis e 55,8% de anfíbios endêmicos
Na Índia existem 172 espécies ameaçadas, ou 2,9%
Entre elas encontram-se o leão-asiático, o tigre-de-bengala e o abutre-indiano-de-dorso-branco (Gyps bengalensis), que está quase ameaçado de extinção devido à ingestão de carne de gado tratada com diclofenaco.
Nas últimas décadas, a invasões humanas generalizadas e ecologicamente devastadoras criaram uma ameaça crítica à vida silvestre da Índia
Em resposta, o sistema de áreas protegidas e parques nacionais, estabelecido pela primeira vez em 1935, foi ampliado consideravelmente
Em 1970, o governo indiano decretou a Lei de Proteção da Vida Silvestre e o "Projeto Tigre", para proteger o habitat crucial destes animais, além de em 1980 ter sido decretada a Lei de Conservação dos Bosques
A Índia tem mais de quinhentos santuários de vida selvagem e treze reservas da biosfera, quatro das quais fazem parte da Rede Mundial de Reservas da Biosfera
Vinte e cinco zonas de umidade estão registradas na Convenção sobre as Zonas Úmidas.
Com uma população de mais de um 1 000 000 000 de habitantes, a Índia é o segundo país mais populoso do mundo
Desde os anos 1960, o país tem vivido um rápido aumento em sua população urbana devido, em grande parte, aos avanços médicos e aos aumentos massivos da produtividade agrícola devidos à "revolução verde"
A população urbana da Índia no fim do século XX era onze vezes superior à do início do século e vem se concentrando cada vez mais nas grandes cidades
Em 2001, 35 cidades indianas tinham população igual ou superior a um milhão de habitantes
Cada uma das três cidades mais populosas (Bombaim, Déli e Calcutá) tinham então mais de dez milhões de habitantes
Porém, nesse mesmo ano, 70% da população indiana vivia em áreas rurais.
A Índia é a segunda entidade geográfica com maior diversidade cultural, linguística e genética do mundo, depois da África
O país é o lar de duas grandes famílias linguísticas: a indo-ária (falada por aproximadamente 74% da população) e a dravídica (falada por aproximadamente 24%)
Outras línguas faladas na Índia provêm das línguas austro-asiáticas e tibeto-birmanesas
O hindi (ou híndi) conta com o maior número de falantes e é a língua oficial da república
O inglês é utilizado amplamente em negócios e na administração e tem o status de "idioma oficial subsidiário", sendo também importante na educação, especialmente no ensino médio e superior.
Cada estado e território da união tem seus próprios idiomas oficiais e a constituição reconhece outras 21 línguas, que são faladas por um importante setor da população ou são parte da herança histórica indiana, e que são denominadas "línguas clássicas"
Enquanto o sânscrito e o tâmil têm sido consideradas como línguas clássicas por muitos anos, o governo indiano também concedeu o estatuto de língua clássica ao canarês e ao telugo
O número de dialetos na Índia chega a mais de 1 652.
Mais de 800 milhões de indianos (80,5 % da população) são hindus
Outros grupos religiosos com presença importante no país são muçulmanos (13,4 %), cristãos (2,3 %), siquistas (1,9 %), budistas (0,8 %), jainistas (0,4 %), judeus, zoroastristas (parsis), entre outros
Os adivasi constituem 8,1 % da população
A Índia tem a terceira maior população muçulmana do mundo e a maior população muçulmana para um país de maioria não muçulmana.
A taxa de alfabetização no país é de 64,8% (53,7% para as mulheres e 75,3% para os homens) O estado com o maior índice de alfabetização é Kerala, com 91%, enquanto Bihar tem a menor taxa, com apenas 47%
A razão sexual é de 944 homens para cada mil mulheres, enquanto que a taxa de crescimento demográfico anual é de 1,38%; a cada ano são registrados 22,01 nascimentos para cada mil pessoas
Segundo a Organização Mundial de Saúde (OMS), a cada ano morrem novecentos mil indianos por beberem água imprópria e por inalarem ar contaminado
A malária é endêmica na Índia
Existem cerca de 60 médicos para cada 100 mil pessoas no país.
A Índia é a democracia mais populosa do mundo
O país é uma república parlamentarista com um sistema multipartidário com seis partidos nacionais credenciados, como o Partido do Congresso Nacional Indiano (em inglês: Indian National Congress - INC ou simplesmente Congresso) e o Partido do Povo Indiano (Bharatiya Janata Party - BJP), além de mais de 40 partidos regionais
O Partido do Congresso é considerado de centro-esquerda ou "liberal" dentro da cultura política indiana, enquanto o BJP é de centro-direita ou "conservador"
Durante a maior parte do período compreendido entre 1950 — quando a Índia se tornou uma república pela primeira vez — e o final dos anos 1980, o Congresso manteve maioria no parlamento indiano
Desde então, no entanto, o partido cada vez mais divide o palco político com o BJP e com poderosos partidos regionais que muitas vezes forçam a criação de coalizões multipartidárias.
Nas três primeiras eleições gerais da República da Índia — em 1951, 1957 e 1962 — o Congresso, liderado por Jawaharlal Nehru, teve uma série de vitórias fáceis
Com a morte de Nehru em 1964, Lal Bahadur Shastri tornou-se rapidamente o primeiro-ministro; ele foi sucedido, após a sua morte inesperada em 1966, por Indira Gandhi, que levou o Partido do Congresso a vitórias eleitorais em 1967 e 1971
Após o descontentamento público causado pela declaração de estado de exceção em 1975 pela primeira-ministra, o Congresso perdeu as eleições em 1977; o então novo Partido Janata, que se opôs ao estado de exceção, ganhou e seu governo durou pouco mais de três anos
Ao voltar ao poder em 1980, o Congresso viu uma mudança em sua liderança em 1984, quando Indira Gandhi foi assassinada e então foi sucedida por seu filho, Rajiv Gandhi, que conquistou uma vitória fácil nas eleições gerais no final daquele mesmo ano
O Congresso foi eleito novamente em 1989, quando a coalizão Frente Nacional, liderada pelo Janata Dal (um partido recém-criado), em aliança com a Frente de Esquerda, venceu as eleições; esse governo também foi relativamente curto: durou pouco menos de dois anos
Novas eleições foram realizadas em 1991, mas nenhum partido obteve a maioria absoluta no parlamento
O Congresso, no entanto, por ser o maior partido único do país, conseguiu formar um governo de minoria liderado por P
V
Narasimha Rao.
Entre 1996 e 1998, ocorreu um forte período de agitação no governo federal com várias alianças de curta duração, tentando estabilizar a Índia
Brevemente, o BJP chegou ao governo em 1996, seguido por uma coalizão de frente unida que excluiu tanto o BJP quanto o INC
Em 1998, o BJP formou com outros partidos menores a Aliança Democrática Nacional, que obteve vitória e se converteu no primeiro governo não congressista por um mandato completo de cinco anos
Nas eleições gerais de 2004, o INC ganhou a maioria das cadeiras no Lok Sabha (câmara baixa do parlamento) e formou um governo de coalização denominada de Aliança Progressista Unida (UPA), apoiada por diversos partidos de esquerda e membros de oposição ao BJP
A UPA chegou novamente ao poder nas eleições gerais de 2009, entretanto, a representação dos partidos de esquerda dentro da coalizão foi reduzida significativamente, Manmohan Singh foi convertido em primeiro-ministro, sendo reeleito após completar um mandato de cinco anos desde as eleições de 1962, onde Jawaharlal Nehru foi eleito no seu cargo.
A constituição indiana, maior do que a de qualquer outra nação do mundo, entrou em vigor em 26 de janeiro de 1950
O seu preâmbulo define a Índia como uma república soberana, secular e democrática
O parlamento indiano é bicameral, regido pelo sistema Westminster
Sua forma de governo foi tradicionalmente descrita como "quase federalista", com uma forte tendência à centralização, tendo os estados relativamente pouco poder
Desde finais da década de 1990, o federalismo tem crescido cada vez mais, como resultado de mudanças políticas, sociais e econômicas.
O presidente da Índia é o chefe de estado e é eleito indiretamente por um colégio eleitoral para um mandato de cinco anos
O primeiro-ministro é o chefe do governo e exerce a maioria das funções do poder executivo
Nomeado pelo presidente, o primeiro-ministro é geralmente próximo do partido ou aliança política que conta com a maioria das cadeiras da câmara baixa do parlamento
O poder executivo consiste no presidente, o vice-presidente, o conselho de ministros (sendo o gabinete seu comitê executivo), encabeçado pelo primeiro-ministro
Qualquer ministro do conselho deve ser membro de qualquer câmara parlamentar
No sistema parlamentarista indiano, o poder executivo está subordinado ao poder legislativo, o primeiro-ministro e seu conselho são diretamente vigiados pela câmara baixa do parlamento.
O poder legislativo da Índia está representado pelo parlamento bicameral, que consiste na câmara alta, chamada Rajya Sabha (conselho dos estados) e a câmara baixa, chamada Lok Sabha (conselho do povo)
A "Rajya Sabha" é um órgão permanente, que conta com duzentos e quarenta e cinco membros que servem por um período de seis anos
A maioria deles é eleita indiretamente pelas legislaturas estatais e territoriais, mediante representação proporcional
Dos 545 membros do Lok Sabha, 543 são eleitos diretamente pelo voto popular para representarem determinados grupos sociais por um período de cinco anos
Os outros dois membros são nomeados pelo presidente entre a comunidade anglo-indiana.
A Índia conta com um poder judiciário de três níveis, que consistem na Suprema Corte de Justiça, encabeçada pelo chefe de justiça, vinte e um tribunais superiores e um grande número de tribunais de primeira instância
A suprema corte é um tribunal de primeira instância para casos relacionados com os direitos humanos fundamentais e um tribunal de apelação acima dos tribunais superiores
É judicialmente independente, tendo o poder de declarar e elaborar leis e revogar leis nacionais ou estaduais que violem a constituição
A função de intérprete último da constituição é uma das funções mais importantes da suprema corte.
Desde a sua independência, em 1947, a Índia mantém relações cordiais com a maioria das nações
Na década de 1950, apoiou fortemente a descolonização da África e da Ásia e desempenhou um papel de liderança no Movimento Não Alinhado
No final da década de 1980, o exército indiano interveio duas vezes no exterior, a convite de países vizinhos: uma operação de manutenção da paz no Sri Lanka entre 1987 e 1990 e uma intervenção armada para impedir uma tentativa de golpe de Estado nas Maldivas
A Índia tem relações muito tensas com o vizinho Paquistão; as duas nações já entraram em guerra quatro vezes: em 1947, 1965, 1971 e 1999
Três dessas guerras foram travadas no território disputado da Caxemira, enquanto a quarta, em 1971, começou depois do apoio da Índia à independência de Bangladesh
Depois de travar a guerra sino-indiana em 1962 e a guerra com o Paquistão em 1965, a Índia estreitou seus laços militares e econômicos com a União Soviética; no final dos anos 1960, os soviéticos eram os maiores fornecedores de armas dos indianos.
Além das atuais relações estratégicas com a Rússia, a Índia tem relações de defesa de grande alcance com Israel e França
Nos últimos anos, tem desempenhado um papel-chave na Associação Sul-Asiática para a Cooperação Regional (SAARC) e na Organização Mundial do Comércio
A nação indiana disponibilizou 100 mil militares e policiais para servir em 35 operações de paz da Organização das Nações Unidas (ONU) em quatro continentes
O país participa da Cúpula do Leste Asiático, do G8+5 e de outros fóruns multilaterais
A Índia tem estreitos laços econômicos com América do Sul, Ásia e África; desde 1991 que prossegue a política "Look East" ("olhar para oriente"), que visa a fortalecer parcerias com os países da Associação de Nações do Sudeste Asiático (ASEAN), Japão e Coreia do Sul, e que gira em torno de muitas questões, mas especialmente aquelas que envolvem investimento econômico e segurança regional.
O teste nuclear de 1964, feito pela China, e as repetidas ameaças do governo chinês de intervir em apoio ao Paquistão na guerra de 1965, convenceram a Índia a desenvolver armas nucleares
O país realizou seu primeiro teste nuclear em 1974 e realizou mais testes subterrâneos em 1998
Apesar das críticas e sanções militares, a Índia não assinou o Tratado de Interdição Completa de Ensaios Nucleares, nem o Tratado de Não Proliferação de Armas Nucleares, por considerar os acordos falhos e discriminatórios.
O país mantém a política nuclear de "não usar primeiro" (em inglês: no first use) e está desenvolvendo uma capacidade tríade nuclear, como parte de sua doutrina de "dissuasão credível mínima"
O governo indiano está desenvolvendo um escudo de mísseis balísticos de defesa e, com colaboração da Rússia, de um avião caça de quinta geração
Outros projetos militares indianos envolvem a concepção e implementação dos porta-aviões da classe Vikrant e dos submarinos nucleares da classe Arihant.
Desde o fim da Guerra Fria, a Índia tem aumentado a sua cooperação econômica, estratégica e militar com os Estados Unidos e a União Europeia
Em 2008, um pacto nuclear foi assinado entre a Índia e os Estados Unidos
Embora a Índia já possuísse armas nucleares na época e não fosse um membro do Tratado de Não-Proliferação Nuclear, o acordo recebeu isenção da Agência Internacional de Energia Atômica e do Grupo de Fornecedores Nucleares, acabando com as restrições anteriores sobre tecnologia e o comércio nuclear do país
Como consequência, a Índia se tornou o sexto Estado com armas nucleares de facto do mundo
Posteriormente o país assinou acordos de cooperação em energia nuclear civil com Rússia, França, Reino Unido e Canadá.
O presidente da Índia é o comandante supremo das forças armadas do país; com 1,6 milhão de soldados ativos, eles compõem o terceiro maior exército do mundo
As forças armadas compreendem o exército, a marinha e a força aérea; organizações auxiliares incluem o Comando de Forças Estratégicas e três grupos paramilitares: os Assam Rifles, a Força Especial de Fronteira e a Guarda Costeira
O orçamento de defesa oficial indiano para 2011 foi de 36,03 bilhões  de dólares, ou 1,83% do seu PIB
Para o ano fiscal que abrange 2012-2013 foram orçados para essa área 40,44 bilhões de dólares.
De acordo com um relatório de 2008 do SIPRI, a despesa militar anual da Índia em termos de poder de compra foi de 72,7 bilhões de dólares
Em 2011, o orçamento anual de defesa do país teve um aumento de 11,6%, embora isso não inclua os fundos que chegam aos militares através de outros ramos do governo
Em 2012, o país era o maior importador de armas do mundo; entre 2007 e 2011, a Índia foi responsável por 10% dos fundos gastos em compras internacionais de armas
Grande parte das despesas militares é voltada para a defesa contra o Paquistão e para combater a crescente influência chinesa no Oceano Índico.

A Índia se subdivide em vinte e nove estados e sete "territórios da União"
Todos os estados e os dois territórios da União de Pondicherry e o território da capital nacional elegem suas legislaturas e governos por meio do modelo de Westminster
Os outros cinco territórios união são regidos de forma direta pelo governo federal, através de várias administrações designadas
Em 1956, em virtude da Lei de Reorganização dos Estados, o território indiano foi dividido baseando-se em aspectos linguísticos
A partir de então, esta estrutura permaneceu sem mudanças
Cada estado ou território da união se divide em distritos administrativos
Por sua vez, os distritos se dividem em tehsils e finalmente em aldeias.
Estados
Territórios da união
A Índia, com um produto interno bruto nominal estimado em 1,843 trilhões  de dólares, ocupa o 10ª lugar na lista de maiores economias do mundo por PIB nominal, enquanto sua paridade de poder de compra calculada em 2011 em 4,4 trilhões de dólares, é a terceira maior do mundo, atrás apenas dos Estados Unidos e da China
Contudo, ainda é um país muito pobre, com uma renda per capita nominal de apenas 1 530 dólares e renda per capita PPC de 3 705 dólares em 2011.
No período compreendido entre as décadas de 1950 e 1980, a economia indiana seguia tendências socialistas
A economia se manteve paralisada por regulamentos impostos pelo governo, o protecionismo e a propriedade pública, o que levou a uma corrupção generalizada e a um lento crescimento econômico
Em 1991, a economia nacional se converteu em uma economia de mercado
Esta mudança na política econômica em 1991 se deu pouco depois de uma crise aguda no balanço de pagamentos, pelo que desde então se pôs ênfase em fazer do comércio internacional e do investimento estrangeiro direto um setor primordial da economia indiana.
Durante as últimas décadas a economia indiana tem tido uma taxa de crescimento anual do produto interno bruto ao redor de 5,8%, convertendo-se em uma das economias de mais rápido crescimento no mundo
A Índia conta com a maior força de trabalho do mundo, com mais de 513,6 milhões de pessoas
Em termos de produção, o setor agrícola representa 28% do PIB; o setor de serviços, 54% e a indústria, 18%
Os principais produtos agrícolas e de gado incluem arroz, trigo, sementes oleaginosas, algodão, juta, chá, a cana-de-açúcar, ovinos, caprinos, aves de curral e pescados.
As principais indústrias são a têxtil, maquinaria, produtos químicos, aço, transportes, cimento, mineração e software
Em 2006, o comércio indiano havia alcançado uma proporção relativamente moderada de 24% do PIB, crescendo à taxa de 6% desde 1985
O comércio da Índia representa um pouco mais de 1% do comércio mundial
As principais exportações incluem os derivados de petróleo, alguns produtos têxteis, pedras preciosas, software, engenharia de bens, produtos químicos, peles e couros
Entre as principais importações estão o petróleo cru, maquinarias, joias, fertilizantes e alguns produtos químicos.
Apesar de seu notável crescimento econômico nas últimas décadas, a Índia contém a maior concentração de pessoas pobres do mundo e tem uma alta taxa de subnutrição em crianças menores de três anos (46% em 2007)
A porcentagem de pessoas vivendo abaixo da linha de pobreza segundo o Banco Mundial, vivendo com menos de um dólar por dia (PPA, em termos nominais Rs
21,6 ao dia nas zonas urbanas e Rs
14,3 nas zonas rurais) diminuiu de 60% em 1981 para 42% em 2005
Apesar de nas últimas décadas a Índia ter evitado a carestia, a metade das crianças tem um peso inferior à média mundial, uma das taxas mais altas do mundo e quase o dobro da taxa da África subsaariana.
Um relatório em 2007 da Goldman Sachs previa que entre 2007 e 2020 o PIB indiano quadruplicaria e que poderia superar o PIB dos Estados Unidos antes de 2050, mas que a Índia continuaria sendo um dos países com habitantes mais pobres do mundo durante várias décadas, com renda per capita abaixo dos seus companheiros "BRIC" (Brasil, Rússia, Índia e China).
Apesar de nos últimos decênios a economia indiana ter aumentado de forma constante, este crescimento tem ocorrido de maneira desigual, em especial quando se compara à qualidade de vida nos diferentes grupos sociais, econômicos, em diversas regiões geográficas, zonas rurais e urbanas
Em 2008, o Banco Mundial afirmava que as prioridades mais importantes para o governo indiano deveriam ser a reforma do setor público, a construção de infraestruturas básicas, o desenvolvimento agrícola e rural sustentável, a eliminação das normas de trabalho, a reforma nos estados mais atrasados e a luta contra a AIDS.
Jawaharlal Nehru, o primeiro primeiro-ministro da Índia, que governou de 15 de agosto de 1947 a 27 de maio de 1964, iniciou reformas para promover a educação superior e a ciência e tecnologia no país
O Instituto Indiano de Tecnologia — concebido por uma comissão de 22 membros de estudiosos e empresários com o objetivo de promover o ensino técnico — foi inaugurado em 18 de agosto de 1951, em Kharagpur, Bengala Ocidental, pelo então ministro da educação, Abul Kalam Azad
Nos anos 1960, laços mais estreitos com a União Soviética permitiram à Organização Indiana de Pesquisa Espacial desenvolver rapidamente o seu programa espacial e avançar em energia nuclear, mesmo após o primeiro teste nuclear da Índia ter sido realizado em 18 de maio de 1974, em Pokharan.
A Índia responde por cerca de 2,9% de todas as despesas em pesquisa e desenvolvimento do mundo em 2012 e o número de publicações científicas do país é crescente
No entanto, de acordo com o ministro de ciência e tecnologia indiano, Kapil Sibal, o país está ficando para trás em ciência e tecnologia em comparação aos países desenvolvidos
A Índia tem apenas 140 pesquisadores para cada milhão de habitantes, em comparação com 4 651 nos Estados Unidos
O país investiu 3,7 bilhões de dólares em ciência e tecnologia entre 2002 e 2003
Em comparação, a China investiu cerca de quatro vezes mais, enquanto os Estados Unidos investiram cerca de 75 vezes mais do que os indianos em ciência e tecnologia
Apesar disso, cinco Institutos Indianos de Tecnologia foram listados entre as dez melhores escolas de ciência e tecnologia da Ásia, pela Asiaweek
O número de publicações de cientistas indianos é caracterizada por algumas das taxas de crescimento mais rápidas entre os principais países
A Índia, juntamente com China, Irã e Brasil são os únicos países em desenvolvimento que fazem parte dos 31 países que juntos são responsáveis por 97,5% da produção científica do mundo.
A educação no país é fornecida e mantida pelos setores público e privado, com controle e financiamento proveniente de três níveis de governo: central, estadual e local
Na cidade antiga de Taxila foi encontrado o primeiro centro de ensino superior registrado da Índia, datado do século V a.C., mas é discutível se ele pode ser considerado uma universidade
A Universidade de Nalanda, fundada em 470, foi o mais antigo sistema educacional universitário de todo o mundo, no sentido moderno de "universidade".
A educação ocidental enraizou-se na sociedade indiana com o estabelecimento do Raj britânico
O sistema educacional indiano está sob o controle do Governo da União e, com alguma autonomia, dos estados
Vários artigos da constituição indiana classificam a educação como um direito fundamental
A maioria das universidades no país é controlada pela União ou pelos governos dos estados
O país tem feito progressos em aumentar a taxa de frequência no ensino primário e na expansão da alfabetização para cerca de três quartos da população
A melhora no sistema de ensino indiano é frequentemente citada como um dos principais contribuintes para o crescimento econômico do país nos últimos anos
Grande parte do progresso, especialmente na educação superior e na pesquisa científica, foi atribuído a várias instituições públicas
O mercado educacional privado indiano movimentou 40 bilhões de dólares em 2008 e aumentou esse valor para 70 bilhões em 2012.
No entanto, o país continua a enfrentar severos desafios nessa área
Apesar do crescente investimento educacional, 25% de sua população ainda é analfabeta, apenas 15% dos estudantes indianos chegam à escola secundária e apenas 7% à pós-graduação
A qualidade da educação, seja no ensino fundamental ou no superior, é significativamente baixa em comparação com a das principais nações em desenvolvimento
Em 2008, as instituições de ensino superior ofereciam vagas suficientes para apenas 7% da população em idade universitária do país, 25% dos cargos de ensino em todo a Índia estão vagos e 57% dos professores universitários indianos não tinham mestrado ou doutorado
Em 2011, existiam 1 522 faculdades de engenharia, com um total anual de 582 mil estudantes, além de 1 244 politécnicos, com um total anual de 265 mil estudantes
No entanto, estas instituições enfrentam problemas, como a escassez de professores e preocupações têm sido levantadas sobre a qualidade do ensino oferecido.
A Índia tem um sistema de saúde universal mantido pelos seus estados e territórios constituintes
A constituição cobra de cada estado "elevar o nível da nutrição e da qualidade de vida de seu povo e da melhoria da saúde pública como entre suas funções primárias"
A Política Nacional de Saúde foi aprovada pelo Parlamento da Índia em 1983 e atualizada em 2002
Paralelo ao setor de saúde pública, e de fato mais popular, é o setor médico privado
Famílias indianas urbanas e rurais tendem a utilizar o setor médico privado com mais frequência do que o setor público, como refletido em pesquisas.
A Índia tem uma expectativa de vida de 64/67 anos (m/f) e uma taxa de mortalidade infantil de 61 por mil nascidos vivos
42% das crianças indianas abaixo de três anos de idade são desnutridas, taxa maior que a encontrada em estatísticas da região subsaariana da África, que é de 28%
Embora a economia do país tenha crescido 50% entre 2001 e 2006, a taxa de desnutrição infantil caiu apenas 1%, ficando atrás de países com taxas de crescimento similares
A desnutrição impede o desenvolvimento social e cognitivo das crianças, além de reduzir seus níveis de escolaridade e renda quando adultas
Estes danos irreversíveis resultam em uma menor produtividade para o país
Como mais de 122 milhões de famílias sem banheiros e 33% sem acesso à latrinas, mais de 50% da população do país (638 milhões de pessoas) defecam ao ar livre todos os dias
Esta taxa é consideravelmente maior do que as de Bangladesh e Brasil (7%) e da China (4%)
Apesar de 211 milhões de pessoas terem ganho acesso a sistemas de saneamento básico entre 1990 e 2008, apenas 31% utilizam os recursos oferecidos.
Desde a liberalização econômica dos anos 1990, o desenvolvimento da infraestrutura no país progrediu a um ritmo rápido e hoje há uma grande variedade de meios de transporte por terra, água e ar
No entanto, o PIB per capita relativamente baixo da Índia fez com que o acesso a estes modos de transporte não tenha sido homogêneo
A penetração de veículos motorizados é baixa para os padrões internacionais, com apenas 103 milhões de carros nas estradas indianas
Além disso, apenas cerca de 10% dos lares do país possuem uma motocicleta
Ao mesmo tempo, a indústria automobilística indiana está crescendo rapidamente, com uma produção anual de mais de 4,6 milhões de veículos e o volume de veículos deverá aumentar significativamente no futuro
Nesse contexto, porém, o transporte público continua a ser o principal meio de locomoção da maioria da população e os sistemas de transporte públicos do país estão entre os mais utilizados no mundo.
Apesar das melhorias em curso na área, vários aspectos do setor de transportes ainda estão cheios de problemas devido à infraestrutura precária e à falta de investimento em regiões menos economicamente ativas do país
A demanda por infraestrutura e serviços de transportes tem vindo a aumentar em cerca de 10% ao ano, já que a infraestrutura atual é incapaz de atender às demandas econômicas crescentes
De acordo com estimativas de 2008 da Goldman Sachs, a Índia teria que gastar 1,7 trilhão de dólares em projetos de infraestrutura ao longo da década seguinte para impulsionar seu crescimento econômico, do qual 500 bilhões de dólares estão orçados para serem gastos durante o Décimo Primeiro Plano Quinquenal.
A rede ferroviária indiana é uma das maiores do mundo (com 63 465 quilômetros de extensão) e é o sistema mais utilizado do planeta, transportando 651 milhões de passageiros e mais de 921 milhões de toneladas de carga em 2011
O sistema ferroviário indiano, introduzido em 1853 pelos britânicos, é fornecido e mantido pela estatal Indian Railways, sob a supervisão do Ministério das Ferrovias.
A Índia tem uma rede de estradas nacionais que ligam todas as principais cidades e capitais estaduais, formando a espinha dorsal econômica do país
Em 2010, o país tinha um total de 79 443 km de estradas nacionais, das quais 200 km eram classificadas como autoestradas
A rede de estradas estaduais totalizava no mesmo ano 131 899 km e o total da rede rodoviária indiana cerca de 3 300 000 km.
De acordo com Projeto de Desenvolvimento Rodoviário Nacional (PNDS), a intenção é equipar algumas das principais estradas nacionais com quatro pistas de rodagem, além de também existir um plano de converter alguns trechos dessas estradas em seis pistas
A Autoridade Nacional de Estradas estima que cerca de 65% da carga e 80% do tráfego de passageiros do país seja transportado por rodovias
As estradas nacionais indianas transportam cerca de 40% do total do tráfego rodoviário, embora apenas cerca de 1,7% da rede de estradas esteja coberta por essas estradas principais
O crescimento médio do número de veículos tem sido em torno de 10,16% ao ano nos últimos anos.
Em 2012 hvia 352 aeroportos civis na Índia, dos quais 251 com pistas pavimentadas
Há mais de 20 aeroportos internacionais
O Aeroporto Internacional Indira Gandhi, em Nova Déli, e o Aeroporto Internacional de Chhatrapati Shivaji, em Bombaim, lidam com mais de metade do tráfego aéreo do sul da Ásia.
Os portos são os principais centros para o comércio
No país, cerca de 95% do comércio exterior em quantidade e 70% em valor ocorre através de portos marítimos
A Mumbai Port & JNPT (Nova Bombaim) controla 70% do comércio marítimo na Índia
Há doze portos principais nas seguintes cidades: Nova Bombaim, Bombaim, Kochi, Calcutá (incluindo Haldia), Paradip, Visakhapatnam, Ennore, Chennai, Thoothukudi, Nova Mangalore, Mormugão e Kandla
Além destes, existem 187 portos menores e intermediários, 43 dos quais lidam com cargas.
A política energética da Índia está em grande parte definida pelo crescente déficit energético do país e pelo maior foco no desenvolvimento de fontes alternativas de energia, particularmente energia nuclear, solar e eólica
Cerca de 70% da capacidade de geração de energia do país provém de combustíveis fósseis, sendo o carvão o responsável por 40% do consumo total de energia indiano, seguido pelo petróleo bruto e pelo gás natural com 24% e 6%, respectivamente
O país é em grande parte dependente de importações de combustíveis fósseis para atender suas demandas de energéticas; em 2030, a dependência da Índia de importações de energia deverá ultrapassar 53% do consumo total do país
Em 2009-10, o país importou 159,26 milhões de toneladas de petróleo bruto, que equivale a 80% do seu consumo interno, e 31% do total das importações indianas são provenientes do petróleo
O crescimento da geração da eletricidade na Índia tem sido dificultado pela escassez de carvão nacional e, como consequência, as importações de carvão para a produção de eletricidade aumentaram 18% em 2010.
Devido à sua rápida expansão econômica, o país tem um dos mercados de energia que crescem mais rapidamente no mundo e espera-se que se torne o segundo maior contribuinte no aumento da demanda energética global até 2035, sendo responsável por 18% do aumento do consumo mundial
Dada a crescente demanda de energia e as limitadas reservas de combustíveis fósseis no mercado interno, o país tem planos ambiciosos para expandir suas indústrias de energia renovável e nuclear
A Índia tem o quinto maior mercado de energia eólica do mundo e tem planos de adicionar cerca de 20 gigawatts de capacidade de energia solar até 2022, além de também prever aumentar a contribuição da energia nuclear para a capacidade total de geração de eletricidade de 4,2% para 9% em 25 anos
O país tem cinco reatores nucleares em construção e planeja construir outros dezoito até 2025.
A história cultural indiana se estende por mais de 4 500 anos de história
Durante o período védico (c. 1 700-500 a.C.), os fundamentos da filosofia, mitologia e literatura hindu foram estabelecidos e muitas crenças e práticas que ainda existem atualmente, tais como dharma, karma, yoga e moksha, foram consolidadas
A Índia é notável por sua diversidade religiosa, sendo hinduísmo, siquismo, islamismo, cristianismo e jainismo as principais e mais populares religiões do país
A religião predominante, o hinduísmo, foi moldada por várias escolas históricas de pensamento, como os upanixades, os yoga sutras, o movimento bhakti e a filosofia budista.
A cultura indiana está marcada por um alto grau de sincretismo e pluralismo
Os indianos têm conseguido conservar suas tradições previamente estabelecidas, enquanto absorvem novos costumes, tradições e ideias de invasores e imigrantes, ao mesmo tempo que estendem a sua influência cultural a outras partes da Ásia, principalmente Indochina e Extremo Oriente.
A sociedade tradicional da Índia está definida como uma hierarquia social relativamente restrita
O sistema indiano de castas descreve a estratificação e as restrições sociais do subcontinente indiano; também define as classes sociais por grupos endogâmicos hereditários, que a princípio se denominam jatis ou castas
A Índia declarou a "intocabilidade" ilegal em 1947 e, desde então, promulgou outras leis antidiscriminatórias e iniciativas para o bem-estar social, embora relatórios sugiram que muitos dalits ("ex-intocáveis") e outras castas mais baixas em áreas rurais continuam a serem segregadas e enfrentam perseguição e discriminação
No local de trabalho das grandes cidades e nas principais empresas indianas ou internacionais, o sistema de castas praticamente perdeu a sua importância.
Os valores tradicionais das famílias indianas são muito respeitados e o modelo patriarcal tem sido o mais comum durante séculos, ainda que recentemente a família nuclear esteja se convertendo no modelo seguido pela população que vive na zona urbana
A maioria dos indianos tem seus casamentos arranjados por seus pais e por outros membros da família respeitados, com o consentimento da noiva e do noivo
O matrimônio é planejado para toda a vida, a taxa de divórcio é extremamente baixa
O casamento na infância é ainda uma prática comum, e metade das mulheres indianas se casa antes dos dezoito anos.
Na Índia, a cada 15 minutos uma violação de uma mulher é reportada
Mas, na maioria dos casos, leva anos até o culpado ser punido
Porém, quando uma vaca é abatida, existem grupos extremistas que, imediatamente, matam ou agridem os suspeitos do crime.A India é considerada o quarto país do mundo mais perigoso para as mulheres
Em 2012, a brutal violação em grupo de Jyoti Singh Pandey no interior de um autocarro em Deli encheu as primeiras páginas dos noticiários, com milhares de pessoas manifestando-se nas ruas para protestar contra a falta de proteção legal para as vítimas de assaltos sexuais, a lentidão ou desprezo dos tribunais, práticas policiais nocivas e as questões sociais subjacentes que levam a esse estado de coisas.
Muitas celebrações indianas são de origem religiosa, ainda que algumas independam da casta ou credo
Alguns dos festivais mais populares do país são: Diwali, Holi, Durga Puja, Eid ul-Fitr, Eid al-Adha, Natal e Vesak
Além destas, a nação tem três festas nacionais: o dia da República, o dia da independência e o Gandhi Jayanti, em homenagem a Mahatma Gandhi
Uma outra série de dias festivos, variando entre nove e doze dias, são oficialmente celebrados em cada estado nacional
As práticas religiosas são parte integral da vida cotidiana e são um assunto de interesse público
A roupa tradicional varia de acordo com as cores e estilos segundo a região e depende de certos fatores, incluindo o clima
Os estilos de vestir incluem prendas simples como o sári para as mulheres e o dhoti para os homens; calças e camisas de estilo europeu também são populares entre os homens
O uso de joias delicadas, modeladas em flores reais usados durante a Índia antiga, faz parte de uma tradição que remonta a cerca de 5.000 anos; pedras preciosas também são usadas na Índia como talismãs.
A culinária indiana apresenta uma forte dependência de ervas e especiarias, com pratos muitas vezes apelando para o uso sutil de uma dúzia ou mais de condimentos diferentes; a gastronomia do país também é conhecida por suas preparações tanduri
No tandur, um forno de argila usado na Índia há quase 5 000 anos, as carnes ficam com uma "suculência incomum" e é possível produzir o pão sírio inchado conhecido como naan
Os alimentos básicos são o trigo (principalmente no norte do país), arroz (especialmente no sul e no leste) e lentilhas
Muitas especiarias populares no mundo todo são nativas do subcontinente indiano, enquanto o pimentão, que é nativo das Américas e foi introduzido pelos portugueses, é amplamente utilizado pela população local
O ayurveda, um sistema de medicina tradicional, usa seis rasas e três gunas para ajudar a descrever os comestíveis
Ao longo do tempo, conforme os sacrifícios de animais feitos pelos védicos foram suplantados pela noção de sacralidade inviolável da vaca, o vegetarianismo foi associado a um alto nível religioso e tornou-se cada vez mais popular, uma tendência auxiliada pelo aumento de normas budistas, jainistas e bhaktis hindus
A Índia tem a maior concentração de vegetarianos do mundo: uma pesquisa realizada em 2006 constatou que 31% dos indianos eram lactovegetarianos e outros 9% eram ovovegetarianos
Entre os costumes alimentares mais tradicionais e comuns estão refeições feitas perto ou no próprio chão, refeições segregadas por casta e gênero e uso da mão direita ou de um pedaço de roti (tipo de pão) no lugar dos talheres.
Grande parte da arquitetura indiana, incluindo o Taj Mahal e outras obras da arquitetura mogol e do sul da Índia, combina antigas tradições locais com estilos importados de outras nações
A arquitetura vernacular, no entanto, é altamente regionalizada
A Vastu Shastra, literalmente "ciência da construção" ou "arquitetura" e atribuída a Mamuni Maia, explora como as leis da natureza afetam as habitações humanas, além de empregar geometria precisa e alinhamentos direcionais para refletir construções cósmicas.
A arquitetura dos templos hindus é influenciada pelos Shastras Shilpa, uma série de textos fundamentais cuja forma mitológica básica é a mandala Vastu-Purusha, uma praça que encarna o conceito de "absoluto"
O Taj Mahal, construído na cidade de Agra entre 1631 e 1648 por ordem do imperador Shah Jahan e em memória de sua esposa, é descrito na lista do Patrimônio Mundial da UNESCO como "a joia da arte muçulmana na Índia e uma das obras-primas universalmente admiradas da herança do mundo"
A arquitetura neo-indo-sarracena, desenvolvida pelos britânicos no final do século XIX, baseou-se em arquitetura indo-islâmica.
A música indiana varia através de várias tradições e estilos regionais
A música clássica abrange dois gêneros e suas diversas ramificações populares: o hindustai, do norte, e escolas carnáticas, do sul
Entre as formas populares regionalizadas incluem-se o filmi e músicas folclóricas; a tradição sincrética dos bauls é uma forma bem conhecida desta última
A dança indiana também tem formas clássicas e diversas
Entre as danças folclóricas mais conhecidas estão o bhangra do Punjabe, o bihu de Assam, o chhau de Bengala Ocidental e Jharkhand, o sambalpuri de Odisha, o ghoomar do Rajastão e o lavani, de Maharashtra
Oito formas de dança, muitas com formas narrativas e elementos mitológicos, têm sido reconhecidas como danças clássicas pela Academia Nacional de Música, Dança e Teatro da Índia
São elas: bharatanatyam, do estado de Tamil Nadu, kathak,de Uttar Pradesh, kathakali e mohiniyattam, de Kerala, kuchipudi, de Andhra Pradesh, manipuri, de Manipur, odissi, de Orissa, e o sattriya, de Assam
O teatro indiano mescla música, dança e diálogos improvisados ou escritos
Muitas vezes baseado na mitologia hindu, mas também inspirado em romances medievais ou eventos sociais e políticos, o teatro indiano inclui o bhavai de Gujarat, o jatra de Bengala Ocidental, o nautanki e o ramlila do Norte da Índia, o tamasha de Maharashtra, o burrakatha de Andhra Pradesh, o terukkuttu de Tamil Nadu e o yakshagana de Karnataka.
As primeiras obras literárias da Índia, compostas entre 1 400 a.C
e 1200 d.C., foram escritas no idioma sânscrito
Obras proeminentes desta literatura sânscrita incluem épicos, como o Mahābhārata e o Ramayana, e dramas de Kālidāsa, como o Abhijñānaśākuntalam (O Reconhecimento de Sakuntala), e poesias, como o Mahākāvya
O Kamasutra, o famoso livro sobre relações sexuais, também se originou no país
Desenvolvida entre 600 a.C
e 300 d.C
no sul da Índia, a literatura sangam compôs 2 381 poemas e é considerada como uma antecessora da literatura tâmil
Do século XIV ao XVIII, as tradições literárias indianas passaram por um período de drástica mudança por causa do surgimento de poetas devocionais (movimento bhakti) como Kabir, Tulsidas e Guru Nanak
Este período foi caracterizado por um espectro variado e amplo de expressão e correntes de pensamento e, como consequência, obras literárias medievais indianas diferem significativamente da tradição clássica
No século XIX, os escritores indianos tomaram um novo interesse pelas questões sociais e descrições psicológicas
No século XX, a literatura indiana foi influenciada pelas obras do poeta e romancista bengali Rabindranath Tagore.
A indústria cinematográfica indiana é a maior do mundo
Bollywood, bairro localizado na cidade de Bombaim onde são feitos os filmes e comerciais em hindi, foi recentemente convertido no centro da indústria cinematográfica mais prolífica do mundo, igualando sua importância com Hollywood
Também são feitos filmes tradicionais e comerciais em zonas onde o bengali, canarês, malaiala, marata, tâmil e telugo são idiomas oficiais
O cinema do sul da Índia atrai mais de 75% da receita do cinema nacional.
A radiodifusão televisiva começou na Índia, em 1959, como um meio estatal de comunicação e teve expansão lenta por mais de duas décadas
O monopólio estatal na transmissão da televisão terminou em 1990 e, desde então, canais por satélite têm se tornado cada vez mais populares na cultura popular da sociedade indiana
Hoje, a televisão é a mídia com maior alcance na Índia; estimativas da indústria indicam que em 2012 havia mais de 554 milhões de consumidores de TV, 462 milhões de satélite e/ou conexões por cabos, em comparação com outras formas de mídia de massa, como a imprensa (350 milhões), o rádio (156 milhões) ou a internet (37 milhões).
Na Índia, vários esportes tradicionais permanecem bastante populares, como o kabaddi, kho kho, pehlwani e gilli-danda
Algumas das primeiras formas de artes marciais asiáticas, como kalari payattu, mushti yuddha, silambam e marma adi, se originaram na Índia
O Rajiv Gandhi Khel Ratna e o Prêmio Arjuna são as mais altas formas de reconhecimento do governo para a realização atlética; o Prêmio Dronacharya é concedido pela excelência em treinamento
O xadrez, que acredita-se que originou-se na Índia como chaturanga, está a recuperar popularidade com o aumento do número de mestres indianos nesse esporte
O tradicional jogo de tabuleiro indiano chamado pachisi foi jogado em uma quadra gigante de mármore pelo imperador Akbar.
Os bons resultados conquistados pela equipe indiana de Copa Davis e outros tenistas indianos no início de 2010 fizeram o tênis se tornar cada vez mais popular no país
A Índia tem uma presença relativamente forte no tiro esportivo e já ganhou várias medalhas no Jogos Olímpicos, nos Campeonatos do Mundo de tiro e nos Jogos da Commonwealth
Outros esportes em que os indianos têm sido bem sucedidos internacionalmente incluem o badminton, o boxe e o wrestling
O futebol é popular em Bengala Ocidental, Goa, Tamil Nadu, Kerala e em estados do nordeste.
O hóquei em campo na Índia é administrado pelo Hockey India
A seleção nacional de hóquei venceu a Copa do Mundo de Hóquei sobre a Grama de 1975 e, até 2012, tinha oito medalhas olímpicas de ouro, uma de prata e duas de bronze, o que a torna a equipe mais bem sucedida dessa prática
A Índia também tem desempenhado um papel importante na popularização do críquete, sendo o esporte mais popular do país
O críquete indiano ganhou a Copa do Mundo de Críquete de 1983 e de 2011, ICC Mundial Twenty20 de 2007 e dividiu o troféu do ICC Champions de 2002 com o Sri Lanka
O Conselho Nacional de Controle do Críquete na Índia (BCCI) realiza uma competição Twenty20 conhecida como Indian Premier League
A Índia já hospedou ou co-organizou vários eventos esportivos internacionais; os Jogos Asiáticos de 1951 e de1982, as Copas do Mundo de Críquete de 1987, 1996 e 2011, os Jogos Afro-Asiáticos de 2003, o ICC Champions Trophy de 2006, a Copa de Hóquei Masculino de 2010 e os Jogos da Commonwealth de 2010
Grandes eventos esportivos internacionais realizados anualmente na Índia incluem o Chennai Open (tênis), a Maratona de Bombaim, a Meia Maratona de Deli e o Indian Masters (golfe)
O primeiro Grande Prêmio da Índia aconteceu no final de 2011
O país tem sido, tradicionalmente, dominante nos Jogos Sul-Asiáticos
Um exemplo dessa dominação é a competição de basquete, onde seleção nacional indiana de basquete venceu três dos quatro torneios até a data.
África do Sul · Antígua e Barbuda · Austrália · Bahamas · Bangladesh · Barbados · Belize · Botswana · Brunei · Camarões · Canadá · Chipre · Dominica · Fiji · Gana · Granada · Guiana · Índia · Ilhas Salomão · Jamaica · Kiribati · Lesoto · Malásia · Malawi · Malta · Maurícias · Moçambique · Namíbia · Nauru · Nigéria · Nova Zelândia · Papua Nova Guiné · Paquistão · Quénia · Reino Unido · Ruanda · Samoa · Santa Lúcia · São Cristóvão e Nevis · São Vicente e Granadinas · Serra Leoa · Seychelles · Singapura · Sri Lanka · Suazilândia · Tanzânia · Tonga · Trinidade e Tobago · Tuvalu · Uganda · Vanuatu · Zâmbia
Ilhas Ashmore e Cartier · Ilha Christmas · Ilhas Cocos (Keeling) · Ilha Heard e Ilhas McDonald · Ilhas do Mar de Coral · Ilha de Norfolk · Território Antárctico Australiano
Dependência de Ross · Ilhas Cook · Niue · Tokelau
Akrotiri e Dhekelia · Anguilla · Bermudas · Gibraltar · Guernsey · Ilha de Man · Ilhas Caimão · Ilhas Geórgia do Sul e Sandwich do Sul · Ilhas Virgens Britânicas · Jersey · Malvinas · Montserrat · Pitcairn · Santa Helena (inclui a ilha de Ascensão e a Ilha de Tristão da Cunha) · Território Antártico Britânico · Território Britânico do Oceano Índico · Turks e Caicos
1775 (MDCCLXXV, na numeração romana) foi um ano comum do século XVIII do actual Calendário Gregoriano, da Era de Cristo, e a sua letra dominical foi A (52 semanas), teve início a um domingo e terminou também a um domingo.
Ano comum com início ao domingo



146 °C 
α-D-glucose: 146 °C 
β-D-glucose: 150 °C 
A glicose, glucose ou dextrose, é um monossacarídeo e é um dos carboidratos mais importantes na biologia
As células a usam como fonte de energia e intermediário metabólico
A glicose é um dos principais produtos da fotossíntese e inicia a respiração celular em seres procariontes e eucariontes
É um cristal sólido de sabor adocicado, de formula molecular C6H12O6, encontrado na natureza na forma livre ou combinada
Juntamente com a frutose e a galactose, é o carboidrato fundamental de carboidratos maiores, como sacarose e maltose
Amido e celulose são polímeros de glucose.
No metabolismo, a glicose é uma das principais fontes de energia e fornece 4 calorias de energia por grama
A glicose hidratada (como no soro glicosado) fornece 3,4 calorias por grama
Sua degradação química durante o processo de respiração celular dá origem a energia química (armazenada em moléculas de ATP - 36 ou 38 moleculas (depende da celula) de ATP por moléculas de glicose), gás carbônico e água.
Por ter 6 átomos de carbono é classificada como uma hexose, uma subcategoria dos monossacarídeos
A D-Glicose é um dos 16 estereoisômeros da aldohexose, também conhecida como dextrose acontece abundantemente na natureza, diferente de seu isomero L-Glicose
No Brasil é comumente fabricada a partir da cana-de-açúcar.
No ano de 1747, Andreas Sigismund Marggraf foi o primeiro a isolar a glicose.
A glicose quando em soluçao com a substancia Benedict sob aquecimento muda sua cor de azul para laranja .
Apresenta fórmula mínima: CH2O
Fórmula estrutural:
A glicose (C6H12O6) contém seis átomos de carbono e um grupo aldeído e é consequentemente referida como uma aldo-hexose
A molécula de glicose pode existir em uma forma de cadeia aberta (acíclica) e anel (cíclica) (em equilíbrio), a última sendo o resultado de uma reação intramolecular entre o átomo C do aldeído e a grupo hidroxil C-5 para formar um hemiacetal intramolecular
Em solução aquosa as duas formas estão em equilíbrio, e em pH 7 a forma cíclica é predominante
Como o anel contém cinco átomos de carbono e um átomo de oxigênio, o que lembra a estrutura do pirano, a forma cíclica da glucose também é referida como glucopiranose
Neste anel, cada carbono está ligado a um grupo hidroxila lateral com exceção do quinto átomo, que se liga ao sexto átomo de carbono fora do anel, formando um grupo CH2OH.

O nome Glicose veio do grego (γλυκύς), que significa "doce", mais o sufixo -ose, indicativo de açúcar
Tem função de regulador de energia, participa das vias metabólicas, além de ser precursora de outras importantes moléculas.
Uma autópsia, necrópsia ou exame cadavérico é um procedimento médico que consiste em examinar um cadáver para determinar a causa e modo de morte e avaliar qualquer doença ou ferimento que possa estar presente
É geralmente realizada por um médico especializado, chamado de legista num local apropriado denominado morgue ou necrotério.
Autópsias não eram permitidas no Brasil nos seus primeiros séculos de colonização portuguesa
Contudo, em casos excepcionais, algumas foram feitas por imposição da justiça e com o devido consentimento do Santo Ofício
Nos territórios sob dominação holandesa e portanto livre do jugo do Tribunal da Inquisição, Willem Piso, no século XVII, realizou livremente as primeiras autópsias no Brasil.
O termo autópsia deriva do grego clássico αυτοψία que significa "ver por si próprio", composto de αυτος (autós, "si mesmo") e ὄψις (ópsis, "visão").
Modernamente, criou-se a sinonímia necrópsia, composta de νεκρός (nekrós, "morto") e ὄψις (ópsis, "visão"), por julgarem que o nome autópsia poderia gerar confusão, por poder ser entendido, equivocadamente, como "exame de si mesmo"
Em todas as demais línguas, porém, diz-se normalmente "autopsia" (em espanhol e italiano), autopsie (em francês), autopsy (em inglês), etc.

(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


1788 (MDCCLXXXVIII, na numeração romana) foi um ano bissexto do século XVIII do actual Calendário Gregoriano, da Era de Cristo, e as suas letras dominicais foram F e E (52 semanas), teve início a uma terça-feira e terminou a uma quarta-feira.
Ano bissexto com início à terça-feira



Inglaterra (em inglês: England) é uma das nações constituintes do Reino Unido
O país faz fronteira com a Escócia ao norte e com o País de Gales a oeste; o Mar da Irlanda está a noroeste, o Mar Celta está a sudoeste, enquanto o Mar do Norte está a leste e o Canal da Mancha, ao sul, a separa da Europa continental
A maior parte da Inglaterra compreende a parte central e sul da ilha da Grã-Bretanha, no Atlântico Norte
O país também inclui mais de 100 ilhas menores, como as Ilhas Scilly e a Ilha de Wight.
A área agora chamada de Inglaterra foi habitada por seres humanos pela primeira vez durante o período Paleolítico Superior, mas o seu nome vem dos anglos, uma das tribos germânicas que se estabeleceram durante os séculos V e VI na região
A Inglaterra tornou-se um Estado unificado em 927 d.C., e desde a Era dos Descobrimentos, que começou durante o século XV, a nação passou a ter um impacto cultural e jurídico significativo sobre o resto do mundo
O idioma inglês, a Igreja Anglicana e o direito inglês (base para os sistemas legais de common law de muitos outros países ao redor do mundo) desenvolveram-se na Inglaterra, e o sistema de governo parlamentar do país tem sido amplamente adotado por outras nações
A Revolução Industrial começou na Inglaterra do século XVIII, transformando sua sociedade na primeira nação industrializada do mundo
A Royal Society da Inglaterra lançou as bases da ciência experimental moderna.
O território da Inglaterra é, em sua maioria, composto por pequenas colinas e planícies, especialmente no centro e no sul do país
No entanto, existem planaltos no norte (por exemplo, Lake District, Peninos e Yorkshire Dales) e no sudoeste (por exemplo, Dartmoor e Cotswolds)
A antiga capital da Inglaterra era Winchester até Londres assumir o posto em 1066
Hoje Londres é a maior área metropolitana no Reino Unido e a maior zona urbana da União Europeia
A população inglesa é de cerca de 51 milhões de pessoas, cerca de 84% da população do Reino Unido é majoritariamente concentrada em Londres, no sudeste e em aglomerações nas Midlands, no noroeste, no nordeste e em Yorkshire, regiões industriais que se desenvolveram durante o século XIX.
O Reino da Inglaterra, que depois de 1284 incluiu o País de Gales, era um Estado soberano até 1 de maio de 1707, quando os Atos de União colocaram em prática os termos acordados no Tratado de União do ano anterior, resultando em uma união política com o Reino da Escócia para criar o novo Reino da Grã-Bretanha
Em 1801, a Grã-Bretanha se uniu com o Reino da Irlanda através de outro ato da união para se tornar o Reino Unido da Grã-Bretanha e Irlanda
Em 1922, o Estado Livre Irlandês foi estabelecido como um domínio separado, mas uma lei de 1927 reincorporou ao reino seis condados irlandeses para criar oficialmente o atual Reino Unido da Grã-Bretanha e Irlanda do Norte, ou simplesmente Reino Unido.


O nome Inglaterra é derivado do Inglês antigo "Engla land" (England), que significa "terra dos anglos"
Os Anglos foram uma das tribos germânicas que se estabeleceram na Inglaterra durante a Alta Idade Média
Segundo o Dicionário Oxford, o primeiro uso conhecido de "Inglaterra" para se referir à parte sul da ilha da Grã-Bretanha ocorreu em 897, e sua ortografia moderna foi usada pela primeira vez em 1538.
O mais antigo fóssil humano descoberto no território consta mais de 700 mil anos atrás
A descoberta foi feita no que é hoje Norfolk e Suffolk
O homem moderno chegou ao território há cerca de 35 mil anos, mas devido às condições difíceis da última Era Glacial, fugiu da Grã-Bretanha para as montanhas do sul da Europa
Apenas os grandes mamíferos, como mamutes, bisões e rinocerontes, permaneceram
Há cerca de 11 mil anos, quando o gelo começou a derreter, os seres humanos voltaram a ocupar a área
Uma pesquisa genética mostrou que eles vieram do norte da Península Ibérica
O nível do mar era mais baixo do que agora, e a Grã-Bretanha estava ligada por terra à Irlanda e a Eurásia
Quando o mar subiu, há 9000 anos, foi separado da Irlanda, e da Eurásia meio século mais tarde
A Beaker Culture chegou por volta de 2500 a.C., e a elaboração de navios construídos a partir de barro e de cobre foi introduzida
Foi nessa época que os grandes monumentos do Neolítico, como Stonehenge e Avebury foram erigidos.
Durante a Idade do Ferro, os Celtas chegaram da Europa Central
O desenvolvimento de fundição de ferro permitiu a construção de arados melhores, o avanço da agricultura (por exemplo, com os campos Celtas), bem como a produção de armas mais eficazes
A sociedade era tribal, e de acordo com Ptolomeu havia cerca de 20 tribos diferentes na área, as divisões são desconhecidas
Tal como outras regiões na fronteira do Império, a Grã-Bretanha tinha apreciado por muito tempo relações comerciais com os romanos.
Os romanos conquistaram a Bretanha em 43, durante o reinado do imperador Cláudio, e a área foi incorporada ao Império Romano como província da Britânia
Em 410, com o declínio do Império Romano, os romanos deixaram a ilha para defender suas fronteiras na Europa continental.
A Inglaterra foi conquistada em 1066 por um exército liderado por Guilherme, o Conquistador, Duque da Normandia, um feudo do Reino da França
Os normandos originaram-se na Escandinávia e se estabeleceram na Normandia alguns séculos depois
O primeiro duque da Normandia foi Rollo, um ancestral de Guilherme, e fundador da Dinastia normanda
Eles introduziram o feudalismo e mantiveram o poder através de barões, que construíram castelos na Inglaterra
O período viu mudanças no comércio e na legislação, incluindo a assinatura da Carta Magna, uma carta jurídica utilizada para limitar o poder soberano por lei e proteger os privilégios dos homens livres.
O monasticismo católico floresceu, as universidades de Oxford e Cambridge foram fundadas com o patrocínio real
Durante o século XIV, a Inglaterra e a França se enfrentaram na Guerra dos Cem Anos
A epidemia da Peste negra atingiu a Inglaterra, a partir de 1348, e matou metade dos seus habitantes
De 1453-1487 uma guerra civil entre dois ramos da Dinastia Plantageneta, a Casa de Iorque e a Dinastia de Lencastre, ficou conhecida como a Guerra das Rosas.
A Guerra se resolveu quando o último rei da Casa de York, Ricardo III, foi morto na Batalha de Bosworth Field, ocorrida em 22 de agosto de 1485, pelas forças de Henrique Tudor, Conde de Richmond, da Casa de Tudor, com descendência galesa, sendo que o ancestral de Henrique, Owen Tudor, era o fundador da Dinastia através de seu casamento com Catarina de Valois, a viúva do rei Henrique V e mãe do rei Henrique VI.
A Dinastia Tudor existiu durante todo o século XVI até a data 29 de março de 1603, quando aos 69 de idade, a protestante Isabel I, filha de Henrique VIII, chamada de a rainha virgem, morreu sem deixar nenhuma descendência
Por indicação da rainha, a Inglaterra passou a ser governada pelos parentes dos Tudor, a escocesa Casa de Stuart, sendo o sucessor de Isabel, Jaime I, também rei da Escócia como Jaime VI, e rei da Irlanda
Ele era filho de Maria da Escócia, rainha soberana da Escócia como única herdeira de seu pai
Maria foi sido perseguida durante toda a sua vida por sua prima Isabel, pois a maioria católica achava ser ela a verdadeira rainha de Inglaterra, o que resultou em sua execução no Castelo de Fotheringhay, em 8 de fevereiro de 1587, aos 44 anos de idade.
Durante a Guerra civil inglesa, Oliver Cromwell subiu ao poder e foi o único representante de um breve período republicano na Inglaterra
Já estabilizado no poder, decretou o Ato de Navegação, favorecendo a economia inglesa e o desenvolvimento posterior de sua marinha.
A Inglaterra corresponde à maior parte dos dois terços sul da Grã-Bretanha
É limitada ao norte pela Escócia e ao oeste pelo País de Gales.
A maior parte da Inglaterra é coberta de colinas ("Roling Hills"), sendo mais montanhosa no norte
A linha divisora entre tipos do terreno é indicada geralmente pela linha Tees-Exe
Há também uma área de pântanos, a leste, que foi drenada para uso agrícola.
As maiores cidades da Inglaterra são:
O Eurotúnel, perto de Dover, liga a Inglaterra ao continente europeu (França).
A Inglaterra, com os seus 54,2 milhões de habitantes, dos quais cerca de um décimo pertencem a grupos étnicos não-brancos, é a nação etnicamente mais diversificada de todo o Reino Unido.
Em 2003, a população de Londres alcançou a marca de 7,5 milhões de habitantes.
Os cristãos já não são maioria na Inglaterra e no País de Gales
De acordo com pesquisa de 2014 publicada no The Guardian, 48,5% dos ingleses e dos galeses disseram não ter religião, quase o dobro dos 25% encontrados no censo de 2011
Os cristãos (anglicanos, católicos e outros) somavam 43,8%
Em 1983, 44,5% da população identificava-se como anglicana, percentagem que caiu para 19% em 2014
Seguidores de religiões não cristãs representavam os restantes 7,7% em 2014.
A Inglaterra não tem nenhum governo ou corpo de representantes independente do Reino Unido.
A Inglaterra é uma Monarquia Parlamentarista, com um parlamento que possui a autoridade de criar leis e providenciar obras públicas
O chefe de estado tem uma função meramente representativa e diplomática, não possuindo qualquer gênero de poder executivo.
O regime parlamentar implica a existência de um primeiro-ministro que é eleito pela maioria do parlamento.
A bandeira da Inglaterra, uma das nações constituintes do Reino Unido, consiste numa cruz de São Jorge vermelha em um fundo branco
Sua origem não foi estabelecida com precisão, mas aparece como símbolo inglês desde a Idade Média
Foi a bandeira do exército britânico e insígnia da marinha mercante até 1606
De 1606 até 1801 foi usada pela marinha mercante.
O brasão da Inglaterra está formado por um único campo de gules em que aparecem três leões passantes de ouro, linguados, com as garras à mostra na cor azul.
Apesar de a Inglaterra não ter nunca adotado oficialmente um hino nacional, os que seguem são muitas vezes utilizados nessa qualidade:
A rosa de Tudor é um emblema heráldico tradicional da Inglaterra
As origens e o nome derivam da Casa de Tudor
A Rosa de Tudor foi adotada como emblema nacional por volta do período da guerra das rosas como símbolo da paz
É também conhecida como a rosa inglesa
Nos dias atuais uma forma estilizada da rosa de Tudor é o símbolo do consulado nacional do turismo.
O carvalho é outro símbolo da Inglaterra, e representa a força e a resistência
O Carvalho Real tornou-se um dos símbolos comemorativos de Carlos II de Inglaterra que, antes de fugir para o exílio depois da execução de seu pai, utilizou-se de um carvalho para esconder-se.
Atualmente a Inglaterra se divide em quatro níveis de subdivisões administrativas: regiões, condados, distritos e paróquias
Porém tradicionalmente, Inglaterra se divide em condados (shires), de constituição que tem sido algo variável
Os condados podem ser definidos para várias razões
Os condados cerimoniais são definidos pelo governo e a cada um é designado um Lord-Lieutenant
A maioria refere a um grupo de autoridades locais e frequentemente com referência geográfica.
† condado cerimonial faz uma área maior do que o condado não-metropolitana.
Não mostrado: Cidade de Londres
A moeda utilizada na Inglaterra é a libra esterlina, com o símbolo £ (pound ou sterling, em inglês), uma das mais fortes moedas do mundo; os peniques (pence, em inglês, singular penny) já foram denominados "dinheiros", em português.
Uma das quatro principais economias europeias, a Inglaterra é um centro líder de comércio exterior e de serviços financeiros, com o sétimo maior Produto Interno bruto do mundo, com dois trilhões de dólares, inferior apenas aos Estados Unidos, China, Japão, Alemanha
A Educação é obrigatória no Reino Unido dos 5 aos 16 anos de idade, sendo oferecida em escolas financiadas pelo governo (state-funded schools) ou particulares (mais conhecidas por independent, também chamadas de public schools na Inglaterra e País de Gales)
As escolas britânicas se classificam também por género, podendo ser escolas para garotos, escolas para garotas ou escolas chamadas coeducacionais
Podem ser ainda day schools (escolas diárias em que os alunos apenas estudam de dia) ou boarding schools (alguns ou todos os alunos estudam e residem na escola), sendo que a maioria das escolas independentes são boarding schools
Existe ainda uma outra classificação dentro do sistema britânico, que são as Grammar schools, destinadas aos alunos mais bem dotados academicamente
De outro lado, ainda existem as escolas especiais, que atendem alunos com necessidades educativas especiais, embora o sistema regular (mainstream) acolha estes alunos em regime de educação inclusiva.
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


Proteínas são macromoléculas biológicas constituídas por uma ou mais cadeias de aminoácidos
As proteínas estão presentes em todos os seres vivos e participam de praticamente todos os processos celulares, desempenhando um vasto conjunto de funções no organismo, como a replicação de ADN, a resposta a estímulos e o transporte de moléculas
Muitas proteínas são enzimas que catalisam reações bioquímicas vitais para o metabolismo
As proteínas têm também funções estruturais ou mecânicas, como é o caso da actina e da miosina nos músculos e das proteínas no citoesqueleto, as quais formam um sistema de andaimes que mantém a forma celular
Outras proteínas são importantes na sinalização celular, resposta imunitária e no ciclo celular
As proteínas diferem entre si fundamentalmente na sua sequência de aminoácidos, que é determinada pela sua sequência genética e que geralmente provoca o seu enovelamento numa estrutura tridimensional específica que determina a sua atividade.
Ao contrário das plantas, os animais não conseguem sintetizar todos os aminoácidos de que necessitam para viver
Os aminoácidos que o organismo não é capaz de sintetizar por si próprio são denominados aminoácidos essenciais e devem ser obtidos pelo consumo de alimentos que contenham proteínas, as quais são transformadas em aminoácidos durante a digestão
As proteínas podem ser encontradas numa ampla variedade de alimentos de origem animal e vegetal
A carne, os ovos, o leite e o peixe são fontes de proteínas completas
Entre as principais fontes vegetais ricas em proteína estão as leguminosas, principalmente o feijão, as lentilhas, a soja ou o grão-de-bico
A grande maioria dos aminoácidos está disponível na dieta humana, pelo que uma pessoa saudável com uma dieta equilibrada raramente necessita de suplementos de proteínas
A necessidade é também maior em atletas ou durante a infância, gravidez ou amamentação, ou quando o corpo se encontra em recuperação de um trauma ou de uma operação
Quando o corpo não recebe as quantidades de proteínas necessárias verifica-se insuficiência e desnutrição proteica, a qual pode provocar uma série de doenças, entre as quais atraso no desenvolvimento em crianças ou kwashiorkor.
Uma proteína contém pelo menos uma cadeia polímérica linear derivada da condensação de aminoácidos, ou polipeptídeo
Os resíduos individuais de aminoácidos estão unidos entre si através de ligações peptídicas
A sequência dos resíduos de aminoácidos em cada proteína é definida pela sequência de um gene, a qual está codificada no código genético
Durante ou após o processo de síntese, os resíduos de uma proteína são muitas vezes alterados quimicamente através de modificação pós-traducional, a qual modifica as propriedades físicas e químicas das proteínas, o seu enovelamento, estabilidade, atividade e, por fim, a sua função
Nalguns casos as proteínas têm anexados grupos não peptídicos, os quais são denominados cofatores ou grupos prostéticos
As proteínas podem também trabalhar em conjunto para desempenhar determinada função, agrupando-se em complexos proteicos
As proteínas podem ser purificadas a partir de outros componentes celulares recorrendo a diversas técnicas, como a precipitação, ultracentrifugação, eletroforese e cromatografia
Entre os métodos usados para estudar a estrutura e funções das proteínas estão a imuno-histoquímica, mutagénese sítio-dirigida, ressonância magnética nuclear e espectrometria de massa.


As proteínas são nutrientes essenciais ao corpo humano
Enquanto a maior parte dos microorganismos e das plantas são capazes de biosintetizar todos os vinte aminoácidos-padrão, os animais, incluindo os seres humanos, necessitam de obter alguns desses aminoácidos a partir da dieta alimentar
Isto deve-se à ausência nos animais de algumas enzimas-chave que têm como função sintetizar esses aminoácidos
Os aminoácidos que o organismo não é capaz de sintetizar por si próprio são denominados aminoácidos essenciais
Os animais podem obter aminoácidos através do consumo de alimentos que contenham proteínas
As proteínas ingeridas são transformadas em aminoácidos através da digestão, a qual envolve a desnaturação da proteína através da exposição ao ácido e à hidrólise por parte de enzimas denominadas proteases
Alguns dos aminoácidos ingeridos são usados para a biosíntese proteica, enquanto outros são convertidos em glicose, através de gliconeogénese, ou entram no ciclo do ácido cítrico.
Além de constituírem a fundação dos tecidos do corpo, as proteínas são também uma fonte de energia
Enquanto fonte de energia, contêm 4 kcal por grama, valor semelhante aos hidratos de carbono, mas diferente dos lípidos, os quais contêm 9 kcal por grama
Durante a digestão, as proteínas são separadas no estômago em cadeias polipeptídicas mais pequenas através da ação do ácido clorídrico e da protease
Isto é essencial para a síntese dos aminoácidos essenciais que não podem ser biossintetizados pelo corpo.
Os aminoácidos essenciais são a leucina, isoleucina, valina, lisina, treonina, triptófano, metionina, fenilalanina e histidina
Os aminoácidos não essenciais são a alanina, asparagina, ácido aspártico e ácido glutâmico
Os aminoácidos condicionalmente essenciais são a arginina, cisteína, glutamina, glicina, prolina, serina e tirosina
Os aminoácidos encontram-se em diversas fontes alimentares de origem animal, como a carne, leite, peixe e ovos
As proteínas estão também disponíveis através de diversas fontes vegetais: cereais integrais, leguminosas, incluindo os secos, soja, fruta nozes e sementes
Os vegetarianos e vegans podem obter os aminoácidos essenciais necessários através da ingestão de diversas proteínas vegetais.
As proteínas são nutrientes essenciais ao crescimento e manutenção do corpo humano
Com a exceção da água, as proteínas são as moléculas mais abundantes no corpo, sendo o principal componente estrutural de todas as células, particularmente dos músculos
As proteínas são também usadas em membranas, como é o caso das glicoproteínas
Depois de serem repartidas em aminoácidos, são usadas como precursores do ácido nucleico, coenzimas, hormonas, resposta imunitária, reparação das células e outras moléculas essenciais para a vida
As proteínas são ainda fundamentais para a formação de células sanguíneas
Acredita-se que as proteínas aumentem o desempenho atlético
Os aminoácidos são usados na produção de tecido muscular e na reparação de tecido danificado
As proteínas só são usadas como fonte de energia quando os recursos de hidratos de carbono e lipídos no corpo diminuem.
As proteínas podem ser encontradas numa ampla variedade de alimentos
A combinação mais adequada de fontes de proteína para cada pessoa depende da região, da acessibilidade, do custo económico, do tipo de aminoácidos e do equilíbrio nutricional, assim como do próprio paladar
Embora alguns alimentos sejam fontes ricas em determinados aminoácidos, o seu valor para na nutrição humana é limitado devido à sua pouca digestibilidade, a fatores antinutricionais, à elevada quantidade de calorias, ao colesterol ou à densidade mineral.
A carne, os ovos, o leite e o peixe são fontes de proteínas completas
Entre as fontes vegetais ricas em proteína estão as leguminosas, nozes, sementes e fruta
As leguminosas têm maior concentração de aminoácidos e são fontes mais completas de proteína do que os cereais e os cereais integrais
Entre os alimentos vegetarianos com concentração de proteínas superior a 7% estão a soja, lentilhas, feijão vermelho e branco, feijão-frade, feijão-da-china, grão-de-bico, feijão-verde, tremoço, amêndoa, castanha-do-pará, cajueiro, noz-pecã e sementes de sésamo, de abóbora, de algodão e de girassol.
Entre os alimentos de base que constituem uma fonte pobre em proteínas estão raízes e tubérculos como o inhame, mandioca e batata-doce, os quais contêm apenas entre 0 e 2% de proteínas
A fruta, embora seja rica noutros nutrientes essenciais, é uma fonte relativamente pobre de aminoácidos
A banana-da-terra é também pobre em proteínas
Para uma alimentação saudável, os alimentos básicos com baixo teor de proteína devem ser complementados com alimentos com proteínas completas e de qualidade, sobretudo durante o desenvolvimento das crianças.
A grande maioria dos aminoácidos está disponível na dieta humana, pelo que uma pessoa saudável com uma dieta equilibrada raramente necessita de suplementos de proteínas
Os aminoácidos mais limitados são a lisina, a treonina e os aminoácidos com enxofre
A tabela em anexo mostra os mais importantes grupos alimentares que constituem fontes de proteínas, sob uma perspetiva mundial
Também lista o desempenho de cada grupo enquanto fonte dos aminoácidos mais limitados, em valores de miligramas de aminoácido limitado por cada grama de proteína total nesse alimento.
Existe um debate considerável sobre as necessidades relativas ao consumo de proteínas
A quantidade de proteínas necessária na dieta de determinada pessoa é determinada em grande parte pelo consumo total de energia e hidratos de carbono, pela necessidade do corpo de nitrogénio e aminoácidos essenciais, composição e massa corporal, taxa de crescimento, nível de atividade física e presença de lesões ou doenças
A atividade física elevada e o aumento da massa muscular aumentam a necessidade de proteínas
A necessidade é também maior durante a infância, gravidez ou amamentação, ou quando o corpo se encontra em recuperação de um trauma ou de uma operação.
De acordo com os valores de referência de ingestão de proteínas da Autoridade Europeia para a Segurança Alimentar, os adultos, incluindo idosos, devem ingerir 0,83 g de proteína por dia por cada quilograma de peso corporal; os recém-nascidos, crianças e adolescentes devem ingerir entre 0,83 e 1,31 g/kg/dia, dependendo da idade
As grávidas devem ingerir valores suplementares de proteína: 1 g, 9g e 28g suplementares por dia durante o primeiro, segundo e terceiro trimestres, respetivamente
As lactantes devem também ingerir valores suplementares: 19 g por dia durante os primeiros seis meses de amamentação e 13 g por dia a partir dos seis meses
De acordo com as recomendações norte-americanas e canadianas, as mulheres com idade entre 19 e 70 anos necessitam de consumir 46 g de proteínas por dia, enquanto os homens no mesmo intervalo etário necessitam de consumir pelo menos 56 g de proteínas por dia
O valor geralmente recomendado para o consumo diário é de 0,8 g de proteínas por cada quilograma de massa corporal
No entanto, esta recomendação baseia-se nas necessidades estruturais, sem considerar o uso de proteínas no metabolismo energético, pelo que se adequa a uma pessoa relativamente sedentária
 Diversos estudos têm concluído que as pessoas ativas e os atletas possam exigir um consumo superior de proteínas, devido ao aumento da massa muscular e da sudação, e da maior necessidade de proteínas enquanto fonte de energia e reparação do corpo
Para estes casos, os valores sugeridos têm oscilado entre 1,6 g/kg e 1.8 g/kg.
Para compensar as variações na ingestão de proteínas ao longo do dia, ou em casos de emergência em que a ingestão de proteínas é temporariamente alta ou baixa, o corpo tenta equilibrar os níveis de proteínas recorrendo a uma reserva de curta duração
No entanto, o corpo é incapaz de armazenar o excesso de proteínas a longo prazo
As proteínas são digeridas em aminoácidos que entram na corrente sanguínea
Os aminoácidos em excesso são convertidos pelo fígado em moléculas úteis, num processo denominado desaminação
A desaminação converte o nitrogénio dos aminoácidos em amónia, a qual é por sua vez convertida pelo fígado em ureia durante o ciclo da ureia
A ureia é depois excretada pelos rins.
O consumo excessivo de proteínas provoca também o aumento da excreção de cálcio na urina, o que se pensa ser devido ao desequilíbrio no pH, agravando o risco da formação de cálculos no sistema urinário
Um estudo epidemiológico de 2006 não verificou a existência de qualquer relação entre o consumo total de proteína e a pressão arterial, embora tenha verificado uma relação inversa entre o consumo de proteína vegetal e a pressão arterial.
Quando o corpo não recebe as quantidades de proteínas necessárias verifica-se insuficiência e desnutrição proteica, a qual pode provocar uma série de doenças, entre as quais atraso no desenvolvimento em crianças, kwashiorkor, pigmentação avermelhada do cabelo e da pele, fígado gorduroso, diarreia, dermatose e diminuição na contagem de linfócitos T, o que aumenta o risco de infeções secundárias
A desnutrição proteica é relativamente comum à escala mundial, tanto em adultos como crianças, e é responsável por cerca de seis milhões de mortes anualmente
Nos países desenvolvidos, esta doença verifica-se predominantemente em idosos ou em hospitais, geralmente associada a outras doenças.
As dietas de alto teor proteico podem ajudar a perder peso ao fazer com que a pessoa se sinta cheia mais rapidamente
Na maioria das pessoas saudáveis, este tipo de dietas não apresenta riscos para a saúde, sobretudo se for seguida durante um curto período de tempo
No entanto, os riscos a longo prazo estão ainda em estudo
O recurso prolongado a este tipo de dieta, geralmente associadas com a limitação do consumo de hidratos de carbono, pode causar insuficiências nutricionais e falta de fibras, o que por sua vez provoca dores de cabeça e obstipação
Algumas destas dietas baseiam-se no aumento do consumo de carne vermelha e lacticínios gordos, o que aumenta o risco de doenças cardiovasculares
As escolhas mais saudáveis para uma dieta de alto teor proteico incluem proteína de soja, feijão, nozes, peixe, aves de criação sem pele, carne de porco e lacticínios magros, devendo ser evitadas as carnes vermelhas e processadas.
A maior parte das proteínas consiste em polímeros lineares formados a partir de um máximo de 20 L-α-aminoácidos
Todos os aminoácidos proteinogénicos têm em comum diversas características estruturais, entre as quais um carbono alfa, ao qual estão quimicamente ligados um grupo de aminas, um grupo de ácido carboxílico e uma cadeia lateral variável
Apenas a prolina difere desta estrutura básica
As cadeias laterais dos aminoácidos comuns apresentam uma grande variedade de propriedades e estruturas químicas
É o efeito combinado de todas as cadeias laterais numa proteína que determina a sua estrutura tridimensional e reatividade química
Os aminoácidos numa cadeia de polipeptídios são unidos por ligações peptídicas
Uma vez unidos na cadeia proteica, cada aminoácido individual é denominado "resíduo", e cada série repetitiva e encadeada de átomos de carbono, nitrogénio e oxigénio é denominada "cadeia principal".
A ligação peptídica tem duas formas de ressonância que contribuem para a formação de uma ligação dupla e inibem a rotação em torno do seu próprio eixo, pelo que os carbonos alfa são aproximadamente coplanares
Os outros dois ângulos diedros na ligação peptídica determinam a forma assumida pela cadeia principal
A extremidade da proteína com um grupo carboxílico livre é denominada C-terminal ou carboxi-terminal, enquanto a extremidade com um grupo livre de amina é denominada N-terminal ou amino-terminal
Os termos "proteína", "polipetídeo" e "peptídeo" são ligeiramente ambíguas e o seu significado pode-se sobrepôr
"Proteína" é geralmente usado para nos referirmos à molécula biológica completa na sua forma terciária estável, enquanto "peptídeo" está geralmente reservado para oligómeros curtos de aminoácidos, aos quais muitas vezes falta uma estrutura tridimensional estável
No entanto, a diferença entre ambos não é bem definida e geralmente corresponde a 20-30 resíduos
"Polipetídeo" pode ser referente a qualquer cadeia linear de aminácidos, independentemente do comprimento, mas onde geralmente não existe uma forma terciária.
As proteínas são produzidas a partir de aminoácidos usando informação codificada nos genes
Cada proteína tem a sua própria sequência de aminoácidos que é especificada pela sequência de nucleótidos do gene que codifica a proteína
O código genético é um grupo de conjuntos com três nucleótidos cada um, denominados codões
Cada uma das combinações de três nucleótidos designa um aminoácido
Por exemplo, AUG (adenina-uracilo-guanina) é o código para a metionina
Uma vez que o ADN contém quatro nucleótidos, o número total de codões possíveis é de 64
Por este motivo, existe alguma redundância no código genético, havendo alguns aminoácidos que são especificados por mais de um codão
Os genes que são codificados no ADN são inicialmente transcritos para pré-ARN mensageiro (ARNm) por proteínas como a ARN-polimerase
A maior parte dos organismos processa em seguida o pré-ARNm, usando várias formas de modificação pós-transcricional, formando assim o ARNm amadurecido, o qual é então usado como molde para a síntese proteica feita pelo ribossoma
Nos procariontes, o ARNm tanto pode ser utilizado assim que é produzido, como ser ligado a um ribossoma depois de se ter afastado do nucleoide
Por outro lado, os eucariontes produzem ARNm no núcleo celular, o qual é depois translocado através do envelope nuclear para o citoplasma, no qual se dá a síntese proteica
A velocidade de síntese proteica é maior nos procariontes do que nos eucariontes, podendo atingir os 20 aminoácidos por segundo.
O processo de síntese de uma proteína a partir de um molde de ARNm é denominado tradução
O ARNm é carregado no ribossoma, no qual são lidos três nucleótidos de cada vez
A leitura é feita fazendo corresponder cada codão com o seu anticodão situado numa molécula de ARN transportador (ARNt), a qual transporta o aminoácido correspondente ao codão por si reconhecido
A enzima aminoacil-tRNA sintetase carrega as moléculas de ARNt com o aminoácido correto
As proteínas são sempre sintetizadas a partir do N-terminal em direção ao C-terminal.
O tamanho de uma proteína sintetizada pode ser medido através do número de aminoácidos e da sua massa molecular total, valor que é geralmente expresso em daltons (Da), sinónimo de unidade de massa atómica
As proteínas das leveduras, por exemplo, têm em média um comprimento de 466 aminoácidos e 53 kDa de massa
As maiores proteínas conhecidas são as titinas, com quase 3000 kDA de massa molecular de 27 000 aminoácidos de comprimento.
As proteínas curtas podem também ser sintetizadas quimicamente através de uma série de métodos denominados síntese de peptídeos, os quais têm por base técnicas de síntese orgânica de elevado rendimento na produção de peptídeos
A síntese química permite a introdução de aminoácidos não naturais nas cadeias de peptídeos
Estes métodos são úteis em laboratórios de bioquímica e biologia celular, embora não se adequem à produção comercial
A síntese química não é eficiente para polipeptídeos maiores do que 300 aminoácidos, e as proteínas sintetizadas podem não assumir imediatamente a sua estrutura terciária nativa
Grande parte dos métodos de síntese química realiza-se a partir do C-terminal em direção ao N-terminal, ao contrário da reação biológica natural.
A maior parte das proteínas enovela-se em estruturas tridimensionais distintas
A forma para a qual uma proteína se enovela naturalmente é denominada conformação nativa
Embora haja muitas proteínas capazes de se enovelar sem assistência, meramente através das propriedades químicas dos seus aminoácidos, há outras que necessitam do auxílio de chaperonas moleculares de modo a se poderem enovelar para a sua conformação nativa
As proteínas podem ter 4 tipos de estruturas dependendo do tipo de aminoácidos, do tamanho da cadeia e da configuração espacial da cadeia polipeptídica: estrutura primária, secundária, terciária e quaternária.
As proteínas não são moléculas completamente rígidas
Para além destes níveis estruturais, as proteínas podem alternar entre várias estruturas enquanto desempenham as suas funções
No contexto destas alterações funcionais, estas estruturas terciárias ou quaternárias são muitas vezes denominadas "conformações", e as transições entre cada uma delas são denominadas "alterações conformacionais"
Estas alterações são frequentemente induzidas pela ligação de uma molécula substrato ao sítio ativo de uma enzima – a região física da proteína que participa na catálise química.
As proteínas podem ser divididas informalmente em três classes principais, de acordo com as estruturas terciárias mais comuns: proteínas globulares, proteínas fibrilares e proteínas membranares
Praticamente todas as proteínas globulares são solúveis e grande parte são enzimas
As proteínas fibrilares são muitas vezes estruturais, como é o caso do colagénio, o principal componente do tecido conjuntivo, ou a queratina, a proteína constituinte do cabelo e das unhas
As proteínas membranares atuam muitas vezes como recetores ou proporcionam canais para que as moléculas possam atravessar a membrana celular.
É a sequência linear de aminoácidos ao longo da cadeia polipeptídica da proteína
É o nível estrutural mais simples e mais importante, pois dele deriva todo o arranjo espacial da molécula
É específica para cada proteína, sendo, geralmente, determinada geneticamente
A estrutura primária da proteína resulta numa longa cadeia de aminoácidos, com uma extremidade "amino terminal" e uma extremidade "carboxi terminal".
É a forma como os aminoácidos se organizam entre si na sequência primária da proteína
Ocorre graças à possibilidade de rotação das ligações entre os carbonos alfa dos aminoácidos e os seus grupos amina e carboxilo
O arranjo secundário de uma cadeia polipeptídica pode ocorrer de forma regular; isso acontece quando os ângulos das ligações entre carbonos alfa e seus ligantes são iguais e se repetem ao longo de um segmento da molécula
A cadeia polipeptídica pode interagir com ela própria através de duas formas principais: pela formação das alfa-hélices e das folhas-beta
Além destas existem estruturas que não são nem hélices nem folhas chamadas laços (loops).
A estrutura terciária é a forma como determinada molécula de proteína se organiza no espaço
Corresponde ao movimento, à organização das alfa-hélices, fitas b e voltas no espaço tridimensional, definido por coordenadas atómicas
Resulta do enovelamento das hélices e das folhas pregueadas de uma estrutura secundária e é mantida nessa posição por interações hidrófugas e hidrófilas.
A estrutura quaternária de uma proteína refere-se à união de várias moléculas proteicas enoveladas num complexo multi-proteico
A interação entre as moléculas é realizada através de ligações não covalentes.
A descoberta da estrutura terciária de uma proteína, ou da estrutura quaternária dos seus complexos, pode fornecer dados importantes acerca da forma como a proteína realiza a sua função
Entre os métodos mais comuns para determinar a estrutura estão a cristalografia de raios X e a ressonância magnética nuclear de proteínas (RMN), ambas capazes de produzir dados à escala atómica
No entanto, a RMN pode disponibilizar dados a partir dos quais é possível determinar as distâncias entre subconjuntos de pares de átomos, permitindo assim determinar todas as conformações finais possíveis de determinada proteína
A interferometria de dupla polarização é um método analítico que permite medir a conformação e as alterações conformacionais das proteínas em função de interações ou de outros estímulos
O dicroísmo circular é outra técnica laboratorial que permite determinar a composição das proteínas a nível de hélices e folhas beta
A crio-microscopia eletrónica (crio-EM) é usada para produzir informação de baixa resolução sobre complexos proteicos de grande dimensão, entre os quais vírus
Uma variante denominada cristalografia eletrónica é, nalguns casos, capaz de produzir informação de elevada resolução, em particular nos cristais bidimensionais de proteínas membranares.
As estruturas resolvidas são geralmente acrescentadas ao Protein Data Bank (PDB), um recurso disponível gratuitamente que permite consultar os dados estruturais de milhares de proteínas
Conhece-se um número muito maior de sequências genéticas do que estruturas proteicas
Além disso, o conjunto de estruturas resolvidas tende a focar-se naquelas que podem ser facilmente adequadas às condicionantes da cristalografia de raio X
As proteínas globulares, em particular, são as mais fáceis de preparar para a cristalografia de raio X, enquanto as proteínas membranares são difíceis de cristalizar e comparativamente pouco representadas no PDB
As iniciativas de genómica estrutural têm vindo a tentar corrigir esta assimetria através da resolução sistemática das estruturas representativas das principais classes de enovelamento
Para além disso, existem ainda métodos de previsão de estruturas proteicas que tentam fornecer uma estrutura plausível para proteínas cujas estruturas ainda não foram determinadas experimentalmente.
As proteínas são os principais intervenientes no interior das células, realizando as tarefas determinadas pela informação codificada nos genes
Excetuando determinados tipos de ARN, a maior parte das restantes moléculas biológicas são elementos relativamente inertes nos quais as proteínas atuam
As proteínas são também o principal componente celular; por exemplo, metade do peso de uma célula de Escherichia coli corresponde a proteínas, enquanto outras macromoléculas como o ADN e o ARN correspondem apenas a 3% e 20% do peso, respectivamente
O conjunto de proteínas que podem ser expressas numa determinada célula ou tipo celular é denominado proteoma.
A principal característica das proteínas, a qual também permite que exerçam um conjunto alargado de funções, é a sua capacidade de ligarem a si outras moléculas, de forma estável e específica
A região da proteína responsável pela agregação de outras moléculas é denominada sítio de ligação, a qual geralmente corresponde a uma depressão na superfície molecular da proteína
Esta capacidade de ligação é mediada pela estrutura terciária da proteína, a qual define a região de ligação, e pelas propriedades químicas das cadeias de aminoácidos laterais
As ligações proteicas podem ser extremamente específicas; por exemplo, a proteína inibidora da ribonuclease liga-se à angiogenina humana, mas não se liga à sua homóloga anfíbia rampirnase
Há variações químicas extremamente subtis que, por vezes, podem ser o suficiente para eliminar por completo a possibilidade de ligação proteica; por exemplo, o aminoacil-tRNA sintetase específico do aminoácido valina não é capaz de se ligar à cadeia lateral do aminoácido isoleucina, muito similar.
As proteínas podem-se ligar não só a outras proteínas, como também a substratos de pequenas moléculas
Quando as proteínas se ligam especificamente a outras cópias da mesma molécula, são capazes de se oligomerizar para formar fibrilas
Este processo ocorre frequentemente em proteínas estruturais constituídas por monómeros globulares que se associam entre si para formar fibras rígidas
As interações entre proteínas regulam também a atividade enzimática, controlam a progressão ao longo do ciclo celular e permitem a formação de complexos proteicos que desempenham diversas reações no âmbito de uma mesma função biológica
As proteínas também se ligam a membranas celulares
A capacidade de ligarem a si parceiros que induzem alterações conformacionais nas proteínas permite a construção de redes de sinalização celular extremamente complexas
Uma vez que as interações entre proteínas são reversíveis, e dependem da disponibilidade de diferentes grupos de proteínas para formar agregados capazes de desempenhar um conjunto alargado de funções, o estudo das interações entre proteínas específicas é fundamental para compreender aspetos importantes da função celular e, por fim, as propriedades que distinguem diferentes tipos de células.
As proteínas podem atuar na célula enquanto enzimas, as quais são catalisadoras de reações químicas
As enzimas são, regra geral, extremamente específicas e aceleram apenas uma única ou muito poucas reações químicas
As enzimas realizam maior parte das reações que fazem parte do metabolismo e manipulam ADN em vários processos, como a replicação de ADN, reparação de ADN e transcrição genética
Algumas enzimas atuam sobre outras proteínas no sentido de acrescentar ou remover grupos químicos, um processo denominado modificação pós-translacional
São conhecidas cerca de 4000 reações químicas catalisadas por enzimas
A taxa de aceleração proporcionada pela catálise é muitas vezes imensa, podendo chegar a valores na magnitude de 10 em relação à reação não catalisada, o que faz com que um processo que naturalmente demoraria 78 milhões de anos, com a enzima seja completo em apenas 18 milissegundos
Os compostos químicos que sofrem reações enzimáticas são denominados substratos
Embora as enzimas possam ser constituídas por centenas de aminoácidos, só uma pequena percentagem dos resíduos é que entra em contacto com o substrato e uma percentagem ainda mais pequena – três a quatro resíduos, em média – é que está diretamente envolvida na catálise.
As proteínas estruturais conferem rigidez a componentes biológicos que, de outra forma, seriam apenas fluidos
A maior parte das proteínas estruturais são proteínas fibrilares; por exemplo, o colagénio e a elastina são componentes fundamentais do tecido conjuntivo, como a cartilagem, enquanto a queratina está presente em estruturas duras como o cabelo, unhas, penas, cascos e algumas carapaças animais
Algumas proteínas globulares podem também desempenhar funções estruturais; por exemplo, a actina e a tubulina são globulares e solúveis enquanto monómeros, mas são capazes de se polimerizar nas fibras rígidas e longas que formam o citoesqueleto, o qual permite à célula manter a sua forma e tamanho
Outras proteínas que têm funções estruturais são as proteínas motoras como a miosina, cinesina e a dineína, as quais são capazes de gerar força mecânica, como a que contrai os músculos
Estas proteínas são cruciais para a motilidade de organismos unicelulares e dos espermatozoides dos organismos multicelulares que se reproduzem através de reprodução sexuada.
Muitas das proteínas estão envolvidas nos processos de sinalização celular e transdução de sinal
Algumas delas, como a insulina, são proteínas extracelulares que transmitem um sinal para outras células em tecidos distantes, a partir da célula onde são sintetizadas
Outras são proteínas membranares que atuam enquanto recetores, cuja principal função é ligar a si uma molécula sinalizadora e induzir uma resposta bioquímica na célula
Muitos dos recetores têm na sua superfície um sítio de ligação e um domínio efetor dentro da célula, o qual pode ter atividade enzimática ou sofrer alterações conformacionais que são detetadas por outras proteínas no interior da célula.
Os anticorpos são componentes proteicos do sistema imunitário adquirido, cuja função principal é ligar a si antigénios ou outras substâncias estranhas ao corpo, marcando-os para serem destruídos
Os anticorpos podem ser segregados para o ambiente extracelular ou ancorados nas membranas de linfócitos B especializados, denominados plasmócitos
Enquanto as enzimas são extremamente limitadas na sua capacidade de ligação, resumindo-se aos substratos necessários para realizar a sua função enzimática, os anticorpos não têm esta restrição, apresentando uma afinidade extremamente elevada.
Muitas das proteínas que transportam ligantes são capazes de ligar a si pequenas biomoléculas, transportando-as para diferentes locais do corpo
Estas proteínas devem ter uma elevada afinidade de ligação nos casos em que o seu ligante esteja presente em elevada concentração, mas serem também capazes de libertar o ligante nos casos em que a sua concentração nos tecidos-alvo seja diminuta
O exemplo canónico de uma proteína ligante é a hemoglobina, a qual transporta o oxigénio dos pulmões para os restantes órgãos e tecidos em todos os vertebrados e tem homólogos em todos os reinos
As proteínas transmembranares atuam também enquanto proteínas transportadoras de ligantes, capazes de alterar a permeabilidade da membrana celular em relação a pequenas moléculas e a iões
A própria membrana tem um núcleo hidrófugo, através do qual as moléculas polarizadas ou carregadas eletrónicamente não são capazes de se difundir
As proteínas membranares possuem canais internos que permitem a este tipo de moléculas entrar e sair da célula
Muitas proteínas com canais iónicos são especializadas no sentido de selecionar apenas um ião em particular; por exemplo, os canais de potássio e sódio muitas vezes aceitam apenas um dos dois iões.
A acumulação de proteínas mal enoveladas pode causar doenças amiloides, um grupo de várias doenças comuns, entre as quais a doença de Alzheimer, doença de Parkinson e doença de Huntington
O risco destas doenças aumenta significativamente com a idade
À medida que o ser humano envelhece, o equilíbrio da síntese, enovelamento e degradação das proteínas vai sofrendo distúrbios, o que provoca a acumulação de proteínas mal enoveladas em agregados
No entanto, as doenças causadas pela agregação de proteínas mal enoveladas não são exclusivas do sistema nervoso central e podem-se manifestar em tecidos periféricos, como no caso da diabetes mellitus tipo 2, cataratas hereditárias, algumas formas de aterosclerose, distúrbios relacionados com a hemodiálise e amiloidose, entre outras
Os genes e produtos proteicos envolvidos nestas doenças denominam-se amiloidogénicos e todas estas doenças têm em comum a expressão de uma proteína fora do seu contexto normal
Em todas estas doenças, a agregação de proteínas pode ser causada por mero acaso, por hiperfosforilação proteica, por mutações que tornam a proteína instável ou ainda pelo aumento desregulado ou patológico da concentração de algumas destas proteínas entre as células
Estes desiquilíbrios na concentração podem ser causados por mutações dos genes amiloidogénicos, alterações na sequência de aminoácidos da proteína ou por deficiências no proteassoma.
As proteínas são uma das moléculas biológicas mais intensivamente estudadas, quer in vitro, in vivo ou in silico
O estudo in vitro de proteínas purificadas em ambiente controlado é útil na aprendizagem da forma como as proteínas desempenham as suas funções; por exemplo, o estudo da cinética enzimática explora o mecanismo químico da atividade catalítica de uma enzima e a sua afinidade relativa em relação às possíveis moléculas substrato
Por outro lado, as experiências in vivo podem fornecer dados sobre o papel fisiológico da proteína no contexto de uma célula ou de um organismo
O estudo in silico recorre a métudos computacionais para estudar proteínas.
Antes de se poder efetuar uma análise in vitro, a proteína deve ser purificada dos restantes componentes celulares
Este processo de purficação geralmente tem início com a citólise da célula, através da qual a membrana celular é rompida e o conteúdo interno libertado para uma solução denominada lisado bruto
A mistura daí resultante pode ser purificada através de ultracentrifugação, a qual fracciona os vários componentes celulares em frações que contêm proteínas solúveis, proteínas e lípidos membranares, organelas celulares e ácidos nucleicos
As proteínas deste lisado são então concetradas através de precipitação, feita através do método de relargagem
São depois usados vários tipos de cromatografia para isolar a proteína ou as proteínas pretendidas, de acordo com propriedades como o peso molecular ou afinidade de ligação
O nível de purificação pode ser monitorizado através de vários tipos de eletroforese em gel, quando são conhecidos o peso molecular e o ponto isoelétrico, através de espectroscopia, quando a proteína possui características espectroscópicas distintas, ou através de análise enzimática, quando a enzima tem atividade enzimática
As proteínas podem ainda ser isoladas de acordo com a sua carga através de focalização isoelétrica.
No caso das proteínas naturais, podem ser necessárias mais etapas no processo de purificação de forma a obter proteínas suficientemente puras para serem usadas em laboratório
Para simplificar este processo, recorre-se muitas vezes a engenharia genética para acrescentar às proteínas características químicas que as tornem mais fáceis de serem purificadas sem, no entanto, afetar a sua estrutura ou atividade
Neste caso, a um dos terminais da proteína é acrescentada uma etiqueta constituída por uma sequência de aminoácidos específica, geralmente uma série de resíduos de histidina (etiqueta de poli-histidina)
Desta forma, quando o lisado é passado sobre uma coluna de cromatografia contendo níquel, os resíduos de histidina ligam-se com o níquel e agarram-se à coluna, enquanto os componentes do lisado sem a etiqueta passam sem entraves
Têm vindo a ser desenvolvidas diversas etiquetas de modo a auxiliar os investigadores na purificação de proteínas a partir de misturas complexas.
O estudo de proteínas in vivo dedica-se às questões relacionadas com a síntese e localização de proteínas no interior de células
Embora muitas das proteínas intrecelulares sejam sintetizadas no citoplasma e as proteínas segregadas sejam sintetizadas no retículo endoplasmático, o processo específico de como as proteínas se orientam para organelas ou estruturas celulares específicas é em muitas situações pouco claro
Uma das técnicas para avaliar a localização celular recorre a engenharia genética para expressar numa célula uma proteína de fusão, a qual é constituída pela proteína em estudo ligada a um gene repórter, como por exemplo a proteína verde fluorescente
A posição da proteína de fusão na célula pode então ser facilmente visualizada através de microscopia.
Outros métodos para obtenção da localização celular de proteínas requerem o uso de marcadores compartimentais conhecidos para diversas regiões celulares
Com o uso de versões destes marcadores etiquetadas com fluorescência, torna-se mais simples a identificação e localização da proteína pretendida.
A técnica padrão para localização celular é a microscopia imunoeletrónica
Esta técnica usa um anticorpo para a proteína pretendida, a par de técnicas clássicas de microscopia eletrónica
A amostra é preparada para uma análise microscópica padrão, sendo depois tratada com um anticorpo dessa proteína que é conjugado com um material eletro-denso, geralmente ouro
Através de mutagénese sítio-dirigida, os investigadores podem alterar a sequência proteica, alterando dessa forma a sua estrutura, localização celular e suscetibilidade à regulação
Esta técnica permite ainda a incorporação nas proteínas de aminoácidos não naturaus, usando ARNt modificado, podendo ainda permitir a conceção de novas proteínas com novas proriedades.
O conjunto total de proteínas presentes numa célula em determinado momento é denominado proteoma, e o estudo em grande escala destes conjuntos define o campo da proteómica, assim denominado em analogia ao campo relacionado da genómica
Entre as principais técnicas da proteómica estão a eletroforese bidimensional, a qual permite a separação de um vasto número de proteínas, a espectrometria de massa, a qual permite a rápida identificação de proteínas e sequenciação de peptídeos, o microarranjo de proteínas, que permite a deteção dos níveis relativos do grande número de proteínas presentes na célula, e o sistema de duplo híbrido, que permite a exploração sistemática de interações proteína-proteína
O conjunto total e biologicamente possível destas interações é denominado interactoma
O esforço sistemático para determinar as estruturas de proteínas e de todos os enovelamentos possíveis é denominado genómica estrutural.
Complementar ao campo da genómica estrutural, a previsão de estruturas das proteínas procura desenvolver métodos eficientes de fornecer modelos plausíveis para proteínas cujas estruturas não foram ainda determinadas experimentalmente
O mais bem-sucedido método de previsão estrutural, denominado modelação por homologia, assenta na existência de uma estrutura-modelo com uma sequência semelhante à proteína a ser modelada
O objetivo da genómica estrutural é fornecer uma representatividade suficiente de estruturas resolvidas que sirva de modelo a todas as restantes.
Os processos de enovelamento e ligação proteica podem ser simulados usando técnicas como a dinâmica molecular ou o método de Monte Carlo, os quais têm vindo cada vez mais a tirar partido da computação distribuída, como o projeto Folding@home
O enovelamento de pequenos domínios proteicos de alfa-hélice, como a proteína acessória do VIH, tem vindo a ser simulado com sucesso in silico
Os métodos híbridos que combinam dinâmica molecular com cálculo de mecânica quântica têm permitido a exploração dos estados eletrónicos das rodopsinas.
As proteínas foram pela primeira vez descritas pelo químico holandês Gerardus Johannes Mulder e assim batizadas pelo químico sueco Jöns Jacob Berzelius em 1838
Mulder levou a cabo análises elementares de proteínas vulgares e constatou que praticamente todas as proteínas apresentavam a mesma fórmula empírica – C400H620N100O120P1S1
Ainda que erradamente, concluiu que as proteínas deveriam ser constituídas por um único tipo de molécula de grande dimensão
O termo "proteína" para descrever estas moléculas foi proposto pelo sócio de Mulder, Berzelius
Proteína deriva da palavra grega πρωτεῖος (proteios), a qual significa "na liderança" ou "a que está à frente"
Mulder prossegui a investigação, identificando produtos da degradação proteica, como o aminoácido leucina, para o qual determinou o peso molecular quase preciso de 131 Da.
Os cientistas pioneiros no campo da nutrição, como o alemão Carl von Voit, acreditavam que a proteína era o mais importante nutriente na manutenção da estrutura corporal, uma vez que existia a crença generalizada de que seria a carne tinha origem na própria carne
Karl Heinrich Ritthausen alargou o campo das proteínas conhecidas com a identificação do ácido glutâmico
Thomas Burr Osborne compilou em 1909 uma revisão detalhada de todas as proteínas vegetais e, no mesmo ano e em conjunto com Lafayette Mendel, determinou os aminoácidos essenciais à sobrevivência de ratos de laboratório aplicando a lei de Liebig
A compreensão das proteínas enquanto polipetídeos foi proporcionada por Franz Hofmeister e Hermann Emil Fischer
O papel central das proteínas enquanto enzimas nos organismos vivos foi determinado em 1926, quando James Batcheller Sumner demonstrou que a urease era de facto uma proteína.
A dificuldade em purificar proteínas em grande quantidade dificultou imenso a investigação dos primeiros bioquímicos
Assim, a investigação inicial focou-se sobretudo em proteínas que podiam ser facilmente purificadas em quantidade, como as do sangue, da clara de ovo, diversas toxinas e enzimas digestivas obtidas em matadouros
Atribiu-se a Linus Pauling a primeira previsão bem-sucedida de de estruturas secundárias de proteínas com base nas ligações de hidrogénio, uma ideia que já tinha sido proposta em 1933 por William Astbury
Posteriormente, a investigação de Walter Kauzmann sobre a desnaturação, baseada em parte nos estudos anteriores de Kaj Ulrik Linderstrøm-Lang, veio a contribuir para a compreensão do enovelamento de proteínas e das estruturas mediadas por interações hidrófugas
A primeira proteína a ser sequenciada foi a insulina, por Frederick Sanger em 1949
Sanger determinou corretamente a sequência de aminoácidos da proteína, demonstrando de forma conclusiva que as proteínas eram constituídas por polímeros lineares de aminoácidos, em vez de cadeias ramificadas ou coloides.
As primeiras estruturas proteicas a serem resolvidas foram as da hemoglobina e da mioglobina, por Max Perutz e John Kendrew, respetivamente, em 1958
Nas décadas posteriores, a crio-microscopia eletrónica de grandes conjuntos macromoleculares e a previsão computacional de estruturas proteicas de pequenos domínios foram métodos que permitiram a investigação de proteínas à escala atómica
No início de 2014, estavam registadas no Protein Data Bank aproximadamente 90 000 estruturas proteicas com resolução atómica.




Gordura é um termo genérico para uma classe de lipídios.
As gorduras, produzidas por processos orgânicos tanto por vegetais como por animais, consistem de um grande grupo de compostos geralmente solúveis em solventes orgânicos e insolúveis em água
Sua insolubilidade na água deve-se à sua estrutura molecular, caracterizada por longas cadeias carbônicas
Por ter menor densidade, esta flutua quando misturada em água
As gorduras têm sua cadeia "quebrada" no organismo pela ação de uma enzima chamada lipase, produzida pelo pâncreas.
Quimicamente as gorduras são sintetizadas pela união de três ácidos graxos à uma molécula de glicerol, formando um éster
Elas são chamadas de triglicerídeos, triglicerídes ou mais corretamente de triacilgliceróis
As gorduras podem ser sólidas ou líquidas em temperatura ambiente, dependendo de sua estrutura e de sua composição
Usualmente o termo "gordura" se refere aos triglicerídeos em seu estado sólido, enquanto que o termo óleo, ao triglicerídeos no estado líquido.
As gorduras podem ser diferenciadas em gordura saturada e gordura insaturada, dependendo da sua estrutura química (veja abaixo)
As gorduras saturadas são encontradas normalmente nos animais, no coco e no óleo de palma, enquanto as insaturadas nos demais vegetais.


Uma regra geral é que todas as gorduras consistem de três moléculas de ácidos graxos com uma molécula de glicerol, formando uma estrutura conhecida como triacilglicerol.
As propriedades das moléculas de gordura dependem dos ácidos graxos que as formam
Os diferentes ácidos graxos são formados por um número diferente de átomos de carbono e hidrogênio.
Os átomos de carbono, cada um ligado em dois átomos de carbono vizinhos, formam uma cadeia em ziguezague quanto maior a quantidade de átomos de carbono mais longa será a cadeia
Ácidos graxos com cadeias maiores são mais suscetíveis a forças intermoleculares de atração, aumentando seu ponto de fusão (daí a consistência em temperatura ambiente)
Longas cadeias também fornecem uma quantidade maior de energia por molécula quando metabolizadas.
Os ácidos graxos que constituem a gordura também se diferenciam pelo número de átomos de hidrogênio ligados na cadeia de átomos de carbono
Cada átomo de carbono é tipicamente ligado a dois átomos de hidrogênio
Quando um ácido graxo possui esta configuração típica ele é chamado de saturado, pois os átomos de carbono estão saturados com hidrogênio.
Em outras gorduras os átomos de carbono podem estar ligados a apenas um átomo de hidrogênio e terem uma ligação dupla com um carbono vizinho
Isto resulta em um ácido graxo insaturado
Mais especificamente seria um ácido graxo monoinsaturado, enquanto um ácido graxo poli-insaturado seria um ácido graxo com mais de uma ponte dupla.
Essa categoria de moléculas é importante para inúmeras formas de vida, atuando tanto no papel metabólico como no papel estrutural.
As gorduras têm várias funções, como fonte e reserva de energia (um grama de qualquer gordura produz 9 kcal de energia), além de ser um importante isolante térmico (forma o tecido adiposo dos mamíferos) para os animais se protegerem contra o frio
São importantes para a síntese de outras substâncias, ou para o melhor funcionamento destas, como as vitaminas lipossolúveis, lipoproteínas, e alguns hormônios sexuais que dependem da existência de gordura para ter um funcionamento ideal.
As gorduras são essenciais para a maioria dos seres heterótrofos, incluindo os seres humanos
No entanto os ácidos graxos realmente essenciais são os das famílias ómega 3 e ómega 6, já que a partir destes o ser humano consegue produzir todos os demais.
Existem vitaminas que são só solubilizadas pelas gorduras, conhecidas como vitaminas lipossolúveis, como exemplo as vitaminas A,D,E, e K
Isso significa que elas só são digeridas, absorvidas e transportadas em conjunto com a gordura
Além disso a gordura é a principal fonte de ácidos graxos, muito importante na dieta.
É mais saudável o consumo de insaturada pois é mais fácil "quebrar" as cadeias insaturadas em relação as cadeias saturadas.
Carboidratos, glicídios, glícidos, glucídios, glúcides ou hidratos de carbono, são compostos de função mista do tipo poliálcool-aldeído ou poliálcool-cetona e outros compostos que, por hidrólise, dão poliálcoois-aldeídos e/ou poliálcoois-cetonas
São as biomoléculas mais abundantes na natureza, constituídas principalmente por carbono, hidrogênio e oxigênio, podendo apresentar nitrogênio, fósforo ou enxofre na sua composição.
Conforme o tamanho, os carboidratos podem ser classificados em monossacarídeos, oligossacarídeos e polissacarídeos.


Os carboidratos são compostos orgânicos constituídos por carbono, hidrogênio e oxigênio, que geralmente seguem a fórmula empírica [C(H2O)]n, sendo n ≥ 7
A proporção entre os átomos de carbono, hidrogênio e oxigênio é de 1:2:1
Contudo, alguns carboidratos não se ajustam a esta regra geral, como a fucose, por exemplo, cuja fórmula molecular é C6H12O5
Outros autores utilizam a fórmula empírica [Cx(H2O)y].
Podem ser poliidroxialdeídos ou poliidroxicetonas, isto é, possuem um grupo que pode ser aldeído ou cetona, respectivamente, e várias hidroxilas, geralmente uma em cada átomo de carbono que não faz parte do aldeído ou grupo funcional cetona
Além de carbono, hidrogênio e oxigênio, alguns carboidratos apresentam nitrogênio, fósforo ou enxofre em sua composição
Quando compostos por aldeídos são chamados de aldose, quando compostos por cetona são chamados de cetose.
Os monossacarídeos, também conhecidos como oses, são carboidratos com reduzido número de átomos de carbono em sua molécula
O "n" da fórmula geral (CnH2nOn) pode variar de 3 a 7 (trioses, tetroses, pentoses, hexoses e heptoses), sendo os mais importantes as pentoses e as hexoses (C6H12O6)
São relativamente pequenos, solúveis em água e não sofrem hidrólise
Devido à alta polaridade, os monossacarídeos são sólidos cristalinos em temperatura ambiente, e assim como os oligossacarídeos, são solúveis em água
São insolúveis em solventes não polares
Embora sejam comumente representados na forma de cadeia linear, as aldoses com quatro carbonos e todos os monossacarídeos com mais de cinco carbonos apresentam-se predominantemente em estruturas cíclicas quando em solução aquosas
A nomenclatura na cadeia cíclica da-se de acordo com a posição da hidroxila (OH)
Na glicose, por exemplo,se a OH que está ligada ao carbono um estiver abaixo do plano do anel irá se chamar de α-glicose, já se estiver acima do plano do anel irá s chamar β-glicose Com exceção da Di-hidroxicetona, todos os monossacarídeos apresentam pelo menos um carbono assimétrico, provocando a apresentação de formas isoméricas opticamente ativas

Os oligossacarídeos são carboidratos resultantes da união de duas a dez moléculas de monossacarídeos
A ligação entre os monossacarídeos ocorre por meio de ligação glicosídica, formada pela perda de uma molécula de água
O grupo mais importante dos oligossacarídeos são os dissacarídeos, formados pela união de apenas dois monossacarídeos
Quando são constituídos por três moléculas de monossacarídeos, recebem o nome de trissacarídeos.
Os oligossacarídeos são solúveis em água, mas como não são carboidratos simples como os monossacarídeos, necessitam ser quebrados na digestão para que sejam aproveitados pelos organismos como fonte de energia.
Os polissacarídeos são carboidratos grandes, às vezes ramificados, formados pela união de mais de dez monossacarídeos ligados em cadeia, constituindo, assim, um polímero de monossacarídeos, geralmente de hexoses
São insolúveis em água e portanto, não alteram o equilíbrio osmótico das células
Os polissacarídeos possuem duas funções biológicas principais, como forma armazenadora de combustível e como elementos estruturais.
Observação: existem outros tipos de polissacarídeos denominados hetropolissacarídeos que originam, por hidrólise, vários tipos diferentes de monossacarídeos
Como por exemplo o ácido hialurônico, condroitinsulfato e a heparina.
Carboidratos que ao contrário dos monossacarídeos se hidrolisam
São divididos em holosídeos e heterosídeos.
São os oligossacarídeos e polissacarídeos que, por hidrólise, produzem somente monossacarídeos
Tipo de açúcar encontrado nas plantas e vegetais.
Rafinose + 2 H2O → glicose + frutose + galactose Celulose + n H2O → n glicose.
São glicídios que sofrem hidrólise, produzindo oses (hidratos de carbono simples) e outros compostos.
Amidalina - Ácido glicônico - Ácido glicurônico - Ácido sacárico - Sorbitol - Trinitrato de celulose - Piroxilina - Acetato de celulose
Claude Bernard (Saint-Julien, 12 de Julho de 1813 — Paris, 10 de Fevereiro de 1878) foi um médico e fisiologista francês.
O historiador da ciência I
Bernard Cohen da Universidade de Harvard denominou-o "um dos maiores homens de ciência de todos os tempos"
É conhecido fundamentalmente pela criação da medicina experimental/baseada em evidências.
Depois de estudar farmácia, tem êxito no teatro como dramaturgo, mas reorienta os seus estudos para a medicina
Licencia-se em 1843
Dedicou a sua carreira à fisiologia, e foi professor no Collège de France, na Sorbonne primeiro, e depois no Museu Nacional de História Natural.
Estudou a homeostasia (constância do meio interior) por volta de 1860
Em 1865, escreveu sua memorável obra Introduction à l’étude de la médicine experimentale (Introdução ao estudo da medicina experimental).
Foi eleito para a Academia Francesa em 1868 (ocupando a Cadeira 29) e recebeu a Medalha Copley de 1876
É considerado um dos principais iniciadores da linha experimental hipotético-dedutiva, frequentemente formalizada como OHERIC: Observação - Hipótese - Experiência - Resultado - Interpretação - Conclusão
Por outro lado, trata-se de uma linha incompleta com respeito à que se apresenta na Medicina Experimental
Nela faltam duas etapas fundamentais
Não se pode colocar uma hipótese sem haver colocado o problema' que há que resolver previamente, posto que uma hipótese é uma possível resposta a uma interrogação suscitada por uma observação
A experiência prova a consequência verificável da hipótese.
Algumas das suas obras são de livre acesso (V
fac-simile em francês)
A Universidade de Lyon I ostenta o seu nome (Université Claude Bernard Lyon I).


1851: Richard Owen • 1852: Alexander von Humboldt • 1853: Heinrich Wilhelm Dove • 1854: Johannes Peter Müller • 1855: Jean Bernard Léon Foucault • 1856: Henri Milne-Edwards • 1857: Michel Eugène Chevreul • 1858: Charles Lyell • 1859: Wilhelm Eduard Weber • 1860: Robert Bunsen • 1861: Louis Agassiz • 1862: Thomas Graham • 1863: Adam Sedgwick • 1864: Charles Darwin • 1865: Michel Chasles • 1866: Julius Plücker • 1867: Karl Ernst von Baer • 1868: Charles Wheatstone • 1869: Henri Victor Regnault • 1870: James Prescott Joule • 1871: Julius von Mayer • 1872: Friedrich Wöhler • 1873: Hermann von Helmholtz • 1874: Louis Pasteur • 1875: August Wilhelm von Hofmann • 1876: Claude Bernard • 1877: James Dwight Dana • 1878: Jean-Baptiste Boussingault • 1879: Rudolf Clausius • 1880: James Joseph Sylvester • 1881: Charles Adolphe Würtz • 1882: Arthur Cayley • 1883: William Thomson • 1884: Carl Ludwig • 1885: Friedrich August Kekulé von Stradonitz • 1886: Franz Ernst Neumann • 1887: Joseph Dalton Hooker • 1888: Thomas Henry Huxley • 1889: George Salmon • 1890: Simon Newcomb • 1891: Stanislao Cannizzaro • 1892: Rudolf Virchow • 1893: George Gabriel Stokes • 1894: Edward Frankland • 1895: Karl Weierstrass • 1896: Carl Gegenbaur • 1897: Albert von Kölliker • 1898: William Huggins • 1899: John William Strutt • 1900: Marcellin Berthelot
1848 (MDCCCXLVIII, na numeração romana) foi um ano bissexto do século XIX do actual Calendário Gregoriano, da Era de Cristo, e as suas letras dominicais foram B e A (52 semanas), teve início a um sábado e terminou a um domingo.
Ano bissexto com início ao sábado




270-280 °C 
O glicogénio  ou glicogênio  é um polissacarídeo e a principal reserva energética nas células animais e bactérias como as cianobactérias, antigamente chamadas de algas azuis, encontrado, principalmente, no fígado e nos músculos
Geralmente também é encontrado nos fungos, sendo neste caso, a principal substância de reserva.


Ocorre intracelularmente como grandes agregados ou grânulos, que são altamente hidratados por apresentar uma grande quantidade de grupos hidroxila expostos, sendo capazes de formar ligações de hidrogênio com a água
É uma molécula constituída por subunidades de glicose unidas por meio de ligações
Apresenta uma ramificação a cada oito a doze unidades.
O glicogênio é especialmente abundante no fígado, onde ele constitui até 7% do peso úmido deste órgão
Neste caso é denominado glicogênio hepático, sendo encontrado em grandes grânulos, eles mesmos agregados de grânulos menores compostos por moléculas de glicogênios unitárias altamente ramificadas e com uma massa molecular média de vários milhões
Esses grânulos apresentam em uma forma intimamente unida as enzimas responsáveis pela sua síntese e degradação
A principal função do glicogênio armazenado no fígado serve para alimentar a necessidade energética das células cerebrais
No caso de se verificar uma esteatose, este é armazenado dentro de vacúolos com limites pouco definidos.
O glicogênio muscular responde em casos de hiperglicemia, pegando o açúcar da corrente sanguínea e armazena para realizar a neoglicogênese
O glicogênio muscular não é usado em resposta á hipoglicemia pelos animais porque eles precisam desse glicogênio para realizar as atividades em busca da sua fonte de alimentos, exemplo: um leão precisa correr para pegar a sua presa, se ele tivesse usado o glicogênio muscular ele não conseguiria correr.
Cada ramificação do glicogênio termina com um açúcar não redutor, sendo assim ele tem tantos terminais não redutores quantas ramificações, porém com um único terminal redutor
Quando este é utilizado como fonte de energia, suas unidades de glicose são retiradas uma a uma, a partir dos terminais não redutores
As enzimas podem agir em muitos terminais, fazendo com que este polissacarídeo se reduza a um monossacarídeo.
O glicogênio é hidrolisado pelas α- e β-amilases
A α-amilase, presente no suco pancreático e na saliva, quebra o laço glicosídico α(1→4) ao acaso, produzindo tanto maltose quanto glicose
Já a β-amilase (que também quebra o laço glicosídico α(1→4)) cliva sucessivas unidades de maltose, iniciando a partir do terminal não reduzido.
A síntese de glicogênio é o processo pelo qual a glicose é polimerizada a glicogênio, que é acumulado nas células em quantidades variáveis de acordo com o tipo celular, funcionando aí como depósito de energia acessível à célula
Em determinadas células, como nas do fígado e músculo, este processo pode ser intenso e ocorrem extensos depósitos de glicogênio
O glicogênio hepático, que chega a 150 g, é degradado no intervalo das refeições mantendo constante o nível de glicose no sangue ao mesmo tempo em que fornecem este metabólito as outras células do organismo
O glicogênio muscular, ao contrário, só forma glicose para a contração muscular.
O século XIX começou no dia 1 de janeiro de 1801 e terminou no dia 31 de dezembro de 1900
Foi um período histórico marcado pelo colapso dos impérios da Espanha, China, França, Sacro Império Romano-Germânico e Mogol
O século também testemunhou o crescimento da influência dos impérios Britânico, Russo, Alemão, Japonês, e dos Estados Unidos, estimulando conflitos militares, mas também avanços científicos e de exploração.
Depois da derrota do Império Francês e seus aliados nas Guerras Napoleônicas, o Império Britânico adquiriu a supremacia mundial, passando a controlar um quarto da população e um quinto do território mundial
Aplicando a Pax Britannica, incentivou o comércio, e lutou contra a pirataria
O século XIX foi uma era de invenções e descobertas, com significante desenvolvimento nos campos da matemática, física, química, biologia, eletricidade e metalurgia, lançando as bases para os avanços tecnológicos do século XX
A Revolução Industrial começou na Inglaterra
A Era Vitoriana foi afamada pelo emprego de jovens crianças em fábricas e minas, além de valores morais rígidos
O Japão embarcou num programa de rápida modernização após a Restauração Meiji, antes de derrotar a China, sob a Dinastia Qing, na primeira Guerra Sino-Japonesa.
Avanços medicinais, o conhecimento da anatomia humana e a prevenção de doenças que ocorreram no século XIX, foram responsáveis pela rápida aceleração do crescimento populacional no Hemisfério Ocidental
A população europeia dobrou durante o século XIX, de cerca de 200 milhões para mais de 400 milhões
A introdução de ferrovias, o primeiro grande avanço no transporte terrestre por séculos, melhorou o modo de vida das pessoas e favoreceu os grandes movimentos de urbanização nos países ao redor do globo
Várias cidades ultrapassaram populações de um milhão ou mais, durante esse século
Londres transformou-se na maior cidade do mundo e na capital do Império Britânico
A sua população expandiu de 1 milhão, em 1800, para 6,7 milhões até o final do século.
Os territórios desconhecidos pelos europeus, incluindo as vastas extensões do interior da África e Ásia, foram descobertos durante esse século
No entanto, o mesmo não ocorreu com zonas extremas do Ártico e da Antártida
Em 1890, havia precisos e detalhados mapas do globo
O liberalismo tornou-se o movimento de reforma proeminente na Europa.
A escravidão ou escravatura foi grandemente reduzida ao redor do mundo após o sucesso da Revolta Escrava no Haiti
A Inglaterra forçou bárbaros piratas a parar com as suas práticas de sequestro e escravismo, banindo a escravidão em todo seu domínio, além de cobrar que a sua marinha encerrasse com o comércio global de escravos
Os Estados Unidos, após a sua Guerra Civil, aboliram a escravidão em 1865
A escravidão brasileira foi abolida em 1888 (ver Abolicionismo)
E a servidão foi abolida na Rússia.
O século XIX também viu a rápida criação e desenvolvimento de muitos desportos, particularmente na Inglaterra e nos Estados Unidos
Assim como o futebol, rúgbi e o beisebol, muitos outros desportes foram desenvolvidos durante esse período, enquanto o Império Britânico facilitou a propagação rápida de desportos como o críquete para diferentes partes do mundo.
Além de marcar a queda da ocupação otomana dos Balcãs que levou à criação da Sérvia, Bulgária, Montenegro e Romênia na sequência da Segunda Guerra Russo-Turca, seguiu-se a grande Guerra da Crimeia.


A Primeira Revolução industrial provoca profundas mudanças na economia e na tecnologia.
O século se caracteriza por romper definitivamente com a fusão que a História havia tido com a literatura
Leopold von Ranke se compromete com a história crítica e cética
Se deixa influenciar pelas correntes filosóficas predominantes do momento, tais como o liberalismo e o nacionalismo chegando a cair inclusive no etnocentrismo, racismo e particularmente no eurocentrismo.
As reflexões sobre a sociedade de Saint-Simon produziram as tendências que modificariam as tendências historiográficas: o positivismo e o materialismo histórico, também influenciado pela dialética hegeliana
Ambas entendem que o comportamento da história se encontra submetido a leis
A primeira concebe o desenvolvimento da história como processos ordenados, a segunda o concebe como resultado de estratos sociais
Além disso, os resultados apresentados por Charles Darwin representam uma importante ruptura com os paradigmas religiosos
Ao demonstrar a Origem das Espécies Darwin coloca o ser humano em pé de igualdade com toda a natureza, questionando as ideias da sua origem divina até então dominantes.
O desenvolvimento da medicina se relaciona diretamente com a migração, superlotação das cidades e as precárias condições de vida da classe trabalhadora própria da Revolução Industrial
A sua consequência foi a proliferação das doenças infecciosas (sífilis, tuberculose) ou relacionadas com a má alimentação (pelagra, raquitismo, escorbuto)
Esses problemas são cruciais para entender a origem da medicina social de Rudolf Virchow e o sistema de saúde pública de Edwin Chadwick que dariam lugar a atual medicina preventiva
A mesma Revolução Industrial, junto com numerosas guerras e revoluções, gerariam um desenvolvimento científico generalizado que contribuiria com a instauração de condições técnicas para o triunfo da assepsia, da anestesia e da cirurgia.
As Revoluções liberais, promovendo cidadãos livre-pensadores, constroem uma nova medicina científica e empírica, desligada do místico e artesanal
Se culmina com a opressão dos velhos cânones éticos do absolutismo e o catolicismo instaurando novos cânones, novos calendários
O século XIX verá nascer a medicina experimental de Claude Bernard, a teoria de Omnia cellula a cellula de Rudolf Virchow, a teoria microbiana das doenças, a teoria da evolução das espécies de Charles Darwin, e a genética de Gregor Mendel.
Década de 1800 | Década de 1810 | Década de 1820 | Década de 1830 | Década de 1840 | Década de 1850 | Década de 1860 | Década de 1870 | Década de 1880 | Década de 1890
França (em francês: France; IPA: [fʁɑ̃s]  ouça), oficialmente República Francesa (em francês: République française; [ʁepyblik fʁɑ̃sɛz]) é um país, ou, mais especificamente, um Estado unitário desconcentrado, localizado na Europa Ocidental, com várias ilhas e territórios ultramarinos noutros continentes
A França Metropolitana estende-se do Mediterrâneo ao Canal da Mancha e Mar do Norte, e do rio Reno ao Oceano Atlântico
É muitas vezes referida como L'Hexagone ("O Hexágono") por causa da forma geométrica do seu território e partilha fronteiras com a Bélgica e Luxemburgo a norte; Alemanha a nordeste; Suíça e Itália a leste; Espanha ao sul e com as micronações de Mônaco e Andorra
A nação é o maior país da União Europeia em área e o terceiro maior da Europa, atrás apenas da Rússia e da Ucrânia (incluindo seus territórios ultramarinos, como a Guiana Francesa, o país torna-se maior que o território ucraniano).
Por cerca de meio milênio, o país tem sido uma grande potência, com forte influência econômica, cultural, militar e política no âmbito europeu e global
Durante muito tempo a França exerceu um papel de liderança e hegemonia na Europa (principalmente a partir da segunda metade do século XVII e parte do XVIII)
Ao longo daqueles dois séculos, a nação iniciou a colonização de várias áreas do planeta e, durante o século XIX e início do século XX, chegou a constituir o segundo maior império da história, o que incluía grande parte da América do Norte, África Central e Ocidental, Sudeste Asiático e muitas ilhas do Pacífico
É conhecida como a terra natal da primeira grande enciclopédia do mundo, a chamada Encyclopédie, formada por 35 volumes e publicada entre 1751 e 1766, em pleno iluminismo do século XVIII.
O país tem seus principais ideais expressos na Declaração dos Direitos do Homem e do Cidadão
A República Francesa é definida como indivisível, laica, democrática e social pela sua constituição
A França é um dos países mais desenvolvidos do mundo, possui a quinta maior economia do mundo por produto interno bruto (PIB) nominal, a nona maior por paridade do poder de compra e a segunda maior de toda a Europa
O país goza de um alto padrão de vida, bem como um elevado nível de escolaridade pública, além de ter uma das mais altas expectativas de vida do mundo
A França foi classificada como o melhor provedor de saúde pública do mundo pela Organização Mundial de Saúde (OMS)
É o país mais visitado no mundo, recebendo 82 milhões de turistas estrangeiros por ano.
O país tem o terceiro maior orçamento militar do mundo, a terceira maior força militar da Organização do Tratado do Atlântico Norte (OTAN) e o maior exército da União Europeia (UE), além de ser um dos cinco membros permanentes do Conselho de Segurança das Nações Unidas e possuir o terceiro maior número de armas nucleares do mundo
O país é um dos membros fundadores da UE e possui a maior área e a segunda maior economia do bloco
É também membro fundador da Organização das Nações Unidas, além de ser membro da Francofonia, do G8, do G20, da Organização para a Cooperação e Desenvolvimento Econômico (OCDE), da Organização Mundial do Comércio (OMC) e da União Latina.


Originalmente aplicado a todo o Império Franco, o nome "França" vem do latim Francia, ou "terra dos francos"
Existem várias teorias quanto à origem do nome francos
Seguindo os precedentes de Edward Gibbon e Jacob Grimm, o nome dos francos foi associado à palavra frank (livre) em inglês
Sugeriu-se que o significado de "livre" fosse adotado porque, após a conquista da Gália, apenas os francos estavam livres da tributação romana
Outra teoria é que ela é derivada da palavra protogermânica frankon, que se traduz como "dardo" ou "lança", visto que o machado usado pelos francos era conhecido como francisca
No entanto, determinou-se que essas armas foram nomeadas devido à sua utilização pelos francos, ao invés do contrário.
Os traços mais antigos de hominídeos no que é agora a França datam de aproximadamente 1,8 milhão de anos atrás
Eles foram confrontados por um clima severo e variável, marcado por várias eras glaciais
Os primeiros hominídeos levavam a uma vida nômade de caçadores-coletores
A França tem um grande número de cavernas decoradas da era paleolítica, incluindo uma das mais famosas e melhor preservadas: Lascaux (aproximadamente 18 000 a.C.).
No final do último período glacial (10 000 a.C.), o clima tornou-se mais suave
Por volta de 7 000 a.C., esta parte da Europa Ocidental entrou na era neolítica e seus habitantes se tornaram sedentários
Após um forte desenvolvimento demográfico e agrícola entre o quarto e o terceiro milênio
A metalurgia apareceu no final do terceiro milênio, inicialmente com trabalhos em ouro, cobre e bronze e, mais tarde, ferro
A França possui inúmeros sítios megalíticos do período neolítico, incluindo o local excepcionalmente denso das Rochas de Carnac (aproximadamente 3 300 a.C.).
Em 600 a.C., os gregos jônicos, originários de Foceia, fundaram a colônia de Massália (atual Marselha), nas margens do Mar Mediterrâneo, o que a torna a cidade mais antiga da França
Ao mesmo tempo, algumas tribos celtas gaulesas penetraram em partes do território da atual da França e esta ocupação se espalhou para o resto da França entre os séculos IV e III a.C.
Por volta de 125 a.C., o sul da Gália foi conquistado pela República Romana, que chamou esta região Provincia Nostra ("Nossa Província"), que ao longo do tempo evoluiu para o nome Provence em francês
Júlio César conquistou o restante da Gália e superou uma revolta realizada pelo chefe gaulês Vercingetórix em 52 a.C
A Gália foi dividida por Augusto em várias províncias romanas
Muitas cidades foram fundadas durante o período galo-romano, incluindo Lugduno (atual Lião), que é considerada a capital dos gauleses
Estas cidades foram construídas em estilo romano tradicional, com um fórum, um teatro, um circo, um anfiteatro e banhos termais
Os gauleses se misturaram com colonos romanos e eventualmente adotaram a cultura e o idioma romano (o latim, do qual a língua francesa evoluiu)
O politeísmo romano se fundiu com o paganismo gálico no mesmo processo de sincretismo.
Desde os anos 250 até os anos 280, a Gália romana sofreu uma grave crise, com as fronteiras fortificadas atacadas em várias ocasiões por bárbaros
No entanto, a situação melhorou na primeira metade do século IV, que foi um período de reavivamento e prosperidade para a Gália romana
Em 312, o imperador Constantino converteu-se ao cristianismo
Posteriormente, os cristãos, que haviam sido perseguidos até então, aumentaram rapidamente em todo o Império Romano
Mas, desde o início do século V, as invasões bárbaras retomaram e as tribos germânicas, como os vândalos, suevos e alanos, cruzaram o rio Reno e se estabeleceram na Gália, na Hispânia e em outras partes do Império Romano em colapso.
No final do período da Antiguidade, a antiga Gália estava dividida em vários reinos germânicos e um território galo-romano restante, conhecido como o Reino de Soissons
Simultaneamente, os celtas britanos, ao fugirem da invasão anglo-saxã da Grã-Bretanha, estabeleceram-se na parte ocidental de Armórica
Como resultado, a península armórica foi renomeada para Bretanha, a cultura celta foi revivida e vários reinos pequenos independentes surgiram nessa região
Os francos pagãos, de quem derivou o nome antigo de "Francie", estabeleceram-se originalmente na parte norte da Gália, mas sob a liderança de Clóvis conquistaram a maioria dos outros reinos no norte e no centro da região
Em 498, Clóvis se tornou o primeiro conquistador germânico após a queda do Império Romano a converter-se ao cristianismo católico, em vez do arianismo; assim, a França recebeu o título de "filha mais velha da Igreja" (em francês: la fille aînée de l'Église) pelo papado.
Os francos abraçaram a cultura galo-romana cristã e a Gália antiga foi finalmente renomeada para Frância ("Terra dos Francos")
Os francos germânicos adotaram as línguas românicas, exceto no norte da Gália, onde os assentamentos romanos eram menos densos e onde surgiram línguas germânicas
Clóvis fez de Paris a sua capital e estabeleceu a dinastia merovíngia, mas seu reino não sobreviveria à sua morte
Os francos tratavam a terra puramente como uma possessão privada e a dividiam entre seus herdeiros; então quatro reinos surgiram depois de Clóvis: Paris, Orléans, Soissons e Reims
Os últimos reis merovíngios perderam poder para seus mordomos do palácio
Um deles, Carlos Martel, derrotou uma invasão islâmica da Gália na Batalha de Tours (732) e obteve respeito e poder dentro dos reinos francos
Seu filho, Pepino, o Breve, usurpou a coroa da Frância dos merovíngios enfraquecidos e fundou a dinastia carolíngia
O filho de Pepino, Carlos Magno, reuniu os reinos francos e construiu um vasto império em toda a Europa ocidental e central.
Carlos Magno foi proclamado Imperador Romano-Germânico pelo Papa Leão III e, assim, restabeleceu a antiga associação histórica entre o governo francês e a Igreja Católica, Ele tentou reviver o Império Romano do Ocidente e sua grandeza cultural
O filho de Magno, Luís I (r
814–840), manteve o império unido; no entanto, o império carolíngio não sobreviveria à sua morte
Em 843, sob o Tratado de Verdun, o império foi dividido entre os três filhos de Luís: a Frância Oriental ficou com Luís, o Germânico; a Frância Média ficou com Lotário I, enquanto que a Frância Ocidental foi para o domínio de Carlos, o Calvo
A Frância Ocidental aproxima-se da área ocupada pela França moderna e é a sua precursora.
A dinastia carolíngia governou a França até 987, quando Hugo Capeto, Duque da França e Conde de Paris, foi coroado o Rei dos Francos
Os seus descendentes — os capetianos, a Casa de Valois e a Casa de Bourbon — unificaram progressivamente o país através das guerras e da herança dinástica no Reino da França, que foi totalmente declarado em 1190 por Felipe II
A nobreza francesa desempenhou um papel proeminente na maioria das Cruzadas, a fim de restaurar o acesso cristão à Terra Santa
Os cruzados franceses constituíam a maior parte do fluxo constante de reforços ao longo do período de 200 anos das Cruzadas, de tal forma que os árabes se referiam uniformemente aos cruzados como franj, sendo que pouco se importavam se realmente vinham da França
Os cruzados franceses também importaram a língua francesa para o Levante, que se tornou a língua franca dos Estados cruzados
Os cavaleiros franceses também eram maioria nas ordens do Hospitalários e dos Templários
Estes últimos, em particular, possuíam várias propriedades em toda a França e, no século XIII, eram os principais banqueiros da coroa francesa, até que Felipe IV aniquilasse a ordem em 1307
A Cruzada Albigense foi lançada em 1209 para eliminar os cátaros, considerados hereges, da região sudoeste da França moderna
No final, os cátaros foram exterminados e o autônomo Condado de Toulouse foi anexado às terras da coroa francesa.
Carlos IV morreu sem um herdeiro em 1328
De acordo com as regras da lei sálica, a coroa da França não podia passar para uma mulher nem a linhagem real poderia passar pela linhagem feminina
Consequentemente, a coroa passou para Filipe de Valois, um primo de Carlos, e não através da linha feminina para o sobrinho de Carlos, Eduardo, que logo se tornaria Eduardo III de Inglaterra
Durante o reinado de Filipe de Valois, a monarquia francesa atingiu o auge de seu poder medieval.
O assento de Filipe no trono foi contestado por Eduardo III e, em 1337, na véspera da primeira onda da Peste Negra, Inglaterra e França entraram em guerra, conflito que posteriormente seria conhecido como Guerra dos Cem Anos
Os limites exatos mudaram muito ao longo tempo, mas as propriedades francesas dos reis ingleses permaneceram extensas por décadas
Com líderes carismáticos, como Joana d'Arc e La Hire, fortes contra-ataques franceses conquistaram territórios continentais dos ingleses
Como o resto da Europa, a França foi fortemente atingida pela Peste Negra; metade dos 17 milhões de habitantes da França morreu no período.
O renascimento francês proporcionou um desenvolvimento cultural espetacular e a primeira padronização da língua francesa, que se tornaria a língua oficial da França e a língua da aristocracia europeia
Também criou um longo conjunto de conflitos militares, conhecidos como as Guerras Italianas, entre o Reino da França e o poderoso Sacro Império Romano-Germânico
Os exploradores franceses, como Jacques Cartier ou Samuel de Champlain, reivindicaram terras na América para a França, preparando o caminho para a expansão do Primeiro Império Colonial Francês
O surgimento do protestantismo na Europa levou a França a uma guerra civil conhecida como Guerras Religiosas, onde, no incidente mais notório, milhares de huguenotes foram assassinados no massacre da noite de São Bartolomeu, em 1572.
Sob o governo de Luís XIII, o energético Cardeal de Richelieu promoveu a centralização do Estado e reforçou o poder real ao desarmar os detentores de poder doméstico na década de 1620
Ele sistematicamente destruiu castelos de senhores que desafiaram o poder central e denunciou o uso da violência privada (duelos, transporte de armas e manutenção de um exército privado)
No final de 1620, Richelieu estabeleceu o "monopólio real da força" como doutrina.
A monarquia atingiu seu pico no século XVII e no reinado de Luís XIV
Ao transformar os poderosos senhores feudais em cortesãos no Palácio de Versalhes, o poder pessoal de Luís XIV se tornou incontestável
Lembrado por suas numerosas guerras, ele fez da França a principal potência europeia
O país tornou-se o mais populoso da Europa e teve uma tremenda influência sobre a política, a economia e a cultura do continente
O francês tornou-se a língua mais utilizada na diplomacia, ciência, literatura e relações internacionais e permaneceu com tal estatuto até o século XX.
Sob Luís XV, o bisneto de Luís XIV, a França perdeu a Nova França e a maioria da Índia Francesa após a derrota na Guerra dos Sete Anos, que terminou em 1763
Seu território europeu continuou crescendo, no entanto, com aquisições notáveis, ​​como Lorena (1766) e Córsega (1770)
O fraco governo do impopular Luís XV, com suas decisões financeiras, políticas e militares mal planejadas — assim como a devastação de sua corte — desacreditaram a monarquia, o que indiscutivelmente abriu o caminho para a Revolução Francesa, que ocorreria 15 anos após sua morte.
Diante de problemas financeiros, o rei Luís XVI convocou os Estados-Gerais (reunindo as três estamentos do reino) em maio de 1789 para propor soluções para o governo
Na sequência de um impasse, os representantes do terceiro estado formaram-se numa Assembleia Nacional, sinalizando o surgimento da Revolução Francesa
No início de agosto de 1789, a Assembleia Nacional Constituinte aboliu os privilégios da nobreza, como a servidão pessoal e os direitos exclusivos de caça
Através da Declaração dos Direitos do Homem e do Cidadão (27 de agosto de 1789), a França estabeleceu direitos fundamentais para os homens
A Declaração afirma "os direitos naturais e imprescritíveis do homem à liberdade, propriedade, segurança e resistência à opressão"
A liberdade de expressão e de imprensa foram declaradas e as prisões arbitrárias foram proibidas
Ela solicitou a destruição de privilégios aristocráticos e proclamou a liberdade e a igualdade de direitos para todos os homens, bem como o acesso a cargos públicos com base em talentos e não nascimento.
Em novembro de 1789, a Assembleia decidiu nacionalizar e vender todos os bens da Igreja Católica Romana, que era o maior proprietário do país
Em julho de 1790, uma Constituição Civil do Clero reorganizou a Igreja Católica Francesa, cancelando a autoridade da Igreja para cobrar impostos e assim por diante
Isto provocou um grande descontentamento em partes da França, o que contribuiria para a guerra civil que acabou alguns anos depois
Apesar do rei Luís XVI ainda gozar de popularidade entre a população, sua desastrosa fuga de Varennes (junho de 1791) parecia justificar rumores de que ele amarrava as suas esperanças de salvação política às perspectivas de invasão estrangeira
Sua credibilidade foi tão profundamente minada que a abolição da monarquia e o estabelecimento de uma república tornaram-se uma possibilidade crescente.
Em 10 de agosto de 1792, uma multidão irritada ameaçou o palácio do rei Luís XVI, que se refugiava na Assembleia Legislativa
Um exército prussiano invadiu a França em agosto de 1792
No início de setembro, os parisienses, enfurecidos pelo exército prussiano capturar Verdun e pelas revoltas contra-revolucionárias no oeste da França, assassinaram entre 1 000 e 1 500 prisioneiros ao atacar as prisões parisienses
A Assembleia e o conselho da cidade de Paris pareciam incapazes de parar esse derramamento de sangue
A Convenção Nacional, escolhida nas primeiras eleições sob sufrágio universal masculino, em 20 de setembro de 1792, sucedeu a Assembleia Legislativa e, em 21 de setembro, aboliu a monarquia proclamando a Primeira República Francesa
O ex-rei, Luís XVI, foi condenado por traição e guilhotinado em janeiro de 1793
A França declarou guerra à Inglaterra e à República Holandesa em novembro de 1792 e fez o mesmo em relação à Espanha em março de 1793; na primavera de 1793, a Áustria, a Grã-Bretanha e a República Holandesa invadiram a França; em março, a França criou uma "república irmã" na "República de Mainz".
Napoleão Bonaparte tomou o controle da República em 1799 ao tornar-se Primeiro Cônsul e depois Imperador do Império Francês (1804–1814/1815)
Como uma continuação das guerras desencadeadas pelas monarquias europeias contra a República Francesa, os conjuntos de coligações europeias declararam guerra ao Império de Napoleão
Os exércitos franceses, no entanto, conquistaram a maior parte da Europa continental com vitórias rápidas, como as batalhas de Jena-Auerstadt ou Austerlitz
Os membros da família Bonaparte foram nomeados como monarcas em alguns dos reinos recentemente estabelecidos
Essas vitórias levaram à expansão mundial dos ideais e das reformas revolucionárias francesas, como o sistema métrico, o Código Napoleônico e a Declaração dos Direitos do Homem
Após a catastrófica Campanha da Rússia e o levante das monarquias europeias contra o seu governo, Napoleão foi derrotado e a monarquia Bourbon foi restaurada
Cerca de um milhão de franceses morreram durante as Guerras Napoleônicas.
Após o seu breve retorno do exílio, Napoleão foi finalmente derrotado em 1815 na Batalha de Waterloo, a monarquia foi restabelecida (1815–1830), com novas limitações constitucionais
A desacreditada dinastia Bourbon foi derrubada pela Revolução de Julho de 1830, que estabeleceu a Monarquia de Julho, que durou até 1848, quando a Segunda República Francesa foi proclamada, na sequência das revoluções europeias de 1848
A abolição da escravidão e o sufrágio universal masculino, ambos brevemente promulgados durante a Revolução Francesa, foram reeditados em 1848.
Em 1852, o presidente da República Francesa, Louis-Napoléon Bonaparte, sobrinho de Napoleão I, foi proclamado imperador do Segundo Império, como Napoleão III
Ele multiplicou as intervenções francesas no exterior, especialmente na Crimeia, no México e na Itália, o que resultou na anexação do Ducado de Saboia e do Condado de Nice, então parte do Reino da Sardenha
Napoleão III foi destruído após a derrota na Guerra Franco-Prussiana de 1870 e seu regime foi substituído pela Terceira República Francesa.
A França tinha possessões coloniais, em várias formas, desde o início do século XVII, mas nos séculos XIX e XX, seu império colonial global ultramarino se estendeu muito e se tornou o segundo maior do mundo, atrás apenas do Império Britânico
Incluindo a França metropolitana, a área total de terra sob soberania francesa atingiu quase 13 milhões de quilômetros quadrados nas décadas de 1920 e 1930, ou 8,6% da área terrestre do planeta
Conhecida como Belle Époque, a virada do século foi um período caracterizado por otimismo, paz regional, prosperidade econômica e inovações tecnológicas, científicas e culturais
Em 1905, o secularismo estatal foi oficialmente estabelecido.
A França era membro da Tríplice Entente quando a Primeira Guerra Mundial estourou
Uma pequena parte do norte da França estava ocupada, mas a França e seus aliados emergiram vitoriosos contra os Impérios Centrais com um tremendo custo humano e material
A Primeira Guerra Mundial deixou 1,4 milhão de soldados franceses mortos, ou 4% de sua população
Entre 27% e 30% dos soldados recrutados de 1912 a 1915 foram mortos
Os anos do Entreguerras foram marcados por intensas tensões internacionais e uma variedade de reformas sociais introduzidas pelo governo da Frente Popular (férias anuais, dias úteis de oito horas, mulheres no governo, etc.).
Em 1940, durante a Segunda Guerra Mundial, a França foi invadida e ocupada pela Alemanha nazista
A França metropolitana foi dividida em uma zona de ocupação alemã no norte e França de Vichy, um regime autoritário recém-criado no sul e que era um Estado fantoche dos nazistas, enquanto a França Livre, governada em exílio e liderada por Charles de Gaulle, foi criada em Londres
De 1942 a 1944, cerca de 160 mil cidadãos franceses, incluindo cerca de 75 mil judeus, foram deportados para campos de extermínio e campos de concentração na Alemanha e na Polônia ocupada
Em 6 de junho de 1944, os Aliados invadiram a Normandia e, em agosto, invadiram Provença
No ano seguinte, os Aliados e a Resistência Francesa emergiram vitoriosos sobre as Potências do Eixo e a soberania francesa foi restaurada com o estabelecimento do Governo Provisório da República Francesa (GPRF).
O GPRF estabeleceu as bases para uma nova ordem constitucional que resultou na Quarta República Francesa, que passou por um crescimento econômico espetacular (les Trente Glorieuses)
A França foi um dos membros fundadores da Organização do Tratado do Atlântico Norte (OTAN) em 1949
O país tentou recuperar o controle da Indochina francesa, mas foi derrotada pelo Viet Minh em 1954 na Batalha de Dien Bien Phu
Apenas alguns meses depois, a França enfrentou outro conflito anticolonial na Argélia
Tortura e execuções ilegais foram cometidas por ambos os lados e o debate sobre o controle da Argélia, então casa de mais de um milhão de colonos europeus, dividiu o país e quase levou a um golpe e a uma guerra civil
Em 1958, a fraca e instável Quarta República deu lugar à Quinta República Francesa, que incluiu uma Presidência fortalecida.
A França permaneceu como uma das economias mais desenvolvidas do mundo, mas enfrentou várias crises econômicas que resultaram em altas taxas de desemprego e aumento da dívida pública
No final do século XX e início do XXI, a França esteve na vanguarda do desenvolvimento de uma União Europeia (UE) supranacional ao assinar o Tratado de Maastricht (que criou a UE) em 1992, ao estabelecer a Zona do Euro em 1999 e ao assinar o Tratado de Lisboa em 2007
O país também gradualmente reintegrou-se à OTAN e desde então participou da maioria das guerras patrocinadas pela organização.
Desde os ataques ao metrôs de Paris em 1995, a França tem sido esporadicamente atacada por organizações terroristas islâmicas, em particular o ataque ao Charlie Hebdo em janeiro de 2015, que provocou as maiores manifestações públicas na história da França (4,4 milhões de pessoas), e os ataques de novembro de 2015 em Paris, que resultaram em 130 mortes, foram os atentados mais mortais em solo francês desde a Segunda Guerra Mundial e os mais mortíferos na União Europeia desde os atentados de Madri em 2004.
A França metropolitana está situada na faixa entre as latitudes de 41 e 51 graus no hemisfério norte (Dunquerque está um pouco a norte da latitude de 51 graus) e entre as longitudes de 6 graus no hemisfério ocidental e 10 graus no hemisfério oriental
Está ainda localizada na parte ocidental da Europa e, portanto, situada na zona de clima temperado do hemisfério norte
Enquanto a França metropolitana está localizada na Europa Ocidental, a França também tem territórios na América do Norte, América Central, América do Sul, sul do Oceano Índico, Oceano Pacífico e uma reivindicação na Antártida
Estes territórios têm diferentes formas de governo que vão desde departamento de ultramar à coletividade de ultramar
Os departamentos e coletividades ultramarinas da França e partilham fronteiras terrestres com o Brasil e Suriname (a partir da Guiana Francesa) e com as antigas Antilhas Holandesas (a partir de São Martinho).
A França metropolitana abrange 547 030 quilômetros quadrados e tem a maior área territorial entre os membros da União Europeia
A França possui uma grande variedade de paisagens, desde as planícies costeiras no norte e oeste, as cordilheiras dos Alpes no sudeste, o Maciço Central da região centro-sul até aos Pirenéus no sudoeste
Com 4 810,45 metros de altitude acima do nível do mar, o Mont Blanc é o ponto mais alto da Europa Ocidental, situado nos Alpes, sobre a fronteira França-Itália
A França Metropolitana também tem sistemas fluviais extensos como o Sena, o Loire, Garona e o Ródano, que divide o Maciço Central dos Alpes e desagua no Mar Mediterrâneo
A Córsega está ao largo da costa do Mediterrâneo.
A área total terrestre da França, com seus departamentos e territórios ultramarinos (excluindo Terra de Adélia), é de 674 843 quilômetros quadrados, 0,45% da área total da Terra
Contudo, a França possui a segunda maior zona econômica exclusiva (ZEE) do mundo, que abrange 11,035 milhões de quilômetros quadrados, cerca de 8% da superfície total de todos as ZEE do mundo, atrás apenas dos Estados Unidos (11 351 000 quilômetros quadrados) e à frente da Austrália (8 232 000 quilômetros quadrados).
A França tem temperaturas amenas o ano todo
As chuvas são abundantes, o sol generoso
É mais fresco e úmido a norte e a oeste; mais quente e seco nas cidades do Mediterrâneo.
O norte e o noroeste do país têm um clima temperado, enquanto que uma combinação de influências marítimas, latitude e altitude produzem um clima variado no resto da França metropolitana
No sudeste prevalece o clima mediterrâneo
No oeste, o clima é predominantemente oceânico, com um elevado nível de pluviosidade, invernos suaves e verões quentes
No interior o clima torna-se mais continental, com verões quentes e tempestuosos, invernos mais frios e menos chuva
O clima dos Alpes e de outras regiões montanhosas é principalmente alpino, com o número de dias com temperaturas abaixo de zero passando de 150 por ano e com uma cobertura de neve com duração de até seis meses.
No inverno, a neve nas montanhas possibilita a prática de esportes de inverno
A neve é rara nas planícies, caindo essencialmente a norte do rio Loire e, esporadicamente, em Paris
Na primavera, as temperaturas são acima de 20 graus Celcius no sul, como em Nice e Cannes
De junho em diante, pode-se andar pelas ruas sem agasalho
Os dias são mais longos, época para viagens ao campo, montanhas e para atividades ao ar livre
O verão é quente e calmo
O sol predomina em todo o país
A temperatura chega, muitas vezes, a 30 graus Celcius em Marselha, a 25 graus Celcius em Brest
As praias ficam lotadas
No outono regressa a chuva, depois as temperaturas amenas no mês de dezembro
Nas ruas, as pessoas se agasalham e os dias vão ficando mais curtos.
Falésias de calcário na Normandia, perto de Étretat.
Vegetação mediterrânea (lavanda) em Provença.
Clima alpino na Saboia (observa-se um íbex à esquerda).
Vinhedos de Alsácia perto de Châtenois.
Bora-Bora na Polinésia Francesa.
Calanches de Piana, Córsega.
A população da França é de aproximadamente 65,4 milhões de pessoas (segundo estimativas para janeiro de 2010), dos quais 62 793 432 habitam a França Metropolitana, com uma densidade de 115 habitantes por quilômetros quadrado, 2 653 942 habitam a França ultramarina, incluindo uma comunidade de dois mil cientistas e investigadores destacados na Antártida.
Segundo dados do CIA World Factbook, 77% da população francesa vivem em áreas urbanas
Paris, junto à sua área metropolitana (correspondente à região conhecida como Ilha de França), concentra 11 769 443 habitantes, o que a converte em uma das maiores do mundo, e a mais povoada da União Europeia
Outras áreas metropolitanas como mais de um milhão de habitantes são Marselha e Lyon, com mais de um milhão e meio habitantes cada.
A esperança de vida ao nascer é de 84,5 anos para as mulheres e 77,1 anos para o homens
Os homens tendem a ter empregos a tempo completo, enquanto nas mulheres tende a ser parcial
Na França, as férias legais pagas somam cinco semanas para cada ano de trabalho
A França é considerada como um dos países com melhor qualidade de vida do planeta
Sua população desfruta de um alto grau de serviços e o índice de saúde é um dos melhores do mundo.
A população é composta por descendentes de vários grupos étnicos, principalmente de origem celta (mas também lígure e ibero), fundamentalmente gauleses fusionados com a população precedente, que deram à região o nome de Gália (que hoje é a França), que incluía também Bélgica, Suíça e Luxemburgo
Cronologicamente, foram-se somando outros grupos étnicos: no processo histórico formativo da França atual, são também significativas as populações de origem grega, romana, basca, germânica (principalmente de francos, como também de burgúndios), viquingue (na Normandia) e, em menor medida, os sarracenos.
Os estudos da população francesa mostram que a maioria dos cidadãos são de origem europeia (91,6%), entre os quais franceses (85%) os outros 6,5% provêm de outros países
5,75 vêm de países da África, 3% da Ásia e 0,6% da América
Esta composição é consequência da evolução migratória e da presença significativa da população nascida na França, porém estrangeira, geralmente imigrantes que através dos anos foram obtendo a cidadania francesa
A população de origem judia era estimada em 550 mil habitantes, a princípios dos anos 2000, ainda que não existam dados estatísticos, pois a lei francesa proíbe coletar dados sobre etnias ou religiões, bem como filiação política.
Desde o século XIX, a França é um país de imigração
Mais de 90% da população nasceu dentro do próprio país
Entre os estrangeiros que vêm se integrando, predominam os magrebes, italianos e espanhóis, portugueses, polacos, subsaarianos, chineses (um milhão em 2007), turcos (entre 400 e 500 mil), vietnamitas (250 mil) e ciganos (entre 200 e 300 mil)
A maior parte de imigrantes nos últimos anos provêm do Magrebe
No total, existem 4,5 milhões de imigrantes no país.
França é um país secular e a liberdade de religião é um direito constitucional
O governo francês não mantém estatísticas sobre adesão religiosa, no entanto existem algumas estimativas não oficiais
O catolicismo romano tem sido a religião predominante na França há mais de um milênio, embora não seja tão ativamente praticado hoje como era antes
Uma pesquisa realizada pelo jornal católico La Croix descobriu que, enquanto em 1965, 81% dos franceses se declaravam como católicos, em 2009 essa proporção era de 64%
Além disso, embora 27% dos franceses ia à missa uma vez por semana ou mais em 1952, apenas 4,5% o fizeram em 2006; 15,2% assistiam à missa pelo menos uma vez por mês
O mesmo estudo constatou que os protestantes responderam por 3% da população, um aumento em relação às pesquisas anteriores e 5% seguiam outras religiões, sendo que os restantes 28% declarando que não tinham nenhuma religião.
De acordo com uma sondagem de janeiro de 2007 realizada pela Catholic World News, apenas 5% da população francesa frequentava a igreja regularmente (ou 10% frequentam os serviços da igreja regularmente entre os entrevistados que se identificaram como católicos)
A pesquisa mostrou que 51% dos entrevistados se identificou como católicos, 31% se identificou como agnósticos ou ateus (outra pesquisa define a proporção de ateus como igual a 27%), 10% se identificou como sendo de outras religiões ou sem opinião, 4% identificados como muçulmanos, 3% se identificaram como protestantes, 1% se identificaram como budistas e 1% se identificaram como judeus
Enquanto isso, uma estimativa independente do politologista Pierre Bréchon, em 2009, concluiu que a proporção de católicos havia caído para 42% enquanto o número de ateus e agnósticos havia subido para 50%
Os valores mais recentes da World Christian Database datados de 2010 e divulgados pelo site The ARDA mostram que 68,23% dos franceses são seguidores do cristianismo, 16,41% são agnósticos, 8,55% são muçulmanos, os ateus são 4,13%, os judeus 1% e outras religiões são seguidas por 1,67% da população
De acordo com o Fórum Pew, "na França, os defensores de uma lei de 2004 que proíbe o uso de símbolos religiosos nas escolas dizem que protegem as meninas muçulmanas de serem forçadas a usar um lenço na cabeça, mas a lei também restringe aqueles que querem usar o véu — ou qualquer outro símbolo "conspícuo" religioso, incluindo grandes cruzes cristãs e turbantes do siquismo — como expressão de sua fé."
De acordo com pesquisa do Eurobarômetro, de 2005, 34% dos cidadãos franceses responderam que "acreditam que existe um deus", enquanto 27% responderam que "acreditam que existe algum tipo de espírito ou força vital e 33% que "não acredito que haja qualquer tipo de espírito, deus, ou força vital." Um outro estudo mostra 32% de pessoas na França se declaram como ateus e outros 32% declaram-se como "cético sobre a existência de Deus, mas não um ateu." Segundo pesquisa de 2010, também do Eurobarometer, a França é o país mais ateu da Europa, com 40% da sua população não acreditando na existência de um deus; 27% dos franceses disseram crer em algum deus, ao passo que 27% acreditavam em algum tipo de espírito ou força vital.
As estimativas do número de muçulmanos na França variam amplamente
De acordo com o censo francês de 1999, havia 3,7 milhões de pessoas "provavelmente de fé muçulmana" na França (6,3% da população total)
Em 2003, o Ministério do Interior francês estimou que o número total de muçulmanos estava entre cinco e seis milhões (8–10%).
Desde 1905 o governo francês tem seguido o princípio da laicidade, em que é proibido de reconhecer qualquer direito específico de uma comunidade religiosa
Em vez disso, o governo apenas reconhece as organizações religiosas, de acordo com critérios formais legais que não tratam a doutrina religiosa
Por outro lado, as organizações religiosas devem abster-se de intervir na elaboração de políticas.
O idioma oficial na França é o francês, proveniente do franciano, variante linguística falada na Ilha de França que nos princípios da Idade Média e, ao longo dos séculos, se impôs ao resto das línguas e variantes linguísticas que se falam em quaisquer partes da França
Também há línguas minoritárias, como o catalão, o bretão, o corso, o occitano, o provençal, o franco-provençal, o basco e o alsaciano.
Apesar disto, esta imposição do francês tem sido fruto de decisões políticas tomadas ao longo da história, com o objetivo de criar um Estado uniformizado linguisticamente
Feito isto, o artigo segundo da constituição francesa de 1958 disse textualmente que «La langue de la République est le français».
Do século XVII a meados do XX, o francês serviu como língua internacional preeminente da diplomacia e das relações internacionais, bem como uma língua franca entre as classes cultas da Europa
A posição dominante da língua francesa nas relações internacionais tem apenas sido desafiada recentemente pelo inglês, desde o surgimento dos Estados Unidos como uma grande potência.
A República Francesa é uma república unitária semipresidencialista com fortes tradições democráticas
A constituição da V República foi aprovada por referendo em 28 de setembro de 1958
É extremamente reforçada a autoridade do executivo em relação ao Parlamento
O poder executivo em si tem dois dirigentes: o presidente da República, atualmente Emmanuel Macron (eleito em 2017 pelo Em Marcha!) que é chefe de estado e é eleito diretamente por sufrágio universal para um mandato de cinco anos (até 2000, eram sete anos) e o Governo, liderado pelo primeiro-ministro nomeado pelo presidente
Após a eleição legislativa de 2017, o primeiro-ministro do país passou a ser Édouard Philippe.
O parlamento francês é uma legislatura bicameral, composto por uma Assembleia Nacional (Assemblée Nationale) e um Senado
Os deputados da Assembleia Nacional representam círculos eleitorais locais e são diretamente eleitos para mandatos de cinco anos.
A Assembleia tem o poder de demitir o gabinete e, assim, a maioria na Assembleia determina a escolha do governo
Os senadores são escolhidos por um colégio eleitoral para mandatos de seis anos (inicialmente nove termos homólogos), e metade dos assentos são submetidos à eleição três cada três anos
Os poderes legislativos do Senado são limitados; em caso de desacordo entre as duas câmaras, a Assembleia Nacional tem a palavra final, exceto para as leis constitucionais e lois organiques (leis que são diretamente previstas pela Constituição), em alguns casos.
Até as eleições de 2017, disputada entre o Em Marcha! e a Frente Nacional, a política francesa caracterizava-se por dois grupos políticos opostos: um de esquerda, centrada em torno do Partido Socialista Francês, e os outros da ala direita, anteriormente centrada em torno do Reagrupamento para a República (RPR) e seu sucessor, o União por um Movimento Popular (UMP).
Na França usa-se o sistema romano-germânico, isto é, a lei surge principalmente a partir de estatutos escritos
Os juízes não fazem leis, mas apenas as interpretam, embora a quantidade de interpretação judicial em determinadas áreas faça com que seja equivalente à jurisprudência
Os princípios básicos do Estado de direito foram estabelecidas no Código de Napoleão, que era, por sua vez, em grande parte, baseado na lei real codificada no reinado de Luís XIV
De acordo com os princípios da Declaração dos Direitos do Homem e do Cidadão a lei só deve proibir as ações prejudiciais à sociedade.
A lei francesa é dividida em duas áreas principais: o direito privado e o direito público
O direito privado inclui, na lei, nomeadamente o direito penal e civil
O direito público inclui, na lei, designadamente o direitos administrativo e constitucional
No entanto, em termos práticos, a lei francesa compreende três principais áreas do direito: direito civil, direito penal e direito administrativo.
A França não reconhece a lei religiosa, nem reconhece crenças religiosas ou a moralidade como uma motivação para a promulgação de proibições
Como consequência, a França há muito tempo não tem qualquer lei de blasfêmia nem leis contra a sodomia (a última sendo abolida em 1791)
No entanto, "os crimes contra a decência pública" (moeurs contraires aux bonnes) ou perturbação da ordem pública (rouble à l'ordre public) foram usados ​​para reprimir manifestações públicas de homossexualidade ou a prostituição de rua
Leis penais só podem abordar o futuro e não o passado criminal (leis ex post facto são proibidas), e para serem aplicáveis, as leis devem ser oficialmente publicadas no Journal Officiel de la République française
Em 2010, a França aprovou uma lei que proíbe véus de rosto em público, incluindo aqueles usados ​​pelas mulheres muçulmanas
A Anistia Internacional condenou a lei como uma violação da liberdade de expressão
Em setembro de 2011, duas mulheres muçulmanas foram multadas por usar o nicabe, mas elas recorreram das multas.
A França é tolerante com a comunidade de lésbicas, gays, bissexuais, travestis, transexuais e transgêneros (LGBT)
Desde 1999, as uniões civis para casais homossexuais são permitidas, embora o casamento homossexual tenha sido legalizado no país somente em 2013
Leis de condenação ao racismo, sexismo ou o antissemitismo são antigas e, por exemplo, leis que proíbem o discurso discriminatório na imprensa datam de 1881.
A França é um membro da Organização das Nações Unidas (ONU) e é um dos membros permanentes do seu Conselho de Segurança, com direito a veto
O país também é membro do G8, Organização Mundial do Comércio (OMC), do Secretariado da Comunidade do Pacífico (SCP) e também da União Latina e Comissão do Oceano Índico (COI), além de ser membro fundador da Organização do Tratado do Atlântico Norte (OTAN), membro associado da Associação dos Estados do Caribe (AEC) e um dos principais participantes da Organização Internacional da Francofonia (OIF), que reúne 51 países de língua francesa.
Como um polo importante para as relações internacionais, a França abriga o segundo maior conjunto de missões diplomáticas em todo o mundo e a sede de diversas organizações internacionais, como a OCDE, a Organização das Nações Unidas para a Educação, a Ciência e a Cultura (UNESCO), a Organização Internacional de Polícia Criminal (Interpol), o Escritório Internacional de Pesos e Medidas e a OIF
A política externa francesa do pós-guerra tem sido amplamente moldada pela adesão à União Europeia (UE), da qual foi um dos membros fundadores
Desde 1960, a França desenvolveu laços estreitos com a Alemanha reunificada para se tornar a força motriz mais influente da UE.
O país ainda mantém forte influência política e econômica em suas antigas colônias africanas e fornece ajuda econômica e tropas para missões de manutenção da paz na Costa do Marfim e no Chade
Recentemente, após a declaração unilateral de independência do norte do Mali pelo Movimento Nacional de Libertação do Azauade (MNLA), durante a rebelião tuaregue, e do subsequente conflito regional com vários grupos islâmicos, como Ansar Dine, a França e outros países africanos intervieram militarmente para ajudar o exército do Mali a retomar o controle
Em 2009, a França foi o segundo maior (em números absolutos) financiador de ajuda humanitária no mundo, atrás dos Estados Unidos e à frente de Alemanha, Japão e Reino Unido, o que representa apenas 0,5% do PIB francês
A organização que administra a ajuda francesa ao exterior é a Agência Francesa de Desenvolvimento, que financia projetos humanitários, principalmente na África subsaariana
Os principais objetivos desta ajuda são "o desenvolvimento de infraestrutura, o acesso a assitência médica e educação, a implementação de políticas econômicas adequadas e a consolidação do Estado de direito e da democracia".
As Forças Armadas Francesas (Armées françaises) são as forças militares e paramilitares (como a Gendarmaria Nacional) do governo francês, sendo o presidente seu comandante-em-chefe
Elas são compostas pelo Exército Francês (Armée de Terre), pela Marinha Francesa (Marine Nationale), pela Força Aérea Francesa (Armée de l' Air) e por uma força paramilitar auxiliar, a Gendarmaria Nacional (Gendarmerie Nationale), e estão entre as maiores forças armadas em todo o mundo
Embora administrativamente as forças armadas francesas estejam sob o comando do Ministério da Defesa, a Gendarmeria é operacionalmente ligada ao Ministério do Interior
A França é membro permanente do Conselho de Segurança das Nações Unidas e é um Estado nuclear reconhecido desde 1960
O país assinou e ratificou o Tratado de Interdição Completa de Ensaios Nucleares e aderiu ao Tratado de Não Proliferação de Armas Nucleares
As despesas militares anuais da França em 2011 foram de 62,5 bilhões de dólares, ou 2,3% de seu PIB, o quinto maior gasto militar do mundo, atrás apenas de Estados Unidos, China, Rússia e Reino Unido.
A dissuasão nuclear francesa conta com total independência
A corrente de força nuclear francesa é composta por quatro submarinos da classe Triomphant equipados com mísseis balísticos
Além da frota de submarinos, estima-se que a França tenha cerca de sessenta mísseis ar-superfície ASMP de médio alcance equipados com ogivas nucleares, dos quais cerca de 50 são usados pela Força Aérea em caças Dassault Mirage 2000N, de longo alcance e com capacidade nuclear, enquanto que cerca de dez estão implantados em aeronaves de ataque Dassault-Breguet Super Étendard da Marinha, que operam a partir do porta-aviões de propulsão nuclear FS Charles de Gaulle
A nova aeronave Rafale F3 irá substituir gradualmente todos os Mirage 2000N e SEM no uso nuclear com a melhoria do míssil ASMP-A com uma ogiva nuclear.
A França tem grandes indústrias militares, além de uma das maiores indústrias aeroespaciais do mundo
Suas plantas industriais produziram equipamentos como o caça Rafale, o porta-aviões Charles de Gaulle, o míssil Exocet e o tanque Leclerc, entre outros
Apesar de se retirar do projeto de aeronave Eurofighter, a França está investindo ativamente em projetos europeus conjuntos, como o helicóptero Eurocopter Tiger, fragatas multiusos, veículos aéreos não tripulados (VANT) e as aeronaves nEUROn e Airbus A400M Atlas
A França é um dos maiores vendedores de armas do mundo, sendo que a maior parte de seu arsenal está disponível para o mercado de exportação, com exceção dos dispositivos de propulsão nuclear.
A França está dividida em 26 regiões administrativas
22 estão na França metropolitana (21 estão na parte continental da França metropolitana, é uma colectividade territorial da Córsega), e quatro são regiões ultramarinas
As regiões estão subdivididas em 100 departamentos que são numerados (principalmente em ordem alfabética)
Esse número é usado em códigos postais e placas de matrícula, entre outros
Os cerca de 100 departamentos estão subdivididos em 341 circunscrições que são, por sua vez, subdivididas em 4 032 cantões
Estes cantões estão divididos em 36 680 comunas, que são municípios com um conselho municipal eleito
Também existem 2 588 entidades intermunicipais, agrupando 33 414 das 36 680 comunas (ou seja, 91,1% de todos os municípios)
Três municípios, Paris, Lyon e Marselha também estão subdivididos em 45 circunscrições municipais.
As regiões, departamentos e comunas são todos conhecidos como coletividades territoriais, o que significa que eles possuem assembleias locais, bem como um executivo
Arrondissements e cantões são divisões meramente administrativas
No entanto, este não foi sempre o caso
Até 1940, os arrondissements também eram coletividades territoriais, com uma assembleia eleita, mas estas foram suspensas pelo regime de Vichy e definitivamente abolida pela Quarta República, em 1946
Historicamente, os cantões eram também coletividades territoriais, com suas assembleias eleitas.

Um membro G8, grupo líder dos principais países industrializados, o país é classificado como a quinta maior economia do mundo e segunda maior da Europa é por PIB nominal; com 39 das 500 maiores empresas do mundo em 2010, a França ocupa o quarto lugar no mundo e o primeiro na Europa na lista Fortune Global 500, à frente da Alemanha e do Reino Unido
A França se juntou aos onze outros membros da União Europeia para criar o euro em 1 de janeiro de 1999, substituindo completamente o franco francês no início de 2002.
A França tem uma economia mista que combina a iniciativa privada extensa (cerca de 2,5 milhões de empresas registradas) com substanciais (embora em declínio) empresas estatais e intervenção do governo
O governo mantém considerável influência sobre segmentos-chave dos setores de infra-estrutura, com participação majoritária em estradas de ferro, eletricidade, aviões, usinas nucleares e telecomunicações.
O país vem relaxando gradualmente o controle sobre estes setores desde o início dos anos 1990
O governo está lentamente corporatizando o setor estatal e vendendo participações na France Télécom, Air France, assim como ações, seguros e indústrias de defesa
A França tem uma importante indústria aeroespacial liderada pelo consórcio europeu Airbus e tem o seu próprio espaçoporto nacional, o Centro Espacial de Kourou.
Segundo a Organização Mundial do Comércio (OMC), em 2009, a França foi sexto maior exportador do mundo e o quarto maior importador de produtos manufaturados
Em 2008, o país foi o terceiro maior destinatário de investimentos estrangeiros diretos nos países da OCDE em 117,9 bilhões de dólares, atrás de Luxemburgo (onde o investimento estrangeiro direto foi de transferências essencialmente monetárias aos bancos localizados no país) e dos Estados Unidos (316,1 bilhões de dólares), mas acima do Reino Unido (96,9 bilhões de dólares), Alemanha (24,9 bilhões de dólares) e Japão (24,4 bilhões de dólares)
No mesmo ano, as empresas francesas investiram 220.000 milhões de dólares fora do país, classificando-o como o segundo mais importante investidor externo direto no âmbito da OCDE, atrás dos Estados Unidos (311,8 bilhões de dólares) e à frente do Reino Unido (111,4 bilhões de dólares), Japão (128 bilhões de dólares) e Alemanha (156,5 bilhões de dólares).
Serviços financeiros, bancários e do setor de seguros são uma parte importante da economia francesa
A Bolsa de Valores de Paris é uma instituição antiga, criada por Luís XV em 1724
Em 2000, as bolsas de valores de Paris, Amesterdã e Bruxelas foram incorporadas à Euronext
Em 2007, a Euronext se fundiu com a Bolsa de Nova Iorque para formar NYSE Euronext, a maior bolsa de valores do mundo.
As empresas francesas mantiveram posições-chave na indústria de seguros e bancária: a AXA é a maior empresa do mundo seguro e está classificada pela revista Fortune como a nona empresa mais lucrativa do mundo
Os principais bancos franceses são BNP Paribas e o Crédit Agricole, classificados como primeiro e sexto maiores bancos do mundo em 2010.
Com 81,9 milhões de turistas estrangeiros em 2007, a França é classificada como o maior destino turístico do mundo, à frente da Espanha (58,5 milhões em 2006) e Estados Unidos (51,1 milhões em 2006)
Este valor de 81,9 milhões de pessoas exclui aquelas que ficam menos de 24 horas na França, como europeus do norte cruzando a França a caminho de Espanha ou da Itália durante o verão.
A França tem 41 locais classificados como Patrimônio Mundial da UNESCO e apresenta cidades de interesse cultural elevado (principalmente Paris, além de Toulouse, Estrasburgo, Bordéus, Lyon e outros), praias e balneários, estâncias de esqui e regiões rurais
O país e, especialmente a sua capital, tem alguns dos maiores e mais renomados museus do mundo, incluindo o Louvre, que é o museu de arte mais visitado no mundo, além do Musée d'Orsay, principalmente dedicado ao impressionismo, e o Beaubourg, dedicado à arte contemporânea
A Disneyland Paris é o parque temático mais popular da França e de toda a Europa, com mais 15 405 000 visitantes em 2009.
Com mais de 10 milhões de turistas por ano, a Riviera Francesa (ou Côte d'Azur), no sudeste da França, é o segundo principal destino turístico no país, após a região parisiense
De acordo com a Agência de Desenvolvimento Econômico Côte d'Azur, a região é beneficiada por 300 dias de sol por ano, 115 quilômetros de litoral, 18 campos de golfe, 14 estações de esqui e 3.000 restaurantes
Todos os anos a Côte d'Azur hospeda 50% da frota mundial de iates luxuosos, sendo que 90% desses iates visitam costa da região pelo menos uma vez na vida.
Um outro destino principal são os castelos do Vale do Loire, este Patrimônio Mundial é notável pela qualidade do seu patrimônio arquitectónico, nas suas cidades históricas, como Amboise, Angers, Blois, Chinon, Nantes, Orléans, Saumur e Tours, mas em particular pelos seus castelos
Os locais turísticos mais populares incluem (de acordo com uma classificação de 2003 por visitantes por ano): Torre Eiffel (6,2 milhões), Museu do Louvre (5,7 milhões), Palácio de Versalhes (2,8 milhões), Museu de Orsay (2,1 milhões), Arco do Triunfo (1,2 milhões), Centro Pompidou (1,2 milhão), Monte Saint-Michel (1 milhão), o Castelo de Chambord (711 mil), Sainte-Chapelle (683 mil), Castelo de Haut-Koenigsbourg (549 mil), Puy de Dôme (500 mil), Museu Picasso (441 mil), Carcassonne (362 mil).
A França é o menor emissor de dióxido de carbono entre os sete países mais industrializados do mundo, devido ao seu forte investimento em energia nuclear
Como resultado de grandes investimentos em tecnologia nuclear, a maior parte da eletricidade produzida no país é gerada por 59 usinas nucleares (78% em 2006, a partir de apenas 8% em 1973, 24% em 1980, e 75% em 1990).
A rede ferroviária da França, que se estende por 29.213 quilômetros, é a mais extensa da Europa Ocidental
É operada pela SNCF, e os trens de alta velocidade incluem o Thalys, Eurostar e TGV, que viaja a 320 quilômetros por hora em uso comercial
O Eurostar, juntamente com o Serviço de Transferência do Eurotúnel, conecta-se com o Reino Unido através do Túnel da Mancha
As ligações ferroviárias estendem-se para todos os outros países vizinhos na Europa, com exceção de Andorra
Ligações intra-urbanas também são bem desenvolvidas, com os serviços de metrô e bondes complementando os serviços de ônibus.
Há aproximadamente 893.300 quilômetros de rodovias utilizáveis na França
A região de Paris está envolvida com uma rede densa de estradas e rodovias que a ligam com praticamente todas as partes do país
Estradas francesas também lidam com um importante tráfego internacional, conectando-se com cidades da vizinha Bélgica, Espanha, Andorra, Mônaco, Suíça, Alemanha e Itália
Não há taxa de matrícula anual ou estrada fiscal, entretanto, o uso da auto-estrada é através de pedágios, exceto nas imediações dos municípios de grandes dimensões
O mercado de carros novos é dominado por marcas domésticas como a Renault (27% dos carros vendidos na França, em 2003), Peugeot (20,1%) e Citroën (13,5%)
Mais de 70% dos carros novos vendidos em 2004, tinham motores a diesel, muito mais do que continha gasolina ou a GPL
A França também possui a ponte mais alta estrada do mundo: o Viaduto de Millau, e construiu muitas pontes importantes, como a Ponte da Normandia.
Há cerca de 478 aeroportos na França, incluindo campos de pouso
O Aeroporto de Paris-Charles de Gaulle, situado nos arredores de Paris, é o maior e mais movimentado aeroporto do país, e manipula grande maioria do tráfego popular e comercial do país e liga Paris com praticamente todas as grandes cidades em todo o mundo
A Air France é a companhia aérea nacional, apesar de numerosas companhias aéreas privadas que fornecem serviços de viagens domésticas e internacionais
Há dez principais portos na França, a maior das quais é, em Marselha, que também é a maior fronteira com o Mar Mediterrâneo
14.932 quilômetros de canais atravessam a França, incluindo o Canal du Midi, que liga o Mar Mediterrâneo ao Oceano Atlântico através do rio Garona.
Em 1802, Napoleão Bonaparte criou o lycée
No entanto, é Jules Ferry que é considerado o pai da moderna escola francesa, que é gratuita, laica e obrigatória até aos 13 anos de idade desde 1882 (o comparecimento escolar na França agora é obrigatório até os 16 anos de idade).
Atualmente, o sistema de ensino na França é centralizado e é composto de três fases, o ensino primário, secundário e ensino superior
O Programa Internacional de Avaliação de Alunos, coordenado pela Organização para a Cooperação e Desenvolvimento Econômico (OCDE), classifica a educação da França como a 25ª melhor do mundo, não sendo nem significativamente superior nem inferior à média da OCDE.
A educação primária e secundária são predominantemente públicas, administradas pelo Ministério da Educação Nacional
O sistema educacional francês é subdividido em cinco diferentes níveis: École Maternelle (pré-escola, de 2 a 5 anos); École Primaire ou Élementaire (5 primeiros anos do ensino fundamental, de 6 a 10 anos); Collège (4 últimos anos do ensino fundamental, entre 11 e 15 anos); Lycée (Ensino médio, entre 16 e 18 anos) e Université (Universidade).
Desde a Idade Média, a França tem sido um dos principais contribuintes para a produção científica
Por volta do início do século XI o Papa Silvestre II reintroduziu o ábaco e a esfera armilar e apresentou os algarismos indo-arábicos e os relógios para a Europa do norte e ocidental
A Universidade de Paris, fundada em meados do século XII, ainda é uma das mais importantes universidades do mundo ocidental.
No século XVII, René Descartes definiu um método para a aquisição de conhecimento científico, enquanto Blaise Pascal tornou-se famoso por seu trabalho sobre a probabilidade e a mecânica de fluidos
Ambos foram figuras-chave da revolução científica que eclodiu na Europa durante este período
A Académie des Sciences foi fundada por Luís XIV para incentivar e proteger o espírito de pesquisa científica francesa
Esteve na vanguarda dos progressos científicos na Europa nos séculos XVII e XVIII
É uma das primeiras academias de ciências.
O período do Iluminismo foi marcado pelo trabalho do biólogo Buffon e do químico Lavoisier, que descobriu o papel do oxigênio na combustão, enquanto Diderot e D'Alembert publicaram a Encyclopédie, que tinha como objetivo dar acesso ao "conhecimento útil" para o povo, um conhecimento que possam aplicar à sua vida cotidiana.
Com a Revolução Industrial, no século XIX, desenvolvimentos científicos espetaculares aconteceram na França com cientistas como Augustin Fresnel, fundador da óptica moderna; Nicolas Léonard Sadi Carnot, que lançou as bases da termodinâmica; ou Louis Pasteur, um dos pioneiros da microbiologia
Outros cientistas franceses eminentes do século XIX têm seus nomes inscritos na Torre Eiffel, em Paris.
Cientistas franceses famosos do século XX incluem o matemático e físico Henri Poincaré, os físicos Henri Becquerel e Pierre e Marie Curie tornaram-se famosos por seus trabalhos sobre a radioatividade, o físico Paul Langevin ou o virologista Luc Montagnier, co-descobridor do HIV/AIDS
Até 2012, 65 franceses ganharam o Prêmio Nobel e 11 receberam a Medalha Fields.
O sistema de saúde francês ficou em primeiro lugar a nível mundial de acordo com a Organização Mundial de Saúde em 1997 e depois novamente em 2000
O sistema de saúde é geralmente livre para as pessoas afetadas por doenças crônicas (Affections de longues durées), tais como câncer, AIDS ou fibrose cística
A expectativa de vida média ao nascer é de 77 anos para homens e 84 anos para as mulheres, uma das mais altas da União Europeia
Existem 3,22 médicos para cada 1000 habitantes na França, enquanto que o gasto médio per capita de saúde foi de 4.719 de dólares em 2008
Em 2007 existiam cerca de 140.000 habitantes (0,4%) da França que viviam com HIV/AIDS.
Apesar dos franceses terem a reputação de ser um dos povos mais magros entre os países desenvolvidos, a França, como outros países ricos, enfrenta uma epidemia crescente e recente de obesidade, principalmente devido à substituição da culinária tradicional francesa saudável por junk food nos hábitos alimentares franceses
No entanto, a taxa de obesidade francesa é muito inferior a dos Estados Unidos (por exemplo, taxa de obesidade na França é a mesma que a estadunidense era na década de 1970) e ainda é a mais baixa da Europa,mas agora é considerada pelas autoridades como um dos principais problemas de saúde pública e é ferozmente combatida; taxas de obesidade infantil estão a abrandar na França, enquanto continua a crescer em outros países.
A França tem sido um centro de criação cultural por séculos
Muitos artistas franceses estiveram entre os mais famosos de seu tempo e a França ainda é reconhecida no mundo pela sua rica tradição cultural
Os sucessivos regimes políticos que sempre promoveram a criação artística e a criação do Ministério da Cultura em 1959 ajudaram a preservar o patrimônio cultural do país e torná-lo disponível ao público
O Ministério da Cultura tem sido muito ativo desde a sua criação na concessão de subsídios aos artistas, promovendo a cultura francesa no mundo, apoiando festivais e eventos culturais, além de proteger monumentos históricos
O governo francês também conseguiu manter uma exceção cultural para defender produtos audiovisuais feitos no país.
A França recebe o maior número de turistas por ano, em grande parte graças aos inúmeros estabelecimentos culturais e edifícios históricos implantados em todo o seu território
Dispõe de 1 200 museus que recebem mais de 50 milhões de pessoas anualmente.
Os locais culturais mais importantes são mantidos pelo governo, por exemplo, através da agência pública do Centro Nacional de Monumentos, que tem cerca de uma centena de monumentos históricos nacionais sob seu cuidado
Os 43.180 edifícios protegidos como monumentos históricos incluem principalmente residências (muitos castelos) e edifícios religiosos (catedrais, basílicas, igrejas, etc), mas também estátuas, memoriais e jardins
A UNESCO inscreveu 37 locais na França como Patrimônios Mundiais.
As primeiras manifestações artísticas vêm do período pré-histórico, em estilo franco-cantábrico
A época carolíngia marca o nascimento de uma escola de iluminadores que se prolongará ao longo de toda a Idade Média, culminando nas ilustrações do livro As Horas Muito Ricas do duque de Berry
Os pintores clássicos do século XVII francês são: Poussin e Lorrain.
No século XVIII predomina o rococó, com Watteau, Boucher e Fragonard
Nos finais do século começa o classicismo de Jacques-Louis David
O romanticismo está dominado pelas figuras de Géricault e Delacroix
A paisagem realista da Escola de Barbizon tem sua continuação em artistas de um realismo mais testemunhial sobre a realidade social de seu tempo, como Millet e Courbet
Na França, a escultura evoluiu por diversos estilos, se sobressaindo em todos eles: pré-histórico, romano, cristão, românico, gótico, renascentista, barroco e rococó, neoclássico (Frédéric Auguste Bartholdi: Estátua da Liberdade), romântico (Auguste Rodin: O pensador), e os contemporâneos.
Na segunda parte do século XIX, a influência da França sobre a pintura tornou-se ainda mais importante, com o desenvolvimento de novos estilos de pintura como o impressionismo e o simbolismo
Os pintores impressionistas mais famosos da época foram Camille Pissarro, Édouard Manet, Edgar Degas, Claude Monet e Auguste Renoir
A segunda geração de pintores de estilo impressionista, Paul Cézanne, Paul Gauguin, Toulouse-Lautrec e Georges Seurat, também estavam na vanguarda das evoluções artísticas, bem como os artistas fauvistas Henri Matisse, André Derain e Maurice de Vlaminck.
Muitos museus na França são inteiramente ou parcialmente dedicados a esculturas e obras de pintura
Uma enorme coleção de obras antigas criadas antes ou durante o século XVIII são exibidas no Museu do Louvre, como a Mona Lisa, também conhecido como La Joconde
Enquanto o Palácio do Louvre tem sido durante muito tempo um museu, o Museu d'Orsay foi inaugurado em 1986 na antiga estação ferroviária Gare d'Orsay, em uma grande reorganização de coleções de arte nacionais, para reunir pinturas francesas da segunda parte de o século XIX (principalmente movimentos de impressionismo e fauvismo)
As obras modernas são apresentadas no Musée National d'Art Moderne, que se mudou em 1976 para o Centro Georges Pompidou
Esses três museus estatais recebem cerca de 17 milhões de pessoas por ano
Outros museus nacionais que hospedam pinturas incluem o Grand Palais (1,3 milhão de visitantes em 2008), mas também há muitos museus pertencentes a cidades, sendo o mais visitado o Musée d'Art Moderne de la Ville de Paris (800 mil visitantes em 2008), que hospeda obras contemporâneas.
A literatura francesa mais antiga data da Idade Média, quando o que agora é conhecido como a França moderna ainda não tinha uma linguagem única e uniforme
Um importante escritor do século XVI foi François Rabelais, cujo romance Gargantua e Pantagruel permaneceu famoso e apreciado até os dias atuais
Michel de Montaigne foi a outra grande figura da literatura francesa durante esse século
O seu trabalho mais famoso, Ensaios, criou o gênero literário do ensaio.
Durante o século XVII, Madame de La Fayette publicou anonimamente La Princesse de Clèves, uma novela que é considerada um dos primeiros romances psicológicos de todos os tempos
Jean de La Fontaine é um dos fabulistas mais famosos da época, autor de obras como A Cigarra e a Formiga
Gerações dos alunos franceses tiveram que aprender suas fábulas, que eram vistas como ajudando a ensinar sabedoria e senso comum aos jovens
Alguns de seus versos entraram no idioma popular para se tornarem provérbios, como "À l'oeuvre, on connaît l'artisan"
[No trabalho, conhecemos o artesão].
Jean Racine, cujo incrível domínio do verso alexandrino e da língua francesa tem sido elogiado há séculos, criou peças como Phèdre ou Britannicus
Ele é, junto com Pierre Corneille (Le Cid) e Molière, considerado como um dos três grandes dramaturgos da época dourada da França
Molière, que é considerado um dos maiores mestres da comédia da literatura ocidental, escreveu dezenas de peças, incluindo Le Misanthrope, L'Avare, Le Malade imaginaire e Le Bourgeois Gentilhomme
Suas peças de teatro têm sido tão populares em todo o mundo que a língua francesa às vezes é apelidada como "linguagem de Molière".
A literatura francesa e a poesia floresceram ainda mais nos séculos XVIII e XIX
As obras mais conhecidas de Denis Diderot são Jacques o Fatalista e O Sobrinho de Rameau
No entanto, ele é mais conhecido por ser o redator principal da Encyclopédie, cujo objetivo era resumir todo o conhecimento de seu século (em campos como artes, ciências, línguas, filosofia) e apresentá-lo ao povo, a fim de lutar contra a ignorância e o obscurantismo
Durante esse mesmo século, Charles Perrault foi um prolífico escritor de famosos contos de fadas infantis, como O Gato de Botas, Cinderela, A Bela Adormecida e Barba Azul
No início do século XIX, a poesia simbolista era um movimento importante na literatura francesa, com poetas como Charles Baudelaire, Paul Verlaine e Stéphane Mallarmé.
No século XIX, surgiram muitos autores renomados franceses
Victor Hugo é muitas vezes descrito como "o maior escritor francês de todos os tempos" por se destacar em todos os gêneros literários
O prefácio de sua peça de teatro Cromwell é considerado o manifesto do movimento romântico
Les Contemplations e La Légende des siècles são considerados "obras-primas poéticas", o versículo de Hugo foi comparado ao de Shakespeare, Dante e Homero.Sua novela Les Misérables é amplamente vista como um dos maiores romances já escritos.
O Prix Goncourt é um prêmio literário francês criado em 1903
Importantes escritores do século XX incluem Marcel Proust, Louis-Ferdinand Céline, Albert Camus e Jean-Paul Sartre
Antoine de Saint Exupéry escreveu Le Petit Prince, que permaneceu popular há décadas entre crianças e adultos em todo o mundo
Os autores franceses tinham mais Prêmios Nobel de Literatura do que os de qualquer outro país
O primeiro Prêmio Nobel de Literatura foi para um autor francês, enquanto que o último Prêmio Nobel de Literatura da França foi recebido por Patrick Modiano, que recebeu o prêmio em 2014
Jean-Paul Sartre também foi o primeiro candidato na história do comitê a recusar o prêmio em 1964.
Na música francesa desde antes do ano 1000 se destaca o canto gregoriano empregado nas liturgias
Na França se criou a polifonia
Na denominada Ars Antiqua, se atribui a Carlos Magno o Scholae Cantorum (783)
Os Juramentos de Estrasburgo, é a obra lírica francesa mais importante da Idade Média, período no que se desenvolvem as Canções de Gesto como a A Canção de Rolando.
A França foi o berço dos trovadores no século XII, assim como do Ars Nova dos séculos posteriores
Durante o Romantismo Paris se converte no centro musical do mundo e na atualidade, a França mantém um lugar privilegiado na criação musical graças a novas gerações de compositores
Dentro dos exponentes da música popular francesa, se encontram figuras como Edith Piaf, Mireille Mathieu, Dalida, Charles Aznavour, Vanessa Paradis, Serge Gainsbourg e Gilbert Becaud.
No que se refere à arquitetura, os celtas deixaram seus rastros também na construção de grandes monólitos ou megálitos, e a presença grega desde o século VI a.C
que hoje é recordada na herança clássica de Marselha
O estilo românico tem exemplos na Maison Carrée, templo romano edificado entre 161 e 138 a.C., ou no Pont du Gard construído entre os anos 40 e 60, em Nimes e declarado patrimônio universal em 1985
Na França se inventou o estilo gótico, plasmado em Catedrais como as de Chartres, Amiens, Notre-Dame ou Estrasburgo.
O Renascimento surgido na Itália, tem seu estilo arquitetônico representado magistralmente no Castelo de Blois ou no Palácio de Fontainebleau entre outros
A arte barroca (também de origem italiana), e o rococó (invenção francesa) têm obras extraordinárias na França
Tal é o caso do Palácio do Louvre e o Panthéon de Paris entre tantos outros.
O modernismo ou arte moderna na arquitetura engloba todo o século XIX e a primeira metade do XX, e Gustave Eiffel revolucionou a teoria e prática arquitetônica de seu tempo na construção de gigantescas pontes e no emprego de materiais como o aço
Sua obra mais famosa é a chamada Torre Eiffel
Outro grande ícone da arquitectura universal é Le Corbusier, um inovador e funcionalista celebrado especialmente por seus aportes urbanísticos nas edificações de vivendas e conjuntos habitacionais.
Os jornais mais vendidos no país são o Le Parisien (com 460 mil vendidos diariamente), o Le Monde e o Le Figaro, com cerca de 300 mil cópias por dia, assim como o L'Équipe, dedicado à cobertura esportiva
Nos últimos anos, jornais gratuitos, com o Metro, o 20 minutes e o Direct Plus, distribuíram mais de 650 mil cópias, respectivamente
No entanto, as maiores taxa de vendas são alcançadas pelo jornal regional Ouest-France, com mais de 750 mil exemplares vendidos, sendo que outros 50 jornais regionais também têm vendas elevadas
O setor de revistas semanais é mais forte e mais variado do que as 400 revistas especializadas publicadas no país.
As revistas semanais mais influentes são a Le Nouvel Observateur, a L'Express e a Le Point (mais de 400 mil cópias), mas a maior circulação entre os semanários é alcançada por revistas de TV e por revistas femininas, como Marie Claire e Elle, que possuem versões estrangeiras
Semanais influentes também incluem jornais investigativos e satíricos, como Le Canard enchaîné e Charlie Hebdo, bem como Paris Match
Como na maioria das nações industrializadas, a mídia impressa foi afetada por uma grave crise na última década
Em 2008, o governo lançou uma iniciativa importante para ajudar a reformar o setor e a deixá-lo financeiramente independente, mas em 2009 teve que dar 600 mil euros para ajudar a mídia impressa a lidar com a crise econômica, além dos subsídios já existentes.
Em 1974, após anos de monopólio centralizado na rádio e televisão, a agência governamental Office de Radiodiffusion Télévision Française (ORTF) foi dividida em várias instituições nacionais, mas os três canais de TV já existentes e quatro estações de rádio nacionais permaneceram sob controle estatal
Foi apenas em 1981 que o governo permitiu a transmissão gratuita no território, acabando com o monopólio estatal no rádio.
A França tem ligações históricas e fortes com o cinema, sendo que foram dois franceses, Auguste e Louis Lumière (conhecidos como Irmãos Lumière) que criaram o cinema em 1895
Vários movimentos cinematográficos importantes, incluindo a Nouvelle vague dos anos 1950 e 1960, começaram no país
A França é conhecida por ter uma indústria cinematográfica forte, devido em parte às proteções oferecidas pelo governo francês
Em 2015, produziu mais filmes do que qualquer outro país europeu
A nação também acolhe o Festival de Cannes, um dos festivais de cinema mais importantes e famosos do mundo.
Embora o mercado cinematográfico francês seja dominado por Hollywood, a França é a única nação no mundo onde os filmes estadunidenses representam a menor parcela da receita total do filme, em 50%, contra 77% na Alemanha e 69% no Japão
Os filmes franceses representam 35% do total das receitas cinematográficas da França, que é a maior porcentagem de receitas cinematográficas nacionais no mundo desenvolvido fora dos Estados Unidos, contra 14% na Espanha e 8% no Reino Unido.Em 2013, o país era o segundo maior exportador de filmes no mundo, depois dos Estados Unidos.
Até recentemente, a França havia sido, durante séculos, o centro cultural do mundo, embora sua posição dominante tenha sido superada pelos Estados Unidos
Posteriormente, o país tomou medidas para proteger e promover a sua cultura, tornando-se um dos principais defensores da exceção cultural
A nação conseguiu convencer todos os membros da União Europeia a se recusarem a incluir a cultura e o audiovisual na lista de setores liberalizados da Organização Mundial do Comércio (OMC) em 1993
Além disso, esta decisão foi confirmada em uma votação na UNESCO em 2005 e o princípio da "exceção cultural" ganhou uma vitória irresistível: 198 países votaram a favor, apenas dois países, os Estados Unidos e Israel, votaram contra.
A culinária francesa é conhecida por ser uma das melhores do mundo
De acordo com as regiões, as receitas tradicionais são diferentes, o norte do país prefere usar manteiga como a gordura preferida para cozinhar, enquanto o azeite é mais usado no sul
Além disso, cada região da França tem especialidades tradicionais icônicas: cassoulet no sudoeste, choucroute na Alsácia, quiche na região de Lorena, bife borgonhesa na Borgonha, tapenade de Provença, etc
Os produtos mais renomados da França são vinhos, incluindo champagne, bordeaux, bourgogne e beaujolais, bem como uma grande variedade de queijos diferentes, como camembert, roquefort e brie
Existem mais de 400 variedades diferentes.
A culinária francesa também é considerada um elemento-chave da qualidade de vida e da atratividade da França
Uma publicação francesa, o guia Michelin, premia com estrelas alguns estabelecimentos selecionados pela excelência
A aquisição ou perda de uma estrela pode ter efeitos dramáticos no sucesso de um restaurante
Em 2006, o guia Michelin concedeu 620 estrelas aos restaurantes franceses, naquela época mais do que qualquer outro país, embora o guia também inspecione mais restaurantes na França do que em qualquer outro país (até 2010, o Japão recebeu várias estrelas Michelin como a França, apesar de ter metade do número de inspetores Michelin trabalhando lá).
Além da tradição do vinho, a França também é um importante produtor de cerveja e rum
As três principais regiões francesas de cerveja são a Alsácia (60% da produção nacional), Nord-Pas-de-Calais e Lorraine
Uma refeição geralmente consiste em três pratos: hors d'oeuvre ou 'entrée (entrada, às vezes sopa), plat principal (prato principal) e fromage (queijo) ou dessert (sobremesa), às vezes com uma salada oferecida antes do queijo ou da sobremesa.
A França foi por duas vezes sede dos Jogos Olímpicos de Verão: a segunda edição, em 1900, e a oitava edição, em 1924
Também sediou os Jogos Olímpicos de Inverno três vezes: a primeira edição, em 1924; a décima edição, em 1968; e a décima-sexta edição, em 1992.
No futebol, a França sediou a Copa do Mundo FIFA por duas vezes, sendo a primeira delas em 1938, quando a Itália conquistou o título, e a segunda em 1998, quando a seleção nacioal, após duas tentativas frustradas de chegar à fase final das Copas de 1958 e 1986, pôde finalmente chegar a final da competição
Durante o mundial, os jogos foram realizados nas cidades de Saint-Denis, Marselha, Paris, Lens, Lyon, Nantes, Toulouse, Saint-Étienne, Bordeaux, e Montpellier
O Mundial foi conquistado pela propria França, seleção anfitriã, sagrando-se pela primeira vez campeã na história, ao vencer a Seleção Brasileira de Futebol por 3 a 0 na final.
Nos Jogos Olímpicos de Verão, a França já foi medalha de ouro na modalidade masculina, em 1984
No futebol feminino, a melhor posição da Seleção Francesa terminou no quarto lugar na Copa do Mundo de Futebol Feminino de 2011 e nos Jogos Olímpicos de Verão de 2012
Em 2016 sediou a Eurocopa e chegou até a final, mas perdeu na prorrogação para Portugal.
A França também tem forte tradição no tênis
Sedia o Grand Slam de Roland Garros e já foi 9 vezes campeã da Copa Davis
René Lacoste, no entanto, foi o único tenista francês a ser n.º 1 do mundo
Na atualidade o melhor tenista francês é Jo-Wilfried Tsonga, ex-n.º 5 do mundo
Um dos maiores esportistas da história da França foi Alain Prost, quatro vezes campeão do Mundial de Pilotos da Fórmula 1, considerado um dos mais bem sucedidos pilotos da categoria de todos os tempos.
A França vem tendo resultados expressivos na natação mundial com nomes como Alain Bernard, Frédérick Bousquet, Laure Manaudou e Camille Muffat (todos ex-recordistas mundiais e medalhistas olímpicos)
O destaque histórico é Jean Boiteux, primeiro francês campeão olímpico na natação
No atletismo, a França tem como destaques históricos Alain Mimoun, Marie-José Perec e Renaud Lavillenie Outro destaque francês é o judoca Teddy Riner, tido como praticamente imbatível em sua categoria
Entre 2007 e 2012 ele foi pentacampeão mundial na categoria +100 kg e em 2012 se tornou campeão olímpico.
Dependências da Coroa e Territórios Ultramarinos Britânicos: Acrotíri e Deceleia • Gibraltar • Guernsey • Jersey • Ilha de Man
Nação do Reino da Dinamarca: Ilhas Faroé
Região Autónoma da Finlândia: Åland
Regiões Autónomas de Portugal: Açores e Madeira
República Turca de Chipre do Norte • Transnístria • Abecásia • Ossétia do Sul • Alto Carabaque
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


Obesidade é uma condição médica em que se verifica acumulação excessiva de tecido adiposo ao ponto de poder ter impacto negativo na saúde
Uma pessoa é considerada obesa quando o seu índice de massa corporal (IMC) é superior a 7002294199500000000♠30 kg/m, e com excesso de peso quando o seu IMC é superior a 7002245166250000000♠25–30 kg/m
O IMC é calculado dividindo o peso da pessoa pelo quadrado da sua altura
A obesidade aumenta a probabilidade de ocorrência de várias doenças, em particular de doenças cardiovasculares, diabetes do tipo 2, apneia do sono obstrutiva, alguns tipos de cancro, osteoartrite, e depressão.
A causa mais comum de obesidade é uma combinação de dieta hiperenergética, falta de exercício físico e suscetibilidade genética
Alguns casos são causados por genes, doenças endócrinas, medicamentos ou perturbações mentais
Não há evidências que apoiem um metabolismo lento como causa de obesidade em pessoas obesas que comem pouco
Em média, as pessoas obesas consomem mais energia do que as restantes, uma vez que quanto maior a massa corporal, maior a necessidade de energia.
A prevenção da obesidade consiste em alterações sociais e escolhas pessoais
O tratamento da obesidade baseia-se na dieta e no exercício físico
A qualidade da dieta pode ser melhorada reduzindo o consumo de alimentos ricos em energia, tais como os que têm grande quantidade de gordura e açúcar, e aumentando a ingestão de fibra dietética
Para acompanhar a dieta adequada pode ser administrada medicação anti-obesidade para reduzir o apetite ou diminuir a absorção de gordura pelo corpo
Quando a dieta, o exercício e a medicação não demonstram ser eficazes, pode ser considerada a aplicação de uma banda gástrica ou uma cirurgia bariátrica para reduzir o volume do estômago ou o comprimento do intestino, o que faz com que a pessoa se sinta cheia mais cedo e que haja menor capacidade de absorção de nutrientes dos alimentos.
A obesidade é uma das principais causas de morte evitáveis em todo o mundo, com taxas de prevalência cada vez maiores em dultos e crianças
Em 2015, 600 milhões de adultos (12% do total) e 100 milhões de crianças eram obesas
A obesidade é mais comum entre mulheres do que entre homens
As autoridades de saúde consideram a obesidade um dos mais graves problemas de saúde pública do século XXI
Em grande parte do mundo contemporâneo, particularmente na sociedade ocidental, a obesidade é alvo de estigma social, embora ao longo da História tenha sido vista como símbolo de riqueza e fertilidade, perspetiva que ainda se mentém em algumas partes do mundo.


A obesidade é uma condição médica na qual se verifica acumulação de tecido adiposo em excesso ao ponto de poder ter impacto negativo na saúde
É definida em função do índice de massa corporal (IMC) e avaliada em termos de distribuição de gordura pelo índice de cintura e quadris e pelos factores de risco cardiovascular
O IMC está intimamente relacionado com a taxa de gordura corporal e a quantidade total de gordura no corpo.
Calcula-se o IMC dividindo o peso do indivíduo pelo quadrado da sua altura, através da seguinte forma:
As definições mais amplamente usadas a nível mundial e em vigor nos países lusófonos, definidas pela Organização Mundial de Saúde (OMS) em 1997 e publicadas em 2000, indicam os valores de referência na tabela à direita
No entanto, alguns países asiáticos redefiniram os valores de obesidade da OMS, uma vez que as populações asiáticas desenvolvem consequências de saúde negativas a um IMC menor do que os caucasianos
Por exemplo, o Japão define obesidade como qualquer IMC superior a 25 kg/m, enquanto que a China usa um IMC superior a 28 kg/m
Algumas entidades de saúde também realizam alterações à definição da OMS
Por exemplo, a literatura cirúrgica divide a obesidade de classe III em mais categorias, cujos valores precisos ainda se encontram em discussão.
Em crianças, o peso considerado saudável varia em função da idade e do sexo
A obesidade em crianças e adolescentes não é definida em função de um número absoluto, mas sim por um percentil
Assim, uma criança com idade superior a dois anos é considerada obesa quando o seu IMC é igual ou superior ao percentil 95 para o seu sexo e idade
Da mesma forma, considera-se que uma criança tem excesso de peso (pré-obesidade) quando o seu IMC está entre o percentil 85 e 95
Os dados de referência nos quais estes percentis se baseiam correspondem ao período entre 1963 e 1994, os quais não foram afetados pelo aumento recente da média de peso.
O excesso de massa corporal está associado a várias doenças, em particular doenças cardiovasculares, diabetes do tipo 2, apneia do sono, alguns tipos de cancro, osteoartrite e asma Em consequência destes factores, determina-se que a obesidade contribui para a diminuição da esperança de vida.
A obesidade é uma das principais causas de morte evitáveis em todo o mundo.
Em cada ano, morrem 3,4 milhões de adultos em consequência da obesidade ou do sobrepeso
A doença está também na origem de 44% dos casos de diabetes, 23% dos casos de doença arterial coronariana e entre 7 e 41% de determinados tipos de cancro
Na Europa, 7,7% das mortes (cerca de um milhão de pessoas) são atribuídas ao excesso de peso
Em média, a obesidade reduz a esperança de vida entre seis a sete anos
Um IMC entre 30 e 35 kg/m reduz a esperança de vida entre dois e quatro anos, enquanto que a obesidade grave (IMC > 40 kg/m) reduz a esperança de vida em dez anos.
O risco de mortalidade é menor no intervalo de IMC de 20-25 kg/m em não fumadores, e 24–27 kg/m em fumadores
Existe uma associação entre valores de IMC superiores a 32 kg/m e a duplicação da taxa de mortalidade entre mulheres, ao longo de um período de 16 anos.
A obesidade aumenta o risco de diversas complicações físicas e psicológicas
Estas comorbidades estão frequentemente integradas numa condição denominada síndrome metabólica, um conjunto de transtornos clínicos que engloba: diabetes mellitus tipo 2, pressão arterial elevada, colesterol elevado e níveis elevados de triglicerídeos
As complicações podem ser causadas diretamente pela obesidade ou de forma indireta, através de mecanismos com causas em comum, como por exemplo uma dieta desequilibrada ou um estilo de vida sedentário
A intensidade da relação entre a obesidade e complicações específicas é variável
Uma das mais fortes é a ligação com a diabetes do tipo II
O excesso de gordura corporal está na origem de 64% dos casos de diabetes em homens e 77% dos casos em mulheres.
As consequências da obesidade a nível da saúde podem ser classificadas em duas categorias genéricas: as que podem ser atribuídas aos efeitos do aumento da massa adiposa (como a osteoartrite, a apneia de sono ou o estigma social) e as que podem ser atribuídas ao aumento do número e do volume de células adiposas, como a diabetes, cancro, doenças cardiovasculares ou a doença hepática gordurosa não alcoólica
O aumento de gordura corporal altera a reação do corpo à insulina, o que pode provocar resistência à insulina, e também cria um estado pró-inflamatório e pró-trombótico.
A nível individual, pensa-se que maior parte dos casos de obesidade se deva a uma conjugação da ingestão de alimentos energéticos em excesso com a ausência de exercício físico
Uma percentagem pequena de casos deve-se principalmente a condições genéticas, transtornos psiquiátricos ou razões médicas em geral
Por outro lado, o aumento generalizado da prevalência de obesidade na sociedade deve-se à facilidade no acesso à dieta hiperenergética, ao aumento da dependência de transportes automóveis e à mecanização do trabalho.
Existe uma relação entre o consumo de energia total e a obesidade
A maior parte da energia consumida em excesso tem origem no aumento do consumo de hidratos de carbono, e não no consumo de gordura
As principais fontes destes hidratos de carbono em excesso são as bebidas açucaradas e as batatas fritas, e acredita-se que o seu consumo excessivo esteja a contribuir para o aumento dos índices de obesidade
À medida que as sociedades se tornam cada vez mais consumidoras de dietas hipercalóricas, fast-food e refeições de grandes porções, a ligação entre o consumo de fast-food e a obesidade torna-se mais evidente.
A disponibilidade de energia dietética per capita varia de forma acentuada entre diferentes regiões e países, e foi-se alterando de forma significativa ao longo do tempo
Entre o início da década de 1970 e o fim da década de 1990, a energia alimentar disponível por pessoa e por dia (a quantidade de alimentos comprados) aumentou em todas as partes do mundo, exceto na Europa do Leste
A maior disponibilidade encontra-se nos Estados Unidos, com 3654 cal por pessoa em 1996, valor que aumentou para 3754 Cal em 2003
Em finais da década de 1990, os europeus tinham disponíveis em média 3394 Cal por pessoa, enquanto que nas regiões em desenvolvimento da Ásia a disponibilidade era de 2648 por pessoa e na África subsariana de 2176 Cal por pessoa
Apesar de estarem disponíveis recomendações de nutrição em diversos países, continuam a existir problemas derivados da ingestão excessiva de alimentos e de escolhas dietéticas pouco saudáveis.
As políticas a as técnicas agrícolas introduzidas na Europa e na América do Norte no pós-guerra proporcionaram a descida acentuada do preço dos alimentos
Entre estas políticas estão os subsídios à produção agrícola, como os que são provenientes da Política Agrícola Comum
No entanto, grande parte dos subsídios destinou-se à produção de milho, soja, trigo e arroz, o que fez com que estes alimentos se tornassem as principais fontes de comida processada
Assim, apesar dos custos de produção e tecnologia envolvidos, a comida processada com base neste alimentos tornou-se mais barata do que a própria fruta ou os vegetais
No fim da década de 2000, começou-se a questionar e a discutir a distribuição de subsídios agrícolas no sentido de melhor adequá-los às necessidades dietéticas, promovendo o cultivo de frutas e vegetais.
O estilo de vida sedentário desempenha um papel significativo na obesidade
A OMS sugere que entre a população mundial verifica-se um declínio das atividades recreativas ativas e que, atualmente, cerca de 30% da população mundial não realiza exercício físico suficiente
Isto deve-se à tendência de evolução para condições de trabalho que exigem cada vez menos esforço físico, ao aumento da utilização de transportes mecanizados e à maior prevalência de tecnologia residencial
No caso das crianças, o declínio na quantidade de atividade física deve-se também à diminuição na quantidade de percursos feitos a pé e à inexistência de educação física.
Tanto em adultos quanto em crianças existe uma correlação entre o tempo passado em frente à televisão e o risco de obesidade
Um estudo de revisão constatou que 63 entre 73 estudos (86%) demonstraram existir um aumento da taxa de obesos em função do aumento da exposição aos meios de comunicação, no qual a taxa aumenta de forma proporcional ao tempo de visualização.
Tal como muitas outras condições médicas, a obesidade é o resultado da interação entre fatores genéticos e ambientais
Perante fatores ambientais idênticos, o risco de obesidade é maior nas pessoas com predisposição genética para a doença
Esta predisposição genética tem origem nos polimorfismos de vários genes que controlam o apetite e o metabolismo
Existem mais de 40 sítios do genoma humano que estão associados ao desenvolvimento de obesidade quando existe comida em quantidade suficiente.
As pessoas com duas cópias do gene FTO pesam em média 3 a 4 quilos a mais e apresentam um risco 1,67 vezes superior de obesidade, em comparação com a restante população
A percentagem de obesidade que pode ser atribuída a factores genéticos varia entre 6 e 85%, dependendo da população examinada
Verifica-se que 7% das pessoas com obesidade grave precoce (obesidade antes dos 10 anos de idade e com IMC três vezes superior ao normal) possuem mutação pontual no ADN
Cerca de 80% dos filhos de dois progenitores obesos são também obesos, valor que contrasta com os menos de 10% entre os filhos de pais com peso normal
A obesidade é também uma das principais características de diversas síndromes genéticas, como a síndrome de Prader-Willi ou a síndrome de Bardet-Biedl.
Embora a influência genética seja importante para compreender a obesidade, ela por si só não explica o aumento dramático da incidência em determinados países ou em escala global
Existem diversas atitudes sociais que aparentam aumentar o risco de obesidade, como o stress, a discriminação, a classe socioeconómica, o tabagismo, o número de filhos e a urbanização.
A correlação entre a classe social e o IMC varia consoante a região do mundo
Em países desenvolvidos, o grupo com menor probabilidade de obesidade são as mulheres das classes superiores
Por outro lado, nos países em desenvolvimento os homens, mulheres e crianças das classes sociais superiores são os que apresentam as maiores taxas de obesidade
No entanto, devido aos efeitos da globalização, as diferenças têm-se vindo a atenuar
Em países desenvolvidos, o número de adultos obesos e crianças com sobrepeso está correlacionado com a desigualdade económica
Têm sido propostas diversas explicações para a relação entre o IMC e a classe social: em países desenvolvidos, as pessoas com maior poder de compra têm a possibilidade de escolher alimentação mais equilibrada e saudável, estão sob maior pressão social para manterem o peso ideal e têm a possibilidade de praticar programas de fitness; em países em vias de desenvolvimento, o padrão observado pode ser explicado pela diferença no acesso à alimentação, pela grande quantidade de energia dispendida no trabalho físico e por valores culturais que favorecem um corpo maior.
Fumar tem um efeito assinalável no peso individual
As pessoas que desistem de fumar aumentam em média entre 4,4 kg (homens) e 5,0 kg (mulheres) nos dez anos seguintes
No entanto, a diminuição do número de fumadores tem tido pouco efeito nas taxas de obesidade entre a população.
Na sociedade ocidental, o número de filhos tem também uma correlação com o aumento do risco de obesidade
O risco de uma mulher aumenta 7% por cada filho, enquanto o de um homem aumenta 4%
Isto pode ser explicado em parte pelo facto de que ter crianças dependentes diminui a atividade física dos pais
Nos países em desenvolvimento, a urbanização também desempenha um papel no aumento das taxas de obesidade
Por exemplo, na China a taxa nacional de obesidade é inferior a 5%, enquanto que nalgumas cidades é superior a 20%.
Algumas doenças físicas e mentais, e os fármacos usados no seu tratamento, podem aumentar o risco de obesidade
Entre as doenças que aumentam o risco de obesidade estão diversas síndromes genéticas raras e algumas condições congénitas ou adquiridas, como o hipotiroidismo, síndrome de Cushing ou deficiência de hormona do crescimento, e transtornos alimentares, como o transtorno da compulsão alimentar periódica
No entanto, a obesidade não é considerada nem classificada como transtorno psiquiátrico
O risco de sobrepeso e obesidade é maior em pessoas com transtornos psiquiátricos.
A desnutrição durante os primeiros anos de vida também aparenta desempenhar um papel no aumento da taxa de obesidade nos países em desenvolvimento
As alterações endócrinas que ocorrem durante períodos de desnutrição podem promover o armazenamento de gordura a partir do momento em que a comida esteja outra vez disponível
Diversos estudos confirmam também que a obesidade está também associada a défices cognitivos.
Alguns medicamentos podem provocar aumento de peso ou alterações na composição do corpo, como a insulina, sulfonilureias, tiazolidinedionas, antipsicóticos atípicos, antidepressivos, glicocorticoides, alguns anticonvulsivos (fenitoína e valproato), pizotifeno e algumas formas de contraceção hormonal.
Tem-se verificado que a flora intestinal difere entre pessoas magras e obesas, havendo uma indicação de que a flora pode afetar o potencial metabólico
Acredita-se que esta alteração no potencial metabólico faz com que o organismo tenha maior capacidade de recolher energia, contribuindo assim para a obesidade
No entanto, ainda não foi demonstrado de forma inequívoca se estas diferenças são causa ou consequência da obesidade
Verificou-se também uma associação entre vírus e obesidade em seres humanos e diversas outras espécies
No entanto, ainda está por determinar a contribuição desta associação para o aumento da taxa de obesidade.
Existem diversos mecanismos fisiopatológicos envolvidos no desenvolvimento e manutenção da obesidade e que participam na regulação do apetite e na ingestão de comida, no padrão de armazenagem do tecido adiposo e no desenvolvimento de resistência à insulina
Desde a descoberta da leptina, foram estudados diversos outros mediadores, como a grelina, insulina, orexina, colecistocinina e a adiponectina
As adipocinas são mediadores produzidos pelo tecido adiposo e supõe-se que sua acção modifique diversas doenças relacionadas à obesidade.
A leptina e a grelina são complementares ao nível da regulação do apetite
A grelina produzida pelo estômago regula o apetite a curto prazo, fazendo com que a pessoa sinta fome quando o estômago está vazio e indicando o momento em que o estômago está cheio
A leptina é produzida pelo tecido adiposo para sinalizar as reservas de gordura no corpo e mediar a regulação do apetite a longo prazo; isto é, comer mais quando as reservas são poucas, e pouco quando as reservas são muitas
Embora a administração de leptina possa ser eficaz num pequeno subgrupo de indivíduos obesos com deficiência de leptina, pensa-se que a maior parte seja resistente à leptina, apresentando inclusive níveis elevados da hormona, o que explica a ineficácia da administração de leptina para suprimir o apetite em grande parte da população.
Embora a leptina e a relina sejam produzidas perifericamente, elas regulam o apetite através de ações no sistema nervoso central
As diversas hormonas reguladoras do apetite atuam no hipotálamo, uma região do cérebro onde está concentrada a regulação da ingestão de alimentos e a gestão de energia
Existem diversos circuitos no hipotálamo que contribuem para a sua função reguladora do apetite, dos quais o sistema das melanocortinas é o mais bem compreendido
O circuito tem início no núcleo arqueado, uma região do hipotálamo com ligações ao hipotálamo lateral e ao hipotálamo ventromedial, os centros responsáveis pela alimentação e sacieção, respetivamente.
O núcleo arqueado contém dois grupos distintos de neurónios
O primeiro grupo coexpressa o neuropeptídeo Y (NPY) e o peptídeo Agouti (AgRP), ao mesmo tempo que estimula o hipotálamo lateral e inibe o hipotálamo ventromedial
O segundo grupo coexpressa pró-opiomelanocortina (POMC) e transcrito regulado por cocaína (CART), estimula o hipotálamo ventromedial e inibe o hipotálamo lateral
Desta forma, os neurónios NPY/AgRP estimulam a alimentação e inibem a saciação, enquanto que os neurónios POMC/CART estimulam a saciação e inibem a alimentação
Ambos os grupos do núcleo arqueado são regulados em parte pela leptina
A leptina inibe o grupo NPY/AgRP e estimula o grupo POMC/CART
Assim, a presença de uma deficiência na sinalização de leptina, causada tanto por insuficiência de leptina como por resistência à leptina, provoca sobrealimentação e pode ser responsável por algumas das formas genéticas e adquiridas de obesidade.
O principal tratamento para a obesidade é uma dieta apropriada e exercício físico
Os programas dietéticos proporcionam redução de peso a curto prazo, embora manter o peso pretendido seja difícil, pelo que geralmente essa redução necessita de ser acompanhada por alterações permanentes no estilo de vida da pessoa, como exercício físico regular e uma dieta menos calórica
A taxa de sucesso da manutenção a longo prazo da redução de peso com alterações no estilo de vida é de cerca de 20%
As alterações na dieta e no estilo de vida são eficazes na limitação do ganho de peso durante a gravidez e têm impacto positivo na saúde da mãe e da criança.
Estão disponíveis alguns fármacos para o tratamento de obesidade
Os mais comuns são o orlistato, a lorcaserina e a associação fentermina/topiramato
No entanto, a aprovação ou não de cada substância pode diferir bastante entre países
Embora o uso de lorcaserina tenha sido aprovado pela Food and Drug Administration norte-americana, o medicamento não foi aprovado pela Agência Europeia do Medicamento
A perda de peso com o orlistato é modesta, em média 2,9 kg entre 1 e 4 anos
O seu uso está associado a taxas elevadas de efeitos adversos gastrointestinais e têm sido levantadas preocupações acerca dos efeitos negativos nos rins
Os outros dois fármacos estão disponíveis nos Estados Unidos, mas não na Europa
A lorcaserina proporciona uma perda de peso média de 3,1 kg superior ao placebo ao longo de um ano
No entanto, pode aumentar os problemas relacionados com as válvulas do coração
A associação fenternina/topiramato apresenta alguma eficácia, embora possa estar associado a problemas no coração
Não existe ainda informação sobre a forma como estes fármacos afetam complicações a longo prazo da obesidade, tais como doenças cardiovasculares ou morte.
O tratamento mais eficaz para a obesidade é a cirurgia bariátrica, ou cirurgia de redução do estômago
O tratamento cirúrgico da obesidade está associado à perda de peso a longo prazo e à melhoria nas condições médicas relacionadas
Verificou-se num estudo uma perda de peso entre 14 e 25% ao longo de dez anos, dependendo do tipo de cirurgia, e uma redução de 29% na mortalidade, em comparação com as medidas convencionais para perder peso
No entanto, ocorrem complicações em 17% dos casos e em 7% é necessária uma segunda intervenção cirúrgica
Devido ao seu custo e riscos associados, atualmente procuram-se novos tratamentos eficazes, mas menos invasivos.
Antes do século XX a obesidade era rara
No entanto, em 1997 a OMS reconheceu formalmente a obesidade enquanto epidemia à escala global
Em 2008, a OMS estimou 500 milhões de adultos (10%) eram obesos e que a prevalência da doença era maior entre as mulheres
A incidência de obesidade também aumenta em função da idade até aproximadamente aos 50-60 anos
Em alguns países desenvolvidos o crescimento da obesidade grave é maior do que o crescimento da obesidade no geral.
Anteriormente considerada um problema restrito aos países industrializados, atualmente verifica-se que o aumento da obesidade se dá à escala global, afetando tanto os países desenvolvidos como os países em vias de desenvolvimento
Este aumento verifica-se de forma mais acentuada em contexto urbano, e a única região do mundo onde não é um problema comum é na África subsariana.
Em Portugal, a prevalência de pré-obesidade é de cerca de 34%, enquanto a prevalência de obesidade de 12%
Cerca de metade da população portuguesa não pratica qualquer atividade física regular, o que tem vindo a contribuir para o aumento acentuado da obesidade no país
A percentagem de sobrepeso é maior entre sexo masculino
Entre a população com idade superior a 55 anos, a prevalência de obesidade é 7,2 vezes superior à média
A maior prevalência de pré-obesidade regista-se no interior norte e centro, enquanto que a maior prevalência de obesidade se regista no Alentejo e em Setúbal
Verifica-se também que a prevalência de obesidade é maior em meio urbano do que em meio rural, e que diminui em função do grau de instrução dos pais
Segundo dados de 2004, 44,1% dos homens adultos apresentavam diagnóstico sobrepeso (IMC 25-29,9) e 14,5% apresentavam diagnóstico de obesidade (IMC ≥30)
Entre as mulheres adultas, 31,9% apresentavam diagnóstico de sobrepeso e 14,6% diagnóstico de obesidade
Nas crianças dos 7 aos 9 anos de idade, a prevalência da obesidade e da pré-obesidade é de 31,56%, sendo a prevalência maior em crianças do sexo feminino
Em 2009-2010, Portugal apresentava a segunda maior taxa de sobrepeso entre adolescentes europeus (32%).
No Brasil, segundo dados de 2008–2009, cerca de metade da população apresenta diagnóstico de sobrepeso
Verificou-se diagnóstico de obesidade em 12,5% dos homens e 16,9% das mulheres com mais de 20 anos, 4,0% dos homens e 5,9% das mulheres entre 10 e 19 anos e 16,6% das crianças do sexo masculino e 11,8% das crianças do sexo feminino entre 5 a 9 anos
Em homens, o excesso de peso e obesidade são mais prevalentes nas Regiões Sudeste, Sul e Centro-Oeste do que nas Regiões Norte e Nordeste, enquanto que nas mulheres a prevalência é maior na região Sul, embora de forma menos acentuada
O excesso de peso é maior em áreas urbanas em relação a áreas rurais
A prevalência de sobrepeso e obesidade no Brasil tem vindo a aumentar, particularmente a partir do final da década de 1990
Em 1974–1975, a prevalência média de sobrepeso em adultos do sexo masculino foi de 18,5%, enquanto que em 2008-2009 foi de 50,1%
Em mulheres adultas, a prevalência aumentou de 28,7% para 48%, respetivamente
Nas crianças entre os 5 e os 9 anos, o aumento é ainda mais acentuado
Em 1974-75, no sexo masculino a prevalência de sobrepeso foi de 10,9% e a prevalência de obesidade de 2,9%, em contraste com 34,8% de sobrepeso e 16,6% de obesidade em 2008-2009
No sexo feminino, a prevalência de sobrepeso aumentou de 8,6% para 32% e a prevalência de obesidade de 1,8% para 11,8%
Em 2008, apenas 10,2% dos brasileiros com 14 anos ou mais de idade praticava exercício físico regularmente
Entre 1970 e 2008, a percentagem da população envolvida no setor agrícola, que é aquele que possibilita maior gasto energético, diminuiu de 44% para 17,4%.
A Guiné-Bissau apresenta a taxa de obesidade mais elevada da África subsariana em ambos os sexos, tanto em adultos como em crianças
Entre os adultos, a taxa é de 16,8% nos homens e 24,2% nas mulheres e entre as crianças a taxa é de 8,1% no sexo masculino e 8,3% no sexo masculino
O país apresenta ainda taxas muito elevadas de sobrepeso (44% nos homens, 47,8% nas mulheres, 15,8% em crianças do sexo masculino e 20,4% no sexo feminino
Em Angola a taxa de obesidade engloba 12% dos homens, 18,7% das mulheres, 5,7% das crianças do sexo masculino e 6% do sexo feminino
No mesmo país, verifica-se sobrepeso em 42,9% dos homens, 49,1% das mulheres, 15,5% dos rapazes e 20,9% das raparigas.Em Moçambique, a taxa de sobrepeso afeta 14,1% dos homens, 26,5% das mulheres, 12,3% dos rapazes e 14,4% das raparigas
Em São Tomé e Príncipe 30,6% dos homens, 45,7% das mulheres, 12,3% dos rapazes e 18,9% das raparigas apresentam sobrepeso
Em Cabo Verde, o sobrepeso afeta 31,8% dos homens, 44% das mulheres, 11,5% dos rapazes e 18,3% das raparigas.
Em agosto de 2015, investigadores da Universidade de Harvard e do MIT descobriram que o gene FTO ativa dois outros genes que impedem a gordura de ser queimada na forma de calor - um processo chamado termogénese
Demonstraram também que é possível desativar estes genes através de uma técnica inovadora (CRISPR) que recorta código de ADN com erros e o substitui pela sequência correta.
"Obesidade" tem origem no latim obesitas, que significa gordo ou corpulento
Ēsus é o particípio passado de edere (comer), com o prefixo ob (sobre)
Os gregos foram a primeira civilização a reconhecer a obesidade enquanto transtorno de saúde
Hipócrates escreveu que "a corpulência não só é uma doença, como é o prenúncio de outras"
O cirurgião indiano Sushruta (século VI a.C.) associou a obesidade à diabetes e às doenças cardiovasculares, recomendando a cura através de exercício físico.
Ao longo de grande parte da História, a humanidade lutou continuamente contra a escassez de alimentos, pelo que a obesidade foi considerada em vários períodos um sinal de prosperidade e riqueza
Muitas culturas viam a obesidade enquanto resultado de defeitos de caráter
Na comédia grega, o obesus era um glutão e uma personagem ridicularizada
Durante a época paleocristã, a gula era vista como um sete pecados capitais.
A obesidade foi particularmente comum entre as elites europeias durante a Idade Média e o Renascimento e nas civilizações do oriente asiático
Durante a revolução industrial constatou-se que o poder económico e militar dos países está intimamente relacionado com a força e o tamanho do corpo dos seus trabalhadores e soldados
O crescimento do IMC médio entre a população, desde o que hoje se considera um peso inferior ao normal até ao que agora se considera peso normal, contribuiu de forma significativa para o desenvolvimento das sociedades industrializadas
Ao longo de todo o século XIX, a média de altura e de peso entre a população do mundo ocidental aumentou de forma significativa
No século XX, à medida que a população ia atingindo o seu potencial genético em termos de altura, o peso começou a aumentar de forma superior à altura, tendo como consequência o aumento da prevalência de obesidade
No pós-guerra, o aumento de prosperidade nos países desenvolvidos fez com que a taxa de mortalidade infantil diminuísse
No entanto, à medida que o índice de massa corporal aumentou, as doenças renais e cardiovasculares foram-se tornando cada vez mais comuns.
Na cultura ocidental contemporânea, o excesso de peso é muitas vezes visto como pouco atrativo e a obesidade está associada a diversos estereótipos negativos
Em qualquer idade, as pessoas obesas enfrentam estigma social e podem ser alvo de bullying, preconceito e discriminação
No entanto, em diversas regiões africanas a obesidade ainda é vista como sinal de riqueza e bem-estar, situação que se tornou ainda mais comum desde o início da epidemia de VIH.
A Organização Mundial de Saúde (OMS) antevê que a preocupação com o sobrepeso e a obesidade possa em breve sobrepôr-se a outras preocupações de saúde pública, como a subnutrição ou as doenças infecciosas, enquanto principal causa de problemas de saúde
A obesidade representa um problema de saúde pública devido à sua prevalência, custos e efeitos na saúde
As medidas de saúde pública procuram compreender e corrigir os fatores ambientais responsáveis pela prevalência cada vez maior de obesidade na população
As soluções apontadas procuram alterar os factores que provocam o consumo excessivo de energia e que inibem a atividade física, como por exemplo implementar refeições saudáveis nas escolas, restringir a publicidade a junk food dirigida a crianças, e diminuir o acesso a bebidas açucaradas na escolas
A nível do planeamento urbano têm sido realizados esforços no sentido de aumentar o acesso a parques e criar espaços pedestres.
No conjunto de todos os países europeus, a obesidade é a causa de 10 a 13% das mortes e estima-se que os custos diretos e indiretos com a doença correspondam a 2–8% da despesa em saúde
Os custos diretos e indiretos dos países União Europeia com a obesidade, em 2002, foram superiores a 32,8 mil milhões de euros
No mesmo ano, em Portugal, o custo direto da obesidade foi estimado em 297 milhões de euros (2,5% da despesa total em saúde), valor a que acrescem os custos indiretos de cerca de 200 milhões de euros.
Nos Estados Unidos, estima-se que em 2005 as despesas médicas devidas à obesidade tenham correspondido a 190,2 mil milhões de dólares, valor que representa 20,6% do total em despesas de saúde desse ano
enquanto que no Canadá o custo da obesidade foi estimado em 2 mil milhões de dólares canadianos em 1997 (2,4% dos custos totais)
Nos Estados Unidos, estima-se que a despesa anual em produtos dietéticos seja um valor entre 40 e 100 mil milhões de dólares.
Os programas de prevenção da obesidade reduzem o custo do tratamento de doenças relacionadas com a obesidade
No entanto, o aumento da esperança de vida leva a custos económicos com outras doenças, pelo que os investigadores concluem que embora a redução da obesidade possa melhorar a saúde pública, é pouco provável que haja redução na despesa total em saúde.
A obesidade pode levar ao estigma social e desvantagens no emprego
Alguns estudos verificaram que as pessoas obesas têm menos probabilidades de serem contratadas para um emprego ou de serem promovidas
As pessoas obesas também recebem, em média, ordenados inferiores às pessoas de peso normal para o mesmo posto de trabalho
As mulheres obesas ganham, em média, 6% menos e os homens 3%
Quando comparados com pessoas de peso normal, os trabalhadores obesos têm, em média, maiores taxas de absentismo do trabalho e maior número de baixas médicas, o que aumenta os custos para os empregadores e diminuiu a produtividade
Um estudo verificou que as pessoas com um IMC superior a 40 kg/m acionavam duas vezes mais seguros de trabalho e tinham doze vezes mais faltas ao trabalho em comparação com o grupo com IMC de 18,5–24,9 kg/m
As lesões mais comuns neste grupo deviam-se a quedas ou esforços, afetando principalmente os membros inferiores, pulsos, costas e mãos.
A obesidade também tem impacto económico em setores específicos
Por exemplo, devido ao crescimento da taxa de obesidade, as companhias de aviação têm encargos com combustível cada vez maiores e pressão para aumentar o tamanho dos bancos
Em 2000, o custo acrescido dos passageiros obesos foi estimado em 275 milhões de dólares
Os prestadores de cuidados de saúde também se vêm obrigados a investir em equipamento especial para pacientes com obesidade grave, como por exemplo equipamento elevatório específico ou âmbulâncias bariátricas
Com a classificação da obesidade como doença crónica, pensa-se que as companhias de seguros apresentem maior abertura para cobrir o tratamento, aconselhamento e cirurgia relacionados com a obesidade, e que diminuam os custos com a investigação e desenvolvimento de fármacos ou terapias genéticas caso sejam compartcipados
No entanto, esta classificação não é obrigatória em termos de legislação, pelo que as seguradoras têm o direito de rejeitar a cobertura para este tipo de tratamento.
Existem diversas organizações que promovem a aceitação da obesidade, as quais se tornaram mais proeminentes a partir da segunda metade do século XX
A principal causa do movimento pró-obesidade é diminuir a discriminação em relação às pessoas obesas ou com sobrepeso
Estes grupos muitas vezes defendem o reconhecimento da obesidade enquanto invalidez
No entanto, alguns setores dentro do movimento também tentam questionar a relação estabelecidade entre a obesidade e os efeitos nocivos que provoca na saúde.
As primeiras representações escultóricas do corpo humano, realizadas há 20 000–35 000 anos, representam mulheres obesas
Alguns historiadores atribuem estas estatuetas de Vénus à tendência para enfatizar a fertilidade, enquanto que outros alegam que possam representar a obesidade das pessoas na época
No entanto, este tipo de corpulência não se observa na arte grega ou romana, provavelmente em função dos ideais de moderação destas civilizações
Esta ausência verifica-se também ao longo de grande parte da arte cristã europeia, onde grande parte dos obesos representados correspondiam a pessoas de estratos socioeconómicos inferiores
Durante o Renascimento, alguns elementos da aristocracia europeia começam a ostentar a sua corpulência, como pode ser observado nos retratos de Henrique VIII
Rubens pintava com frequência retratos de corpo inteiro de mulheres obesas, facto que está na origem do termo "rubenesco"
Durante o século XIX a perspetiva ocidental sobre a obesidade alterou-se profundamente
Após vários séculos em que a obesidade era vista como sinónimo de riqueza e estatuto social, a norma social desejável passou a ser a magreza.
No século XXI, a obesidade infantil atingiu proporções epidémicas, com taxas em ascensão tanto nos países desenvolvidos como nos países em vias de desenvolvimento
Por exemplo, a taxa de obesidade entre crianças do sexo masculino no Canadá subiu de 11% na década de 1980 para mais de 30% na década de 1990
No Brasil, no mesmo período, a taxa de obesidade infantil aumentou de 4 para 14%.
Tal como no caso dos adultos, existem diversos factores que contribuem para o recente aumento da obesidade infantil
Acredita-se que as alterações dietéticas e a cada vez menor atividade física sejam as duas causas mais relevantes
Uma vez que em muitos casos a obesidade infantil persiste na fase adulta e está associada a diversas doenças crónicas, as crianças com obesidade são frequentemente examinadas com o intuito de diegnosticar hipertensão arterial, diabetes, hiperlipidemia e fígado gorduroso
O tratamento em crianças passa sobretudo por intervenções ao nível do estilo de vida e técnicas de comportamento, embora as tentativas de fazer aumentar a atividade física em crianças tenham geralmente pouco êxito
Não se encontra aprovada medicação para este grupo etário.
A obesidade em animais de estimação é relativamente comum em diversos países
Por exemplo, as taxas de sobrepeso e de obesidade em cães nos Estados Unidos variam entre 23 e 41%, sendo 5,1% obesos
No caso dos gatos, a taxa de obesidade era ligeiramente superior a 6,4%
O risco de obesidade em cães está relacionado com o facto dos seus donos serem ou não obesos, embora não se verifique esta relação no caso dos gatos.
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


Pleistoceno – Recente
O cão (Canis lupus familiaris), no Brasil também chamado de cachorro, é um mamífero carnívoro da família dos canídeos, subespécie do lobo, e talvez o mais antigo animal domesticado pelo ser humano
Teorias postulam que surgiu do lobo cinzento no continente asiático há mais de 100 000 anos
Ao longo dos séculos, através da domesticação, o ser humano realizou uma seleção artificial dos cães por suas aptidões, características físicas ou tipos de comportamentos
O resultado foi uma grande diversidade de raças caninas, as quais variam em pelagem e tamanho dentro de suas próprias raças, atualmente classificadas em diferentes grupos ou categorias
As designações vira-lata (no Brasil) ou rafeiro (em Portugal) são dadas aos cães sem raça definida ou mestiços descendentes.
Com expectativa de vida que varia entre dez e vinte anos, o cão é um animal social que, na maioria das vezes, aceita o seu dono como o "chefe da matilha" e possui várias características que o tornam de grande utilidade para o homem
Possui excelente olfato e audição, é bom caçador e corredor vigoroso, relativamente dócil e leal, inteligente e com boa capacidade de aprendizagem
Deste modo, o cão pode ser adestrado para executar um grande número de tarefas úteis, como um cão de caça, de guarda ou pastor de rebanhos, por exemplo
Assim como o ser humano, também é vítima de doenças como o resfriado, a depressão e o mal de Alzheimer, bem como das características do envelhecimento, como problemas de visão e audição, artrite e mudanças de humor.
A afeição e a companhia deste animal são alguns dos motivos da famosa frase: "O cão é o melhor amigo do homem", já que não há registro de amizade tão forte e duradoura entre espécies distintas quanto a de humano e cão
Esta relação figura em filmes, livros e revistas, que citam, inclusive, diferentes relatos reais de diferentes épocas e em várias nações
Entre os cães mais famosos que viveram e marcaram sociedades estão Balto, Laika e Hachiko
Na mitologia, o Cérbero é dito um dos mais assustadores seres
No cinema, Lassie é um dos mais difundidos nomes e, na animação, Pluto, Snoopy e Scooby-Doo há décadas fazem parte da infância de várias gerações.
As origens do cão doméstico baseiam-se em suposições, por se tratar de ocorrências de milhares de anos, cujos crescentes estudos mudam em ambiente e datação dos fósseis
Uma das teorias aponta para um início anterior ao processo de domesticação, apresentando a separação de lobo e cão há cerca de 135 000 anos, sob a luz dos encontrados restos de canídeos com uma morfologia próxima à do cinzento, misturados com ossadas humanas
Outras, cujas cronologias são mais recentes, sugerem que a domesticação em si começou há cerca de 30 000 anos, os primeiros trabalhos caninos e o início de uma acentuada evolução entre 15 000 e 12 000, e por volta de 20% das raças encontradas atualmente, entre 10 000 e 8000 anos no Oriente Médio
Além das imprecisões do período, há também discordâncias sobre a origem
Enquanto especula-se que os cães sejam descendentes de uma outra variação canídea, as mais aceitáveis são a descendência direta do lobo cinzento ou dos cruzamentos entre lobos e chacais.
As evidências baseiam-se também em achados arqueológicos, já que foram encontrados cães enterrados com humanos em posições que sugerem afetividade
Segundo estes trabalhos de pesquisa, o surgimento das variações teria ocorrido por seleção artificial de filhotes de lobos-cinzentos e chacais que viviam em volta dos acampamentos pré-históricos, alimentando-se de restos de comida ou carcaças deixadas como resíduos pelos caçadores-coletores
Os seres humanos perceberam a existência de certos lobos que se aproximavam mais do que outros e reconheceram certa utilidade nisso, pois eles alertavam para a presença de animais selvagens, como outros lobos ou grandes felinos
Mais sedentários devido ao desenvolvimento da agricultura, os seres humanos então deram um novo passo na relação com os caninos
Eventualmente, alguns filhotes foram capturados e levados para os acampamentos na tentativa de serem utilizados
Com o passar dos anos, os animais que, ao atingirem a fase adulta, mostravam-se ferozes, não aceitando a presença humana, eram descartados ou impedidos de se acasalar
Deste modo, ao longo do tempo, houve uma seleção de animais dóceis, tolerantes e obedientes aos seres humanos, aos quais era permitido o acasalamento e que, quando adultos, eram de grande utilidade, auxiliando na caça e na guarda
Esse gradual processo, baseado em tentativas e erros, levou eventualmente à criação dos cães domésticos.
Foi ainda durante a Pré-História que surgiram os primeiros trabalhos caninos e, com isso, começaram a fortalecer os laços com o ser humano
Cães de caça e de guarda ajudavam as tribos em troca de alimento e abrigo
Com o tempo, aperfeiçoaram o rastreio e dividiram o abate das presas com os humanos
Por possuírem alta capacidade de adaptação, espalharam-se ao redor do mundo, levados durante as migrações humanas e aparecendo em antigas culturas romanas, egípcias, assírias, gaulesas e pré-colombianas, tendo então sua história contada ao lado da do homem.
No Egito Antigo, os cães eram reverenciados como conhecedores dos segredos do outro mundo, bem como utilizados na caça e adorados na forma do deus Anúbis
Esta relação com os mortos teria vindo do hábito de se alimentarem dos cadáveres, assim como os chacais
No continente europeu, mais precisamente na Grécia Antiga, cães eram relacionados aos deuses da cura, com templos que abrigavam dezenas deles para que os doentes pudessem ser levados até lá e terem suas feridas lambidas
Neste período, também combateram junto aos exércitos de Alexandre, o Grande, espalhando-se pela Ásia e Europa
Na Gália, além de guardiões e caçadores, detinham a honra de serem sacrificados aos deuses e enterrados nos túmulos de seus donos
Durante o período do Império Romano, os cães, sempre fortes e de grande porte, foram utilizados para a diversão do público em grandes brigas no Coliseu de Roma
Trazidos da Bretanha e da parte ocidental da Europa, eram mantidos presos e sem alimentos, para que pudessem ficar agressivos durante os espetáculos, nos quais deviam matar prisioneiros, escravos e cristãos
Sua fama ficou tão grande que as raças da época quase foram extintas, devido ao exagerado uso em guerras e apresentações.
Com o fim do Império Romano, o mundo entrou na fase da Idade Média, já com os cães espalhados pelo continente europeu, levados pelos mercadores fenícios do Oriente Médio à região mediterrânea e adentrado a região seguindo soldados romanos
Foi nessa época que os caninos perderam o relativo prestígio de antes, já que doenças como a peste negra assolavam a Europa e eram os cães que comiam os cadáveres nas periferias das cidades
A Igreja Católica, enquanto instituição mais influente, passou a relacioná-los à morte e considerá-los criaturas das trevas
Sua mentalidade supersticiosa popularizou-os como animais de bruxas, vampiros e lobisomens
Tal influência, por incentivo da Inquisição, resultou em matanças de lobos, cães e híbridos
Indo ainda mais além, estipulou decretos que diziam que se qualquer preso acusado de bruxaria fosse visitado por um cão, gato ou pássaro, seria imediatamente considerado culpado de bruxaria e queimado na fogueira
Apesar de toda a perseguição, no fim dessa época os cães já começavam a ser vistos como companhia infantil.
Durante o Renascimento, a visão negativa sobre os cães foi desaparecendo, já que caíram no gosto dos nobres
Durante este período, os caninos eram utilizados para a caça esportiva e criados com cuidado dentro dos canis de cada castelo
Com as famílias livres para desenvolverem suas próprias raças, as variedades de cada região começaram a surgir
Estas novas raças eram consideradas tesouros não encontrados em nenhum outro lugar do mundo, e por isso, dadas de presente entre a nobreza, por representarem grande sinal de riqueza
Esta atitude ajudou a difundir ainda mais a variedade e a preservar determinadas raças, quando em seu lugar de origem acabavam exterminadas
Adiante, também na Europa, nasceram os cães de companhia, já que o apreço por eles crescia, conforme se via a fidelidade
Guilherme de Orange dos Países Baixos chegou a declarar que seu cão o salvou de um atentado
Ao mesmo tempo que a diversidade crescia no continente, tribos siberianas usavam seus cães para praticamente tudo, já que eram bastante fortes e úteis para locomoção e outras atividades
Estes caninos, importados da Sibéria, ajudaram o ser humano na conquista dos pólos pelos primeiros homens a pisar no Polo Sul e Polo Norte, puxando seus trenós.
No período das grandes navegações, os homens migraram ao Novo Mundo com seus caninos
Apesar de não serem desconhecidos dos povos pré-colombianos, a variedade o era
Também durante a conquista, a presença deste animal teve sua utilidade: nas guerras contra os nativos, farejadores eram utilizados para encontrar e matar os índios
A respeito disso, há a lenda de que, na atual República Dominicana, milhares de indígenas foram exterminados por uma tropa de 150 soldados de infantaria, trinta cavaleiros e vinte cães rastreadores
Durante o século XIX, apesar de polêmicos, os treinamentos dos caninos para lutas e guerras, ganhou popularidade como na época de Alexandre
Nessa fase, algumas raças foram compostas por animais menores, mais brutos e de musculatura mais forte, como o bull terrier.
No século seguinte, eventos tornaram a marcar a evolução canina
As guerras mundiais extinguiram as raças das regiões mais afetadas e ajudaram a popularizar as variedades militares, como o pastor alemão e o dobermann, enquanto rastreadores
No Japão, em plena guerra, o imperador decretou que todos os cães que não pastores alemães fossem mortos para a confecção de uniformes militares com seu couro
Devido a isso, muitos criadores de akitas cruzaram seus animais com pastores alemães, para tentar fugir ao decreto
Os resultantes destes cruzamentos, levados aos Estados Unidos pelos soldados, foram os primeiros na criação de mais uma nova raça
Foi também após as guerras mundiais que surgiram os primeiros centros de treinamento de cães-guia de cego.
Modernamente, apesar de fazer parte da história humana desde a imagem divina aos soldados das guerras, o cão tornou-se um animal de estimação apenas no século XX, já adaptado aos modos de vida dos seres humanos, devido a sua habilidade de fazer de diversos ambientes os melhores possíveis, e ao voltar suas capacidades de aprendizado à domesticação
Diz-se que esta mútua relação entre os dois mais numerosos carnívoros do mundo deve-se à compreensão e à evolução cerebral canina em entender o que querem as pessoas.
Levando-se em consideração os estudos que apontam o lobo como antecessor do cão, é possível traçar semelhanças e diferenças entre estas duas subespécies
Os mais antigos esqueletos de cães descobertos datam de cerca de 30 000 anos depois do aparecimento do Homo sapiens, sempre exumados em associação com o resto das ossadas humanas
Aos pesquisadores, pareceu lógico associá-los aos canídeos pré-existentes, como o lobo, o chacal e o coiote
No entanto, em descobertas feitas na China, nas quais encontravam-se vestígios dos cães, o coiote e o chacal não foram identificados na região
Ainda no Oriente, notou-se as primeiras associações do homem com uma variedade de lobo com tamanho reduzido, de cerca de 150 000 anos
Nessa teoria, a ausência das duas espécies e o fato de Canis lupus e Canis (lupus) variabilis terem coexistido e possivelmente reproduzido, pode confirmar a explicação do lobo como ancestral do cão, e por sob questionamentos a teoria mais difundida, do acasalamento entre o cinzento, o chacal e até mesmo, o coiote
Essa hipótese, segundo estudos mais recentes, aliou-se a novas descobertas: o aparecimento de algumas raças de cães nórdicos diretamente originados do lobo; o resultado de trabalhos genéticos comparando o DNA destas espécies, que mostraram uma semelhança superior a 99,8% entre o cão e o lobo, enquanto não ultrapassa 96% entre o cão e o coiote; e a existência de mais de 45 subespécies de lobos, que poderiam estar na origem da diversidade racial observada nos cães.
As semelhanças entre cães e lobos dificultam os trabalhos dos arqueólogos para fazer distinção exata entre os vestígios de cada subespécie, quando apresentam-se incompletos ou quando o contexto arqueológico torna a coabitação pouco provável
De certo, o cão primitivo só se diferencia do seu ancestral por alguns detalhes pouco fiáveis, como o comprimento do focinho, a angulação do stop ou particularidades na arcada dentária.
O lobo-cinzento, que supõe-se ser a única espécie de lobo tendo o cão como uma de suas subespécies, é um canídeo selvagem que vive em alcateias
Fisicamente, pode atingir 2 m de comprimento e pesar mais de 60 kg
Suas cerca de quinze subespécies habitam florestas ou planícies da Europa, Ásia, Estados Unidos, Canadá e o norte da África, mas, em alguns lugares, como o Japão, estão à beira da extinção
Já o cão é o único canídeo domesticado pelo homem, em um processo milenar
Seu tamanho varia entre 1 – 45 kg, e vive tanto isolado quanto em matilhas
Sua diversidade de raças é, em boa parte, devida à seleção artificial feita pelo homem na busca de qualidades aproveitáveis e de submissão
É ainda um animal sem riscos de extinção, apesar de algumas raças não mais existirem
Em comum, além das características físicas, estes dois possuem as comportamentais e de povoamento
Suas caudas compridas são usadas para comunicação quando precisam mostrar obediência diante do dominante, por exemplo
Vigorosos, não são tão velozes quanto os felinos, mas capturam suas presas pelo cansaço da persistência
Pelo globo, dispersaram-se há milhares de anos, espalhando-se pela Ásia, Europa e África
À Oceania e às Américas, chegaram levados pelo homem.
O modo como se alimentam também é semelhante
O lobo obtém a maior parte de sua comida caçando em grupo e atacando presas de grande porte
A competição entre seus membros leva ainda a um rápido consumo do alimento
Após matar a presa, come até se satisfazer, passando um longo período sem se alimentar
Como os antepassados, os cães domésticos comem rapidamente e poucas vezes ao dia
Essa tendência em comer muito rápido pode virar um problema, pois os cães podem se engasgar ou engolir grandes quantidades de ar
Os caninos alimentados em grupo podem apresentar as relações de dominação dos lobos e, como resultado, os dominantes obtêm a maior parte do alimento e os subordinados ficam com menos do que precisam
Como diferença, ao passo que o lobo alimenta-se do que captura, o cão doméstico usufrui de rações fabricadas especificamente para suas necessidades físicas
Comunicativamente, além das comuns características básicas de uso de gestos e odores, estas duas subespécies apresentam uma diferença marcante: enquanto os lobos amadurecem suas formas de comunicação conforme atingem a idade adulta, certas raças caninas resultantes de seleção artificial mantêm a forma que aprenderam enquanto filhotes
Em pesquisa realizada entre quinze raças caninas e o lupino, o descendente direto husky siberiano foi o único a confirmar igualdade nos meios de comunicação, marcando quinze pontos em quinze avaliações
Na outra ponta, o cavalier king charles spainel mostrou dois, o que ainda assim é capaz de demonstrar semelhança, já que outras raças superaram os 50% de equiparidade entre seus meios de comunicação mesmo com a interferência humana direta, que sempre busca as características que melhor lhe favoreçam, em detrimento dos instintos animais
Em suma, apesar de não ser possível definir como única, a descendência direta do lobo pode ser confirmada devido as características muito semelhantes tanto físicas quanto comportamentais, ainda que a interferência humana tenha sido extrema.
Na seleção natural, processo proposto por Darwin, apenas os mais aptos se reproduzem e se multiplicam, eliminando assim, geração após geração, os genes problemáticos
É devido a esta razão que os animais selvagens são visivelmente saudáveis psicológica e fisicamente
Na seleção artificial, especificamente dos cães, o critério é acasalar os caninos a partir das formas físicas, chamadas morfológicas, orgânicas, chamadas fisiológicas, e mentais, conhecidas como psíquicas
Como exemplo dessas seleções está a criação das raças pequenas, resultados dos acasalamentos dos espécimes menores, independente de suas capacidades de sobrevivência
Conduzida pelo ser humano, a seleção artificial é direcional: a partir de indivíduos selecionados por suas características, tem-se as novas ninhadas, que serão novamente selecionadas, de acordo com as peculiaridades desejadas
Desta forma, os genes responsáveis pelas características escolhidas aumentam de frequência e tendem a entrar em homozigose
Ao mesmo tempo, pode-se evitar a reprodução de indivíduos que não possuam as qualidades almejadas.
Todavia, não se obtém apenas benefícios destes cruzamentos seletivos
Juntamente com os genes das características visíveis, são repassados aqueles que, apesar de presentes, não se manifestaram no indivíduo, mas que, provavelmente, afetarão seus descendentes
Alguns acarretam propensão para males como displasia coxofemoral, surdez, miopia, diversas doenças de pele e problemas psicológicos
Disfarçadamente, há ainda um outro problema que acomete os caninos
No intuito de criar diferentes raças, o homem desenvolveu características extremas, que atrapalham o bem-estar do animal: os buldogues têm os focinhos tão achatados que não conseguem respirar normalmente; shar peis têm tanta pele extra que desenvolvem micoses e infecções nas dobras; e os border collies tornaram-se hiperativos, entre outros exemplos.
Em suma, apesar do sucesso na criação de variadas raças com determinadas características físicas e mentais, como o aperfeiçoamento de cães para pastoreio, há os problemas derivados dessas seleções, que dificultam as vidas dos espécimes e lhes causam graves problemas hereditários de saúde
Para evitar estes males, é preciso não reproduzir cães com problemas psicológicos ou físicos mesmo que sejam campeões de beleza ou excelentes em alguma atividade útil ao ser humano
Apesar da possibilidade, não há registro de raça canina criada em laboratório.
Etimologicamente, o latim cattus designava tanto significado para cão quanto para gato
Ao longo do tempo, a palavra sofreu modificação para catulus, depois canus
Catellus, que se referia a cachorrinho, e catula, à cachorra, também derivaram dessa forma
Apenas cachorrinha teve um caminho etimológico distinto, pois veio de canícula, que significava a estrela conhecida como Sírio
Por problemas no significado, que era confundido com o da catapulta, os romanos dobraram a letra t do original catus, que foi modificando-se ao longo dos anos, passando a duas palavras para dois significados distintos e seus derivados
Segundo a história semântica das palavras do português, foi constatado que, assim como as palavras mudam em sua forma e sua sintaxe através dos anos, seu significado, por vezes, vai se modificando também, em decorrência de uma série de fatores sociais e culturais
Diante disso, o vocábulo cachorro, proveniente do basco, indicava qualquer tipo de filhote, e, por um processo de restrição de significado linguístico, passou a indicar filhote de cão e o próprio cão
Essa explicação justifica o sinônimo entre as duas palavras e a adoção comum das pessoas, apesar dos significados constantes nos dicionários da língua portuguesa.
Segundo o Dicionário Aurélio de Língua Portuguesa, na variante brasileira, cão significa mamífero canídeo, domesticado pelo homem desde tempos remotos, que atende pelo plural de cães e tem como forma feminina, cadela
Cachorro, por sua vez, entendido como sinônimo, tem cachorra como feminino e cachorros como forma plural, designa sim um cão novo, uma cria de lobo ou ainda qualquer cão
Em sentido pejorativo, o cachorro é sinônimo de canalha e aparece ainda em formas cristalizadas da gíria e de expressões populares, como "matar cachorro a grito" e "quem não tem cão, caça com gato"
Segundo o dicionário online Priberam, na variante europeia, cão possui um significado denotativo mais amplo, além dos conhecidos na variante sul-americana, com sete significados conotativos e três denotativos
O mesmo se aplica a cachorro, que possui uma maior variação de significados em Portugal.
O cão foi descrito por Lineu em 1758 como Canis familiaris, e considerado como uma espécie distinta do lobo, descrito também por Lineu no mesmo ano como Canis lupus
Outros nomes foram descritos por Lineu, Johann Friedrich Gmelin e Charles Hamilton Smith para a mesma espécie, sendo considerados sinônimos.
A ancestralidade canina vem sendo discutida e estudada desde há muitos anos
Teorias antigas sugerem uma origem proveniente do chacal-dourado ou então uma origem híbrida entre várias espécies
Um levantamento das sequências da região de controle do DNA mitocondrial em 140 cães e 162 lobos demonstrou que o lobo é o único ancestral dos cães
Esta conclusão foi confirmada em outro estudo envolvendo 654 cães e 38 lobos da Eurásia
Enquanto há uma aceitação do lobo como único progenitor do cão, a questão taxonômica envolvendo o reconhecimento de uma ou duas espécies distintas ainda não está resolvida.
Baseado na consistência genética, Wayne considerou que o cão, apesar da diversidade em tamanho e proporção, nada mais é do que um lobo
Em contraste, análises estatísticas de crânios têm repetidamente demonstrado uma separação total entre lobo e cão
O conceito ecológico de espécie proposto por Van Valen foi aplicado por alguns pesquisadores para demonstrar características adaptativas específicas nos cães por viverem em um nicho antropogênico
Esta hipótese suporta o reconhecimento do Canis familiaris como uma espécie distinta do Canis lupus, apesar de uma idade de separação não superior a 12 000 a 15 000 anos atrás.
Apesar de certos pesquisadores continuarem a reconhecer duas espécies distintas, existe uma tendência recente em seguir a classificação proposta por Wozencraft (1993; 2005) que inclui o C
familiaris como uma subespécie de C
lupus
Pela lei da prioridade estipulada pelo Código Internacional de Nomenclatura Zoológica, o nome C
familiaris, descrito na página 38, tem prioridade sobre C
lupus, descrito na página 39 do Systema Naturae por Linnaeus
Por questões de usabilidade e estabilidade, foi requisitado à Comissão Internacional de Nomenclatura Zoológica a conservação de dezessete nomes específicos baseados em espécies selvagens, entre eles o Canis lupus.
Quando comparado fisicamente a seu ancestral, o cão possui mínimas diferenças no design genético
A estrutura óssea, os tipos de músculo, nervos e dentições, por exemplo, são idênticos
Até mesmo a pelagem é similar, já que ambos, salvo algumas exceções, possuem uma dupla camada de pelos
Como diferença acentuada, tem-se o fato dos lobos contarem com cérebro e glândulas produtoras de hormônios mais pesados, já que vivem em ambientes que requerem respostas rápidas a eventos extremos
Mais especificamente, sua anatomia divide-se em cinco grandes áreas de estudo: a externa, a osteologia, a artrologia, a miologia e dos órgãos internos:
Animais quadrúpedes e digitígrados, o que lhes garante maior agilidade, são considerados os mais difundidos mamíferos domésticos e possuem várias raças adestradas para os mais diferentes fins
Sua longevidade atinge os vinte anos e suas características externas, como tamanho e pelagem, são tão variadas que dificultam a descrição comum de um cão
Contudo, entre as principais características externas, iguais em todas as raças, estão o stop, a cabeça, o pescoço, as espáduas, a garupa, os ombros, a cauda, as coxas, os cotovelos, os joelhos, os jarretes, os boletos, as patas posteriores e as munhecas, como ilustra a imagem
Mais detalhadamente, suas características externas dividem o corpo do animal em três áreas: na zona anterior, estão a cabeça, o pescoço, o peitoral e os membros frontais; na zona posterior, encontram-se os membros posteriores e a cauda; e nos aprumos, nota-se a posição dos membros em comparação a uma superfície horizontal, que refletem sob os elementos principais da locomoção do cão e suas aptidões, isto é, a postura de seus membros
Outra característica comum é a dentição
Em geral, um cão possui um total de 42 dentes, divididos em 12 incisivos, 4 caninos, 16 pré-molares e 10 molares
Sua pele, outra característica comum nestes animais, representa a maior parte de seu sistema imunológico
Ao longo dela, certas áreas mostram-se sob formas diferentes, pois têm propósitos específicos
As unhas e as patas são para a durabilidade, as orelhas para sinalização social e as glândulas da derme para demarcação pelo cheiro.
Com base na diversidade, é possível classificar cães em categorias de acordo com seu peso e sua morfologia
De acordo com o peso, as raças dividem-se em quatro subcategorias: pequena (< 10 kg), média (11–25 kg), grande (26–45 kg) e gigante (> 45 kg)
Na outra ponta, a classificação morfológica apresenta-se um pouco mais complexa, apesar de ter apenas três subcategorias: os cães longilíneos possuem seu comprimento superior a sua largura e espessura, e apresentam-se em formas alongadas e esbeltas; os brevilíneos são o aposto, abarcando exemplares robustos e arredondados; já os mediolíneos são o equilíbrio entre as duas classificações anteriores
Outra marcante característica, capaz de distinguir cães dentro de sua própria raça, é a pelagem, que, variando em comprimento e tipo, gera combinações
Os comprimentos são quatro, ao passo que os tipos são cinco: sem pelo, raso, curto e semi-longo; duro, heterogêneo, liso, sedoso e lanoso.
A estrutura interna, comum a cães das mais variadas raças, é, assim como em grande parte dos mamíferos, dividida em quatro áreas maiores:
A primeira delas é o esqueleto, a rígida estrutura que sustenta o corpo e desempenha as funções de proteção, movimento, reserva de elementos químicos, como o cálcio, e a produção de glóbulos vermelhos nestes animais
Nos cães, que têm ao longo do corpo um total de 25 divisões ósseas maiores, observam-se dois fenômenos durante a fase referente a pré-puberdade: o aumento da espessura e do comprimento ósseos e a calcificação total da cartilagem de conjugação
Este sistema é ainda sustentado por ligamentos e tendões fortes e elásticos
O crânio, que tem por função principal a proteção do cérebro, é composto por treze ossos que se soldam logo após o nascimento e articulam-se diretamente à coluna vertebral, composta por sete vértebras cervicais, treze torácicas, sete lombares, três sacrais e um número variável de vértebras no comprimento da cauda
Já a caixa torácica é formada por dez pares de costelas, ligadas ao esterno
Também partes importantes na movimentação e locomoção são as articulações caninas, divididas em dois tipos: as sinoviais, que permitem grande mobilidade e estabilidade, e as não-sinoviais, soldas ósseas ao nível da caixa craniana cuja união se dá através de um tecido fibroso
Recobrindo estas duas estruturas estão os 34 músculos superficiais do cão, responsáveis por todos os movimentos voluntários ou involuntários, divididos entre estriados, lisos e cardíacos, e de funções flexoras, extensoras, abdutoras e adutoras
É na parte frontal que se encontra a maior concentração muscular dos cães
Entre as peculiaridades deste sistema estão o fato de permitirem um giro da cabeça de 220º e que as patas escavem e arranhem com força.
Internamente, notam-se ainda as topografias, que têm relação com os funcionamentos e as divisões dos órgãos caninos internos
É na topografia torácica que se encontra o aparelho respiratório, composto pelas cavidades nasais, a faringe, quarenta anéis cartilaginosos formadores da traqueia, os brônquios, os bronquíolos e os alvéolos pulmonares, importantes para a vascularização dos pulmões
No tórax do canino também está o aparelho cardiovascular, cujo coração apresenta quatro cavidades, tem a forma predominante de um globo, está mais situado a esquerda do tórax e possui um tamanho que varia de 120 g à 15 kg, dependendo da raça
Este aparelho é composto ainda por outras oito partes
Já na outra topografia, a abdominal, está o aparelho digestivo, com 17 partes, que vão da boca ao ânus
As particularidades deste aparelho apresentam-se no volume considerável do estômago, devido ao regime carnívoro do animal, e na boca, cuja mastigação é pouco desenvolvida, o que deixa o trabalho digestivo quase completamente para o estômago
Também nesta área do corpo do canino, está o aparelho urinário, cuja diferença dos demais mamíferos reside no fato de um rim ser suspenso na cavidade abdominal, enquanto o outro encontra-se fixado sob a última vértebra torácica e as duas primeiras lombares
Outra peculiaridade presente neste sistema é o fato da uretra ser mais comprida e menos larga nos machos que nas fêmeas
O baço, também localizado no abdómen, é um órgão linfático que compõe o sistema de defesa do organismo, já que, quando o animal ingere mais alimentos do que pode suportar, acompanha o estômago para trás, sedendo-lhe mais espaço e evitando problemas digestivos
É ainda no baço que o sangue novo é fabricado em conjunto com a medula óssea.
Os cães pertencem à família dos canídeos, da qual fazem parte também as raposas e os lobos
Esta família de predadores possui sentidos apurados para a captura de presas e para proteção da matilha
Apesar da domesticação e do cruzamento seletivo, o que tornaram o cão menos dependente de seus sentidos, estes ainda são considerados habilidades sensoriais incríveis
Assim como em humanos e outros mamíferos, seus sentidos dividem-se em cinco:
É de muito tempo que a reprodução canina divide-se em assistida e natural
A primeira refere-se ao fato de o macho observar sua cadela seja em um cruzamento natural, seja em um manipulado - de fins financeiros, como uma cria de pedigree para venda ou competições, ou ainda, para seleção artificial de uma raça ou criação de uma nova, geralmente realizados através de inseminações artificiais ou cruzamentos controlados
Em relação aos animais, as fêmeas, assim como as mulheres, nascem com um determinado número de óvulos, enquanto os machos atingem a idade sênior de doze anos ainda férteis.
Em um cruzamento natural, assistido ou não, o processo é iniciado na fase do cio da cadela, que dura em uma média de quinze a vinte dias, cujo ápice da fertilidade é atingido entre o 8.º e o 11.º dias
A cópula então começa com uma fase de farejamento
A ereção do macho é possibilitada pela rigidez do osso peniano e pelo fluxo de sangue do tecido erétil
Com um monte bem sucedido, desencadeia-se então as contrações vaginais na fêmea que favorecem a ascensão dos espermatozóides, a manutenção da ereção e o "aprisionamento" do macho durante a ejaculação na fase prostática
Esta fase dura um mínimo de cinco minutos, embora possa atingir trinta
Já a inseminação artificial, sempre assistida, é feita de três diferentes formas: com sêmen fresco, refrigerado ou congelado
Contudo, todas se caracterizam como técnicas de reprodução impossíveis de ocorrerem sem a intervenção do ser humano, que vão, desde o recolhimento do material do macho a sua introdução na fêmea.
Faz parte da reprodução também a gestação, que dura em média sessenta dias e gera um número variado de filhotes, dependendo do tamanho e do sistema reprodutor da fêmea, bem como os cuidados com os cachorros
A alimentação de uma cadela durante a gestação é fundamental para o nascimento de uma cria saudável
Os cuidados alimentares devem ter início antes mesmo do acasalamento e prosseguirem até o desmame dos filhotes, já que ela é bastante exigida também nesta etapa
A fêmea não deve estar gorda quando cruzar e não pode receber gorduras na alimentação, mas ao contrário, tem bastante necessidade de proteínas, cálcio e sais minerais
Por fim, faz-se ainda necessária atenção aos filhotes
Nesta fase, a cadela é protetora e os amamenta por cerca de 45 dias
Aos poucos, os cachorros, que desenvolvem primeiramente o olfato e o tato junto à mãe, abrem os olhos e as orelhas, que lhes conferem dois sentidos bastante aguçados.
Na outra ponta da reprodução está a esterilização, chamada também de castração, comum em animais domésticos e uma necessidade para o controle de animais nas cidades, geralmente abandonados nas ruas
A esterilização em si consiste na remoção cirúrgica completa dos órgãos com funções restritivamente reprodutoras
Nas fêmeas, retira-se o útero e os ovários, o que elimina os cios
Nos machos, retiram-se os testículos, deixando-se a bolsa escrotal vazia
O processo é classificado como indolor, devido a anestesia, incômodo, após o procedimento, e seguro, devido a eficácia dos resultados para o animal e para a sociedade.
O envelhecimento canino é um processo natural ainda não totalmente entendido, embora sabido que ocorra de modo variado, dependendo das raças e de seu porte
Enquanto um cão de médio porte vive em torno de doze anos, um gigante tem expectativa de vida mais curta
Antes, acreditava-se que estes animais envelheciam sete anos para cada ano de vida de um ser humano
No entanto, essa teoria foi revista, e mais recentemente, tenta-se comparar o estágio de desenvolvimento inicial da vida do cão com aquele dos seres humanos
De acordo com alguns resultados obtidos, raças pequenas alcançam seus tamanhos finais entre os oito e os doze meses; raças de porte médio entre doze e dezesseis meses; de porte grande entre dezesseis e dezoito meses; e as gigantes, por volta dos dois anos
Com isso, foi possível traçar um paralelo que resultou em variação de porte para porte
As raças pequenas e médias têm os cinco primeiros anos de vida para o primeiro ano humano
Deste ponto em diante, são quatro para cada ano vivido por um ser humano
Já as raças grandes e gigantes, de maturidade mais lenta, envelhecem sete e doze, respectivamente, em seu primeiro ano de vida, com cinco e sete anos a partir do segundo ano de vida, para cada tamanho
Com base nessas afirmações, pode-se dizer que um chihuahua nascido no mesmo dia e ano que um homem, tenha, cinco anos mais tarde, 21.
Cães de idade avançada estão mais sujeitos a doenças, dores e alterações comportamentais
Por isso, é importante dar atenção às mudanças da idade de um cão doméstico, pois isso permite suprir novas necessidades e proporciona melhores condições de vida
Entre os principais males que podem acometer os idosos caninos estão a artrite, o mal de Alzheimer e a depressão
Esses problemas e outros, como a queda de dentes, decorrentes da idade, são diagnosticáveis desde o início pela observação das mudanças comportamentais e pela realização de constante acompanhamento veterinário
Problemas de visão e audição, quietude e esbranquiçamento e queda do pelo são fatores considerados normais, causados pelo avanço da idade.
A forma de comunicação mais conhecida dos cães é o latido, apesar de chorarem, rosnarem, uivarem, cheirarem e utilizarem de sua linguagem corporal para se fazerem entender tanto para os caninos quanto para os seres humanos.
A relação entre os cães ocorre, na grande maioria das vezes, de modo bem diferente da dos homens
Por conta disso, muitas vezes suas atitudes não são compreendidas, como porque se cheiram tanto, latem sem motivos, estão brincando e de repente começam a brigar
Os cães também sentem medo, ansiedade, interesse, alegria e outras emoções
E, por serem animais gregários, dedicam parte do tempo em conhecer seu status dentro da relação
No aprendizado, cães precisam do contato com outros cães para aprenderem sua linguagem
Durante as primeiras sete ou oito semanas, os cachorros aprendem toda a base da comunicação com a mãe
Se eles a machucam, ela grunhe e os afasta, e na época do desmame, mostra-se aborrecida com o ataque às mamas, por exemplo
A partir daí, o contato com os irmãos também é importante
Nas brincadeiras com outros filhotes, o cachorro aprenderá como demonstrar a dor e a brigar pela comida
De todas as formas de comunicação, a mais importante da vida do cão, entre os cães, é a corporal
Através da leitura da posição das orelhas, da cauda, dos olhos e do corpo em geral, os cães poderão identificar o estado de outro animal, como a aceitação das brincadeiras ou da dominância
O odor, também de animal para animal, é importante na comunicação para a identificação única de cada indivíduo
É através do cheiro que ainda identificam quando uma cadela está no cio ou a mensagem da urina em determinado local demarcado.
Pelo ser humano comunicar-se verbalmente, acredita que esta seja a principal forma de comunicação canina
O latido, em geral, significa um pedido de atenção quando carentes, aborrecidos, excitados ou sozinhos, e um alerta de perigo
Entre homem e animal, além do latido, outra forma de comunicação é o choro
Chorando, os cachorros percebem desde cedo que tanto a mãe quanto os donos lhe atendem e passam a usar disso como meio de obter atenção
Além disso, o choramingo demonstra susto com barulhos altos, como trovões
O rosnado por sua vez, é o som mais simples de se entender, tanto para os caninos, quanto para os humanos, pois significa ataque caso não haja o recuo do outro diante da posse, demarcação ou proteção
Por ser um sinal de agressividade, não costuma ser ignorado
Por fim, o uivo é um som familiar e único, que demonstra também excitação, o alerta, a solidão e o desejo
É usado quando caçam e encurralam suas presas ou só para ver se alguém aparece
Em um paralelo, o uivo é tão contagiante quanto o bocejo humano: quando um começa e outro ouve, o faz
No relacionamento homem e animal, seus meios de comunicação causam problemas que geram determinadas soluções apenas para o ser humano
Entre as mais eficientes e definitivas estão o uso de coleiras antilatidos, que associam o ato de latir com algo negativo, como jatos de citronela no focinho, e as operações que retiram as cordas vocais.
Assim como em todos os mamíferos, as funções de sustentação, proteção e locomoção são executadas pelos esqueletos ósseo e muscular
Igualmente aos seres humanos, os cães possuem estrutura básica, cujos níveis encontram-se nas alturas escapular e pélvica, uma para os membros superiores e outra para os membros inferiores
A diferença encontra-se no fato das duas alturas servirem para a locomoção canina, ao passo que só a inferior é utilizada na locomoção humana
Para andar, os caninos dependem dos graus articulares, mas principalmente do sistema neuro-muscular, que exerce as suas funções de contração e relaxamento, graças a ligação ao sistema nervoso e as superfícies articulares do esqueleto ósseo
Suas patas, fundamentais na locomoção, têm nos coxins a única parte da pele com glândulas sudoríparas, o que ajuda a mante-las flexíveis
São ainda pouco sensíveis ao frio e ao calor, o que lhes ajuda quando em situações mais rigorosas, bem como possuem entre quatro e cinco dedos, o que proporciona sensibilidade, adaptação e aderência muito boas
Em comparação ao cavalo, outro forte animal domesticado, o cão é ainda um melhor saltador, devido a sua musculatura, e possui uma coluna mais flexível.
Nos caninos, apesar da locomoção ser algo comum a todas as raças, existem peculiaridades que acompanham o tamanho e o peso do animal
Cães como o são-bernardo são muito mais pesados que aqueles de ossos leves, como o afghan hound, e por isso, na relação com o ser humano, há de se ter cuidado quanto as práticas e trabalhos pretendidos para eles, já que muitas destas raças possuem limitações devido a seleção artificial, como o buldogue, de pernas curvadas e o dachshund, de patas curtas.
O tipo de andar que o cão executa é a chamada andadura, aquela passada completa, quando o membro volta a assumir a mesma posição do início, no momento em que toca o solo novamente, pronto para a repetição
De acordo com visualizações e definições, o andar do cão é variado e pode ser chamado de trote, cuja passada se completa com dois tempos, ou seja, duas patas tocando o chão ao mesmo tempo; trote em diagonal, quando forem de lados opostos; passo de camelo, quando dois membros, que tocam o solo simultaneamente, forem do mesmo lado; e galope de corrida e lento, que significam os membros posteriores e os anteriores movimentando-se quase ao mesmo tempo
Todos estes tipos de andadura são muito parecidos, mas cada um reflete a postura do animal e possui um ritmo determinado pela cadência dos tempos
Independente disso, são mais fáceis de serem vistos em competições de raça.
De acordo com a Federação de Cinofilia Internacional, em francês: Fédération Cynologique Internationale, regida pela Federação Cinológica Internacional, existem onze grupos de raças oficiais, porém variados de país para país, já que cada organização internacional admite diferentes grupos para a classificação do conjunto de raças que reconhece
A oficial, por sua vez, considera "os cães que realizam o mesmo tipo de trabalho ou que tenham a mesma semelhança física, a fim de que os cinófilos possam ter mecanismos facilitados para julgamento da estrutura e dinâmica dos exemplares de cães apresentados em exposições de beleza e fundamentalmente, organizar aquelas raças que, com particularidades e utilidades similares, sejam facilmente identificadas pela sua função":
Dentro destes grupos estão mais de quatrocentas raças ao redor do globo, que, por suas funções, dividem-se em um número variado de categorias, como de guarda, de tiro e caça, de utilidade, de luxo e de companhia
Entre as raças mais populares do mundo, eleitas no ano de 2009, estão o labrador retriever, considerado amigável e boa companhia para as crianças; o golden retriever, dito simpático, gentil e brincalhão; o yorkshire terrier, classificado como ativo e protetor apesar de seu diminuto tamanho; o pastor alemão, que figura como uma das raças mais inteligentes e leais; o beagle, visto como grande farejador; o dachshund, de corpo exótico; o boxer, ativo e leal; o poodle, ativo e companheiro; o shih tzu, dito excelente companheiro; e o schnauzer miniatura, visto como esperto e amável.
Há ainda o vira-lata (Brasil), ou rafeiro (Portugal), denominações dadas aos cães ou gatos sem raça definida (SRD), como são geralmente referenciados em textos veterinários
Em geral são considerados sem raça definida os mestiços, descendentes da mescla natural e desordenada de diferentes raças.
1 - labrador retriever
2 - golden retriever
3 - yorkshire terrier
4 - pastor alemão
5 - beagle
6 - dachshund
7 - boxer
8 - poodle
9 - shih tzu
10 - schnauzer
A saúde de um canino doméstico inclui uma boa alimentação, exercícios, um ambiente equilibrado e o acompanhamento veterinário:
Da dieta do canino doméstico tem-se em vista que a simples alimentação seria dar-lhe comida
Para a manutenção de sua saúde então, é fundamental nutri-lo com proteínas, cálcio, lipídios, carboidratos, minerais e vitaminas
Em geral, estes nutrientes são encontrados em situações normais para animais selvagens, nas dosagens que necessitam ou acumulam
Como o cão não vive livre ou abandonado nas ruas, isso é feito através de análise do cotidiano familiar, de suas atividades e da consulta ao veterinário, a fim de equilibrar cardápio fresco e ração, considerando a particularidade de cada animal
Filhotes, adultos e seniores podem trocar o hábito alimentar dependendo da necessidade
Independente da troca, esta deve ser mais gradual à medida que aumenta a idade do canino, já que este pode se mostrar mais resistente fisiológica e/ou psicologicamente à mudança alimentar
Há ainda de se considerar que o canino não gasta energia como seus antecessores livres e o exagero na alimentação, que causa sobrepeso e obesidade nos animais, e os alimentos proibidos aos cães, como os ricos em açúcares, gordura saturada e sódio, por exemplo
Outro alimento perigoso é o chocolate, em qualquer forma que se apresente
A subtância nele presente, chamada teobromina, pode causar intoxicação alimentar, coma e até casos de óbito
Por isso, deve-se não apenas evitar, mas proibir a ingestão de chocolate nestes animais
Em 2009, como reflexo da má alimentação dos domésticos, foi constatado, pela Associação de Prevenção à Obesidade dos Animais de Estimação, que 45% do cães e 58% dos gatos estão acima do peso ou obesos, em geral refletindo a condição física de seus donos
Como consequência deste quadro, os animais estão desenvolvendo, de acordo com veterinários, problemas coronarianos, displasia, pressão alta, artrite, diabetes, aumento no risco de derrames e câncer
Como solução, foi apontada a união da dieta equilibrada e os exercícios físicos.
Como onívoro, faz parte da dieta de um cão boa parte do que come um ser humano
No entanto, sua alimentação balanceada é mais facilmente mantida por meio das rações industrializadas e devem ser oferecidas de acordo com tamanho, idade e atividades que o animal executa
A comida caseira também pode ser dada, mas a complicação de atender às exigências nutricionais é maior, estraga com rapidez e pode causar tártaro ao animal
Outra vantagem que a ração apresenta é o fato de ser dura, o que promove o atrito e a limpeza dos dentes, já que o tártaro pode causar inflamações, perda de dentes e até mesmo doenças graves.
Entre as doenças que os cães podem ter, algumas se destacam por serem transmitidas aos seres humanos e outros mamíferos, como as dermatofitoses, as intoxicações por salmonella, a leptospirose e a raiva, que atinge o sistema nervoso
Tais enfermidades são denominadas zoonoses e tratáveis por meio da vacinação, higiene e tratamento da doença em si
Crianças e idosos são mais suscetíveis a estes problemas devido ao sistema imunológico debilitado ou pouco desenvolvido
Todavia, dependendo da progressão e da demora no diagnóstico, nem todas apresentam-se curáveis.
Para os caninos em si, que se resfriam como muitos outros animais, existem sete doenças comuns e fatais, que também podem ser evitadas através de vacinação anual ou combatidas por meio de fortes tratamentos: a tosse canina, doença infecto-respiratória causada por uma bactéria, é tratável com antibióticos e comum onde muitos cães vivem juntos; a coronavírus, contraída quando um cão entra em contato com as fezes ou outras excreções de espécimes infectados, causa apatia e vômitos, e é tratada com abundância de líquidos e medicação; a cinomose, vista como a doença infecciosa mais fatal, é causada por vírus transmitido diretamente pelo ar, com tratamento eficaz apenas no primeiro de seus dois estágios e se em cães de sistema imunológico saudável; a hepatite infecciosa canina, doença viral espalhada por contato direto, causa febre, inchaço das amígdalas e dores estomacais, e é tratada com medicação adequada e tratamento intravenoso, cujos resultados aparecem em quatro dias; a leptospirose, causada por bactéria e transmitida através da urina, causa febre, depressão, letargia e perda de apetite, além de úlcera na boca e na língua, e tem como tratamento a internação e o uso de antibióticos; a parvovirose, doença altamente contagiosa que se espalha através das patas, pelo, saliva e fezes de um cão infectado ou por sapatos de pessoas, é considerada altamente fatal nos filhotes, tem como sintomas a diarreia aguda e o dano ao músculo cardíaco, e seu tratamento é feito através de medicação adequada e a obrigatória esterilização do ambiente, para que o cão não adoeça novamente com maior gravidade.
Outras enfermidades, também tratáveis, causam desconforto ao animal, invalidez temporária ou permanente, dores e tratamentos extensivos, como as úlceras, problemas neurológicos, de vista, nas orelhas e na boca, alergias e dermatites
De um modo mais abrangente, pulgas e carrapatos representam os dois maiores males dos cães, pois causam e transmitem inúmeras doenças, além do desconforto que causam na pele, com as constantes mordidas
Em geral, a higiene, a boa alimentação e um acompanhamento veterinário evitam ou diminuem os efeitos danosos destes problemas físicos em cães domésticos
Psicologicamente, um dos maiores problemas sofridos por estes animais é a depressão, que se manifesta em forma de agressão, quietude ou histeria
Em pesquisa liderada pela espanhola Belen Rosado, constatou-se que a maior causa da agressão e dos latidos caninos são a depressão, em geral advinda de uma vida muito sedentária, o que os estressaria
Os exames realizados apontaram baixa de serotonina e alta de cortisol, causadores da desestabilização emocional
Para os veterinários, apenas o exercício físico e a companhia seriam capazes de amenizar ou eliminar este problema.
O controle de animais é feito pelo órgão responsável pelo controle de agravos e doenças transmitidas por animais, chamadas zoonoses, através do controle das populações de animais domésticos (cães, gatos e animais de grande porte) e controle de populações de animais sinantrópicos, como os ratos e os pombos
São geralmente órgãos governamentais credenciados pelos ministérios da saúde
Relacionado aos cães, os centros de controles de animais, além de efetuarem o recolhimento dos abandonados nas ruas e a castração por exemplo, também promovem campanhas de adoção dos bichos recolhidos, em geral saudáveis, vacinados, castrados e vermifugados.
As organizações protetoras dos animais são entidades de ajuda a cães, gatos e outros animais abandonados, como os pássaros em geral
Algumas delas abrigam centenas de animais que são retirados das ruas para se evitar o sacrifício pelos centros de controle, enquanto controladoras populacionais
Essas entidades, que podem ser sociedades, associações ou organizações, precisam de voluntários e auxílio para se manterem ativas
Também promovem campanhas de adoção de animais e protegem seus direitos em geral, como à vida e ao bem-estar.
Existem, em território urbano, uma classificação que divide a presença canina em quatro
Nas três primeiras, encontram-se os domésticos totalmente supervisionados, os semi-supervisionados e os de vizinhança, todos sob os cuidados dos humanos
Já na última, tem-se os chamados ferais, independentes e irrestritos, que formam matilhas de dez a quinze indivíduos que não interagem com os homens.
Esta classe canina interfere diretamente no equilíbrio do ecossistema que ocupa
Por se manterem afastados de grupos humanos obtêm sua subsistência a partir de resíduos dispersos na periferia das cidades e da caça a animais de reservas e matas circunvizinhas
Nas ocasiões em que ocorrerem contatos com seres humanos e outros animais de estimação, os riscos de agravos são maiores que com os demais estratos populacionais, por manifestarem agressividade mais acentuada que os próprios animais selvagens
Em contrapartida, estes animais apresentam altas taxas de mortalidade e baixas de reprodução
Possuem o instinto da caça desenvolvido e não são seletivos, pois variam desde pequenas presas anfíbias a grandes mamíferos de cerca de 10 kg
Considerados um dos principais predadores da vida selvagem nativa em áreas protegidas em todo o mundo, estes cães são agressivos tanto com seres humanos quanto com outros animais
Possuem hábitos mais noturnos e não matam apenas para alimentação
Suas populações não são vacinadas contra raiva e outras doenças transmissíveis, o que as torna transmissoras potenciais de vírus, representando um perigo para a vida selvagem e para o ser humano, caso entre em contato com um
Tal comportamento e o perigo que representam às sociedades e a outros animais, deixa como solução apenas a sua erradicação.
Por outro lado, o relacionamento com o homem não se reduz a bom ou agradável
Há casos de pessoas atacadas por seus animais domésticos e casos de pessoas que maltratam, quando não seus próprios caninos, os de outros ou de rua
Do homem para o animal existem diversos tipos de maus tratos, desde a direta agressão física ao uso abusivo de seus bichos em rinhas e como cobaias
São ainda postos em gaiolas minúsculas, sem higiene e alimentação
Tais agressões são consideradas, em determinados países, como violação ao direito dos animais e preveem punição legislativa
Abandonar cães doentes e idosos também é considerado crime
No Brasil, a lei protege os animais desde 1934, pelo decreto lei Nº24.645, de julho, e mais tarde, a lei de crimes ambientais nº 9605, de 16 de fevereiro de 1998, reforçou este decreto e especificou várias violações e penalidades de detenção para aqueles que praticam crimes contra os animais:
Em Portugal constituem crime "todas as violências injustificadas contra animais, considerando-se como tais os actos consistentes, sem necessidade, se infligir a morte, o sofrimento cruel e prolongado ou graves lesões a um animal." e abandonar "os animais doentes, feridos ou em perigo" de uma forma geral
Essas medidas gerais de proteção foram decretadas pela Assembleia da República nos termos dos artigos 164.º, alínea d), e 169.º, n.º 3, da Constituição.
É no cérebro que se abrigam as capacidades herdadas e gravadas, base da formação mental do cão, que mostram comportamentos e habilidades potenciais deste animal
A chamada inteligência canina é dividida em três habilidades mentais baseadas em instinto: aprendizagem, resolução de problemas e inteligência comunicativa
Dos lobos, os cães herdaram a chamada flexibilidade mental, que significa a capacidade de aprender com as experiências que os ajudam a adaptarem-se ou a modificarem o ambiente para que se torne um lugar melhor para viverem
Instintivamente cautelosos e desconfiados, aprendem também em quem confiar e quem devem evitar
Para solucionarem um problema, o cérebro funciona com rapidez de construção com o menor número possível de falsos inícios
Essa combinação constitui sua capacidade de resolução, em geral deficiente nos cães, e na qual o border collie se destaca, enquanto cão de pastoreio.
A inteligência comunicativa é a conhecida obediência ou inteligência de trabalho
Ainda que seja bom nas outras duas habilidades, precisa entender o que o os comandos do ser humano e os outros cães dizem, para perceber instintivamente a hierarquia da matilha, comunicando-se através da linguagem corporal e do cheiro
O labrador retriever é um exemplar excelente em inteligência comunicativa enquanto cão de tiro, devido a sua persistência em se concentrar.
Os cães possuem ainda o instinto natural de saberem o que devem ou não comer
Quando mastigam grama, significa por exemplo, que estão adicionando fibra à alimentação
Para compreenderem relações, possuem uma habilidade hereditária que lhes permite perceber a hierarquia e reforçar a ordem, o mesmo sendo aplicado na hora de interpretar a postura de outro animal ou do ser humano
Os caninos possuem também a habilidade de se localizarem, traçando mapas mentais de grandes territórios
Todavia, muitos vivem restritivamente ao lar e não desenvolvem esta capacidade, terminando então com um ruim senso de direção
Estes animais ainda são capazes de julgar movimentos e forças, como a aproximação de uma onda na praia
Resumindo, a inteligência canina é utilizada pelo ser humano para desenvolver e utilizar de suas habilidades mais destacadas, ao passo que serve ainda para o melhor convívio entre os de sua espécie.
Seu temperamento é variado de cão para cão, ainda que uma dada raça seja padronizada no papel a ter um determinado tipo de comportamento, como o companheirismo do poodle
No entanto, não há neles uma característica presente no ser humano: o racismo por julgamento
Apesar de demonstrar aversão a determinado grupo de pessoas, os motivos são nunca ter tido contato com tais pessoas, ter dono inseguro a dado grupo e o estímulo à desconfiança canina para um determinado grupo
Outra marcante característica do comportamento canino é a coprofagia
As razões variam de deficiência metabólica ou doença à motivos meramente comportamentais, como as cadelas que comem as fezes de seus filhotes, para manter o canto deles limpo
Os tratamentos para este comportamento, além de imprecisos, são controversos
Sabidamente um animal social, é afetado também pela chamada "mentalidade de massa", através da qual é estimulado ou simplesmente consegue fazer algo que sozinho não faria, como o ganho da confiança para encarar ameaças maiores
Em contrapartida, este comportamento pode também ser negativo, estimulado por maus hábitos, como latir excessivamente ou avançar.
Para o bom relacionamento homem e canino existe um ato fundamental , o adestramento, já que os cães são seres vivos que sentem, têm necessidades, possuem sentimentos e emoções, e este exercício constante lhes dá segurança e equilíbrio
Durante o processo, o dono dita, o cão obedece e acostuma-se com bons atos
Um canino que nunca aprendeu a sentar ou ficar, pode fugir ou correr na direção do perigo
Para um adestramento ser bem sucedido, o homem precisa entender o potencial e as limitações do animal e ensina-lo o respeito através das atividades
Em geral, todos os cães são capazes de aprenderem os comandos básicos para manterem um bom equilíbrio na relação, mais especificamente quando feitos por meio das brincadeiras, já que tanto o homem quanto o canino são animais neotênicos
É através das atividades que ele aprende, se socializa, desenvolve-se, se exercita e supre suas necessidades de gasto energético
Em suma, no relacionamento homem e animal, é o adestramento que dá uma boa base, norteia uma relação equilibrada destas espécies tão distintas, direciona e mostra as maiores habilidades de dadas raças
Em contrapartida, é primordial saber adestrar um cão, com as palavras certas e os métodos corretos - cujas linhas ainda não estão totalmente traçadas pelos profissionais - a fim de evitar traumas e inseguranças.
O processo de domesticação fez com que os cães se adaptassem aos homens em todos os sentidos
Desse modo, estes animais adquiriram riqueza fônica superior à do lobo, alimentam-se das mesmas coisas e mudaram sua morfologia para acompanhá-los ao longo do tempo
No entanto, neste relacionamento perfeito, um detalhe precisa estar todo o tempo estabelecido: a hierarquia
Assim, fica claro ao cão que o homem é o dominante do líder canino da matilha, tornando tal estabelecimento possível devido a sua superior inteligência quantitativa
Deste ponto, é dever do ser humano, como líder, premiar boas condutas, castigar a desobediência, administrar os recursos essenciais e não usar de brutalidade
Isso dá ao cão a proteção e a certeza de que todas as suas necessidades serão satisfeitas, e acima disso, uma boa relação de convivência
Essa convivência explica que, ao longo dos tempos de mutualidade, foi possível obter-se um êxito tão grande no relacionamento entre duas espécies distintas, só comparadas com aquelas que precisam umas das outras para sobreviverem
Segundo estudos realizados na Universidade de Viena, a adaptação dos cães é devida ao fato de terem desenvolvido a habilidade de aprendizado por imitação
Habilidade esta que evoluíram e continuam a utilizar para evitar o aprendizado por tentativa e erro, considerado, na prática, mais arriscado
A pesquisa, que afirma esta ser uma característica comum em outros grupos animais, destaca a diferença canina no fato de terem crescido e se desenvolvido no meio humano ao longo dos anos
É inquestionável, portanto, e pode-se afirmar com segurança que a adaptação foi feita do cão ao homem e não em sentido contrário.
Em termos práticos, o cão obtém dessa relação uma melhora em sua atitude quanto à sobrevivência, já que tem comida em abundância, evita a depredação e otimiza a qualidade reprodutiva; e também quanto à atitude social, pois se integra em uma mais ampla
Já o homem é ainda mais favorecido, pois melhora a segurança de seu grupo, as necessidades gregárias e por vezes as físicas e psicológicas.
Reconhecida e inegavelmente uma espécie domesticada, algumas raças de cães possuem características específicas que os fazem se destacar em algumas tarefas
Para desenvolver mais estas peculiaridades os cães normalmente são adestrados para obedecerem ao dono e para reagir corretamente a determinadas situações
Tal estrutura, elaborada pelo ser humano ao longo de seu convívio e interação com os caninos, só é possível devido ao comportamento do cão em relação ao homem e gerou certa variedade de classificação de suas raças, todas admitidas pelo órgão oficial máximo
Todavia, em toda classificação são postas as informações standard, que mostram o nome de origem do cão, seu padrão e suas eventuais variedades, bem como características comportamentais, de caráter, educação e utilização
Em suma, o standard é obtido através dos estudos da cinologia e apresenta a origem da raça e suas diferentes variedades admitidas, a aparência geral e o aspecto que deve ter sua estrutura externa: a cabeça, o pescoço, o corpo, os membros e a cauda
Como última característica, o standard evolui com o passar dos anos, estabelecendo padrões que se modificam de acordo com a evolução de cada raça seguindo os processos naturais e artificiais de reprodução.
Existem ainda os caninos com funções específicas, sem distinção e limitações de raças, com certas preferências de acordo com as aptidões de cada categoria, como por exemplo, os cães-guia de cegos, adestrados para guiar deficientes visuais totais ou parciais, e auxiliá-los nas tarefas caseiras e nas ruas; e os cães ouvintes, selecionados e treinados para ajudarem os surdos ou deficientes auditivos, alertando-os para sons importantes dentro de casa, como campainhas e alarmes de incêndio, bem como fora, chamando a atenção para sons como das sirenes, empilhadoras, aproximação de pessoas e o chamamento do nome do manipulador.
Além destas várias funções, em geral desenvolvidas e utilizadas em conjunto com o ser humano, há ainda a provável mais antiga relação de afeição mútua, que transformou o cão no "melhor amigo do homem"
Tal afirmação, apesar de considerada por muitos apenas uma crença popular, possui um início
Esta frase foi pronunciada pela primeira vez pelo advogado George Graham Vest, em um tribunal dos Estados Unidos, já que seu cliente, Charles Burden, dono de um galgo chamado Old Drum, descobriu que seu vizinho o havia assassinado sem motivo aparente e decidiu denunciar o fato
No julgamento, Graham então discursou:
Neste relacionamento homem e animal, o cão não se importa se seu dono reside em uma mansão ou na rua, qual a sua religião ou a cor de sua pele
Vasilhas com água limpa e comida, cuidado, carinho e respeito são o suficiente para conquistar a confiança dele, que por isso, recebeu o título de melhor amigo do homem, antes mesmo da frase ser dita pela primeira vez
Em retribuição aos cuidados, o canino está sempre disposto a acompanhar o humano, não difama ninguém e não se importa com a aparência dos outros
Por vezes, a ligação é tão forte, que se o dono adoece, o cão fica ao pé da cama lhe esperando levantar
Um dos exemplos dessa forte ligação foi a menina ucraniana Oxana Malaya, a chamada garota-cachorro
Cuidada e criada por cães, adaptou-se ao ambiente no quintal de casa e viveu cinco anos como membro da matilha
Por estas razões, é tido como integrante da família por muitas pessoas e, por suas habilidades adquiridas, é um grande ajudante nas mais variadas tarefas
Por outro lado, há a desconfiança de que o cão não seja um animal de estimação, mas sim um evoluído parasita
Tal afirmação advém do fato do canino se adaptar completamente para satisfazer a necessidade biológica que o ser humano tem de cuidar de outro ser dependente e o tornar familiar, como também estar sempre perto quando o homem se sente só, aflito ou inseguro, e por, aparentemente estar no controle, pois o homem lhe dá comida quando sente fome, o leva ao veterinário quando está doente e lhe dá atenção quando pede.
É de tempos que o cão se relaciona com o homem
Através deste convívio, observam-se momentos positivos e negativos
Na cultura, povoa a realidade com heróis, companheiros de passatempo e de trabalho, os sonhos e como úteis cobaias; na Mitologia, o canino também está presente, desde a ocidental à oriental; e, na ficção, figura em filmes, desenhos animados, seriados de televisão, livros e revistas:
De entre os discípulos de Sócrates uma corrente de pensamento passou à história com o nome de cinismo, que deriva do Ginásio Cinosargos, onde pregara Antístenes de Atenas ou, segundo outros autores, da palavra em grego para cão (Kynos), que seria o animal que seus adeptos tinham por exemplo como forma de vida ideal - na busca pela felicidade o homem só a obtém pela vida simples, com desprezo pelas riquezas e prazeres
O cínico mais notável foi Diógenes de Sínope que, além da corrente filosófica de nome "canino" também se identificava com o cão: conta-se que ele, morando num tonel, foi saudado por Alexandre Magno; este apresentou-se como um rei de quem as pessoas imputavam certa fama
Diógenes respondera-lhe ser "um cão, de quem dizem alguma coisa"; questionado pelo imperador por que se dava um nome tão "baixo", este respondera ser "porque eu adulo os que me dão, ladro contra os que me recusam e mordo os maus".
Enquanto presença na sociedade humana, uma das primeiras aparições do cão como parte da produção cultural foi nas belas artes, figurando das pinturas às esculturas antigas
Na Pré-História, cerca de 4500 a.C, surgiram as primeiras pinturas rupestres com os cães de caça, cujas aparências não se assemelhavam a nenhuma raça atual
Contudo, no Egito Antigo, a semelhança pôde ser percebida em algumas ilustrações
No Ocidente, durante o período do Império Romano, o canino figurou na cultura e foi retratado na produção artística como o guardião do lar, feroz e dedicado ao dono
Já na Idade Média, regrediu à Pré-história e passou a ser fundamentalmente um cão de caça, voltando a estar quase ausente de todas as manifestações pictóricas, provavelmente em virtude da má imagem que os artistas tinham nessa época de bichos vadios, agressivos, perigosos e esfomeados, que alimentavam-se de cadáveres
Por esta razão, figuravam apenas em pinturas de suas matilhas caçadoras.
Foi no Renascimento que a imagem do canino se humanizou, pois surgiu neste período o cão de companhia
Estes eram pintados em quadros ao lado de suas donas, apresentando-se menores que os anteriores caçadores
Foi durante o século XVI que foram representados em abundância nas artes
No século seguinte, o cão ganhou quadros para si, assumindo o papel principal da reprodução artística
Foi nesse período que surgiram os artistas especializados em retratar animais, como o francês François Desportes, e as pinturas realistas, tanto da anatomia, quanto das expressões
Pouco mais de cem anos adiante, os cães ganharam imagens quase sentimentais nas pinturas, conquistando espaço como símbolo de admiração e inspiração
Todavia, foi apenas no século XX que atingiu sua plenitude como animal de companhia, figurando em pinturas sendo acariciados por suas donas em passeios de gôndola ou sobre almofadas de seda.
Na produção de esculturas, a presença canina também foi grande
Começou ainda na Pré-História, representados em potes de barro, nos quais apareciam animais com um abdómen exagerado e patas curtas
Adiante, na produção pré-colombiana, passaram a ter os traços da divindade à qual se encontravam associados, dando à produção escultural a expressão do mundo espiritual e místico
No Egito, o cão representava a figura do Deus Anubis, além de aparecer em obras de calcário e em baixo relevo, quando esculpidas as matilhas
Na Ásia, foi também esculpida a divindade do cão-leão, que figura em entradas de templos
Apesar de presente em esculturas de distintas culturas, somente na produção assíria o ato de esculpir os cães ganhou qualidade
Eram desenhados a sós ou em grupos, mas sempre com sutileza de traços
Nas antigas Roma e Grécia, estes traços foram aperfeiçoados para proporcionar um realismo quase perfeito, ainda que não tivessem grande valor sociocultural
Na Idade Média nasceram as representações imaginárias, nas quais os caninos figuravam nas casas como simples adornos
Mais tarde, apesar da forte presença na pintura renascentista, pouco apareceu na escultura da época, já que o cavalo era o foco principal dos artistas
Do século XVII em diante, o cão continuou a ser objeto escultural, agora mais para pesquisa que pela arte em si, que ficou a cargo dos artistas de animais.
Além da produção artística, o cão figura modernamente na sociedade nos mais diferentes níveis, desde cão de companhia de um presidente da república a cão de agility e exposição
Nesse esporte, praticado em dupla, há a interação cão e dono, em uma atividade que trabalha a atenção, a força e a agilidade canina, além da liderança do homem
Nascido em 1978, na Inglaterra, foi considerado esporte de entretenimento, como a exposição canina de estrutura e beleza
É nela que se estabelecem a qualificação e a classificação seletivas de exemplares que tenham potencial para aprimorar a criação de cães
Diferente do que se pensa, a classificação geral é feita entre os caninos presentes, ao passo que a qualificação, tida como mais importante, pois concede estatuto de acordo com suas virtudes e suas faltas, é feita para garantir a pureza de uma determinada raça
Não relacionado diretamente com o animal, o cão continua no meio esportivo como mascote de times e de eventos mundiais, como a Copa do Mundo de Futebol de 1994, realizada nos Estados Unidos
O apreço pelos cães os tornam de mascotes esportivos a mascotes do dia a dia, como um SRD adotado em um cemitério brasileiro
Tão presente positivamente na cultura humana, povoa seus sonhos de forma negativa
Os variados significados de sonhar com o cão não trazem boa sorte, pois podem representar traição, fraude, surpresas ruins, intrigas familiares e reflexos negativos de personalidade
Na metafísica, são os guardiões do mundo subterrâneo
Podem também representar a parte mais animal da natureza humana, e muitos o vêem como a energia masculina em sua melhor expressão.
No âmbito científico, há o uso de animais para experimentação de produtos ou aperfeiçoamento das raças, os chamados cobaias, e para pesquisa genética
Em todos estes usos, há leis que proíbem os maus tratos e asseguram o melhor ambiente possível
Essas pesquisas genéticas são baseadas no fato de homem e cão partilharem determinadas doenças de mesma base genética, podendo então contribuir com informações sobre a patogenia de efermidades como câncer, epilepsia, diabetes e problemas cardiovasculares
Sem correr o risco dos maus-tratos, os cães também estão presentes na área tecnológica, mas como robôs
Em uma pesquisa realizada no Japão, a maioria dos entrevistados disse preferir a companhia de um animal a de um ser humano
Daí então nasceu o conceito do cão-robótico para entretenimento
Como um exemplo está Aibo, da Sony, com vários recursos de inteligência artificial embutidos, que lhe dão a capacidade de aprender através da técnica de tentativa e erro e assim descobrir o que pode ou não fazer
Existe também uma nova versão desse robô, com capacidade de achar a tomada para recarregar suas baterias e reconhecer a voz e o rosto de seu dono
O Aibo pode ainda ter sua personalidade controlada por computador e ser manipulado por e-mail
Socializando, pode-se ver um time de futebol formado por vários desses robôs com aspectos de brinquedo: eles fazem gol e comemoram colocando as patas dianteiras para cima.
Além dessas, há outra utilidade apreciada pelos homens: o cão enquanto iguaria culinária
Animal de estimação e de imagem demasiada humana em várias culturas, em algumas é visto como alimento
Na Coreia do Sul, a carne de cachorro é um prato tradicional, chamado boshintang, para ser consumido na busca da boa saúde durante os conhecidos três "dias do cachorro"
No entanto, essa oriental tradição é frequentemente rejeitada pelos jovens sul-coreanos, devido à ocidentalização do pensamento de que o cão é um companheiro e não uma refeição
Na China, outro país oriental, há também o consumo de cachorro, mas como um prato exótico, devido a sua extrema variedade e fartura
Com mais de três mil anos de existência, a culinária deste país varia muito devido à adaptação das pessoas às regiões remotas, que aproveitam da natureza o que ela oferece para sobreviver
Apesar disso, o governo chinês rascunhou uma lei que proíbe o consumo de determinados animais, entre eles o cão.
No relacionamento homem e canino, ao longo da história da Humanidade, muitos cães vieram a ter destaque por ações heroicas, puro companheirismo, e até mesmo pioneirismo, conquistando com isso, certa fama e reconhecimento humano
Entre os maiores exemplos está Balto, um mestiço de husky siberiano e lobo-cinzento, que foi herói no estado norte-americano do Alasca em 1925
Sua história, na qual salva vidas da difteria após percorrer uma enorme distância em plena nevasca para buscar remédios, é contada em filme, no qual é dublado pelo ator Kevin Bacon
Outro herói canino é Barry, um são-bernardo que salvou entre quarenta e cem pessoas perdidas na neve dos Alpes suíços durante 14 anos
Seu corpo está preservado no Museu de História Natural de Berna
Já Laika foi uma vira-lata do programa espacial soviético e o primeiro ser vivo a entrar em órbita espacial, feito este a bordo da Sputnik 2
Assim como a cadela, Snuppy foi um outro pioneiro, desta vez no campo da ciência, ao tornar-se o primeiro cão clonado do mundo
Da raça galgo afegão, nasceu em 2005, após experimentos realizados pelos sul-coreanos e tornou-se notícia no mundo todo
Entre os maiores exemplos de companheirismo documentados está o caso do akita japonês Hachiko, cuja história deu origem ao filme Sempre ao seu lado protagonizado pelo ator Richard Gere
Este cão nasceu no início da década de 1920, no Japão, e vivia com o professor universitário Hidesaburo Ueno em Tóquio, onde o acompanhava de casa até a estação de trem de Shibuya
Em 1924, o professor faleceu e Hachi foi doado a outra família
Apesar disso, o cão sempre voltava à estação para esperar pelo antigo dono, repetindo o ato por dez anos até falecer em 1935, tornando-se uma lenda japonesa com direito a três estátuas de bronze, um filme nacional rodado em 1987 e um livro infantil
No Ocidente, Greyfriars Bobby, um skye terrier que viveu na Escócia, ficou conhecido por ter guardado o túmulo de seu dono por 14 anos, até falecer em 14 de janeiro de 1872
Um ano após sua morte, Lady Burdett-Coutts mandou erguer uma fonte e uma estátua em sua homenagem
Filmes e livros também foram baseados na vida deste cão, incluído um produzio pela Walt Disney Productions.
Na tradição católica lusa, quem mata um cão deve uma alma a São Lázaro
No Brasil, em decorrência da associação de sinonímia entre as palavras 'cão' e 'diabo', utiliza-se preferencialmente a palavra "cachorro" (do latim vulgar cattŭlus, por catŭlu 'filhote de cão'), mesmo para nomear o animal adulto
Em Portugal, mantém-se a acepção de "cachorro" como 'filhote de cão'.
Por influência dos muçulmanos, a visão sobre os cães na África ganhou sentido pejorativo, tal como ocorre em Angola, onde a literatura oral banta figura os cães como símbolos de covardia, sordidez e servilismo
Nos Açores, chama-se o demônio de cão negro e cão tinhoso
Aventa-se que tal associação, entre "cão" e "demônio", tenha sido trazida para o Brasil pelos colonos açorianos, já no século XVIII.
Na Roma Antiga acreditava-se que os cães viam os espíritos
Segundo a crença popular brasileira, quando isto ocorre, diz-se o esconjuro: "Todo o agouro para o teu couro"
Acredita-se que, quando o animal uiva, está a chamar desgraça para o dono
Então, repete-se o mesmo dito anterior ou vira-se um sapato com a palmilha para o alto, para que o animal se cale
Quando o cachorro cava a terra com o focinho voltado para a rua ou cava à entrada da casa, acredita-se que cava a sepultura do dono; se, porém, cava a terra com o focinho voltado para a casa é sinal de dinheiro
É sinal de azar o cão dormir com a barriga para cima; se urinar na porta, traz boa sorte
Dentre as inúmeras crendices há também o cão dito "pesunho" - que possui uma unha a mais - o qual, acredita-se, seja capaz de ver e perseguir lobisomens.
Popularizou-se, no nordeste do Brasil, a expressão "o cão do segundo livro" - geralmente aplicada a alguma coisa, situação ou pessoa muito difícil, insuportável ou, com uma conotação positiva, a alguém capaz de grandes proezas
A origem desse "cão" está nos livros de leitura de Felisberto de Carvalho, que eram utilizados nas escolas elementares, entre o final do século XIX e meados do século XX
No Segundo Livro de Leitura, na 17ª lição, é contada uma lenda, supostamente de origem árabe, acerca dos malefícios do alcoolismo
Um dos personagens da narrativa é o próprio diabo - o "cão", causador de uma série de desgraças, e que ficou conhecido como "o cão do segundo livro"
O cão do segundo livro é também o título de um auto de Natal, em dois atos, do escritor pernambucano Osman Lins.
Faz parte do imaginário humano a premissa de que o cão e o gato são inimigos naturais, bem como o felino é do rato
Frases do tipo "parecem cão e gato" reforçam a ideia de que os dois não se toleram
É sabido que estes mamíferos, apesar de domesticados e sob o apreço do homem, possuem hábitos totalmente diferentes, o que não é sinônimo de inimizade
O cão, mais sociável que o gato, devido a sua relação de dependência, pode sim viver com um gato sob o mesmo teto.
Essa afirmação popular pode ter surgido por disputas territoriais ocorridas diante dos olhos das pessoas
Quando um outro animal é introduzido no ambiente, o cão sente-se o protegendo do invasor
Isso pode acontecer com qualquer bicho, mas tornou-se mais comum entre cães e gatos por ambos serem espécies domesticadas e do agrado do ser humano
O cão vê o novo morador como ameaça, rosna para ele e o gato responde igualmente com o seu tipo de rosnado, o que significa uma agressão para o canídeo, que começa a persegui-lo
Rápido, o felino é um estímulo ao instinto caçador do cão, que não para de correr atrás
Ao que o gato cessa a correria, o cão desiste, pois a diversão acabou
Essas perseguições renderam filmes e personagens animados, como o buldogue Spike, o cão que persegue o gato Tom, e o longa Como cães e gatos, que mostram estes mamíferos como inimigos e provocadores mútuos
Na outra ponta, quando estes casos ocorrem entre dois caninos, o ser humano vê apenas como ciúme e não os iguala.
Na Suméria, vinte séculos antes de Cristo, a deusa Bau (Bawa ou Babu) tinha seu nome provavelmente derivado do latido do cão.
Da mitologia ocidental à oriental, o cão figura como fera e como divindade
Uma das mais famosas imagens ocidentais é a de Cérbero: besta presente na mitologia greco-romana, é o filho de Tifão e Equidna, inimigo de Zeus, era irmão do cão bicéfalo Ortros e da Hidra, a serpente de sete cabeças
De sua união com Quimera nasceram o Leão da Nemeia e a Esfinge
Cérbero vivia na entrada do reino do deus Hades e costumava latir muito
Para aplacar sua ira, os mortos lhe davam um bolo feito de farinha e mel, presente que seus parentes deixavam nos túmulos
Apesar da conhecida lenda, sua morfologia no entanto, sofre com discrepâncias quanto ao número de cabeças, ainda que a versão mais aceita seja com três
Sua cauda também é atribuída de várias formas, como de escorpião, de cão ou de cabeça de serpente.
Outro conhecido cão mitológico da Grécia, é Argos, cujo dono era Odisseu
Na Odisseia de Homero, foi Argos o único a reconhecer o herói quando este retornou para casa, morrendo logo depois disso para que os invasores de sua casa não percebessem que Odisseu estava disfarçado e pronto para prendê-los
Outros cães presentes na mitologia grega são Argyreos e Chryseos, feitos de prata e ouro respectivamente, confeccionados pelo deus Hefesto; Ortros era o cão companheiro de Gerião, conhecido por ter sido morto por Hércules
Ainda no ocidente, o canino também figurou nas mitologias nórdica, com os Kenning, as conhecidas montarias das valquírias; germânica, com Barghest, lobo domesticado pelos goblins; celta, com Failinis da lenda dos 'argonautas' gaélicos, e Bran, o cão de Finn; e egípcia, com Anúbis.
No lado oriental da mitologia, este animal aparece como Tien-koan, o cão celestial chinês; e como Hōkō, a besta de cinco caudas da mitologia japonesa
Como híbrido, o cão também figura, mas na mitologia do Antigo Egito, como um cinocéfalo, macaco com cabeça de canídeo
Os cinocéfalos chegaram à Idade Média, sendo populares as lendas como a de São Cristóvão com a cabeça de cão.
Nas religiões o cão também possui o seu papel
Para os judeus, apesar de considerados impuros por se alimentares de restos, fosse de cadáveres, fosse de lixo, também eram vistos positivamente, devido a palavra do Talmude
Este afirma que os cães devem ser tolerados e que o acesso ao alimento ritualmente impuro foi a recompensa concedida por Deus aos cães, retribuindo o silêncio destes na noite em que os israelitas começaram o êxodo do Egito, além de um cão ter sido dado por Deus a Caim como sinal de proteção
No Catolicismo, apesar do início preconceituoso da Idade Média, a imagem dos cães passou a ser positiva desde a narrativa do nascimento de Jesus, no qual figuraram como cães de pastoreio, até a história do cão Giggio, sempre defendendo São João Bosco
Para a religião islâmica, os cães, antes vistos como párias e com o decreto de Maomé para seu extermínio, continuam vistos como animais a serem evitados e eliminados, mas agora apenas quando vadios e disseminadores de doenças, já que possuem utilidade ao ser humano quando em atividades como pastoreio, caça e guarda.
A ficção produziu inúmeros cães, que aparecem da literatura ao cinema, seja em filmes ou desenhos animados, passando pela banda desenhada
Entre os mais famosos é possível citar alguns que marcaram gerações, seja apenas em países ou pelo mundo.
Criação dos estúdios Disney, os 101 Dálmatas foram um desenho animado rodado pela primeira vez em 1961, que viraram filme 35 anos mais tarde, com direito a uma continuação chamada 102 Dálmatas
Além, viraram jogos de videogame, pelúcias, roupas e acessórios
Também criação deste estúdio é o cão Pluto, da raça bloodhound, companheiro do rato Mickey
Criado em 1950, sua personalidade quase humana o destacou pelo mundo
Em 1941, o desenho Me dê uma pata, protagonizado pelo canino, conquistou o Óscar de melhor curta-metragem de animação
Assim como os dálmatas, Pluto também é estampado em diversos produtos, bem como outro famoso cão da vida do rato norte-americano: Pateta, cuja primeira aparição em desenho animado deu-se em 1932
Destacado também pela Disney foi Banzé, o filhote de A Dama e o Vagabundo, filme também destacado pelo estúdio e por apresentar o romance entre dois caninos de mundo tão distintos, exibido no ano de 1955.
Nos desenhos animados, Scooby-doo, o dinamarquês criado no ano de 1969 por Iwao Takamoto, e Snoopy, cão da raça beagle, personagem da história em quadrinhos Peanuts criado por Charles Schulz, destacaram-se por permanecerem em exibição nas televisões ao redor do mundo, e por figurarem em diversos produtos e também bandas desenhadas
Scooby inclusive foi às telas do cinema com dois filmes
Especificamente nos quadrinhos, Bidu, cão azul da raça schnauzer criado pelo brasileiro Maurício de Sousa, e Ideiafix, minúsculo companheiro do Obelix, também destacaram-se como seres fictícios.
Já no cinema e na literatura, destacam-se o cachorro Quincas Borba do dono filósofo homônimo no romance Quincas Borba (1891) escrito por Machado de Assis, e o paradoxal nome de Baleia, cadela raquítica de Vidas Secas (1938), escrito por Graciliano Ramos, onde, numa terra de seca, ela humaniza-se com fantasias de um mundo cheio de preás gordos, enquanto os personagens sertanejos animalizam-se e seifam sua vida
Destaca-se também Lassie, cadela que deu nome à série e ao famoso filme rodado ao lado de Elizabeth Taylor; Rin-tin-tin, astro de quase trinta filmes, detentor de uma estrela na Calçada da Fama e um dos primeiros cães do mundo a se tornarem celebridade; e Marley, um canino real que marcou a vida de uma família e saiu do livro escrito e vivido por John Grogan, para as telas do cimena em Marley & Eu
Publicação e película contaram a história do pior cão do mundo com o maior coração de todos
Existem ainda vários cães que aparecem em diversos filmes, desenhos e tiras de jornais, como o companheiro Odie de Garfield, que fazem parte de famílias, são amigos, falantes ou comunicativos, guerreiros ou trapaceiros, que sempre povoam a imaginação do ser humano.

chacal-prateado (C
adustus)
L
culpaeus
raposa-cinzenta (U
cinereoargenteus)
V
bengalensis
(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


1889 (MDCCCLXXXIX, na numeração romana) foi um ano comum do século XIX do actual Calendário Gregoriano, da Era de Cristo, a sua letra dominical foi F (52 semanas), teve início a uma terça-feira e terminou também a uma terça-feira.
Ano comum com início à terça-feira




Hormona  ou hormônio  é uma substância química específica fabricada pelo sistema endócrino ou por neurónios altamente especializados e que funciona como um sinalizador celular
O termo provém do grego ormóni (ὁρμῶν) que significa evocar ou excitar.


O nome hormona foi primeiramente utilizado em 1905, pelo fisiologista inglês Ernest Starling durante uma palestra sobre o controle químico das funções corporais no Royal College of Physicians em Londres
Ele definiu hormonas como mensageiros químicos produzidos recorrentemente para atender necessidades fisiológicas do organismos e carregados do órgão em que são produzidos para o orgão de destino pela corrente sanguínea
Poucos anos antes, Starling e seu colega William Bayliss haviam identifcado o primeiro hormona, a secretina, durante experimentos sobre a digestão.
As hormonas ou hormônios são secretados em quantidades muito pequenas na corrente sanguínea
Assim sendo, podem ser produzidas por um órgão ou em determinadas células do órgão
São libertadas e transportadas diretamente pelo sangue
A sua função é exercer uma ação reguladora (indutora ou inibidora) em outros órgãos ou regiões do corpo
Em geral trabalham devagar e agem por muito tempo, regulando o crescimento, o desenvolvimento, a reprodução e as funções de muitos tecidos, bem como os processos metabólicos do organismo.
Os hormônios ligam-se aos receptores localizados sobre a superfície da célula ou no seu interior, sendo que a ligação de um hormona a um receptor acelera, reduz ou altera a função celular de uma outra maneira, controlando a função de órgãos inteiros
Alguns hormonas afetam somente um ou dois órgãos (eg
hormona estimulante da tireóide), enquanto outros afetam todo o organismo (eg
hormona tireoidiano).
Podemos também citar como exemplo a insulina, que controla a razão e a maneira pela qual a glicose é utilizada pelo corpo
Outras hormonas incluem as sexuais, os corticoesteroides, a adrenalina, a tiroxina, e a hormona do crescimento
Em plantas, as hormônios são conhecidas como factores de crescimento.
Nas mulheres, por volta dos 40 anos de idade, há uma queda brusca na produção de hormônios, que é chamada de menopausa; nos homens, essa queda é chamada de andropausa.
Algumas dos hormônios mais conhecidas são os que regulam as funções sexuais dos mamíferos (a testosterona e o estrogénio) e as que regulam o nível de glicose no sangue (como a insulina).
Alguns dos principais órgãos produtores de hormonas no homem são a hipófise, o hipotálamo, a tiroide, as paratiroides, as glândulas suprarrenais, o pâncreas e as gónadas.
Os hormonas podem ser classificados segundo as propriedades químicas:
Testículos: testosterona • AMH • inibina
Ovário: estradiol · progesterona · activin and inhibin · relaxina (gestação)

Ilhotas pancreáticas (ou Ilhotas de Langerhans) são um grupo especial de células do pâncreas que produzem insulina e glucagon, substâncias que agem como importantes reguladores do metabolismo de açúcar
No pâncreas humano existem entre 1 e 2 milhões de ilhotas de langerhans, com cerca de 0,3 mm de diâmetro organizadas ao redor de pequenos capilares.
Nomeadas em homenagem a Paul Langerhans, o cientista alemão que as descobriu em 1869, essas células se dispõem em aglomerados (clusters) no pâncreas
Elas fazem e secretam estes hormônios que ajudam o corpo a quebrar e usar o alimento.
São as ilhotas pancreáticas que compõem o pâncreas endócrino (parte endócrina do pâncreas).
Os hormônios produzidos nas ilhotas de Langerhans são secretados diretamente na circulação sanguínea por (pelo menos) quatro tipos diferentes de células:
Os ilhéus podem influenciar-se entre si através de comunicação parácrina e autócrina, e as células beta são acopladas eletricamente a células beta (mas não a outros tipos de células).
Como os ilhéus de Langerhans são destruídas na diabetes tipo I, pesquisadores estão buscando ativamente uma tecnologia de transplante de ilhotas como um meio de curar essa doença, em substituição ao transplante de pâncreas
O procedimento é relativamente simples, tem poucas complicações e exige uma hospitalização de curta duração
O grande problema é a obtenção das células, que são originárias de cadáveres
São necessários em média três doadores para se conseguir um número razoável de células.
No Brasil, o primeiro transplante de ilhotas de Langerhans para curar diabetes do tipo I ocorreu em 2004, no Hospital Albert Einstein de São Paulo.
1869 (MDCCCLXIX, na numeração romana) foi um ano comum do século XIX do actual Calendário Gregoriano, da Era de Cristo, e a sua letra dominical foi C, teve 52 semanas, início a uma sexta-feira e terminou também a uma sexta-feira.
Ano comum com início à sexta-feira



(Veja a página de ajuda para mais informações)

Atenção: Você está a recriar uma página eliminada ou renomeada anteriormente.

Deverá considerar se é ou não apropriado continuar a editá-la
Saiba o que pode ser feito quando uma página criada por você é eliminada.
O registo de eliminação e de movimento desta página é apresentado, por conveniência, a seguir:

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


(Veja a página de ajuda para mais informações)

Você não está autenticado(a)
Embora sua edição seja bem-vinda, o seu endereço IP será registado no histórico desta página.

Ao salvar, você concorda irrevogavelmente em liberar as suas contribuições sob as licenças Creative Commons Attribution/Share-Alike License 3.0 e GFDL
Você concorda em ser creditado por reutilizadores, no mínimo, por meio de uma hiperligação ou URL para a página na qual está contribuindo
Veja as condições de uso para detalhes.

Copiar e colar: – — ‘ ’ “ ” ° ″ ′ ≈ ≠ ≤ ≥ ± − × ÷ ← → · §   Para assinar em páginas de discussão: ~~~~


{{}}   {{{}}}   |   []   [[]]   [[Categoria:]]   #Redirecionamento [[]]   &nbsp;   &ensp;   &emsp;   <s></s>   <u></u>   <sup></sup>   <sub></sub>   <code></code>   <pre></pre>   <blockquote></blockquote>   <poem></poem>  <br />   <ref></ref>   <ref name="nome"></ref>   <ref group="nota"></ref>   {{Referências}}   <references/>   <references group="nota"/>   <includeonly></includeonly>   <noinclude></noinclude>   <nowiki></nowiki>   <!-- -->   <pre></pre>   <hiero></hiero>   <timeline></timeline>   <syntaxhighlight></syntaxhighlight>   <div></div>   <span></span>   <small></small>   <span class="plainlinks"></span>   {{DEFAULTSORT:}}   {{PAGENAME}}    {{NAMESPACE}}   {{fullurl:}}   {{#if:texto|s|n}}   {{#ifeq:1|2|s|n}}   {{#switch:c|v1=r1|v2=r2|alt}} 



Símbolos: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ ’ “ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³   ♭ ♯ ♮   @ © ® ™
Caracteres: A Á À Â Ä Ǎ Ă Ā Ã Å Ą Æ Ǣ a á à â ä ǎ ă ā ã å ą æ ǣ   B b   C Ć Ċ Ĉ Č Ç c ć ċ ĉ č ç   D Ď Đ Ḍ Ð d ď đ ḍ ð   E É È Ė Ê Ë Ě Ĕ Ē Ẽ Ę Ə e é è ė ê ë ě ĕ ē ẽ ę ə   F f   G Ġ Ĝ Ğ Ģ g ġ ĝ ğ ģ   H Ĥ Ħ Ḥ h ĥ ħ ḥ   I Í İ Î Ï Ǐ Ĭ Ī Ĩ Į i í ı ì î ï ǐ ĭ ī ĩ į   J Ĵ j ĵ   K Ķ k ķ   L Ĺ Ŀ Ľ Ļ Ł Ḷ Ḹ ḹ l ĺ ŀ ľ ļ ł Ḷ Ḹ ḹ   M Ṃ m ṃ   N Ń Ň Ñ Ņ Ṇ n ń ň ñ ņ ṇ   O Ó Ò Ô Ö Ǒ Ŏ Ō Õ Ǫ Ő Ø Œ o ó ò ô ö ǒ ŏ ō õ ǫ ő ø œ   P p   Q q   R Ŕ Ř Ŗ Ṛ r ŕ ř ŗ ṛ ṝ   S Ś Ŝ Š Ş Ṣ ß s ś ŝ š ş ṣ ß   T Ť Ţ Ṭ Þ t ť ţ ṭ þ   U Ú Ù Û Ü Ǔ Ŭ Ū Ũ Ů Ų Ű Ǘ Ǜ Ǚ Ǖ u ú ù û ü ǔ ŭ ū ũ ů ų ű ǘ ǜ ǚ ǖ   V v   W Ŵ w ŵ   X x   Y Ý Ŷ Ÿ Ỹ Ȳ y ý ŷ ÿ ỹ ȳ   Z Ź Ż Ž z ź ż ž   ß Ð ð Þ þ Ə ə   {{Unicode|}} 
Grego: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω 
Cirílico: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я   ́ 
AFI: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   {{AFI|}}


O Canadá (em inglês: Canada, pronunciado [ˈkænədə] ( ouvir); em francês: Canada, pronunciado: [kanada]) é um país que ocupa grande parte da América do Norte e se estende desde o oceano Atlântico, a leste, até o oceano Pacífico, a oeste
Ao norte o país é limitado pelo oceano Ártico
É o segundo maior país do mundo em área total, superado apenas pela Rússia, e a sua fronteira comum com os Estados Unidos, no sul e no noroeste, é a mais longa fronteira terrestre do mundo.
As terras ocupadas pelo Canadá são habitadas há milênios por diferentes grupos de povos aborígines
Começando no fim do século XV, expedições britânicas, portuguesas e francesas exploraram e, mais tarde, se estabeleceram ao longo da costa Atlântica do país
A França cedeu quase todas as suas colônias na América do Norte em 1763 depois da Guerra dos Sete Anos
Em 1867, com a união de três colônias britânicas da América do Norte em uma confederação, o Canadá foi formado como um domínio federal de quatro províncias
Isto começou com um acréscimo de províncias e territórios e com um processo de aumento de autonomia do Reino Unido
Esta ampliação de autonomia foi salientada pelo Estatuto de Westminster de 1931 e culminou no Canada Act de 1982, que eliminou os vestígios de dependência jurídica do Parlamento Britânico.
O Canadá é uma federação composta por dez províncias e três territórios, uma democracia parlamentar e uma monarquia constitucional, com a rainha Isabel II como chefe de Estado — um símbolo dos laços históricos do Canadá com o Reino Unido — sendo o governo dirigido por um primeiro-ministro, cargo ocupado atualmente (2018) por Justin Trudeau
É um país bilíngue e multicultural, com o inglês e o francês como línguas oficiais
Um dos países mais desenvolvidos do mundo, o Canadá tem uma economia diversificada, dependente dos seus abundantes recursos naturais e do comércio, particularmente com os Estados Unidos, país com que o Canadá tem um relacionamento longo e complexo
É um membro do G7, do G20, da OTAN, da OCDE, da OMC, da Comunidade das Nações, da Francofonia, da OEA, da APEC e das Nações Unidas.


Existem várias teorias quanto à origem etimológica da palavra Canadá
O "Dictionary of Canadianisms on Historical Principles Online" considera que a etimologia da palavra Canadá não se encontra claramente estabelecida e apresenta uma extensa lista com várias teorias que foram apresentadas ao longo dos tempos.
A teoria com mais aceitação talvez seja a de que a origem do nome Canadá venha da palavra iroquesa kanata, que significa aldeia ou povoado
Em 1535, nativos americanos vivendo na região utilizaram a palavra para explicar ao explorador francês Jacques Cartier o caminho para a aldeia de Stadacona, local onde encontra-se atualmente a cidade de Quebec
Cartier utilizou a palavra não somente em referência a Stadacona, mas bem como à toda região sujeita ao domínio de Donnacona, então cacique de Stadacona
Por volta de 1547, mapas europeus passaram a nomear esta região, acrescida das áreas que a cercavam, pelo nome Canada.
Outra teoria atribui a origem do nome Canadá a navegadores espanhóis que tendo chegado às costas do Canadá e não tendo encontrada nem ouro nem nada de proveito, terão dito "Aca nada", palavras que, mais tarde terão sido repetidas pelos nativos e pelos franceses.
Outra teoria bastante divulgada desde há séculos é a de que um navegador português depois de visitar estas terras geladas do continente norte-americano terá deixado escrito num mapa “Cá Nada” pois nestas terras nada havia de interessante e mais tarde um copista francês terá interpretado estas duas palavras como sendo o nome da terra
O historiador luso-alemão Rainer Daehnhardt defensor desta última teoria refuta a hipótese da origem nativa iroquesa argumentando que os iroqueses habitavam o interior e que existe cartografia anterior aos primeiros contactos com iroqueses e que já faz uso da palavra Canada.
A partir do século XVII, aquela parte da Nova França, situada ao longo do rio São Lourenço e das margens norte dos Grandes Lagos, era conhecida como Canadá
Posteriormente, foi dividida em duas colônias britânicas, Canadá Superior e Canadá Inferior, até a união das duas como uma única Província Britânica do Canadá, em 1841
Até a década de 1950, o Canadá era oficialmente — e comumente — chamado de Dominion of Canada (Domínio do Canadá)
À medida que o Canadá adquiriu maior autoridade e autonomia política do Reino Unido, o governo federal passou a utilizar cada vez mais somente Canada em documentos oficiais, em documentos governamentais e em tratados
Com o Canada Act de 1982, o nome oficial do país passou a ser simplesmente Canadá, assim escrito nos dois idiomas oficiais do país, o inglês e o francês
Com o Canada Act, o dia da independência canadense, 1 de julho, mudou de nome, de Dominion Day para Canada Day.
Estudos arqueológicos e genéticos indicam uma presença humana no norte de Yukon há 26 500 anos e no sul de Ontário há 9 500 anos
As planícies de Old Crow e as cavernas de Bluefish são dois dos mais antigos sítios arqueológicos de habitação humana (paleoamericanos) no Canadá
Entre os povos das Primeiras Nações, há oito mitos únicos de criação e suas adaptações
As características das civilizações aborígines canadenses incluíam assentamentos permanentes ou urbanos, agricultura, cidadania, arquitetura monumental e complexas hierarquias sociais
Algumas dessas civilizações já tinham desaparecido antes da colonização europeia (início do século XVI) e foram descobertas através de pesquisas arqueológicas.
Estima-se que no final do século XV e início do século XVI viveriam entre 200 000 e dois milhões de indígenas no que é atualmente o Canadá — o valor atualmente aceito pela Comissão Real sobre a Saúde Aborígine do Canadá é de 500 000
Surtos repetidos de doenças infecciosas europeias como a gripe, o sarampo e a varíola (para as quais os indígenas não tinham imunidade natural), combinados com outros efeitos do contato europeu, resultou em uma diminuição de 40% a 80% da população indígena após a chegada dos europeus
Os povos aborígines do Canadá incluem as Primeiras Nações, Inuit e Métis
Métis é uma cultura mestiça originada em meados do século XVII, quando as Primeiras Nações e os Inuit se misturaram com os colonos europeus
Os esquimós tinham uma interação mais limitada com os colonizadores europeus durante períodos iniciais.
Por volta do ano 1000, viquingues estabeleceram o colonato de Vinlândia (atual região do Golfo de São Lourenço, Nova Brunswick e Nova Escócia)
A ocupação de Leifsbudir foi superficial e durou pouco tempo, porém representou o primeiro contato europeu com a América e o primeiro assentamento escandinavo na América do Norte (com exceção da Groenlândia), cerca de 500 anos antes das viagens de Cristóvão Colombo.
A primeira visita documentada a terras canadenses por navegadores europeus ocorreu em 1497 ou 1498, quando o veneziano ao serviço de Inglaterra Giovanni Caboto (conhecido em inglês como John Cabot) aportou à Terra Nova
Alguns historiadores defendem que há indícios que a Terra Nova já teria sido visitada pelo navegador português João Vaz Corte Real em 1472 ou antes e por Diogo de Teive e o seu piloto Pero Vasques Saavedra em 1452.
Baseando-se no Tratado de Tordesilhas, a Coroa Portuguesa alegava ter direitos territoriais na área visitada por John Cabot, em 1497-1498
Em 1498, o marinheiro luso João Fernandes Lavrador visitou o que é agora a costa leste do Canadá, sendo que o seu apelido deu origem ao topônimo "Labrador"
Posteriormente, entre 1501 e 1502, os irmãos Corte-Real exploraram Terra Nova e Labrador
Em 1506, o rei D
Manuel I criou impostos para a pesca do bacalhau nas águas da região
No ano 1521, João Álvares Fagundes e Pêro de Barcelos comandaram viagens de reconhecimento e estabeleceram postos avançados de pesca
No entanto, a extensão e natureza da presença portuguesa no norte do continente americano durante o século XVI permanecem obscuras
Em 1534 Jacques Cartier explorou o Canadá em nome da França
O explorador francês Samuel de Champlain chegou em 1603 e estabeleceu os primeiros assentamentos europeus permanentes em Port Royal em 1605 e Quebec em 1608.
A colonização europeia começou efetivamente no século XVI, quando os britânicos, e principalmente, os franceses estabeleceram-se pelo Canadá
Os britânicos não tiveram uma forte presença no antigo Canadá, instalando-se originalmente na Terra de Rupert — uma gigantesca área que posteriormente daria origem aos Territórios do Noroeste, Manitoba, Saskatchewan e Alberta, que são áreas no centro, oeste e noroeste do país — sendo que a região dos Grandes Lagos e do Rio São Lourenço, bem como a região que atualmente compõe as atuais províncias de Nova Escócia e New Brunswick, estava toda nas mãos dos franceses
A Nova França (Nouvelle-France) e a Acádia continuavam a se expandir
Essa expansão não foi bem aceita pelos iroqueses e, principalmente, pelos britânicos e os colonos das chamadas Treze Colônias (as quais se tornariam os Estados Unidos), desencadeando uma série de batalhas que culminou, em 1763, no Tratado de Paris — no qual os franceses cederam seus territórios da Nova França e da Acádia aos britânicos.
Os britânicos, que já então dominavam as imensas Terras de Rupert bem como os territórios de Nunavut, Territórios do Noroeste e Yukon — emitiram o Quebec Act, que permitiu aos franceses estabelecidos no antigo Canadá que continuassem a manter seu código civil e sancionou a liberdade de religião e de idioma — permitindo que a Igreja Católica e a língua francesa continuassem a sobreviver no Canadá até os dias atuais.
Com a Guerra da Independência dos Estados Unidos, que durou de 1775 até 1783, o Canadá recebeu levas de colonos leais aos britânicos, provenientes das Treze Colônias britânicas rebeldes
Tais colonos se estabeleceram no que é a atual província de Ontário
Com isso, os britânicos decidiram separar o Canadá em dois, criando o Canadá Superior (atual Ontário) e o Canadá Inferior (atual Quebec), além do território de New Brunswick (antiga Acádia — parte dos territórios antigamente colonizados pelos franceses).
Os Estados Unidos, em 1812, invadiram o Canadá Inferior e o Canadá Superior, na tentativa de anexar o resto das colônias britânicas na América do Norte, desencadeando a Guerra de 1812
Os Estados Unidos não tiveram sucesso, recuando ao tomarem conhecimento da chegada de tropas britânicas enviadas para combatê-los — mas ocuparam temporariamente as cidades de York (atual Toronto) e Quebec, queimando-as ao se retirarem
Em retaliação, tropas canadenses e britânicas perseguiram os americanos em fuga, invadindo o nordeste dos Estados Unidos, atacando e queimando várias cidades, inclusive a capital, Washington, D.C..
Em 1837, houve uma grande rebelião de colonos, tanto no Baixo Canadá quanto no Alto Canadá
Isso levou os britânicos a uma tentativa de assimilar a cultura francesa à britânica — entre outras coisas, o Baixo Canadá e o Alto Canadá foram unidos em uma única província do Canadá.
O receio de uma segunda invasão vinda dos Estados Unidos gerou imensas despesas em relação ao quesito de defesa (mais tropas, armamentos, suprimentos, etc), aliado ao fracasso britânico em assimilar os franceses em 1830, fez com que a ideia da Confederação Canadense (idealizada por colonos canadenses), cujo objetivo era integrar o Canadá e defender melhor a região de um eventual ataque dos Estados Unidos, fosse aprovada pelos britânicos
Em 1 de julho de 1867, as províncias do Canadá, New Brunswick e Nova Escócia tornaram-se uma federação, tornando-se em parte politicamente independentes do Reino Unido — porém, os britânicos ainda teriam controle sobre o Ministério das Relações Exteriores do Canadá por mais 64 anos.
Depois de 1867, lentamente outras colônias britânicas aceitaram unir-se à Confederação Canadense, sendo que a primeira foi a Colúmbia Britânica, e em 1880, os Territórios do Noroeste — cedidos pela Companhia da Baía de Hudson
Posteriormente, os Territórios do Noroeste seriam divididos nas atuais províncias de Alberta, Saskatchewan e Manitoba, além dos territórios de Yukon e Nunavut
O oeste canadense foi totalmente integrado ao território canadense, não sem a geração de conflitos de cunho étnico, social e econômico, dos quais destacam-se a Rebelião de Red River, ocorrida entre 1869 e 1870, e a Rebelião de Saskatchewan, ocorrida em 1885, ambas lideradas pelo líder Métis Louis Riel.
Como o Reino Unido ainda mantinha o controle das relações exteriores do Canadá, ao abrigo da Lei da Confederação, com a declaração britânica de guerra em 1914, o Canadá foi automaticamente envolvido na Primeira Guerra Mundial
Os voluntários enviados para a Frente Ocidental passaram mais tarde a fazer parte do Corpo Canadense
O Corpo desempenhou um papel importante na Batalha de Vimy e em outras grandes batalhas da guerra
Dos cerca de 625 000 que serviram, cerca de 60 000 foram mortos e outros 173 000 ficaram feridos
A Crise de Recrutamento de 1917 eclodiu quando o primeiro-ministro conservador Robert Borden decretou o serviço militar obrigatório com a oposição dos quebequenses que falavam a língua francesa
Em 1919, o Canadá entrou na Liga das Nações, independentemente do Reino Unido e, em 1931, o Estatuto de Westminster, afirmou a independência do Canadá.
A Grande Depressão trouxe dificuldades econômicas para todo o Canadá
Em resposta, o partido político Co-operative Commonwealth Federation (CCF), em Alberta e Saskatchewan, promulgou várias medidas para estabelecer um estado de bem-estar social (sendo Tommy Douglas o pioneiro) em 1940 e 1950
O Canadá declarou guerra à Alemanha de forma independente durante a Segunda Guerra Mundial sob o governo do primeiro-ministro liberal William Lyon Mackenzie King, três dias após o Reino Unido
As primeiras unidades do Exército canadense chegaram na Grã-Bretanha em dezembro de 1939.
As tropas canadenses desempenharam papéis importantes na Batalha de Dieppe em 1942 em França, na invasão aliada da Itália, nos desembarques do Dia D, na Batalha da Normandia e na Batalha do rio Escalda, em 1944
O Canadá deu asilo e proteção à monarquia dos Países Baixos, enquanto este país esteve ocupado, e é creditado pela liderança e contribuição importante para a sua libertação da Alemanha nazista
A economia canadense cresceu fortemente com a fabricação de materiais militares pela indústria para o Canadá, Reino Unido, China e União Soviética
Apesar de uma outra crise de recrutamento em Quebec, o Canadá terminou a guerra com uma das maiores forças armadas do mundo e com a segunda maior economia do planeta.
O Domínio de Terra Nova (hoje Terra Nova e Labrador), na época um equivalente do Canadá e da Austrália como um domínio, uniu-se ao Canadá em 1949
O crescimento do Canadá, combinado com as políticas dos sucessivos governos liberais, levou ao aparecimento de uma nova identidade canadense, marcada pela adoção da atual bandeira, em 1965, a aplicação do bilinguismo oficial (inglês e francês), em 1969, e o multiculturalismo oficial em 1971
Houve também a fundação de programas social-democratas, tais como saúde universal, o Canada Pension Plan e empréstimos estudantis, apesar de os governos provinciais, sobretudo Québec e Alberta, se oporem a muitos destes planos como incursões em suas jurisdições
Finalmente, uma outra série de conferências constitucionais resultou na chamada patriation ("patriamento" ou "patriação") de 1982 — até essa altura a constituição do Canadá era uma lei britânica que só podia ser alterada pelo parlamento britânico
Simultaneamente a esse processo, foi criada a Carta Canadense dos Direitos e das Liberdades
Em 1999, Nunavut tornou-se território terceiro do Canadá, após uma série de negociações com o governo federal.
Ao mesmo tempo, o Quebec passou por profundas mudanças sociais e econômicas através da "Revolução Tranquila", dando origem a um movimento nacionalista e mais radical na província chamado Front de libération du Québec (FLQ), cujas ações culminaram na Crise de Outubro de 1970
Uma década depois, um referendo malsucedido sobre a soberania-associação da província de Quebéc realizou-se em 1980, depois que as tentativas de emenda constitucional fracassaram em 1990
Em um segundo referendo realizado em 1995, a soberania da província foi rejeitada por uma margem de apenas 50,6% para 49,4%
Em 1997, a Suprema Corte decidiu que a secessão unilateral de uma província seria inconstitucional e o Clarity Act foi aprovada pelo parlamento, que define os termos de uma saída negociada da Confederação.
Além das questões sobre a soberania de Quebec, uma série de crises sacudiu a sociedade canadense no final dos anos 1980 e início dos anos 1990
Estes incluem a explosão do Voo Air India 182 em 1985, o maior assassinato em massa da história do Canadá; o Massacre da Escola Politécnica de Montreal em 1989, quando um atirador alvejou várias estudantes universitárias; e a crise Oka, em 1990, o primeiro de uma série de violentos confrontos entre o governo e grupos aborígines do país
O Canadá também participou da Guerra do Golfo, em 1990, como parte de uma força de coalizão liderada pelos Estados Unidos, e foi ativo em várias missões de paz no final dos anos 1990
O país enviou tropas para o Afeganistão em 2001, mas recusou-se a enviar tropas para o Iraque quando os Estados Unidos invadiram esta nação em 2003.
O Canadá ocupa a maior parte do norte da América do Norte, partilhando as fronteiras terrestres com os Estados Unidos Continentais ao sul e com o estado estadunidense do Alasca a noroeste, estendendo-se desde o oceano Atlântico a leste até o oceano Pacífico a oeste, e com o oceano Ártico a norte.
Em área total (incluindo as suas águas), o Canadá é o segundo maior país do mundo, sendo superado apenas pela Rússia
Em área terrestre (área total menos a área de lagos e rios), o Canadá é o quarto maior país do planeta.
Desde 1925, o Canadá reivindica a porção do Ártico entre os meridianos 60° W e 141° W, mas essa reivindicação não é universalmente reconhecida
O assentamento humano mais setentrional do Canadá (e do mundo) é a Canadian Forces Station Alert, na ponta norte da Ilha Ellesmere, latitude 82,5°N, a 817 km do Polo Norte
A maior parte do Ártico canadense é coberto por gelo e permafrost
O Canadá também tem o litoral mais extenso do mundo com 202 080 quilômetros de extensão.
A densidade populacional do país, de 3,3 habitantes por quilômetro quadrado, está entre as mais baixas do mundo
A parte mais densamente povoada do país é o Corredor Cidade de Quebec - Windsor, (situado no sul de Quebec e Sul de Ontário) ao longo dos Grandes Lagos e do rio São Lourenço, no sudeste.
O Canadá tem um litoral muito extenso no seu norte, leste e oeste e, desde o último período glacial consiste em oito regiões florestais distintas, incluindo a vasta floresta boreal sobre o Escudo Canadense
A vastidão e a variedade da geografia, ecologia, vegetação e relevo do Canadá deram origem a uma grande variedade de climas em todo o país.
Por causa de seu grande tamanho, o Canadá tem mais lagos do que qualquer outro país do mundo, contendo grande parte da água doce do planeta
Há também água nas geleiras das Montanhas Rochosas canadenses e nas Montanhas Costeiras.
As temperaturas médias do inverno e do verão em todo o Canadá variam de acordo com a região
O inverno pode ser rigoroso em muitas regiões do país, particularmente no interior e nas pradarias canadenses, que têm um clima continental, onde as temperaturas médias diárias estão perto de -15 °C, mas podem cair abaixo de -40 °C com uma sensação térmica extremamente fria.
No interior, a neve pode cobrir o solo durante quase seis meses do ano (mais no norte)
O litoral da Colúmbia Britânica desfruta de um clima temperado, com um inverno ameno e chuvoso
Nas costas leste e oeste, as temperaturas médias são mais elevadas, geralmente um pouco acima de 20 °C, enquanto entre as costas, a média de temperatura máxima no verão varia de 25 a 30 °C, com calor extremo ocasional em algumas localidades do interior superior a 40 °C.
O Canadá também é geologicamente ativo, com muitos terremotos e vulcões potencialmente ativos, nomeadamente o Complexo Vulcânico Monte Edziza e os montes Meager, Garibaldi e Cayley
A erupção vulcânica do Cone Tseax em 1775 causou um desastre catastrófico, matando 2.000 pessoas do povo Nisga'a, destruindo sua aldeia no vale do rio Nass no norte da Colúmbia Britânica; a erupção produziu um fluxo de lava de 22,5 km, e segundo a lenda do povo Nisga'a, ele bloqueou o fluxo do rio Nass.
Religiões no Canadá em 2011.
O censo canadense de 2016 registrou uma população total de 35 151 728 habitantes, um aumento de cerca de 5% em relação aos números de 2011
Entre 2011 e maio de 2016, a população do Canadá cresceu 1,7 milhão de pessoas, em grande parte pelos imigrantes, representando dois terços do aumento da população
Entre 1990 e 2008, a população aumentou 5,6 milhões, equivalente ao crescimento de 20,4%
Os principais impulsionadores do crescimento da população são a imigração e, em menor medida, o crescimento natural
O Canadá tem a maior taxa de imigração per capita do mundo, impulsionada pela política econômica e pelo reagrupamento familiar, e acolheu um número entre 240 000 e 265 000 novos residentes permanentes em 2010
A maioria da população canadense, bem como os principais partidos políticos, apoiam o nível atual de imigração no país. Em 2014, um total de 260 400 imigrantes foram admitidos no Canadá
E recentemente o governo canadense aceitou entre 280 mil e 305 mil novos residentes permanentes
Os novos imigrantes se instalam principalmente em grandes áreas urbanas do país, como Toronto, Montreal, Vancouver e Calgary
O país também aceita um grande número de refugiados, representando mais de 10% do acolhimento global de refugiados
Cerca de quatro quintos da população do Canadá vive a 150 quilômetros da fronteira com os Estados Unidos
Uma proporção similar vive em áreas urbanas concentradas no Corredor Quebec - Windsor (nomeadamente a Grande Golden Horseshoe, que inclui as áreas de Toronto, Montreal e Ottawa), a Lower Mainland (que consiste na região do entorno de Vancouver) e o Corredor Calgary-Edmonton em Alberta.
A densidade populacional do Canadá é de apenas 3,7 pessoas por quilômetro quadrado, está densidade está entre as mais baixas do mundo
Em comum com muitos outros países desenvolvidos, o Canadá está passando por uma mudança demográfica para uma população mais idosa, com mais aposentados e menos pessoas em idade ativa
Em 2006, a idade média da população era de 39,5 anos
Os resultados censitários também indicam que, apesar do aumento da imigração desde 2001 (que deu ao Canadá uma maior taxa de crescimento da população do que no anterior período intercensitário), o envelhecimento da população canadense não diminuiu durante o período.
O apoio ao pluralismo religioso é uma parte importante da cultura política do Canadá
Segundo o censo de 2011, 67,3% dos canadenses identificam-se como cristãos; destes, os católicos formam o maior grupo (38,7% dos canadenses)
A maior denominação protestante é a Igreja Unida do Canadá (9,5% dos canadenses), seguida pelos anglicanos (6,8%), os batistas (2,4%), luteranos (2%) e outros cristãos (4,4%)
23,9% dos canadenses declaram-se sem religião e os restantes 8,2% são filiados com religiões não cristãs, sendo a maior delas o islamismo (3,2%), seguido pelo hinduísmo (1,5%).

Origens étnicas autodeclaradas no Canadá de acordo com o Censo de 2016.
De acordo com o censo de 2016, a maior origem étnica autodeclarada do país é a canadense (representando 32% da população), seguida de ingleses (18,3%), escoceses (13,9%), franceses (13,6%), irlandeses (13,4%), alemães (9,6%), chineses (5,1%), italianos (4,6%), aborígenes (4,4%), indianos (4,0%) e ucranianos (3,9%)
São reconhecidos 600 povos das Primeiras Nações abrangendo 1.172.790 pessoas
A população indígena do Canadá está crescendo quase o dobro da taxa nacional, 4% da população reivindicava uma identidade indígena em 2006
Outros 22,3% da população pertenciam a uma minoria não indígena visível
Em 2016, os maiores grupos étnicos minoritários visíveis foram asiáticos do sul da Ásia (5,6%), chineses (5,1%) e negros (3,5%)
Entre 2011 e 2016, a população minoritária visível aumentou 18,4%
Em 1961, menos de 2% da população (cerca de 300.000 pessoas) eram membros de grupos minoritários
Os povos indígenas ou aborígenes não são considerados uma minoria visível na Lei de Equidade no Emprego, e essa é a definição que a Statistics Canada também usa
Em 2031, estima-se que um em cada três canadenses poderá pertencer a um grupo minoritário relevante.
As duas línguas oficiais do Canadá são o inglês e o francês
O bilinguismo oficial é definido na Carta Canadense dos Direitos e das Liberdades, o Official Languages Act e o Official Language Regulations; é aplicado pelo Comissário de Línguas Oficiais
O inglês e francês têm o mesmo estatuto em tribunais federais, no Parlamento, e em todas as instituições federais
Os cidadãos têm o direito, sempre que houver demanda suficiente, de receber serviços do governo federal em inglês ou francês, e as minorias que utilizam um dos idiomas oficiais têm garantidas suas próprias escolas em todas as províncias e territórios do país.
O inglês e o francês são as línguas maternas de 59,7% e 23,2% da população, respectivamente, e as línguas mais faladas em casa, 68,3% e 22,3% da população, respectivamente
98,5% dos canadenses falam inglês ou francês (67,5% falam apenas em inglês, 13,3% falam apenas francês e 17,7% falam ambas as línguas)
Comunidades cujas línguas oficiais são o inglês ou o francês, constituem 73,0% e 23,6% da população, respectivamente.
A Carta da Língua Francesa faz do francês a língua oficial em Quebec
Embora mais de 85% dos canadenses francófonos vivam em Quebec, existem populações significativas de francófonos em Ontário, Alberta e no sul de Manitoba
Ontário tem a maior população de língua francesa fora de Quebec
New Brunswick, a única província oficialmente bilíngue, tem uma minoria de acadianos de língua francesa constituindo 33% da população
Há também grupos de acadianos no sudoeste da Nova Escócia, na Ilha Cape Breton e nas partes central e ocidental da Ilha do Príncipe Eduardo.
Outras províncias não têm línguas oficiais, mas o francês é utilizado como língua de instrução, nos tribunais, e para outros serviços do governo, além do inglês
Manitoba, Ontário e Quebec permitem que o inglês e francês sejam falados nas legislaturas provinciais e que leis sejam aprovadas em ambas as línguas
Em Ontário, o francês tem um estatuto legal, mas não é completamente cooficial
Existem 11 grupos de línguas aborígines, compostas por mais de 65 dialetos distintos
Destes, apenas as línguas Cree, Inuktitut e Ojibway têm uma população de falantes fluentes grande o suficiente para serem consideradas viáveis para sobreviverem no longo prazo
Várias línguas indígenas têm estatuto oficial nos Territórios do Noroeste
O inuktitut é a língua maioritária em Nunavut e uma das três línguas oficiais do território.
Mais de seis milhões de pessoas no Canadá indicam uma língua não oficial como sua língua materna
Algumas das mais comuns primeiras línguas não oficiais incluem o chinês (cantonês, principalmente, 1 012 065 falantes como primeira língua), italiano (455 040), alemão (450 570), punjabi (367 505), espanhol (345 345), árabe (261 640) e português (219 275).
O Canadá tem fortes tradições democráticas mantidas por um governo parlamentar dentro do constructo de monarquia constitucional, sendo a monarquia no Canadá a fundação dos poderes executivo, legislativo e judiciário e sua autoridade originária da população canadense
O soberano é a Isabel II do Reino Unido, que também atua como chefe de Estado de outros 15 países da Commonwealth e reside principalmente no Reino Unido
Como tal, o representante da Rainha, o Governador-geral do Canadá (atualmente Julie Payette), cumpre a maior parte dos deveres reais no Canadá.
Contudo, a participação direta das figuras reais e vice-reais, em qualquer destas áreas da governação é limitada; na prática, o seu uso dos poderes executivos é dirigido pelo Gabinete, uma comissão dos ministros da Coroa responsável perante a Câmara dos Comuns eleita, e liderada pelo primeiro-ministro do Canadá (atualmente, Justin Trudeau), o chefe de governo
Para garantir a estabilidade do governo, o governador-geral normalmente nomeia como primeiro-ministro o líder do partido político que tem a maioria relativa na Câmara dos Comuns e o primeiro-ministro escolhe o Gabinete
O cargo de primeiro-ministro é assim uma das instituições mais poderosas do governo, dando início a maior parte da legislação para aprovação parlamentar e selecionando para a nomeação pela Coroa, além dos acima mencionados, o governador-geral, vice-governadores, senadores, juízes federais, chefes de corporações da coroa e agências governamentais
O líder do partido com o segundo maior número de assentos geralmente se torna o líder da oposição da Câmara dos Comuns (atualmente [2010] Michael Ignatieff) e faz parte de um sistema parlamentar contraditório destinado a manter o governo em xeque.
Cada Membro do Parlamento na Câmara dos Comuns é eleito por maioria simples em um distrito eleitoral
As eleições gerais têm de ser convocadas pelo governador-geral, a conselho do primeiro-ministro, no prazo de quatro anos após a eleição anterior, ou podem ser desencadeadas pela derrota do governo em um voto de confiança na Câmara dos Comuns
Os membros do Senado, cujos assentos são distribuídos numa base regional, podem servir até aos 75 anos de idade
Quatro partidos tiveram representantes eleitos para o parlamento federal nas eleições de 2008: o Partido Conservador do Canadá (partido governista), o Partido Liberal do Canadá (a oposição oficial) , o Novo Partido Democrático (NDP) e o Bloco Quebequense
A lista dos partidos históricos com representação eleita é extensa.
A estrutura federal do Canadá, divide as responsabilidades de governo entre o governo federal e os governos das dez províncias
As legislaturas provinciais são unicamerais e operam de maneira parlamentar semelhante à da Câmara dos Comuns
Os três territórios do Canadá também têm legislaturas, mas estas não são soberanas e têm menos responsabilidades constitucionais do que as províncias bem como algumas diferenças estruturais.
A Constituição do Canadá é a lei suprema do país e consiste em um texto escrito e convenções não escritas
A Lei Constitucional de 1867 (conhecida como British North America Act, antes de 1982) afirmava a governação com base no precedente parlamentar "semelhante, em princípio, ao do Reino Unido" e dividia os poderes entre os governos federal e provinciais; o Estatuto de Westminster de 1931 concedeu plena autonomia e a Lei Constitucional de 1982 adicionou a Carta Canadense dos Direitos e das Liberdades, que garante os direitos e liberdades básicos que normalmente não podem ser cancelados por qualquer nível de governo — apesar de uma cláusula permitir que o Parlamento federal e as legislaturas provinciais cancelem certas secções da Carta por um período de cinco anos — e acrescentou uma emenda constitucional.
Embora tenham existido conflitos, as primeiras interações entre os europeus canadenses com as Primeiras Nações e os povos Inuítes foram relativamente pacíficas
Combinado com o desenvolvimento econômico tardio do Canadá em muitas regiões, essa história pacífica permitiu aos povos indígenas canadenses terem uma influência relativamente forte na cultura nacional, preservando a sua identidade própria
A Coroa do Canadá e os povos aborígines do país começaram suas interações durante o período de colonização europeia
Os Tratados numerados, o Indian Act, a Lei Constitucional de 1982 e outras leis foram estabelecidas
Uma série de onze tratados foram assinados entre os aborígines canadenses e os monarcas reinantes do Canadá entre 1871-1921
Esses tratados são acordos com o Governo do Canadá, administrados pela Lei Aborígine Canadense e supervisionados pelo Ministério de Assuntos Indígenas e Desenvolvimento da Região Norte
O papel dos tratados foi reafirmado pela Seção Trinta e Cinco da Lei Constitucional de 1982, que "reconhece e afirma os atuais direitos aborígines e contratuais"
Estes direitos podem incluir provisões sobre o fornecimento de serviços como cuidados de saúde e isenção de impostos
O quadro jurídico e político dentro do qual o Canadá e as Primeiras Nações operam foi adicionalmente formalizado em 2005, com o Acordo Político Primeiras Nações - Coroa Federal, que estabeleceu a cooperação como "a pedra angular de uma parceria entre o Canadá e as Primeiras Nações".
O sistema judiciário do Canadá desempenha um papel importante na interpretação das leis e tem o poder de derrubar leis que violam a Constituição
A Suprema Corte do Canadá é a mais alta corte e o árbitro final, sendo atualmente (2010) presidida por Beverley McLachlin, P.C
(a primeira mulher Chefe de Justiça) desde 2000
Os seus nove membros são nomeados pelo governador-geral sob o conselho do Primeiro-Ministro e do Ministro da Justiça
Todos os juízes dos níveis superior e de apelação são nomeados após consulta com as entidades jurídicas não governamentais
O gabinete federal também nomeia os juízes para tribunais superiores aos níveis provincial e territorial
Cargos do sistema judiciário nos níveis mais baixos provinciais e territoriais são preenchidos por seus respectivos governos.
O direito comum prevalece em toda parte, exceto em Quebec, onde predomina o direito civil
O direito penal é uma responsabilidade exclusivamente federal e é uniforme em todo o Canadá
A aplicação da lei, incluindo tribunais criminais, é uma responsabilidade provincial, mas nas áreas rurais de todos as províncias, exceto Ontário e Quebec, o policiamento é realizado pela Real Polícia Montada do Canadá federal.
O Canadá e os Estados Unidos compartilham a maior fronteira indefesa do mundo, cooperam em campanhas e exercícios militares e são o maior parceiro comercial um do outro
O Canadá, no entanto, tem uma política externa independente, demarcando-se por vezes das posições do seu vizinho, como é o caso da manutenção de relações plenas com Cuba e da recusa em participar oficialmente na Guerra do Iraque
O país também mantém laços históricos com o Reino Unido e com a França e outras ex-colônias britânicas e francesas por meio da associação do Canadá na Comunidade das Nações e na Francofonia
O Canadá é conhecido por ter uma relação forte e positiva com os Países Baixos e o governo holandês tradicionalmente oferece tulipas (símbolo do país europeu) ao Canadá todos os anos, em memória da contribuição canadense para a libertação dos holandeses da Alemanha nazista durante a Segunda Guerra Mundial.
O país emprega atualmente uma força de voluntários profissionais militares de mais de 67 000 soldados regulares e aproximadamente 26 000 em reserva
As Forças Armadas do Canadá (CF) compõem o exército, a marinha e a força aérea
O Canadá é uma nação industrial com um setor de ciência e tecnologia altamente desenvolvido
Desde a Primeira Guerra Mundial, o Canadá produz os seus próprios veículos de combate de infantaria, mísseis anticarros teleguiados e armas de pequeno porte para as suas forças armadas, em especial para o exército.
A forte ligação com o Império Britânico e com a Comunidade das Nações levou a uma participação importante nos esforços militares britânicos na Segunda Guerra Boer, na Primeira Guerra Mundial e na Segunda Guerra Mundial
Desde então, o Canadá tem sido um defensor do multilateralismo, fazendo esforços para resolver problemas globais, em colaboração com outras nações
O Canadá foi um dos membros fundadores das Nações Unidas em 1945 e da OTAN em 1949
Durante a Guerra Fria, o Canadá foi um dos principais contribuintes para as forças da ONU na Guerra da Coreia e fundou o Comando de Defesa Aeroespacial da América do Norte (NORAD), em cooperação com os Estados Unidos, para se defender contra potenciais ataques aéreos por parte da União Soviética.
Durante a Guerra do Suez em 1956, o futuro primeiro-ministro Lester B
Pearson aliviou as tensões ao propor a criação da Força de Paz das Nações Unidas, pela qual ele foi agraciado com o Prêmio Nobel da Paz de 1957
Como esta foi a primeira missão de paz da ONU, Pearson é geralmente creditado como o inventor do conceito
O Canadá tem participado desde então de 50 missões de paz, incluindo todos os esforços de paz da ONU até 1989, e tem mantido forças em missões internacionais em Ruanda, na ex-Iugoslávia, entre outras; Canadá tem por vezes enfrentado controvérsias sobre as suas intervenções em países estrangeiros, como no Caso Somália de 1993
O número de militares canadenses que participam em missões de paz tem diminuído muito nas últimas duas décadas.
O Canadá se tornou membro da Organização dos Estados Americanos (OEA) em 1990 e organizou a Assembleia Geral da OEA em Windsor, Ontário em junho de 2000 e a Terceira Cúpula das Américas em Quebec, em abril de 2001
O país pretende ampliar seus laços com economias do Pacífico através da associação na Cooperação Econômica da Ásia e do Pacífico (Apec).
Desde 2001, o Canadá tem tropas no Afeganistão como parte da força de estabilização dos Estados Unidos e da ONU, através da Força Internacional de Assistência para Segurança comandada pela OTAN
O país comprometeu-se a retirar da província de Candaar em 2011, altura em que terá gasto um total estimado de US$ 11,3 bilhões  na missão
O Canadá e os Estados Unidos continuam a integrar as agências estaduais e provinciais para reforçar a segurança ao longo da Fronteira Canadá-Estados Unidos através da Iniciativa de Viagens do Hemisfério Ocidental.
Em fevereiro de 2007 o Canadá, Itália, Noruega, Reino Unido e Rússia anunciaram seus compromissos de financiamento para lançar um projeto de US$ 1,5 bilhões  para ajudar a desenvolver vacinas que eles disseram que poderia salvar milhões de vidas nos países pobres e chamou outras para se juntarem ao projeto
Em agosto de 2007, a soberania canadense nas águas do Ártico foi contestada depois de uma expedição subaquática russa ao Polo Norte; o Canadá tem considerado a área como parte do território soberano desde 1925.
O Canadá é uma federação composta por dez províncias e três territórios
Por sua vez, estes são agrupados em regiões: Oeste do Canadá, Centro do Canadá, Províncias atlânticas do Canadá e o Norte do Canadá (esta última composta por três territórios: Yukon, Territórios do Noroeste e Nunavut)
O Leste do Canadá refere-se ao Centro do Canadá e ao Canadá Atlântico juntos
As províncias têm mais autonomia do que os territórios e são responsáveis pela maioria dos programas sociais do Canadá (como saúde, educação e assistência social) e, juntas, arrecadam mais receita que o governo federal, uma estrutura quase única entre as federações do mundo
O governo federal faz pagamentos de equalização para garantir que padrões razoavelmente uniformes dos serviços e impostos sejam mantidos entre as províncias mais ricas e menos ricas.

O Canadá é uma das nações mais ricas do mundo, com um elevado rendimento per capita, e é membro da Organização para a Cooperação e Desenvolvimento Econômico (OCDE) e do G8
É uma das dez maiores nações comerciais do mundo
O Canadá é uma economia mista, sendo classificado acima dos Estados Unidos no índice da Heritage Foundation de liberdade econômica e mais acima da maioria das nações da Europa ocidental
Os maiores importadores estrangeiros de produtos canadenses são os Estados Unidos, o Reino Unido e o Japão
Em 2008, as mercadorias importadas pelo Canadá valiam mais de 442,9 bilhões  de dólares, dos quais 280,8 bilhões dólares dos Estados Unidos, 11,7 bilhões de dólares do Japão e US$ 11,3 bilhões do Reino Unido
O déficit comercial do país em 2009 totalizou C$ 4,8 bilhões, comparado com um superávit de C$ 46,9 bilhões em 2008.
Em outubro de 2009, a taxa de desemprego nacional do Canadá foi de 8,6%
As taxas de desemprego provinciais variam de 5,8% em Manitoba até 17% em Terra Nova e Labrador
A dívida federal do Canadá está estimada em 566,7 bilhões de dólares em 2010-11, superior aos 463,7 de bilhões dólares no período 2008-09
A dívida externa líquida do Canadá aumentou de US$ 40,6 bilhões para US$ 193,8 bilhões no primeiro trimestre de 2010
O déficit conjunto, federal e provinciais, no ano fiscal de 2009-10 alcançou US$ 100 bilhões  e prevê-se que o déficit federal seja de C$ 49,2 bilhões em 2010-11.
No século passado, o crescimento da manufatura, mineração e do setor de serviços transformou o país de uma economia basicamente rural para uma mais industrial e urbana
Como outros países desenvolvidos, a economia canadense é dominada por serviços, que empregam cerca de três quartos dos canadenses
O Canadá é incomum entre os países desenvolvidos devido à importância do setor primário em sua economia, sendo as indústrias madeireiras e de petróleo duas das mais importantes do país.
O Canadá é um dos poucos países desenvolvidos que são exportadores líquidos de energia
A costa atlântica do Canadá e a província de Alberta possuem vastas jazidas de gás natural e petróleo em alto-mar
A imensa reserva das areias betuminosas do Athabasca dá ao Canadá a segunda maior reserva de petróleo do mundo, a seguir à da Arábia Saudita.
O Canadá é um dos maiores fornecedores mundiais de produtos agrícolas; as pradarias canadenses são um dos mais importantes produtores de trigo, canola e outros cereais
O Canadá é o maior produtor mundial de zinco e urânio e é uma fonte global de muitos outros recursos naturais, como ouro, níquel, alumínio e chumbo
Muitas cidades no norte do Canadá, onde a agricultura é difícil, são sustentáveis por causa das minas próximas ou pelas suas fontes de madeira
O Canadá também tem um setor industrial bastante grande centrado no sul de Ontário e de Quebec, com os setores automóvel e aeronáutico representando indústrias particularmente importantes.
A integração econômica com os Estados Unidos tem aumentado significativamente desde a Segunda Guerra Mundial
Isto tem atraído a atenção dos nacionalistas do Canadá, que estão preocupados com a autonomia cultural e econômica do país na era da globalização, visto que as mercadorias e produtos de mídia estadunidenses se tornaram onipresentes
O Acordo de Comércio de Produtos Automotivos de 1965 abriu as fronteiras ao comércio na indústria automobilística entre os Estados Unidos e o Canadá
Na década de 1970, as preocupações com a autossuficiência energética e as participações estrangeiras nos setores de fabricação levaram o governo liberal do então primeiro-ministro Pierre Trudeau a decretar o Programa Nacional de Energia (NEP) e a Agência de Revisão do Investimento Estrangeiro (FIRA).
Em 1980, o governo do primeiro-ministro Brian Mulroney aboliu a NEP e mudou o nome da FIRA para "Investment Canada", com o intuito de encorajar o investimento estrangeiro
O Tratado de livre comércio entre Canadá e Estados Unidos (TLC) de 1988, eliminou as tarifas aduaneiras entre os dois países, enquanto o Tratado Norte-Americano de Livre Comércio (NAFTA) ampliou a zona de livre comércio para incluir o México na década de 1990
Em meados da década de 1990, sob o governo liberal de Jean Chrétien, o país começou a alcançar excedentes orçamentais anuais e diminuiu sua dívida nacional
Em 2008, a crise financeira global causou uma recessão, o que poderá levar a taxa de desemprego do país atingir os 10%.
De acordo com o relatório de 2012 da Organização para a Cooperação e Desenvolvimento Econômico (OCDE), o Canadá é um dos países mais educados do mundo
O país ocupa o primeiro lugar mundial no número de adultos com educação superior, com cerca de 51% da população adulta tendo obtido pelo menos uma graduação universitária ou um diploma universitário
O Canadá usa cerca de 5,3% do seu PIB em educação e também investe fortemente no ensino superior (mais de 20.000 dólares americanos por estudante)
Em 2014, 89% dos adultos com idades entre 25 e 64 anos tinham o equivalente a um diploma do ensino médio, em comparação com uma média de 75%, dos países da OCDE.
Desde a adoção da seção 23 da Lei Constitucional de 1982, a educação em inglês e francês está disponível na maioria dos lugares do Canadá
As províncias e territórios canadenses são responsáveis por seus respectivos sistemas educacionais
Cada sistema é similar, embora reflita a cultura, história e geografia regionais
Os limites da escolaridade obrigatória, entrada até os 5-7 anos e pelo menos até aos 16-18 anos, contribuem com uma taxa de alfabetização de 99%
O ensino superior também é administrado pelos governos provinciais e territoriais, que fornecem a maior parte do financiamento, o governo federal administra bolsas de pesquisa adicionais, empréstimos estudantis e bolsas
Em 2002, 43% dos canadenses com idade entre 25-64 possuía educação superior, e para aqueles com idade entre 25 a 34, a taxa de formação superior era de 51%
O Programa Internacional de Avaliação de Alunos indica que os estudantes canadenses possuem um desempenho bem acima da média da OCDE, particularmente em matemática, ciências e leitura.
O Canadá é uma nação industrial com um setor de ciência e tecnologia altamente desenvolvido
Cerca de 1,88% do PIB do Canadá é investido em pesquisa e desenvolvimento (P&D)
O país tem dezoito laureados com prêmios Nobel de física, química e medicina e é o 12º país do mundo em termos de acesso à internet, com 28 milhões de usuários, 84,3% da população total.
A Defence Research and Development Canada (DRDC) é uma agência do Departamento de Defesa Nacional, cujo objetivo é responder às necessidades científicas e tecnológicas das Forças Canadenses
Ao longo dos anos, a DRDC tem sido responsável por inúmeras inovações e invenções de aplicação prática tanto no mundo civil quanto no mundo militar
Estes incluem o CADPAT, traje anti-G, CRV7, laser de dióxido de carbono e o gravador de dados de voo
A DRDC também contribui no desenvolvimento do mais avançado radar de varredura eletrônica ativa do mundo, como parte de um esforço internacional, envolvendo o Canadá, a Alemanha e os Países Baixos.
A Agência Espacial Canadense conduz pesquisas espaciais, planetárias e de aviação, assim como desenvolve foguetes e satélites
Em 1984, Marc Garneau tornou-se o primeiro astronauta do Canadá, servindo como especialista de carga da STS-41-G
O Canadá foi classificado em terceiro lugar entre os 20 países de topo nas ciências espaciais
O Canadá é um dos países participantes na Estação Espacial Internacional e um dos pioneiros do mundo em robótica espacial com o Canadarm, Canadarm2 e Dextre
Desde a década de 1960, as Indústrias Aeroespaciais do Canadá projetaram e construíram 10 satélites, incluindo o RADARSAT-1, o RADARSAT-2 e o MOST
O Canadá também produziu um dos mais bem sucedidos foguetes de sondagem, o Black Brant; mais de 1000 foram lançados desde o início da sua produção em 1961
Universidades de todo o Canadá estão trabalhando no primeiro aterrissador do país: o Northern Light, projetado para procurar vida em Marte e pesquisar o ambiente de radiação eletromagnética e as propriedades da atmosfera do planeta vermelho
Se o Northern Light for bem-sucedido, o Canadá será o terceiro país a pousar em outro planeta.
O Canadá é um país desenvolvido, cuja economia inclui a extração e exportação de matérias-primas de seu vasto território
Devido a isso, o país tem um sistema de transporte que inclui mais de 1 400 000 km de estradas, 10 aeroportos internacionais principais, 300 aeroportos menores, 72 093 km de vias férreas operacionais e mais de 300 portos comerciais e portos que dão acesso aos oceanos Pacífico, Atlântico e Ártico, bem como aos Grandes Lagos e ao canal de São Lourenço
Em 2005, o setor de transporte respondia por 4,2% do PIB do Canadá, em comparação com os 3,7% das indústrias de mineração, petróleo e extração de gás natural.
Em 2007, o Canadá tinha um total de 72 212 km de ferrovias de cargas e passageiros
As receitas totais de serviços de transporte ferroviário em 2006 foram de US$ 10,4 bilhões, dos quais apenas 2,8% foram provenientes de serviços de passageiros
A Canadian National Railway e a Canadian Pacific Railway são as duas principais companhias de frete ferroviário do país, cada uma tendo operações em toda a América do Norte
Em 2007, 357 milhões de toneladas/quilômetro de mercadorias e 4,33 milhões de passageiros foram transportados por via férrea
34 281 pessoas foram empregadas pela indústria ferroviária no mesmo ano.
Há um total de 1 042 300 km de estradas no país, dos quais 413 600 km são pavimentadas, incluindo 17 000 km de vias expressas
Em 2006, 626 700 km não estavam pavimentadas
O transporte rodoviário gerou 35% do PIB total do transporte, contra 25% para o transporte ferroviário, aquático e aéreo combinados, sendo as estradas o principal meio de transporte de passageiros e mercadorias do país
A Rodovia Trans-Canadá atravessa todo o país e é uma das mais longas rodovias do mundo, com 8 030 km de extensão
O segmento da Via Expressa Macdonald-Cartier que passa por Toronto é o trecho rodoviário mais movimentado da América do Norte, e um dos mais amplos e movimentados do mundo.
O transporte aéreo compunha 9% do PIB do setor de transportes canadense em 2005
A maior companhia aérea do país é a Air Canada, que teve 34 milhões de clientes em 2006 e, em abril de 2010, operava com 363 aviões
A indústria aérea canadense viu uma alteração significativa após a assinatura do acordo de céus abertos entre EUA-Canadá, em 1995, quando o mercado tornou-se menos regulado e mais competitivo
Dos mais de 1 700 aeródromos, aeroportos certificados, heliportos e bases de hidroaviões registrados, 26 são especialmente designados pelo Sistema Nacional de Aeroportos do Canadá: incluem todos os aeroportos que lidam com 200 mil ou mais passageiros a cada ano, bem como o principal aeroporto que serve cada capital federal, provincial e territorial
Os três principais aeroportos do país por número de passageiros são o Aeroporto Internacional Toronto Pearson (sendo também o maior do país), o Aeroporto Internacional de Vancouver e o Aeroporto Internacional Pierre Elliott Trudeau  em Montreal.
Em 2005, 139,2 milhões de toneladas de carga foram carregadas e descarregadas nos portos canadenses
O Porto de Vancouver é o porto mais movimentado do Canadá, tendo passado por ali 68 milhões de toneladas ou 15% do total do transporte doméstico e internacional do Canadá em 2003.
Cerca de 100 jornais diários em inglês e dez jornais diários em francês são impressos no Canadá
O jornal que possui a maior circulação do país é o Toronto Star, publicado em língua inglesa
O jornal francófono de maior circulação no Canadá (e também do mundo, fora da França) é o Le Journal de Montréal
Cerca de 1 500 periódicos são impressos e publicados no Canadá
Os periódicos de maior circulação do país são Maclean's e Chatelaine.
A mídia e a indústria do entretenimento estadunidenses são populares, se não dominantes, no Canadá anglófono; inversamente, muitos produtos culturais canadenses e artistas são bem sucedidos nos Estados Unidos e no mundo
Muitos produtos culturais são comercializados em direção a um unificado mercado "norte-americano" ou global
A criação e a preservação da cultura distintamente canadense são apoiadas por programas do governo federal do país, através de leis e instituições como a Canadian Broadcasting Corporation (CBC), o National Film Board of Canada e da Canadian Radio-television and Telecommunications Commission.
A cultura canadense tem sido historicamente influenciada por culturas e tradições de britânicos, franceses e indígenas
Existem diferentes culturas, línguas, arte e música aborígines por todo o Canadá
Muitas palavras, invenções e jogos norte-americanos indígenas tornaram-se parte da linguagem cotidiana do Canadá
A canoa, raquetes de neve, tobogã, lacrosse, cabo de guerra, xarope de ácer e o tabaco são exemplos de produtos, invenções e jogos
Algumas das palavras da língua inglesa de origem indígena incluem barbecue, caribou, chipmunk, woodchuck, hammock, skunk, mahogany, hurricane e moose
Várias áreas, cidades e rios das Américas têm nomes de origem indígena
O nome da província de Saskatchewan deriva do nome em língua cree do rio Saskatchewan, "Kisiskatchewani Sipi"
O nome da capital do Canadá, Ottawa, vem do termo "adawe", que em língua algonquina significa "negociar"
O Dia Nacional dos Aborígines reconhece as culturas e as contribuições dos povos aborígines do Canadá.
A cultura do país foi fortemente influenciada pela imigração vinda de todo o mundo
Muitos canadenses valorizam o multiculturalismo e veem o Canadá como sendo inerentemente multicultural
No entanto, a cultura do país tem sido fortemente influenciada pela cultura estadunidense por causa da proximidade e da alta taxa de migração entre os dois países
A grande maioria dos imigrantes de língua inglesa que veio para o Canadá entre 1755 e 1815 eram estadunidenses das Treze Colônias; durante e imediatamente após a Guerra da Independência dos Estados Unidos, 46 000 estadunidenses leais à coroa britânica vieram para o Canadá
Entre 1785 e 1812, mais estadunidenses emigraram para o Canadá, em resposta às promessas de terra.
As artes visuais canadenses têm sido dominadas por Tom Thomson - o mais famoso pintor do Canadá - e pelo Grupo dos Sete
A curta carreira de Thomson pintando paisagens canadenses durou apenas uma década até sua morte em 1917 aos 39 anos
O Grupo dos Sete era composto por pintores com um foco nacionalista e idealista, que exibiram suas obras distintas pela primeira vez em maio de 1920
Embora referido como tendo sete membros, cinco artistas - Lawren Harris, A
Y
Jackson, Arthur Lismer, J
E
H
MacDonald e Frederick Varley - foram responsáveis por articular as ideias do grupo
Eles juntaram-se brevemente com Frank Johnston e com o artista comercial Franklin Carmichael
A
J
Casson passou a fazer parte do Grupo em 1926
Outra associada do grupo foi a proeminente artista canadense Emily Carr, conhecida por suas paisagens e retratos dos povos indígenas da costa noroeste do Pacífico.
O Canadá tem uma infraestrutura e uma indústria de música desenvolvida, com a radiodifusão regulada pela Canadian Radio-television and Telecommunications Commission
A indústria musical canadense tem produzido compositores, músicos e conjuntos renomados internacionalmente, tais como Guy Lombardo, Murray Adaskin, Rush, Joni Mitchell e Neil Young
Vencedores canadenses de vários Grammy Awards incluem Michael Bublé, Celine Dion, K
D
Lang, Sarah McLachlan, Alanis Morissette e Shania Twain
Outros cantores famosos são Avril Lavigne, Justin Bieber e a luso-canadense Nelly Furtado.A Academia Canadense de Artes e Ciências administra os prêmios da indústria fonográfica do Canadá, como os Juno Awards, que tiveram início em 1970 e são considerados a principal premiação musical do país.
O hino nacional do Canadá, "O Canada", foi adotado em 1980, originalmente encomendado pelo vice-governador de Quebec, o Sr
Théodore Robitaille, para a cerimônia do Feriado Nacional de Quebec de 1880
Calixa Lavallée escreveu a música, que foi uma adaptação de um poema patriótico composto pelo poeta e juiz Sir Adolphe-Basile Routhier
O texto foi escrito originalmente apenas em francês, antes de ter sido traduzido para o inglês em 1906.
Os símbolos nacionais do Canadá são influenciados por fatores naturais, históricos e aborígines
O uso da folha de bordo como um símbolo do Canadá data do início do século XVIII
A folha de bordo é representada em bandeiras atuais e anteriores do Canadá, na moeda de um centavo, e no Brasão de Armas
Outros símbolos nacionais proeminentes incluem o castor, ganso-do-canadá, mobelha-grande, a Coroa, a Real Polícia Montada do Canadá, e, mais recentemente, o totem e o Inukshuk.
Os esportes oficiais nacionais do Canadá são o hóquei no gelo no inverno e lacrosse no verão
O hóquei é um passatempo nacional e o esporte mais popular no país
Também é o esporte mais jogado pelos canadenses, com 1,65 milhões de participantes em 2004
As seis maiores regiões metropolitanas do Canadá, Toronto, Montreal, Vancouver, Ottawa, Calgary e Edmonton têm franquias da National Hockey League (NHL), e há mais jogadores do Canadá na NHL que de todos os outros países combinados
Outros esportes populares incluem o curling e o futebol canadense, sendo este último jogado profissionalmente na Canadian Football League (CFL).Golfe, baseball, esqui, futebol, voleibol e basquetebol são amplamente jogados em níveis juvenis e amadores, mas ligas profissionais e franquias não estão generalizadas.
O Canadá tem sediado vários grandes eventos esportivos internacionais, incluindo os Jogos Olímpicos de Verão de 1976 em Montreal, os Jogos Olímpicos de Inverno de 1988 em Calgary e o Campeonato Mundial de Futebol Sub-20 de 2007
O Canadá também foi o país anfitrião dos Jogos Olímpicos de Inverno de 2010 em Vancouver e Whistler, na Colúmbia Britânica, e dos Jogos Pan-Americanos de 2015 em Toronto.
História · Geografia · Política · Forças Armadas · Demografia · Economia · Educação · Transportes · Telecomunicações · Cultura · Turismo · Imagens
Área · Crescimento · Despesas anuais · Etimologia · Expectativa de vida · IDH · Nível educacional · PIB · Pobreza · População · Violência
Alberta · Colúmbia Britânica · Saskatchewan · Manitoba · Ontário · Quebec · New Brunswick · Ilha do Príncipe Eduardo · Nova Escócia · Terra Nova e Labrador
Yukon · Territórios do Noroeste · Nunavut
Províncias: Victoria · Edmonton · Regina · Winnipeg · Toronto · Quebec · Fredericton · Charlottetown · Halifax · St
John's
Territórios: Whitehorse · Yellowknife · Iqaluit
Calgary · Vancouver · Saskatoon · Montreal · Moncton
História · Geografia · Política · Forças Armadas · Demografia · Economia · Educação · Transportes · Telecomunicações · Cultura · Turismo · Imagens
Área · Crescimento · Despesas anuais · Etimologia · Expectativa de vida · IDH · Nível educacional · PIB · Pobreza · População · Violência
Alberta · Colúmbia Britânica · Saskatchewan · Manitoba · Ontário · Quebec · New Brunswick · Ilha do Príncipe Eduardo · Nova Escócia · Terra Nova e Labrador
Yukon · Territórios do Noroeste · Nunavut
Províncias: Victoria · Edmonton · Regina · Winnipeg · Toronto · Quebec · Fredericton · Charlottetown · Halifax · St
John's
Territórios: Whitehorse · Yellowknife · Iqaluit
Calgary · Vancouver · Saskatoon · Montreal · Moncton
 Antígua e Barbuda ·  Austrália ·  Bahamas ·  Barbados ·  Belize ·  Canadá ·  Granada ·  Ilhas Salomão ·  Jamaica ·  Reino Unido ·  Nova Zelândia ·  Papua-Nova Guiné ·  Santa Lúcia ·  São Cristóvão e Nevis ·  São Vicente e Granadinas ·  Tuvalu
África do Sul · Antígua e Barbuda · Austrália · Bahamas · Bangladesh · Barbados · Belize · Botswana · Brunei · Camarões · Canadá · Chipre · Dominica · Fiji · Gana · Granada · Guiana · Índia · Ilhas Salomão · Jamaica · Kiribati · Lesoto · Malásia · Malawi · Malta · Maurícias · Moçambique · Namíbia · Nauru · Nigéria · Nova Zelândia · Papua Nova Guiné · Paquistão · Quénia · Reino Unido · Ruanda · Samoa · Santa Lúcia · São Cristóvão e Nevis · São Vicente e Granadinas · Serra Leoa · Seychelles · Singapura · Sri Lanka · Suazilândia · Tanzânia · Tonga · Trinidade e Tobago · Tuvalu · Uganda · Vanuatu · Zâmbia
Ilhas Ashmore e Cartier · Ilha Christmas · Ilhas Cocos (Keeling) · Ilha Heard e Ilhas McDonald · Ilhas do Mar de Coral · Ilha de Norfolk · Território Antárctico Australiano
Dependência de Ross · Ilhas Cook · Niue · Tokelau
Akrotiri e Dhekelia · Anguilla · Bermudas · Gibraltar · Guernsey · Ilha de Man · Ilhas Caimão · Ilhas Geórgia do Sul e Sandwich do Sul · Ilhas Virgens Britânicas · Jersey · Malvinas · Montserrat · Pitcairn · Santa Helena (inclui a ilha de Ascensão e a Ilha de Tristão da Cunha) · Território Antártico Britânico · Território Britânico do Oceano Índico · Turks e Caicos
Frederick Grant Banting (Alliston, 14 de novembro de 1891 — Terra Nova, 21 de fevereiro de 1941) foi um médico canadense.
Estudou na Universidade de Toronto e foi médico militar durante a Primeira Guerra Mundial
Posteriormente foi ajudante de fisiologia na Universidade do Ontário Ocidental e a partir de 1921 professor na Universidade de Toronto.
Recebeu o Nobel de Fisiologia ou Medicina de 1923
É considerado um dos descobridores da insulina.
Em 1930, o Parlamento do Canadá concedeu-lhe uma ajuda para a instalação de um laboratório de investigação (o Instituto Banting) e a sua universidade criou uma cátedra com o seu nome
Aí trabalhou em várias linhas: as suas últimas investigações no Instituto debruçavam-se sobre o cancro, o córtex adrenal e a silicose.
Durante a Segunda Guerra Mundial foi major do Corpo Médico e chefe da secção médica do Conselho Nacional de Investigação do Canadá.
Morreu devido aos ferimentos sofridos em um acidente de aviação na Terra Nova.


1901: Emil Behring • 1902: Ronald Ross • 1903: Niels Finsen • 1904: Ivan Pavlov • 1905: Robert Koch • 1906: Camillo Golgi e Santiago Ramón y Cajal • 1907: Alphonse Laveran • 1908: Ilya Mechnikov e Paul Ehrlich • 1909: Emil Kocher • 1910: Albrecht Kossel • 1911: Allvar Gullstrand • 1912: Alexis Carrel • 1913: Charles Robert Richet • 1914: Robert Bárány • 1919: Jules Bordet • 1920: August Krogh • 1922: Archibald Hill e Otto Meyerhof • 1923: Frederick Banting e John Macleod • 1924: Willem Einthoven
Lista completa | (1901-1925) • (1926-1950) • (1951-1975) • (1976-2000) • (2001-2025)
Charles Herbert Best, CBE (1899 — 1978) foi um fisiologista canadense
Foi figura de destaque nas pesquisas sobre sangue e diabetes, assistente de Frederick Grant Banting na descoberta da insulina, em 1921.
1921 (MCMXXI, na numeração romana) foi um ano comum do século XX do actual calendário gregoriano, da Era de Cristo, e a sua letra dominical foi B (52 semanas), teve início a um sábado e terminou também a um sábado.
Ano comum com início ao sábado



Ver Artigos temáticos do ano
Insulina é uma hormona responsável pela redução da glicémia (taxa de glicose no sangue), ao promover a entrada de glicose nas células
Esta é também essencial no metabolismo de sacáridos (hidrato de carbono), na síntese de proteínas e no armazenamento de lípidos (gorduras).
É produzida nas células beta das ilhotas de Langerhans, do pâncreas endócrino
Atua numa grande parte das células do organismo, como nas células presentes no fígado, em músculos e no tecido adiposo, contudo não atua em células específicas cujos transportadores membranares não são sensíveis à insulina, como é o caso das células nervosas.
Quando a produção de insulina é deficiente, a glicose acumula-se no sangue e na urina, destruindo as células por falta de abastecimento: diabetes mellitus
Para doentes nessa condição, a insulina é providenciada através de injeções, ou bombas de insulina
Recentemente foi aprovado o uso de insulina inalada
Porém, ainda existem controvérsias acerca do uso do produto comercializado pela Pfizer
A agência de saúde britânica não recomenda o uso.
A insulina é um polipéptido de estrutura química plenamente conhecida, e pode ser sintetizada a partir de diversos animais
Mais recentemente, surgiram os medicamentos análogos de insulina, que constituem moléculas que, não sendo insulina, possuem as mesmas características químicas e portanto reactivas, são moléculas "de insulina" modificadas em laboratório.
O controlo da produção de insulina pelo corpo é um sistema muito complexo.


Em 1869, Paul Langerhans, um estudante de medicina em Berlim, estudava a estrutura do pâncreas através de um microscópio quando reparou em células, antes desconhecidas, espalhadas pelo tecido exócrino
A função da "pequena porção de células", mais tarde denominada como ilhotas de Langerhans, era desconhecida, mas Edouard Laguesse posteriormente sugeriu que tais células poderiam produzir algum tipo de secreção que participasse no processo de digestão.
Em 1889, o médico germano-polaco Oscar Minkowski em colaboração com Joseph von Mehring removeu o pâncreas de um cão saudável para demonstrar o papel do órgão na digestão de alimentos
Vários dias após a remoção do pâncreas, o guarda do cão reparou que existiam muitas moscas a alimentarem-se da urina do animal
Verificou-se com o teste da urina do cão que havia açúcar nesta, o que demonstrou pela primeira vez a relação entre o pâncreas e a diabetes
Em 1901, outro passo importante foi alcançado por Eugene Opie, quando este estabeleceu claramente a ligação entre as ilhotas de Langerhans e a diabetes: "Diabetes mellitus..
é causada pela destruição das ilhotas de Langerhans e ocorre apenas quando tais células são em parte ou totalmente destruídas".
Durante as duas décadas seguintes foram feitas várias tentativas de isolamento da secreção das ilhotas como um tratamento potencial de diabetes
Em 1906, Georg Ludwig Zuelzer foi parcialmente feliz no tratamento de cães com extrato pancreático, mas teve que interromper o seu trabalho
Entre 1911 e 1912, E
L
Scott da Universidade de Chicago usou extratos pancreáticos aquosos e notou uma leve diminuição da glicosúria, mas não conseguiu convencer o director da instituição com os resultados, e a pesquisa teve de ser encerrada
Israel Kleiner demonstrou efeitos semelhantes na Rockfeller University em 1919, mas o seu trabalho foi interrompido pela Primeira Guerra Mundial
Nicolae Paulescu, um professor de fisiologia da Escola Romena de Medicina, publicou um trabalho parecido em 1921 realizado na França e patenteado na Romênia, e discute-se desde então se Paulescu não tenha sido o verdadeiro descobridor da insulina.
Entretanto, o comitê do Prêmio Nobel em 1923 deu crédito pela extração prática da insulina a uma equipa da Universidade de Toronto
Em outubro de 1920, Frederick Banting lia um dos artigos de Minkowski e concluiu que Minkowski estava a estudar as secreções digestivas originalmente, e por isso não se conseguia extrair a insulina com sucesso
Ele redigiu uma nota para si mesmo: "Ligar duto pancreático do cão
Manter cães vivos até que acinos se degenerem, sobrando ilhotas
Tentar isolar secreção interna delas e aliviar glicosúria".
Ele viajou a Toronto para se encontrar com J
J
R
Macleod, que não se impressionou plenamente com a ideia
De qualquer forma, Macleod deixou à disposição de Banting um laboratório da universidade, e um assistente, Charles Best, e dez cães enquanto saía de férias no verão de 1921
O método de Banting e Best era amarrar uma ligadura ao redor do duto pancreático dos cães e, várias semanas depois, examinar que as células digestivas pancreáticas tinham morrido e sido absorvidas pelo sistema imunológico, deixando milhares de ilhotas
Isolava-se a proteína dessas ilhotas para produzir o que vinham chamando de isletina
Banting e Best mantiveram um cão pancreatectomizado vivo durante todo o verão.
Macleod viu o valor da pesquisa no seu regresso da Europa, mas pediu uma contraprova para saber se o método realmente funcionava
Várias semanas depois ficou claro que o segundo ensaio tinha sido um sucesso, e assim Macleod ajudou na publicação dos resultados em novembro daquele ano
Porém, precisavam de seis semanas para extrair a isletina, o que tornava o ensaio dramaticamente demoroso
Banting sugeriu que tentassem usar pâncreas de feto de bezerro, que ainda não teria desenvolvido glândulas digestivas, e ficou alivado pelo sucesso da empreitada.
Com a solução para a fonte de isletina, faltava agora purificar a proteína
Em dezembro de 1921, Macleod convidou o brilhante bioquímico James Collip para ajudar na tarefa, e num mês prepararam-se para um teste.
Em 11 de janeiro de 1922, Leonard Thompson, um diabético de quatorze anos, recebeu a primeira injeção de insulina
Infelizmente, o extrato estava tão impuro que ele acabou sofrendo uma reação alérgica severa, e injeções adicionais foram canceladas
Durante os doze dias seguintes, Collip trabalhou dia e noite para melhorar o extrato, e uma segunda dose foi injetada no dia 23
Desta vez foi um sucesso, não apenas em não apresentar efeitos colaterais, mas também por eliminar completamente os sintomas de diabetes
Entretanto, Banting e Best não se davam bem com Collip, porque aparentemente viam nele um intruso, e então Collip abandonou-os.
Durante a primavera de 1922, Best conseguiu melhorar as técnicas de preparo a ponto de poder extrair grandes quantidades de insulina, embora o extrato ainda permanecesse impuro
Contudo, receberam uma oferta de ajuda de Eli Lilly logo após as suas publicações em 1921, e aceitaram-na em abril
Em novembro, Lilly conseguiu a façanha de produzir grandes quantidades de insulina bastante pura
Depois disso, a insulina foi lançada no mercado.
Por esta descoberta marcante, Macleod e Banting foram premiados com o Prêmio Nobel em Fisiologia em 1923
Banting, aparentemente insultado porque Best não fora mencionado, dividiu seu prêmio com ele, e Macleod imediatamente dividiu o seu com Collip
A patente da insulina foi vendida à Universidade de Toronto por um dólar.
A sequência exata de aminoácidos contida na molécula de insulina, a chamada estrutura primária, foi determinada pelo biólogo britânico Frederick Sanger
Foi a primeira vez que a estrutura de uma proteína fora completamente determinada
Por isso, ele recebeu o Prêmio Nobel de Química em 1958
Em 1967, após décadas de trabalho, Dorothy Crowfoot Hodgkin determinou a conformação espacial da molécula mediante estudos de difração de raios X
Ela também recebeu um Prêmio Nobel.
A insulina é sintetizada nos humanos e em outros mamíferos dentro das células-beta das ilhotas de Langerhans, no pâncreas
Um a três milhões de ilhotas de Langerhans formam a parte endócrina do pâncreas, que é principalmente uma glândula exócrina
A parte endócrina totaliza apenas 2% da massa total do órgão
Dentro das ilhotas de Langerhans, as células-beta constituem 60-80% do todo.
A insulina é sintetizada a partir da molécula precursora proinsulina pela ação de enzimas proteolíticas conhecidas como prohormônio convertases (PC1 e PC2)
A insulina ativa tem 51 aminoácidos e é um polipeptídeo
A insulina bovina difere da humana em três resíduos de aminoácidos enquanto que a suína, em um resíduo
A insulina de peixes também é muito próxima à humana
Em humanos, a insulina tem um peso molecular de 5808
Ela é formada por duas cadeias de polipeptídeos ligadas por duas pontes dissulfídicas (veja a figura), com uma ligação dissulfídica adicional na cadeia A (não mostrada)
A cadeia A consiste de 21, e a cadeia B, de 30 aminoácidos
A insulina é produzida como uma molécula de prohormônio - proinsulina - que é mais tarde transformada, por ação proteolítica, em hormônio ativo.
A parte restante da molécula de proinsulina é chamada de peptídeo C
Este polipeptídeo é liberado no sangue em quantidades iguais à da insulina
Como insulinas exógenas não contêm peptídeo C, o nível em plasma desse peptídeo é um bom indicador de produção endógena de insulina
Recentemente, descobriu-se que esse peptídeo C também possui atividade biológica, que está aparentemente restrita a um efeito na camada muscular das artérias.
Pacientes com diabetes mellitus tipo 1 dependem de Insulinoterapia, ou seja da administração de insulina exógena (geralmente por via subcutânea), para a sua sobrevivência, pois a hormona não é produzida por seu organismo
Também certos pacientes com diabetes tipo 2 podem eventualmente necessitar de insulina se outras medicações não conseguirem controlar os níveis de glicose no sangue de forma adequada.
Inicialmente a insulina utilizada por diabéticos era extraída do pâncreas de bois e porcos, por ser parecida com a humana, mas esta insulina podia acarretar problemas, como reações alérgicas, ou não ser eficaz em alguns pacientes
Atualmente a insulina é produzida através da técnica de ADN recombinante, primeiro produto da moderna biotecnologia a ser comercializado mundialmente
A técnica surgiu no Brasil em 1990, em um projeto desenvolvido por Marcos Luís Mares Guia, bioquímicos da UFMG e pesquisadores da Biobrás e da Universidade de Brasília
A técnica consiste em introduzir na bactéria Escherichia coli, comum na flora intestinal humana, o gene da pró-insulina humana, para que ela passe a produzir o hormônio, um processo que dura 30 dias, um terço do tempo do método tradicional
Em 2001 somente quatro empresas no mundo, incluindo a Biobrás, tinham tecnologia de produção industrial da insulina recombinante
A Biobrás patenteou o processo nos Estados Unidos em 2000 e em 2002 foi comprada pela dinamarquesa Novo Nordisk
Comprada a Biobrás, a Novo Nordisk elevou rapidamente seus preços de fornecimento ao Ministério da Saúde combinando a importação e produção local, até acabarem fechando a produção dos cristais de insulina no Brasil para aqui fazer só envazamento.
Em 2013 o governo federal anunciou que o Brasil vai retomar a produção de insulina por meio do Laboratório Biomanguinhos, da Fundação Oswaldo Cruz, parte de um acordo firmado entre o governo e o laboratório ucraniano Indar, um dos três produtores remanescentes de insulina no mundo, que vai transferir a tecnologia para a produção nacional do medicamento.
Após o acordo de intenções com a Ucrânia, a Novo Nordisk, embora alegasse que a insulina ucraniana não tinha qualidade, fez proposta de compra do Indar ao governo
Um mês após a assinatura do contrato, em uma nova licitação governamental para aquisição de insulina, os preços da insulina oferecidos pelas empresas concorrentes baixaram quase à metade.
As ações nas células incluem:
Testículos: testosterona • AMH • inibina
Ovário: estradiol · progesterona · activin and inhibin · relaxina (gestação)
O Século XX iniciou em 1° de janeiro de 1901 e terminou em 31 de dezembro de 2000
Foi um período que se notabilizou pelos inúmeros avanços tecnológicos, conquistas da civilização e reviravoltas em relação ao poder
No entanto, esses anos podem ser descritos como a "época dos grandes massacres", já que nunca se matou tanto como nos conflitos ocorridos no período
Em muitos países da Europa e da Ásia, o século XX também foi largamente apelidado de "Século Sangrento"
Os cientistas europeus Giovanni Arrighi e Eric Hobsbawm escreveram sobre o período, o qual também intitularam seus livros, mas de perspectivas distintas: O longo século XX e Era dos Extremos: o breve século XX, 1914-1991, respectivamente
Também é associado ao Século Americano.
O século XX foi marcado por um período de mudanças
Com invenções como a lâmpada, o automóvel e o telefone no final do século anterior, a qualidade de vida aumentou para muitos, ao passo que esse progresso não só prosseguiu no Século XX, assim como foi essencial para grandes mudanças no cenário político global
Os Estados Unidos tiveram grandes ganhos econômicos e políticos; por volta de 1900, os Estados Unidos eram a potência industrial líder no mundo em termos de produção
A África, América Central, América do Sul e Ásia também gradualmente rumaram a uma maior autonomia
Com a criação de novos estados independentes em ex-possessões europeias, o balanço de poder ao longo do século XX começou a se deslocar para fora da Europa.
Na Europa, mudanças começaram também
O Império Britânico alcançou o ápice de seu poder
Império alemão e Reino de Itália, que passaram a existir como nações unificadas no final do século XIX, trataram de crescer em poder, economia e influência
Com o nacionalismo à toda a força nesse momento, as potências europeias competiram entre si por terras, força militar e poderio econômico
A Ásia e a África, para a maioria, ainda estava sob controle de seus conquistadores europeus como consequência do neocolonialismo
Exceções existiram, contudo, como na China e no Japão
Além disso, Império do Japão e o Império Russo estavam em guerra entre si em 1905
A Guerra Russo-Japonesa foi uma das primeiras instâncias de uma potência europeia caindo perante uma assim chamada "nação inferior"
A própria guerra reforçou o militarismo japonês e desenvolveu o crescimento de status do Japão por poder no cenário internacional
A Rússia czarista, por outro lado, não lidou bem com a derrota
A guerra expôs a fraqueza militar do país e o crescente retrocesso econômico
Os Estados Unidos foram um elemento de crescente influência na política mundial durante o século XIX
Tornaram sua presença conhecida no cenário mundial desafiando a os espanhóis na Guerra Hispano-Americana, ganhando colônias de Cuba e das Filipinas como protetorados.
Agora, com crescimento na imigração e uma resolução de uma questão de unidade nacional através da sangrenta Guerra Civil Americana, os Estados Unidos estavam surgindo também como uma usina de força industrial, rivalizando com a Grã-Bretanha, Alemanha e França
Com tal crescimento de poder na Ásia, e especialmente na América do Norte, e com crescente rivalidade entre as potências europeias, o cenário estava preparado para que a política mundial sofreria uma grande reviravolta.


Linha de montagem da Ford, 1913.
Guglielmo Marconi A figura central da história do rádio.
Albert Einstein, considerado a imagem da "inteligência" e do "pacifismo".
Santos Dumont O Pai da Aviação.
O 14-Bis.
Alexander Fleming O descobridor da penicilina retratado em um selo.
Michael Jackson (1958-2009) o rei do Pop, recordista de venda de álbuns e ícone da música, é considerado "o maior artista de todos os tempos".
Madonna (1958-) a rainha do Pop, polêmica, abriu caminho na música para a abordagem de variados temas, entre eles sexualidade e religião.
The Beatles (John, Ringo, Paul e George), símbolo do progressismo cultural da segunda metade do século.
Elvis Presley (1935-1977), o rei do Rock, símbolo da rebeldia e ousadia trazidas com o rock and roll.
Pelé (1940-) o Atleta do Século e tricampeão do mundo de futebol.
Garrincha (1933-1983) o Anjo das Pernas Tortas e bicampeão do mundo de futebol.
Guitarra elétrica, invenção que revolucionou a música popular.
Humphrey Bogart (1899-1957), premiado ator norte-americano, no filme Casablanca de 1942
Charles Chaplin (1889-1977), considerado o "Rosto do Século XX".
Clark Gable (1901-1960), brilhante ator norte-americano no filme Gone With the Wind (um dos primeiros filmes a cores) de 1939, em que estrelou com Vivien Leigh
Judy Garland (1922-1969), no filme The Wizard of Oz de 1939, um sucesso de bilheteria e um dos primeiros filmes a cores.
Marilyn Monroe (1926-1962), reconhecida como símbolo sexual, no filme Gentlemen Prefer Blondes, de 1953.
Cena da "Queda Babilônia" um dos episódios do filme Intolerância de D.W
Griffith, de 1916, considerado por muitos críticos o maior filme da era muda de todos os tempos.
David Wark Griffith (1875-1948), cineasta norte-americano, considerado o "pai" da montagem paralela do close e dos movimentos de câmera.
Alfred Hitchcock (1889-1980), cineasta anglo-americano, diretor de filmes de suspense que revolucionaram a estética cinematográfica do Século XX.
Cecil Blount DeMille (1881-1959), outro cineasta norte-americano, diretor de superproduções épicas como Os Dez Mandamentos e Cleópatra.
Harold Lloyd (1893-1971), ator e cineasta norte americano do cinema mudo.
Federico Fellini (1920-1993), importante cineasta italiano do Século XX, diretor de clássicos famoso como Il bidone, A Doce Vida, 8½, Julieta dos Espíritos, Amarcord, Roma, Entrevista, E la nave va e La voce della luna.
Stanley Kubrick (1928-1999) influente cineasta, reconhecido pela sua meticulosidade e persistência técnica, presente em seus clássicos como 2001: A Space Odyssey, A Clockwork Orange e The Shining.
Le Voyage dans la Lune, de 1902, de Georges Méliès, primeiro filme de ficção científica.
The Great Train Robbery, de Edwin Stanton Porter, de 1903, primeiro faroeste da história do cinema.
Jean-Luc Godard (1930-), um dos mais polêmicos cineastas do Século XX.
Pôster de The Birth of a Nation, de D.W
Griffith, primeiro longa-metragem norte-americano, de 200 minutos, de 1915.
Mariah Carey (1970-) considerada como a "songbird supreme", alcançou diversos recordes e conseguiu ser a artista solo com mais músicas em primeiro lugar.
Tropas russas se posicionando
O cenário se formava.
A queda muro de Berlim em 9 de novembro de 1989, a vitória capitalista na Guerra Fria.
Fokker Dr
I.
A Primeira Guerra Mundial começou em 1914 e terminou em 1918
Foi iniciada com o assassinato do herdeiro do trono do Império Áustro-Húngaro, o Erzherzog (Arquiduque) Franz Ferdinand (mais conhecido nos países lusófonos como Francisco Ferdinando ou Francisco Fernando), por Gavrilo Princip (Gabriel Príncipe) da organização nacionalista Sérvia "Mão Negra"
Chamado pelo nacionalismo eslavo para ajudar, os russos vieram a ajudar os sérvios quando foram atacados
Alianças tecidas, corrida armamentista crescente e velhos ódios arrastaram a Europa para a guerra
Os aliados da I Guerra Mundial, conhecidos como "A Tríplice Entente", compreendia o Império Britânico, o Império Russo e a França, assim como o Reino de Itália e os Estados Unidos mais tarde na guerra (em retaliação aos submarinos alemães, que torpedearam o navio RMS Lusitania)
Do outro lado, Alemanha, juntamente com a Áustria-Hungria e mais tarde o Império Otomano, ficaram conhecidos como "As Potências Centrais".
Em 1917 a Rússia terminou com ações hostis contra as Potências Centrais após a queda do Czar
Os Bolcheviques negociaram o Tratado de Brest-Litovsk com a Alemanha apesar de ter custado muito à Rússia
Apesar de a Alemanha ter trocado do Frente Oriental para a Ocidental grande quantidade de forças após o Tratado de Brest-Litovsk, não conseguiu parar o avanço dos aliados, especialmente com a entrada das tropas norte-americanas em 1918.
A própria guerra foi também uma oportunidade para as nações combatentes exibirem sua força militar e engenhosidade tecnológica
Os alemães introduziram a metralhadora e gases mortais
Os britânicos foram os primeiros a usar tanques
Ambos os lados tiveram uma oportunidade de testar suas novas aeronaves para ver se elas poderiam ser usadas em combate
Acreditou-se que a guerra seria curta
Infelizmente, desde que a guerra de trincheiras foi criada como a melhor forma de defesa, os avanços em ambos os lados foram muito lentos
Portanto, a guerra arrastou-se por um período mais longo e causou mais fatalidades que o esperado.
Quanto a guerra finalmente terminou em 1918, os resultados aprontaram o cenário para os próximos cinquenta anos
Primeiro e mais importante, os alemães foram forçados a assinar o Tratado de Versalhes, forçando-os a fazer pagamentos exorbitantes para reparar os danos causados durante a Guerra
Muitos alemães sentiram que aquelas reparações eram injustas porque eles não haviam de fato "perdido" a guerra nem sentiam que haviam causado a guerra (vide Dolchstoßlegende)
A Alemanha nunca foi ocupada por tropas aliadas, no entanto teve que aceitar um governo democrático liberal imposto pelos vitoriosos após a abdicação do Kaiser Wilhelm II (Guilherme II).
Muito do mapa da Europa foi redesenhado pelos vitoriosos baseados na teoria que guerras futuras poderiam ser prevenidas se todos os grupos étnicos tivessem sua própria "pátria"
Novos estados como a Jugoslávia e Checoslováquia foram criados do antigo Império Áustro-Húngaro para acomodar as aspirações nacionalistas desses grupos
Um órgão internacional chamado de a Liga das Nações foi formado para mediar disputas e prevenir futuras guerras, apesar de que sua efetividade foi severamente limitada, entre outras coisas, pela recusa dos Estados Unidos de se juntar a ela.
O mundo inteiro sentiu o gosto amargo do que o combate industrializado em escala mundial poderia fazer
A ideia de guerra como uma nobre defesa de um país por uma boa causa desapareceu, quando os povos de todas as nações refletiram acerca das deficiências de seus líderes, que haviam causado a dizimação de toda uma geração de jovens
Ninguém tinha interesse em outra guerra de tamanha magnitude
O pacifismo tornou-se popular e virou moda.
A Revolução Russa de 1917 deflagrou uma onda de revoluções comunistas por toda a Europa, alertando muitos de que uma revolução mundial socialista poderia ser realizada em um futuro próximo (ver: Revoluções de 1917-23)
Contudo, as revoluções europeias foram derrotadas, Lenin morreu em 1924, e em poucos anos Josef Stalin deslocou Leon Trotsky como o líder "de facto" (ver: Divergências entre Stalin e Trotsky) e concentrou-se no "socialismo em um só país"
Abandonou a NEP (Nova Política Econômica), instituída em 1922 por Lenin e, embarcou em um plano ousado de coletivização forçada e industrialização acelerada com seus planos quinquenais
A maioria dos socialistas e mesmo muitos comunistas tornaram-se desiludidos com o subjugo autocrático de Stalin, suas punições e assassínios de seus "inimigos" no grande Expurgo, assim como as notícias de fome (Holodomor), democídio que ele impôs ao seu próprio povo.
O comunismo fortaleceu-se nas democracias ocidentais enquanto a economia global implodiu em 1929 naquilo que ficou conhecido como Grande Depressão
Muitas pessoas viram isso como o primeiro estágio do fim do sistema capitalista e foram atraídos para o comunismo como uma solução à crise econômica.
Foice e martelo
Símbolo de uma das correntes político-econômicas deste século: o Comunismo.
Conosco Deus, pela ressurreição da Rússia!
Propaganda anticomunista do Exército Branco russo.
"Entreguerras" é a denominação dada ao período que se estende do fim da primeira guerra mundial, em 11 de novembro de 1918, até o início da segunda guerra mundial, em 1 de setembro de 1939.
O período foi marcado pela quebra da bolsa de Nova Iorque, associada a graves tensões políticas, culminando com a ascensão dos regimes totalitários em alguns países europeus e também no resto do mundo
Na Alemanha e na Itália, surgiram o nazismo e o fascismo, respectivamente
No Brasil, além do surgimento de um movimento de inspirações semelhantes ao fascismo, o integralismo, houve a ascensão de Getúlio Vargas ao poder, instaurando o Estado Novo
Esse período entre-guerras pôs fim à hegemonia do capitalismo, e o socialismo foi colocado em prática
Quando o socialismo infiltrou-se na Rússia deu origem aos partidos de oposição ao czarismo.
A economia após a Primeira Guerra Mundial permaneceu forte ao longo da década de 1920
A guerra proveu estímulo para a indústria e para a atividade econômica em geral
Houve muitos sinais de alerta predizendo o colapso do sistema econômico global em 1929 que foram de uma maneira geral incompreendidos pelas lideranças políticas da época
A resposta à crise geralmente fez a situação piorar, uma vez que milhões de pessoas assistiram suas economias tornarem-se irrisórias e a ideia de um emprego estável com um salário razoável se dissipando.
Muitos procuraram repostas em ideologias alternativas como o comunismo e o fascismo
Eles acreditavam que o sistema econômico estava em colapso e novas ideias eram necessárias para resolver a crise
As primeiras respostas à crise eram baseadas na pressuposição que o mercado livre iria corrigir a si mesmo, contudo, este fez pouco para corrigir a crise ou aliviar o sofrimento de muitas pessoas
Portanto, a ideia de que um sistema existente seria reformado pela intervenção governamental na economia (keynesianismo) ao invés de uma abordagem laissez-faire tornou-se proeminente como uma solução para a crise.
Governos democráticos assumiram a responsabilidade de prover serviços necessários para na sociedade e aliviar a pobreza e assim nascia o estado de bem-estar social
Estes dois princípios político-econômicos, a crença em intervenção governamental e o estado de bem-estar social, como oposição à crença de que o mercado livre e instituições privadas, iria definir muitas batalhas políticas pelo resto do século.
O fascismo apareceu pela primeira vez na Itália com a ascensão ao poder de Benito Mussolini em 1922
Isso aconteceu com o apoio da Igreja Católica e uma grande proporção das classes mais abastadas como um grande enfrentamento à ameaça do comunismo.
Quando Adolf Hitler chegou ao poder na Alemanha em 1933, uma nova variante do fascismo chamada nazismo apoderou-se da Alemanha extinguiu a república de Weimar e encerrou a experiência alemã com a democracia.
O Partido Nacional Socialista na Alemanha era dedicado à restauração da honra e do prestígio alemão, a unificação dos povos de língua germânica e a anexação da Europa Central e Oriental como estados vassalos, com a população eslava servindo com trabalho escravo para atender aos interesses econômicos alemães
Houve também um grande apelo para a pureza racial (a ideia de que os alemães eram a Herrenvolk ou raça mestra) e um vicioso antissemitismo/antijudaísmo que promoveu a ideia de que os judeus eram sub-humanos (Untermensch) e dignos apenas de extermínio.
Suástica: símbolo máximo do nazismo.
Benito Mussolini e Adolf Hitler.
Cartazes de propaganda nazista e propaganda comunista dos anos 1930.
Símbolo do Antifascismo (ver: Resistência alemã e Resistência italiana).
Muitos povos na Europa Oriental e os Estados Unidos saudaram a ascensão de Hitler com alívio ou indiferença
Não viam nada de errado com uma Alemanha forte pronta para desafiar a ameaça comunista ao Ocidente (ver: Anticomunismo)
O antissemitismo durante a Grande Depressão rapidamente se espalhou já que muitos estavam contentes de culpar os judeus de causar a crise econômica.
Hitler começou a colocar seu plano em movimento, anexando a Áustria no Anschluss, ou reunificação da Áustria com a Alemanha, em 1938
Ele então negociou a anexação dos Sudetos (Sudentenland), uma área montanhosa de língua alemã da Tchecoslováquia, na Conferência de Munique
Os britânicos estavam ávidos de evitar guerra e acreditavam na promessa de Hitler de proteger a segurança do estado checo
Hitler anexou o resto do estado checo logo a seguir
Não poderia mais ser dito que Hitler estava puramente interessado em unificar o povo alemão.
O fascismo não era a única forma de ditadura a ascender no período pós-guerra
Quase todas as novas democracias nas nações da Europa Oriental caíram e foram substituídas por regimes autoritários
A Espanha também tornou-se uma ditadura sob a liderança do General Francisco Franco após a Guerra Civil Espanhola
Estados totalitários tentaram alcançar controle total sobre seus povos bem como sua total lealdade
Eles mantiveram o estado sobre o indivíduo, e foram responsáveis por alguns dos piores atos na história, como o Holocausto, ou mesmo um Grande Expurgo perpetrado por Estaline em seu próprio povo mais tarde quando seu regime foi responsável por milhões de mortes
De fato, nesse momento, a democracia parecia estar em declínio
Foi um período de medo e dúvida, explorado por diversos homens inescrupulosos que cometeram atos terríveis com o apoio de suas populações.
O marco inicial ocorreu no ano de 1939, quando a Wehrmacht (forças armadas alemãs) invadiram a Polônia
De imediato, a França e a Inglaterra declararam guerra à Alemanha
De acordo com a política de alianças militares existentes na época, formaram-se dois grupos: Aliados (liderados por Inglaterra, URSS, França e Estados Unidos) e o Eixo (Alemanha, Itália e Japão)
A 27 de Setembro de 1940, em Berlim, as Potências do Eixo firmaram o Pacto Tripartite
A Segunda Guerra Mundial (1939–1945) opôs os Aliados às Potências do Eixo, tendo sido o conflito que causou mais vítimas em toda a história da Humanidade
As principais potências aliadas eram a República da China, a França, a Grã-Bretanha, a União Soviética e os Estados Unidos
O Brasil se integrou aos Aliados em 1943
A Alemanha, a Itália e o Japão, por sua vez, perfaziam as forças do Eixo
Muitos outros países participaram na guerra, quer porque se juntaram a um dos lados, quer porque foram invadidos, ou por haver participado de conflitos laterais
Em algumas nações (como a França e a Jugoslávia), a Segunda Guerra Mundial provocou confrontos internos entre partidários de lados distintos
O líder alemão de origem austríaca Adolf Hitler, Führer do Terceiro Reich, pretendia criar uma "Nova Ordem Nazista" na Europa, baseada nos princípios nazistas da suposta superioridade alemã, na exclusão; e, supostamente eliminação física incluída; de algumas minorias étnicas e religiosas, como os judeus e os ciganos, bem como deficientes físicos e homossexuais; na supressão das liberdades e dos direitos individuais e na perseguição de ideologias liberais, socialistas e comunistas.
Tanto a Itália como o Japão entraram na guerra para satisfazer os seus propósitos expansionistas (ver: Grande Itália e Expansionismo japonês)
As nações aliadas (como a França, a Grã-Bretanha e os Estados Unidos) opuseram-se a estes desejos das potências do Eixo
Estas nações, juntamente com a União Soviética, após a invasão desta pela Alemanha (operação Barbarossa), constituíram a base do grupo dos Aliados.
O período de 1939 a 1941 foi marcado por vitórias do Eixo, lideradas pelas forças armadas da Alemanha, que conquistou o Norte da França, Iugoslávia, Polônia, Ucrânia, Noruega e territórios no norte da África
O Japão anexou a Manchúria, enquanto a Itália conquistava a Albânia e territórios da Líbia.
Em 1941 o Japão ataca a base militar norte-americana de Pearl Harbor no Oceano Pacífico (Havaí)
Após este fato, considerado uma traição pelos norte-americanos, os estados Unidos entraram no conflito ao lado das forças aliadas.
De 1941 a 1945 ocorreram as derrotas do Eixo, iniciadas com as perdas sofridas pelos alemães no rigoroso inverno russo durante a batalha de Stalingrado
Neste período, ocorre uma regressão das forças do Eixo que sofrem derrotas seguidas
Com a entrada dos Estados Unidos, os aliados ganharam força nas frentes de batalhas.
O Brasil participa diretamente, enviando para a Itália (região de Monte Cassino) os pracinhas da FEB, Força Expedicionária Brasileira
Os cerca de 25 mil soldados brasileiros conquistam a região, somando uma importante vitória ao lado dos Aliados.
Logo após os eventos na Checoslováquia, Reino Unido e França garantiram proteção à Polônia, que parecia ser o próximo na lista de Hitler
A Segunda Guerra Mundial oficialmente começou em 1 de Setembro de 1939
Nesta data, Hitler lançou sua Blitzkrieg, ou guerra-relâmpago, contra a Polônia
Grã-Bretanha e França, para grande surpresa de Hitler, imediatamente declararam guerra à Alemanha, mas a ajuda que podiam oferecer à Polônia era irrisória
Apenas poucas semanas depois, as forças polacas estavam subjugadas e o seu governo fugiu para o exílio em Londres.
Iniciando a II Grande Guerra, os alemães haviam lançado um novo tipo de estratégia de guerra, caracterizado pelas forças altamente móveis e o uso de aeronaves de grande porte
A estratégia alemã se concentrava na devoção do Wehrmacht, ou forças armadas alemãs, no uso de grupos de tanques, chamados de divisões Panzer, e grupos de infantaria móvel, em harmonia com incansáveis ataques do céu
Cerco também era uma parte importante da estratégia
Esta mudança esmagou qualquer expectativa de que a Segunda Guerra Mundial seria lutada nas trincheiras como a primeira.
Enquanto as forças de Hitler conquistavam a Polônia, a União Soviética, sob o Secretário Geral Josef Stalin, estava agindo para garantir territórios em uma parte secreta de um tratado de não-agressão (o Pacto Molotov-Ribbentrop) entre a URSS e a Alemanha
Este tratado deu a Stalin caminho livre para as repúblicas bálticas da Estônia, Letônia e Lituânia, assim como a Polônia Oriental, todos que permaneceriam como possessões soviéticas após a guerra
Em 17 de Setembro teve início a Invasão Soviética da Polónia
Stalin também lançou um ataque à Finlândia, que ele esperava reduzi-la a nada além de um estado fantoche soviético, mas o Exército Vermelho encontrou dura resistência no que ficou conhecido como a Guerra do Inverno, e teve sucesso em ganhar apenas um limitado território dos finlandeses
Esta ação levaria mais tarde a uma aliança entre os finlandeses e a Alemanha quando do ataque à União Soviética em 1941.
Após a derrota da Polônia, um período conhecido como Guerra de Mentira aconteceu durante o inverno de 1939-1940
Tudo isso mudou em 10 de Maio, 1940, quando os alemães lançaram um ataque massivo aos Países Baixos (Bélgica, Holanda e Luxemburgo), mais provavelmente para superar a Linha Maginot de defesas nas fronteiras franco-alemãs
Com isto testemunhou-se a incrível queda do Eben Emael, um forte belga considerado inviolável e guardado por 600 belgas, a uma força de apenas 88 paraquedistas alemães
O pior foi que o Rei Leopoldo III da Bélgica se rendeu aos alemães em 28 de Maio sem avisar seus aliados, expondo o flanco inteiro das forças aliadas para grupos de panzers alemães
Seguindo-se à conquista dos Países Baixos, Hitler ocupou a Dinamarca e a Noruega, começando em 9 de Abril de 1940
A Noruega era mais importante estrategicamente por causa de suas rotas navais que supriam minas suecas cruciais para a máquina de guerra nazista
A Noruega resistiu por algumas semanas cruciais, mas a Dinamarca rendeu-se após apenas quatro dias.
Com o desastre nos Países Baixos, a França, considerada àquela época possuir o melhor exército do mundo, durou apenas quatro semanas, com Paris sendo ocupada em 14 de Junho
Três dias depois, o Marechal Philippe Pétain se rendeu aos alemães
A disputa na França também levou a um dos maiores mistérios da guerra, e o primeiro grande tropeço de Hitler, na batalha de Dunquerque, onde um terço de milhão de soldados britânicos e franceses encurralados foram evacuados não apenas por barcos de guerra britânicos, mas por cada barco que o exército conseguiu encontrar, incluindo botes de pesca
Hitler se recusou a "arriscar" seus panzers em ação em Dunquerque, seguindo conselho do Ministro da Aeronáutica Herman Göring e permitindo à Luftwaffe, ou Força Aérea alemã, cuidar do serviço
A ironia nisso foi que os homens que escaparam formariam a cúpula do exército que invadiria as praias da Normandia em 1944
Hitler não ocupou toda a França, mas por volta de três quartos, incluindo toda a costa do Atlântico, permitindo que o Marechal Pétain permanecesse como ditador de uma área conhecida como França de Vichy
Contudo, membros do Exército francês que escaparam se uniram ao redor do General Charles de Gaulle para criar as Forças Francesas Livres, que continuaria a batalhar com Hitler por uma França independente
Neste momento, Mussolini declarou guerra aos aliados em 10 de Junho, pensando que a guerra estava quase acabada, mas ele conseguiu ocupar apenas alguns poucos metros do território francês
Ao longo da guerra, os italianos seriam muito mais um peso aos nazistas do que uma mão, e mais tarde custariam a eles um tempo precioso durante a ocupação da Grécia.
Aqui está uma das maiores ironias da história
Hitler agora permanecia em uma posição única
Ele já havia conquistado um montante incrível de território em um curto espaço de tempo, e teve a chance de dominar toda a Europa (ver: Europa ocupada pela Alemanha Nazista)
Certamente, de um ponto de vista militar, é incrível que Hitler tivesse perdido a II Guerra Mundial
Ao longo de 1940 e 1941, ele tomou conhecimento e controle virtual da Hungria, Romênia e Bulgária, assim como a Finlândia como um desconfortável aliado
O segredo é que Hitler apoiou as ideias de generais como Heinz Guderian, geralmente chamado de profeta da guerra acelerada, e Erwin Rommel, um gênio militar que emergiu na II Guerra Mundial
Hitler atribuiu seus sucessos ao seu próprio gênio militar, e sua autoconfiança seria mais tarde a principal causadora da derrota da Alemanha
Hitler poderia agora tornar-se governante da Europa, e possivelmente ditador do mundo, se ele apenas tivesse seguido os planos de senso comum defendidos pelos muitos generais alemães
Contudo, ele não seguiu, salvando o mundo de dominação nazista.
Hitler agora se vira para a Grã-Bretanha, que ficou sozinha contra ele
Ele ordenou a seus generais que desenhassem planos de invasão, com o nome código de Operação Leão Marinho, e ordenou à Luftwaffe para lançar um ataque aéreo maciço contra as ilhas britânicas, o que viria a ser conhecido como Batalha da Grã-Bretanha
Os britânicos no começo sofreram perdas consideráveis, mas conseguiram virar a guerra contra a Alemanha, abatendo 2 698 aviões alemães ao longo do verão de 1940 contra apenas 915 perdas da Royal Air Force (RAF)
O ponto-chave da virada aconteceu quando os alemães interromperam ataques bem sucedidos contra fábricas britânicas de aviões e estações de comando e coordenação de radar e passaram a bombardear civis, o que ficou conhecido como bombardeio de terror usando o distinto som de "bomba" criado pelo bombardeiro alemão, o Stuka
A mudança veio após uma pequena força de bombardeio britânica ter atacado Berlim
Hitler ficou furioso
Contudo, esta decisão de mudar o foco do ataque permitiu aos britânicos reconstruir a RAF e mais tarde forçar os alemães a adiar indefinidamente a Leão Marinho.
A importância da Batalha da Bretanha é que ela marcou o começo da derrota de Hitler
Em segundo lugar, marcou o advento do radar como uma arma fundamental na guerra aérea moderna
Com o radar, esquadrões de combatentes poderiam ser rapidamente organizados para responder aos bombardeiros que vinham tentar bombardear alvos civis
Também foi possível a identificação do tipo e um palpite no número de aeronaves inimigas a caminho, assim como rastrear aviões amigos.
Hitler, abatido por sua derrota sobre os céus da Inglaterra, agora mirava a leste para a União Soviética
Apesar de ter assinado o pacto de não-agressão com Estaline, Hitler desprezava o comunismo e desejava destruí-lo na terra de seu nascimento
Ele originalmente planejou lançar o ataque no começo da primavera de 1941 para evitar o desastroso inverno russo
Contudo, um golpe pró-aliado na Jugoslávia e a derrota quase vergonhosa de Mussolini em sua invasão à Grécia da ocupada Albânia fez com que Hitler lançasse uma campanha pessoal de vingança na Jugoslávia e ocupasse a Grécia ao mesmo tempo
Os gregos teriam uma vingança amarga; o ataque causou um atraso de muitas semanas cruciais da invasão da Rússia.
Em 22 de Junho de 1941, Hitler apontou a Estaline o maior exército que o mundo havia visto
Mais de três milhões de homens e suas armas foram postos em serviço contra os soviéticos
Estaline havia sido avisado sobre o ataque, tanto por outros países quanto por sua própria rede de inteligência, mas havia se recusado a acreditar nisso
Portanto, o exército russo estava totalmente despreparado e sofreu incríveis retiradas no início da guerra, apesar das ordens de Estaline de contra-atacar os alemães
Ao longo de 1941, forças alemãs, divididas em 3 grupos do exército (Grupo do Exército A, Grupo do Exército B e Grupo do Exército C), ocuparam os estados bálticos da Ucrânia e Bielorrússia, levantaram cerco em Leningrado (atual São Petersburgo) e avançou até 22 quilômetros de Moscovo
Neste momento crucial, o inverno russo, que começou cedo naquele ano, atrasou o Wehrmacht alemão a um ataque aos portões de Moscovo
Estaline havia planeado evacuar a cidade, e já tinha movido funções importantes do governo, mas decidiu ficar e lutar pela cidade
Tropas recentemente chegadas do leste sob o comando do gênio militar Marechal Georgi Zhukov contra-atacou os alemães e os afastou de Moscovo
O exército alemão então enfrentou o inverno.
Aqui marca o terceiro grande tropeço de Hitler
Ele poderia ter ganho a guerra da URSS exceto por algumas razões
Uma, ele começou a guerra tarde demais para evitar o inverno russo
Segundo, ele tentou capturar muito território muito rápido; ele queria que o exército alemão avançasse sem parar até os Urais, o que somava 2 600 000 km² de território, quando ele provavelmente deveria ter se concentrado em tomar Moscovo e então partir para o coração da União Soviética
Terceiro, ele ignorou a experiência similar de Napoleão Bonaparte quase cento e cinquenta anos antes em sua tentativa de conquistar a Rússia
Apesar disso, Estaline não estava em uma boa posição
Aproximadamente dois quintos do poder industrial da URSS estava em mãos alemãs
Além disso, os alemães eram no início vistos por muitos como libertadores lutando contra os comunistas
Estaline também não era um general muito hábil, e assim como Hitler, no início tentou lutar na guerra como um estrategista militar
Contudo, Hitler conseguiu virar todas as vantagens que tinha contra si, e perdeu a única esperança que restava: conquistar o Cáucaso e tomar controle do Norte da África e do Oriente Médio rico em petróleo.
Mussolini lançou uma ofensiva no Norte africano da Líbia, controlada pelos italianos, contra o Egito, controlada por britânicos
Contudo, os britânicos esmagaram os italianos e estavam prestes a conquistar a Líbia
Hitler decidiu ajudar enviando alguns milhares de tropas, uma divisão da Luftwaffe (o Afrika Korps) sob comando do primeiro-general Erwin Rommel
Rommel decidiu usar sua pequena força para repetidamente esmagar as forças maciçamente superiores do Reino Unido e recapturar a cidade portuária de Tobruk e avançar até o Egito
Contudo, Hitler, enrolado com sua invasão à União Soviética, recusou mandar Rommel e mais tropas
Se tivesse, Rommel poderia ter conquistado o Oriente Médio, onde os regimes aliados ao Eixo tinham tomado a rota no Iraque e Pérsia (atual Irão)
Lá, Rommel poderia ter cortado uma das principais rotas de fornecimento aos soviéticos através da Pérsia, e ajudado a tomar o Cáucaso, virtualmente neutralizando a efetividade britânica na guerra e potencialmente selando o destino da URSS
Contudo, Hitler tropeçou novamente, jogando fora os últimos vestígios da vantagem alemã em sua ofensiva em 1942.
Após o inverno, Hitler lançou uma ofensiva nova na primavera de 1942, com o objetivo de capturar o Cáucaso rico de petróleo e a cidade de Estalingrado
Contudo, ele repetidamente mudou suas tropas para onde elas não eram mais necessárias
A ofensiva falhou, e o 6º Exército inteiro, considerada uma das melhores tropas alemãs, ficou aprisionada em Estalingrado
Hitler agora recusou-se a deixar o 6º Exército escapar
Ele insistiu que o exército alemão forçaria sua entrada
Herman Goering também assegurou a Hitler que a Luftwaffe poderia fornecer ao 6º Exército adequadamente, quando ele poderia na realidade apenas fornecer apenas uma fração mínima da munição e da ração necessárias
Consequentemente, o faminto 6º Exército rendeu-se, deixando uma grande surpresa aos alemães
Ao final, a derrota em Estalinegrado foi o momento da virada da guerra no leste.
Enquanto isso, os japoneses atacaram os Estados Unidos em Pearl Harbor no Havai em 7 de Dezembro de 1941
Este ataque desastroso forçou os norte-americanos a entrarem na guerra
Hitler não precisaria ter declarado guerra aos Estados Unidos, mantendo assim sua neutralidade na Europa, mas não o fez assim
Tanto ele quanto Mussolini declararam guerra apenas alguns dias após o ataque
Naquele momento, a maioria dos generais alemães, preocupados com a guerra na Rússia, nem mesmo perceberam a entrada dos Estados Unidos
Seria um deslize crucial.
Ao longo do resto de 1942 e 1943, os soviéticos começaram a ganhar terreno em relação aos alemães
A batalha de tanques de Kursk é um exemplo
Contudo, a essa altura, Rommel foi forçado a abandonar o norte da África após a derrota em El Alamein, e o Wehrmacht se deparou com grandes baixas que não conseguiria substituir
Hitler também insistiu em uma política de "defesa a todo custo" que proibia a entrega de qualquer território
Ele seguiu a política da "luta até o último homem" que foi completamente ineficiente
No começo de 1944, Hitler havia perdido todas as suas iniciativas na Rússia, e ainda se esforçava para segurar a mudança de maré contra ele.
De 1942 a 1944, os Estados Unidos e a Grã-Bretanha atuaram apenas de uma forma limitada no teatro europeu, muito a contragosto de Estaline
Eles expulsaram os alemães da África, invadindo o Marrocos e a Argélia em 8 de Novembro de 1942
Então, em 10 de Julho de 1943, os aliados invadiram a Sicília, em preparação para um avanço pela Itália, o "ponto fraco" do Eixo, como Winston Churchill a chamou
Em 9 de Setembro, a invasão da Itália começou
No inverno de 1943, a metade sul da Itália estava em mãos Aliadas
Os italianos, muitos deles que não apoiavam a guerra, já haviam se voltado contra Mussolini
Em Julho, ele foi extirpado do poder e feito prisioneiro, apesar dos italianos terem contínuo apoio do eixo
Em 8 de Setembro, os italianos se renderam formalmente, mas a maioria da Itália que não estava em mãos aliadas era controlada por tropas alemãs e aqueles leais a nova República Social Italiana de Mussolini (Mussolini foi libertado por paraquedistas alemães), o que consistia na realidade na zona em encolhimento de controle alemão
Os alemães ofereceram dura resistência, mas em 4 de Junho de 1944, Roma caiu.
De 1942 a 1944, a Segunda Batalha do Atlântico aconteceu
Os alemães esperavam cortar as linhas vitais de abastecimento entre o Reino Unido e a América, afundando muitas toneladas de carregamento com U-boats, submarinos alemães
Contudo, o desenvolvimento do contratorpedeiro e aeronaves com um alcance de patrulha maior foram eficientes para barrar a ameaça do U-boat
Em 1944, os alemães perderam a Batalha do Atlântico.
Em 6 de Junho de 1944, os Aliados Ocidentais finalmente lançam o ataque mais que aguardado ao "Forte Europa" tão pedido por Estaline
A ofensiva, na Frente Ocidental, de nome código Operação overlord, começou cedo pela manhã do dia 6 de Junho
O dia, conhecido como Dia D, foi marcado por um clima instável
Rommel, que agora estava a cargo de defender a França contra um possível ataque aliado, pensou que os Aliados não atacariam durante uma tempestade, e foi em um feriado na Alemanha
Aqui, um grande erro ocorreu para os alemães, selando o sucesso da operação
Os alemães esperavam um ataque, mas no porto natural de Calais e não nas praias da Normandia
Eles não sabiam sobre os portos artificiais
Também, pistas plantadas pelos Aliados sugeriam Calais como o local de desembarque.
Nesse ponto, a guerra parecia estar ficando pior para a Alemanha
Em 20 de julho de 1944, um grupo de oficiais alemães tentou assassinar Hitler (o Atentado de 20 de julho, do qual participaram Claus von Stauffenberg, entre outros)
A bomba que usaram o feriu, mas a segunda não foi usada, e uma mesa protegeu Hitler em um lance de sorte
Os conspiradores ainda poderiam ter arquitetado um golpe, mas apenas a cúpula da Paris ocupada agiu, prendendo forças da SS e da Gestapo na cidade
O ministro da propaganda alemã, Joseph Goebbels, agiu salvando o dia para Hitler
Esta foi uma dentre várias tentativas da resistência alemã para eliminar Hitler.
Na França, os aliados tomaram a Normandia e finalmente Paris em 25 de agosto
A leste, os russos avançaram quase até a antiga fronteira russo-polaca
Nesse momento, Hitler introduziu as armas-V, o V-1, o V-2 (mais tarde) e, o canhão V-3
V-1 e V-2 foram os primeiro mísseis utilizados na guerra moderna
O V-1 era quase sempre interceptado por pilotos aéreos, mas o V-2 era extremamente rápido e carregava uma grande quantidade de carga
Contudo, este avanço chegou muito tarde na guerra e não teve muito efeito prático
Os alemães estavam também próximos de introduzir um grande número de novas armas terríveis, incluindo aeronaves de propulsão avançada, que eram muito rápidas para para aeronaves comuns, e melhorias em submarinos que permitiriam aos alemães lutar novamente de forma eficiente no Atlântico
Tudo isso veio muito tarde para salvar Hitler
Apesar da invasão de Setembro na Holanda ter falhado (operação Market Garden), os aliados fizeram avanços contínuos
No verão de 1944, Hitler apostou tudo em uma última tentativa desesperada no Oeste, conhecida como a Batalha do Bulge, que, apesar do avanço inicial, foi um fracasso, por causa da introdução de novos tanques aliados e baixo número de tropas entre os alemães, o que evitou qualquer ação real de ser tomada.
No início de Fevereiro de 1945, os três líderes aliados, Franklin Roosevelt, Winston Churchill, e Joseph Stalin se encontraram na recém liberada Yalta na Crimeia na União Soviética na Conferência de Yalta
Ali, eles acordaram em relação a um plano para dividir a Europa do pós-guerra
A maior parte do leste foi para Stalin, que concordou em permitir eleições livre na Europa Oriental, coisa que nunca cumpriu
O oeste ficou para a Grã-Bretanha, França e Estados Unidos
A Alemanha seria dividida entre os quatro, assim como Berlim (ver: Zonas ocupadas pelos Aliados na Alemanha)
Aqui o território da Guerra Fria foi estabelecido
As fundações da Cortina de Ferro e da corrida nuclear foram sedimentados por estes três homens em Yalta.
No começo de 1945 Hitler já estava muito enfraquecido
Os russos lançaram um ataque devastador a partir da Polônia, onde libertaram Varsóvia, contra a Alemanha e a Europa Ocidental, com a intenção de tomar Berlim
Os alemães sucumbiram no oeste, permitindo que os aliados penetrassem Alemanha adentro
Entretanto, o comandante das forças aliadas, o general estadunidense Dwight D
Eisenhower, recusou-se a atacar Berlim e, ao invés disso, ficou obcecado com relatórios sobre possíveis atividades de guerrilha no sul do país, o que na verdade só existia na propaganda de Joseph Goebbels
Em 25 de abril os russos tinham Berlim sitiada
Hitler permaneceu na cidade, em seu bunker (Führerbunker), e suicidou-se cinco dias depois, depois de uma cerimônia de casamento com sua amante de longa data, Eva Braun
Os alemães aguentaram mais sete dias sob o comando do Almirante Karl Doenitz, seu novo líder, mas acabaram se rendendo incondicionalmente em 7 de maio, encerrando a guerra na Europa (ver Dia da Vitória na Europa).
Tanques japoneses nas Filipinas.
O afundamento do porta-aviões japonês Shoho.
Yamato: O "super navio" japonês.
O Holocausto (que grosso modo significa "completamente queimado") foi o extermínio deliberado e sistemático de milhões de judeus, ciganos, eslavos, opositores políticos, prisioneiros de guerra soviéticos, homossexuais e doentes mentais e psiquiátricos, dentro do programa governamental denominado Aktion T4, antes e durante a Segunda Guerra Mundial, sob o Terceiro Reich na Alemanha
Alguns autores, porém, consideram que o Holocausto se refere apenas ao extermínio dos judeus.
Na realidade, a perseguição aos judeus teve início com a ascensão ao poder do partido nacional-socialista, muito antes da guerra, sendo o primeiro grande acontecimento a Kristallnacht ("Noite dos Cristais")
Os sentimentos antissemitas que já de há muito existiam de forma latente entre a população alemã foram consistentemente inflamados pela maquina de propaganda nazista (ver: Leis de Nuremberg).
Após a conquista da Polônia, o Terceiro Reich, que havia previamente deportado judeus e outros "indesejados", repentinamente tinha dentro de suas fronteiras a maior concentração de judeus do mundo
A solução foi isolá-los do resto da população, deportando-os para campos de concentração ou obrigando-os a viver em guetos, em condições deploráveis e de superpovoamento
Dezenas de milhares morreram assim de fome e de doença, quantas vezes na própria rua
À medida que a Alemanha ia conquistando novos territórios, as SS e os Einsatzgruppen, unidades paramilitares, reuniam e assassinavam sistematicamente os judeus.
Mas foi na Conferência de Wannsee que o regime nazi mostrou o quão longe era capaz de levar a sua loucura (ver: Eugenia nazista e Política racial da Alemanha Nazista)
Com efeito, pretendia-se que o extermínio completo da população judaica fosse mais célere, eficaz e, sobretudo, sistemático
Assim, em 1942, os principais líderes nazis reuniram-se em Wannsee, nos arredores de Berlim, a fim de encontrarem aquilo que designaram como a Solução Final da Questão Judaica (em alemão, "Endlösung der Judenfrage")
Em 4 de Outubro de 1943, o comandante da SS, Heinrich Himmler, proferiu o Discurso de Posen, onde deixou claro o destino que regime reservava para os indivíduos considerados Untermensch (sub-humanos).
Tendo-se criado toda uma rede de campos de extermínio na Alemanha e na Polónia, deu-se início, em todos os territórios sob o domínio do Terceiro Reich (a França e a União Soviética ocupadas, a Polónia, a Hungria, os Países Baixos, etc.), à deportação em massa dos judeus
Nestes campos foram mortos milhões de judeus: fuzilados, enforcados e, sobretudo, gaseados
Os deportados foram igualmente utilizados como mão-de-obra escrava e como cobaias de experiências médicas
Para além disso, a fome e a sede, a insalubridade, a exposição aos elementos, os maus-tratos, a pura exaustão ceifaram centenas de milhares de vidas
Em termos globais estima-se que o total das vítimas do Holocausto se situe entre os nove e os onze milhões, seis milhões dos quais judeus.
No Julgamento de Nuremberg, a unânime condenação das experiências médicas levadas a cabo pelos nazisstas levou à criação do Código de Nuremberg, um documento que visa definir uma ética para a investigação médica em seres humanos.
É inegável que os nazisstas sentiam um prazer absolutamente sádico com o sofrimento vivido nos campos de morte
À entrada de um dos mais terríveis campos, Auschwitz, pode ler-se "Arbeit Macht Frei" ("O trabalho liberta")
No total, foram mortos sete milhões de judeus, homossexuais, Testemunhas de Jeová, ciganos e prisioneiros políticos, a maior parte nos campos de concentração
Nos campos morreram também milhões de prisioneiros soviéticos e aliados.
Tem havido alguma controvérsia quanto ao efectivo conhecimento do Holocausto pela população alemã
Ao que tudo indica, o cidadão comum estava bem informado sobre a existência dos campos de concentração, amplamente noticiada em muitos jornais e revistas
Em muitos locais da Alemanha e países ocupados, os judeus tinham de atravessar, às centenas, cidades e aldeias, a caminho das empresas que os utilizavam como mão-de-obra escrava
De qualquer forma, os soldados aliados testemunharam que o cheiro dos campos podia ser sentido numa área de muitos quilómetros
Um pequeno número de pessoas nega liminarmente que o Holocausto tenha ocorrido (ver: Negacionismo do Holocausto), se bem que tais teses tenham vindo a ser solidamente refutadas pelos mais conceituados historiadores (ver: Críticas ao Negacionismo do Holocausto).
Depois da Segunda Guerra Mundial, a maioria do mundo industrializado estava em ruínas como resultado das bombas aéreas, bombardeios navais, e leis de proteção de campanha
Os Estados Unidos foram uma exceção notável a isto; com exceção de Pearl Harbor e alguns outros incidentes isolados, os EUA não sofreram ataques em sua terra natal
Os Estados Unidos e a União Soviética, que, apesar da devastação de suas áreas mais populosas, reconstruíram-se rapidamente, encontraram-se dividindo o mundo como as duas superpotências dominantes.
Muito do oeste da Europa foi reconstruído depois da guerra com assistência do Plano Marshall
Alemanha, grande instigadora da guerra, foi colocada sob controle militar pelos Estados Unidos, Grã-Bretanha, França e a União Soviética
Berlim, apesar de estar em território soviético, foi dividido entre os quatro poderes
A ocupação de Berlim continuaria até 1990
O Japão também foi colocado sob ocupação americana; a ocupação iria durar cinco anos, até 1949
Estranhamente, estes dois poderes do Eixo, apesar da ocupação militar, logo cresceram para se tornar a segunda (Japão) e terceira (Alemanha ocidental) maiores economias do mundo
Em resposta ao Plano Marshall, a União Soviética criou em 1949, o COMECON (Conselho para Assistência Econômica Mútua)
Inicialmente, o COMECON prestou auxílio aos países da Europa oriental, posteriormente também recebendo como membros, países da América Latina e Ásia.
Seguindo o fim da guerra, os Aliados da Segunda Guerra Mundial processaram um grande número de oficiais alemães por crimes de guerra e outras ofensas no Tribunal de Nuremberg
Apesar de Adolf Hitler ter cometido suicídio, muitos de seus cabeças, incluindo Hermann Göring, foram declarados culpados
Julgamentos menos conhecidos de oficiais do eixo também ocorreram, incluindo o Tribunal Militar Internacional para o Extremo Oriente que julgou os Crimes de guerra do Japão Imperial
Muitos dos crimes de guerra dos Aliados ficaram impunes.
A falha da Liga das Nações em prevenir a Segunda Guerra Mundial essencialmente dissolveu a organização
Uma nova tentativa de paz mundial começou com a fundação das Nações Unidas em 24 de outubro de 1945 em São Francisco, Califórnia
Hoje, quase todos os países são membros, mas o sucesso da organização em seus objetivos é duvidoso.
O fim da Segunda Guerra Mundial apresentou um panorama bem diferente do da Primeira Guerra: neste, a desmobilização militar foi generalizada e a produção bélica cessou
Após 1945, entretanto, as grandes potências não só conservaram os seus exércitos, mas desenvolveram ainda mais a indústria bélica, num quadro em que o armamentismo casava-se com a paz.
Fato que ficou conhecido como a corrida armamentista na Guerra Fria.
O mundo se organizou sobre novas bases, destituindo a Europa da posição de eixo do poder mundial e elegendo Washington e Moscou como novos centros, o que reativou o confronto entre capitalismo e socialismo
As nações tendiam para um ou outro polo de poder, fixado a bipolarização do mundo, marcadas pela tensão internacional, alimentada pelo conflito ideológica e política dos Estados Unidos e da União Soviética.
Os Estados Unidos despontaram como um Estado superior a qualquer outro em recursos materiais, financeiros e tecnológicos, como a nação detentora da bomba atômica, do domínio nuclear, com a vantagem de não ter sofrido a devastação e a exaustão da guerra em seu território
Para a União Soviética era vital igualar-se aos norte-americanos a a fim de que o socialismo pudesse sobreviver
Assim, embora tivesse saído da guerra com um saldo catastrófico; 1700 cidades arrasadas, 60 mil quilômetros de estradas de ferro destruídas e mais de vinte milhões de mortos; Josef Stálin colocou como metas prioritárias de seu governo a reconstrução nacional e a corrida nuclear.
Em 1949, a União Soviética alcançava parte de seus objetivos, ao dominar a tecnologia bélica nuclear
A partir daí, a conjuntura internacional estabelecia que as grandes potências seriam as que possuíssem o domínio bélico atômico
Vinte anos depois do final da Segunda Guerra, 25 nações já possuíam status nuclear militar.
A Europa, embora devastada, aderiu á nova ordem, compondo com os blocos rivais
Na França, após o afinal da guerra, organizou-se a Quarta República, formada por uma aliança entre os seguidores de Charles de Gaulle, o líder do governo no exílio, e membros dos movimentos da Resistência francesa
O novo governo caracterizou-se pela divisão e instabilidade interna e pela busca contínua de recuperação econômico-financeira.
O Holocausto acelerou os esforços para repatriar e assentar judeus na Palestina
A Grã-Bretanha, que previamente havia ocupado a Palestina sob mandato da Liga das Nações, retirou-se e partiu a área em territórios palestinos e judaicos com assistência das Nações Unidas
As tensões étnicas, religiosas e políticas criadas por isso atormentaram o mundo desde então
Três guerras regionais: a Crise de Suez em 1956, a Guerra dos Seis Dias e a Guerra do Yom Kippur, envolveram Israel e países fronteiriços.
Os palestinos de Israel também resistiram ativamente à ocupação israelense na Faixa de Gaza assim como na Cisjordânia
Alguns participaram de ações como a Primeira Intifada e atentados suicidas contra militares israelenses e alvos civis, alvos que grupos como o Hamas não fazem distinção.
Quase todas as principais nações que estavam envolvidas na II Guerra Mundial começaram a abrir mão de suas colônias logo após o conflito
Os Estados Unidos deram a independência às Filipinas, sua principal possessão no Pacífico
Potências europeias como a Grã-Bretanha também começaram a se retirar de suas possessões na África e na Ásia
A França foi forçada a sair tanto da Indochina quanto, mais tarde, da Argélia.
A segunda metade do século vinte foi profundamente prejudicada pela competição entre as duas superpotências mundiais: os Estados Unidos e a União Soviética
A situação ficou especialmente tensa com o advento das armas nucleares
Os Estados Unidos, explodiram sua primeira bomba nuclear e usaram tais armas contra Hiroshima e Nagasaki.
A União Soviética explodiu sua primeira bomba em 9 de agosto de 1949
A Grã-Bretanha, França e a República Popular da China também desenvolveram capacidades nucleares, realisticamente posando como ameaça de aniquilação da raça humana pela primeira vez na história.
Um grupo de países, os países não alinhados, optou por manter uma posição de neutralidade durante a Guerra Fria
Desejando assegurar tal neutralidade, estes promoveram a criação do Movimento Não Alinhado.
A Guerra Fria foi nomeada assim porque as duas superpotências opositoras nunca lutaram diretamente entre si
A guerra entre as duas potências poderia ter sido apocalíptica; a ameaça de uma destruição mútua certa preveniu as duas potências de iniciar um conflito aberto
Ao contrário, eles competiram por influência política e focaram em corrida armamentista e corrida espacial.
Também lutaram entre si indiretamente através de guerras por procuração, tais como a Guerra do Vietnã e a Guerra do Afeganistão
A Europa foi transformada em terra de ninguém de nações aliadas
Os Estados Unidos fundaram a Organização do Tratado do Atlântico Norte (OTAN) com a intenção de organizar as nações capitalistas da Europa Ocidental na resistência aos soviéticos.
Em resposta, a União Soviética instalou regimes comunistas em países na Europa Oriental que haviam sido ocupados ao final da II Guerra Mundial, criou o Comecon (Conselho para Assistência Econômica Mútua) e organizou estes países no Pacto de Varsóvia
A URSS também construiu o Muro de Berlim para servir como uma barreira entre a Berlim Ocidental, ocupada pela OTAN e Berlim Oriental, ocupada pelos soviéticos
O território alemão também foi dividido entre Alemanha Ocidental e Alemanha Oriental juntamente com as zonas de ocupação do final da guerra (ver: Zona de ocupação soviética na Alemanha e Zonas ocupadas pelos Aliados na Áustria)
Esta divisão deu vida ao discurso de Winston Churchill sobre a Cortina de Ferro, na qual ele proclamou que "Uma cortina de ferro caiu sobre a Europa."
Duas guerras e uma terceira quase-guerra na primeira década do século se tornaram o foco da batalha do capitalismo versus comunismo
A primeira foi a Guerra da Coreia, luta entre a Coreia do Norte, apoiada pela República Popular da China, e a Coreia do Sul, apoiada pelos Estados Unidos
A invasão da Coreia do Norte na do Sul levou à intervenção dos Estados Unidos
O general Douglas MacArthur liderou as tropas americanas, e do Canadá, Austrália, Grã-Bretanha e outros países em repelir a invasão do Norte
Contudo, a guerra chegou a um impasse depois que a intervenção chinesa empurrou as forças da ONU de volta, e um cessar-fogo terminou as hostilidades, deixando as duas Coreias divididas e tensas pelo resto do século.
A Guerra do Vietnã é provavelmente a segunda guerra mais visível do século XX, após a Segunda Guerra Mundial
Após a retirada francesa de sua antiga colônia, o Vietnã se partiu em duas metades, assim como a Coreia
Conflito entre Norte e Sul acabou por tornar-se uma guerra regional
Os Estados Unidos forneceram ajuda para o Vietnã do Sul, mas não foi diretamente envolvido até que a Resolução do Golfo de Tonkin, aprovada em reação a um suposto ataque norte-vietnamita aos contratorpedeiros norte-americanos, trouxe os Estados Unidos à guerra como beligerante.
A guerra foi inicialmente vista como uma batalha para conter o comunismo (ver Doutrina Truman, Contenção e Teoria do Dominó), mas, conforme mais norte-americanos eram convocados e notícias de eventos como a Ofensiva do Tet e o massacre de My Lai vazaram, o sentimento norte-americano se voltou contra a guerra
O Presidente dos Estados Unidos Richard Nixon foi eleito em parte devido a uma promessa de um "plano secreto" para parar com a guerra.
Esta Doutrina Nixon envolveu uma retirada gradual de forças norte-americanas; Unidades sul-vietnamitas deveriam substituí-las, com a cobertura de poder aéreo norte-americano
Mas o plano não foi bem sucedido, e a guerra espalhou-se para o vizinho Camboja enquanto forças sul-vietnamitas foram empurradas mais ainda
Com o tempo, os Estados Unidos e o Vietnã do Norte assinaram os Acordos de Paz de Paris, encerrando o envolvimento dos Estados Unidos na guerra
Sem a ameaça da retaliação dos Estados Unidos, o Norte continuou a violar o cessar-fogo e invadiu o Sul com força militar total
Saigão foi capturada em 30 de abril de 1975, e o Vietnã foi unificado sob um governo comunista um ano mais tarde, efetivamente trazendo um final a uma das guerras mais impopulares de todos os tempos.
A crise dos mísseis de Cuba ilustrou quão próximo se esteve de entrar em uma guerra nuclear durante a Guerra Fria
Cuba, sob o governo socialista de Fidel Castro, firmou laços fortes com a União Soviética
Isto obviamente inquietou os Estados Unidos, devido a proximidade de Cuba
Quando o avião espião Lockheed U-2 voou sobre a ilha revelando que lançadores de misseis soviéticos estavam sendo instalados, o Presidente dos Estados Unidos, John F
Kennedy, instituiu um bloqueio naval e publicamente confrontou a União Soviética
Depois de uma semana tensa, a União Soviética voltou atrás e mandou removerem os lançadores, não querendo o risco de iniciar uma nova guerra mundial.
John F
Kennedy
Cenas da Guerra do Vietnã.
Prisioneiro vietcongue em 1967.
Soldado vietcongue em 1968.
Com as tensões da Guerra Fria correndo soltas, a União Soviética e os Estados Unidos levaram sua rivalidade às estrelas em 1957 com o lançamento soviético da Sputnik 1
Uma "corrida espacial" entre as duas potências se seguiu
Apesar da URSS ter alcançado diversos feitos importantes, como a primeira nave na Lua (Luna 2) e o primeiro humano no espaço (Yuri Gagarin), os Estados Unidos acabaram alcançando a dianteira com seus programas Mercury, Gemini e Apollo, que culminaram no pouso tripulado da Apollo 11 na Lua
Cinco outros pousos tripulados deram sequência (Apollo 13 foi forçado a abortar a missão)
Em adição, ambos os países lançaram inúmeras sondas no espaço, como a Venera 7 e Voyager 2.
Nas décadas seguintes, o espaço tornou-se um lugar um tanto quanto mais amigável
Voos espaciais tornaram-se possíveis com o ônibus espacial norte-americano, que foi a primeira espaçonave reutilizável a ser usada com sucesso
A Mir e Skylab permitiram uma habitação humana prolongada no espaço
Na década de 1980, ocorreram tentativas de militarizar o espaço: o presidente dos EUA, Ronald Reagan, propôs o projeto de armas espaciais "Guerra nas Estrelas" (Iniciativa Estratégica de Defesa), para construir um sistema de defesa antimísseis orbital
Em resposta, a URSS desenvolveu o Polyus, uma estação de combate espacial
Nos anos 1990, o trabalho na Estação Espacial Internacional começou.
A criação do transistor revolucionou o desenvolvimento do computador
Os primeiros computadores, aparelhos eletromecânicos do tamanho de um quarto construídos para quebrar códigos criptográficos durante a II Guerra Mundial, se tornaram mais poderosos (ver: Enigma e Ultra)
Computadores tornaram-se reprogramáveis ao invés de aparelhos de um propósito fixo.
A invenção da linguagem de programação significava que os operadores de computador poderiam se concentrar em solução problemas em um alto nível, sem ter que pensar em termos de instruções individuais para o próprio computador.
A criação de sistemas operacionais ou sistemas operativos também desenvolveu muito a produtividade da programação
Arquitetando nisso, os pioneiros do computador podiam agora perceber o que eles tiveram visão
A interface gráfica, pilotada por um mouse de computador tornou simples o aproveitamento do potencial do computador
O armazenamento para programas de computador progrediu de cartões perfurados e fita de papel a fita magnética, discos flexíveis e discos rígidos
Memória magnética e memória de bolha acabaram como memória de acesso aleatório (RAM).
A invenção do processador de texto, da folha de planilha e a database aprimoraram muito a produtividade sobre o antigo papel, máquina de escrever e gabinetes
A vantagem econômica dada às empresas levou a eficiências econômicas nos próprios computadores
CPUs mais econômicos levaram a centenas de empresas e designs caseiros de computadores; o computador caseiro estourou, liderado pelo Apple II, o ZX80, o Commodore PET e o MSX.
IBM, pensando em que o futuro agora estava em computadores individuais ao invés de enormes terminais presos a um mainframe, desenvolveram seu IBM Personal Computer
Crucialmente, a IBM fez todas as especificações de seu computador abertas ao invés de privadas, com exceção da BIOS
Como o único impedimento para um sistema aberto com desenvolvedores interdisciplinares era a BIOS, foi realizada uma engenharia reversa pela Compaq, e o PC IBM se tornou o primeiro sistema de computadores completamente aberto, levando-o ao seu atual domínio do mercado
Aproveitando esta onde de popularidade, os vendedores do sistema operacional do PC (Microsoft) levantaram-se para ocupar o espaço de empresa de software mais poderosa do mundo.
A década de 1980 foi considerada a Era da Informação
A ascensão de aplicativos de computador e processamento de dados transformou "informação" etérea tão preciso como comodidades físicas
Isto trouxe o espectro de "Propriedade Intelectual", aonde pessoas e companhias lutariam pelo controle de simples fatos e ideias, motivados pela nova economia focada nestas coisas
O governo dos Estados Unidos fez algoritmos patenteáveis, formando a base de Patente de Software
A controvérsia disto e de Propriedade de Software levou Richard Stallman a criar a Free Software Foundation, e começar o Projeto GNU.
Computadores também viraram uma plataforma de entretenimento
Jogos de Computador foram desenvolvidos por programadores de software exercitando sua criatividade em grandes sistemas em universidades, mas estes esforços só foram comercialmente vitoriosos com jogos de arcade como "PONG" e "Space Invaders"
Uma vez que o mercado de computadores pessoais estava estabilizado, jovens programadores em seus quartos criaram a essência da indústria de jogos para jovens
Para conseguir vantagem em tecnologia avançada, jogos de console foram criados
Como sistemas de arcade, estas máquinas tinha hardware especializado desenhado para operações de jogos (como sprites e movimento paralaxe) ao invés de tarefas de computadores comuns.
Redes de computadores apareceram em dois grandes estilos: a LAN (Local Area Network), ligando computadores em um escritório ou escola entre eles, e a WAN (Wide Area Network), ligando as LANs e unindo-as
Inicialmente, computadores dependiam de redes de telefone para se linkarem, fazendo surgir a subcultura dos Bulletin Boards
Entretanto, um projeto DARPA para criar redes de computadores a prova de bomba levaram a criação da Internet, uma rede de redes
A base desta rede era o robusto protocolo de rede TCP/IP
Graças aos esforços de Al Gore, a Internet cresceu além de seu papel militar quando universidades e empresas comerciais ganharam permissão para conectar suas redes a ela.
O maior ímpeto foi o correio eletrônico, uma forma muito mais rápida e conveniente de comunicação do que a carta convencional e a distribuição de memorandos
Entretanto, a Internet continuou um "segredo bem guardado" para o público geral, que estavam acostumados com Bulletin Boards e serviços como Compuserve e America Online
Isto mudou quando Tim Berners-Lee desenvolveu uma forma mais simples do hipertexto de Vannevar Bush, que criou a World Wide Web
A "teia" subitamente transformou a Internet numa imprensa além das barreiras geográficas de países físicos; foi chamado cyberespaço
Qualquer um com um computador e conexão com a Internet poderia fazer páginas em simples formato HTML e publicar suas ideias ao mundo.
O imenso sucesso da rede também deu combustível ao comércio pela Internet
Compras em casa sempre foram um elemento de "visões do futuro" desde o desenvolvimento do telefone, mas agora a competição era para prover consumismo conveniente e interativo
Companhias de comércio através de websites ficaram conhecidas como "Ponto Com" devido ao sufixo ".com" de endereço comercial de Internet.
A falta de democracia, o atraso econômico e a crise nas repúblicas soviéticas acabaram por acelerar a crise do socialismo no final da década de 1980 (ver: Revoluções de 1989)
Em 1989 cai o Muro de Berlim e as duas Alemanhas são reunificadas
No começo da década de 1990, o então presidente da União Soviética Gorbachev começou a acelerar o fim do socialismo naquele país e nos aliados (ver: Previsões de colapso da União Soviética)
Com reformas econômicas (Perestroika), acordos com os Estados Unidos e mudanças políticas (Glasnost), o sistema foi se enfraquecendo
Iniciava-se o colapso econômico da União Soviética
Era o fim de um período de embates políticos, ideológicos e militares
O capitalismo vitorioso, aos poucos, iria sendo implantado nos países socialistas.
Ao final do século XX, o mundo estava em grandes encruzilhadas
Ao longo do século, mais avanços tecnológicos foram feitos do que em toda a história precedente
Computadores, a Internet e outras tecnologias alteraram radicalmente o cotidiano
Contudo, muitos problemas desafiam o mundo.
Primeiramente, a diferença entre as nações ricas e as pobres continua a crescer
Alguns dizem que esse problema não pode ser resolvido, que havia uma quantidade específica de riqueza e só poderia ser dividida entre esse tanto
Outros dizem que nações poderosas com grandes economias não estão fazendo o suficiente para rapidamente desenvolver as economias do Terceiro Mundo
Contudo, países em desenvolvimento desafiam muitas questões, incluindo a quantidade de tarefas a serem resolvidas, populações com grande crescimento e a necessidade de proteger o meio ambiente, e o custo que isso gera.
Em segundo lugar, doenças ameaçam desestabilizar muitas regiões do mundo
Novos vírus como o SARS, Nilo Ocidental e Gripe das aves continuaram a se espalhar rápida e facilmente
Em nações pobres, a malária e outras doenças afetam a maioria da população
Milhões são infectados com o VIH, o vírus que causa a SIDA
O vírus tornou-se uma epidemia no sul da África.
Globalização crescente, especificamente uma Americanização, também estava ocorrendo
Apesar de não ser necessariamente uma ameaça, causa sentimentos anti-Ocidente e antiamericano em partes do mundo, especialmente o Oriente Médio
O inglês rapidamente tornou-se uma lígua global, com os povos que não o falam tornando-se crescentemente em desvantagem.
Terrorismo, ditaduras e o crescimento de países com armas nucleares também são questões que requerem atenção imediata
Maior quantidade de guerras, com o fim da era dos combustíveis fósseis se aproximando, são esperadas
Ditadores como Kim Jong-un na Coreia do Norte e o Aiatolá Ali Khamenei no Irão continuam a liderar suas nações rumo a desconfiança nacional pelo possível desenvolvimento de armas nucleares
O medo existente não era de que os terroristas já estivessem tentando conseguir armas nucleares, mas que eles já tivessem as obtido.
Metabolismo (do grego metabolismos, μεταβολισμός, que significa "mudança", troca) é o conjunto de transformações que as substâncias químicas sofrem no interior dos organismos vivos
O termo "metabolismo celular" é usado em referência ao conjunto de todas as reações químicas que ocorrem nas células
Estas reacções são responsáveis pelos processos de síntese e degradação dos nutrientes na célula e constituem a base da vida, permitindo o crescimento e reprodução das células, mantendo as suas estruturas e adequando respostas aos seus ambientes.
As reações químicas do metabolismo estão organizadas em vias metabólicas, que são sequências de reacções em que o produto de uma reacção é utilizado como reagente na reacção seguinte
Diferentes enzimas catalisam diferentes passos de vias metabólicas, agindo de forma concertada de modo a não interromper o fluxo nessas vias
As enzimas são vitais para o metabolismo porque permitem a realização de reacções desejáveis mas termodinamicamente desfavoráveis, ao acoplá-las a reacções mais favoráveis
As enzimas regulam as vias metabólicas em resposta a mudanças no ambiente celular ou a sinais de outras células.
O metabolismo é normalmente dividido em dois grupos: anabolismo e catabolismo
Reacções anabólicas, ou reacções de síntese, são reacções químicas que produzem nova matéria orgânica nos seres vivos
Sintetizam-se novos compostos (moléculas mais complexas) a partir de moléculas simples (com consumo de energia sob a forma de ATP)
Reacções catabólicas, ou reacções de decomposição/degradação, são reacções químicas que produzem grandes quantidades de energia (ATP) a partir da decomposição ou degradação de moléculas mais complexas (matéria orgânica)
Quando o catabolismo supera em atividade o anabolismo, o organismo perde massa, o que acontece em períodos de jejum ou doença; mas se o anabolismo superar o catabolismo, o organismo cresce ou ganha massa
Se ambos os processos estão em equilíbrio, o organismo encontra-se em equilíbrio dinâmico ou homeostase
O metabolismo é fundamentalmente estudado pela Bioquímica, usando muitas vezes também técnicas ligadas à Biologia Molecular e à Genética.


O metabolismo de um organismo determina quais substâncias são nutricionais e quais são tóxicas
Por exemplo, alguns procariontes utilizam ácido sulfídrico como nutriente; este gás é no entanto venenoso para animais
A velocidade a que se processa o metabolismo, determinada pela taxa metabólica, também influencia a quantidade de alimento requerida por um organismo.
Uma característica do metabolismo é a semelhança de vias metabólicas básicas entre espécies muito diferentes
Por exemplo, o conjunto de intermediários reacionais encontrados no ciclo dos ácidos tricarboxílicos é encontrado de forma universal, em células tão diferentes como a bactéria Escherichia coli ou o elefante
Esta estrutura metabólica semelhante está provavelmente associada à grande eficiência dessas vias e na sua antiguidade na história da evolução.
A história do estudo científico do metabolismo estende-se por quatro séculos, tendo evoluído da observação de organismos animais inteiros até ao estudo de reacções metabólicas individuais na Bioquímica moderna
As primeiras experiências conduzidas de forma controlada foram publicadas por Santorio Santorio em 1614 no seu livro Ars de statica medecina
Neste, Santorio descreveu como determinou o seu próprio peso antes e depois de comer, beber, dormir, trabalhar, ter relações sexuais, jejuar e excretar
Ele descobriu que a maior parte da comida ingerida era perdida no que ele chamou de "perspiração insensível".
Nestes estudos iniciais, os mecanismos destes processos metabólicos não eram conhecidos; pensava-se que o tecido vivo era animado por uma "força vital".
No século XIX, enquanto estudava a fermentação do açúcar a álcool por leveduras, Louis Pasteur concluiu que a fermentação era catalisada por substâncias dentro das células de levedura, a que ele chamou de "fermentos"
Pasteur escreveu que "a fermentação alcoólica é um acto correlacionado com a vida e organização das células de levedura, não com a morte ou putrefacção das células."  Esta descoberta, junto com a publicação da síntese química da ureia por Friedrich Wöhler em 1828, provou que os compostos orgânicos e as reacções químicas existentes nas células partilham o mesmo princípio que qualquer outra área da Química.
A descoberta das enzimas no início do século XX, por Eduard Buchner, separou o estudo das reacções químicas do metabolismo do estudo biológico das células, marcando o início da Bioquímica como ciência independente
A quantidade de conhecimento bioquímico cresceu rapidamente durante o início do século XX
Um dos bioquímicos mais prolíficos dessa época foi Hans Krebs, que fez diversas contribuições no estudo do metabolismo
Ele descobriu o ciclo da ureia e, mais tarde, junto com Hans Kornberg, o ciclo dos ácidos tricarboxílicos (também conhecido por esta razão como ciclo de Krebs) e o ciclo do glioxilato.
A investigação bioquímica moderna tem sido ajudada com a invenção e desenvolvimento de diversas técnicas, como a cromatografia, a difracção de raios X, a espectroscopia de ressonância magnética nuclear, a marcação isotópica, a microscopia electrónica e simulações de dinâmica molecular
Estas técnicas permitiram a descoberta e análise detalhada de diversas moléculas e vias metabólicas nas células.
A maioria das estruturas que compõem os seres vivos é fabricada a partir de três classes básicas de moléculas: aminoácidos, glícidos e lípidos
Como estas moléculas são vitais, o metabolismo concentra-se na fabricação destas, na construção de células e tecidos ou na sua degradação para uso como fonte de energia
Muitos compostos bioquímicos podem ser ligados entre si formando polímeros, como o ADN e as proteínas
Estas macromoléculas são parte essencial de todos os organismos vivos.
Alguns dos polímeros mais comuns estão listados abaixo:
As proteínas são compostas por aminoácidos dispostos numa cadeia linear e ligados entre si por ligações peptídicas
Muitas proteínas são as enzimas que catalisam as reacções químicas no metabolismo
Outras proteínas têm funções estruturais ou mecânicas, como o sistema de armação celular usado para manter a forma da célula, o citoesqueleto.
As proteínas têm também papéis importantes na sinalização celular, resposta imunitária, adesão celular, transporte activo através de membranas e no ciclo celular.
Os lípidos são o grupo mais diversificado de compostos bioquímicos
Constituem grande parte das membranas biológicas, tais como a membrana celular; além desta função estrutural, também servem como fonte de energia
Os lípidos são normalmente definidos como moléculas biológicas hidrofóbicas ou anfipáticas solúveis em solventes orgânicos como o benzeno ou o clorofórmio.
As gorduras são um grupo alargado de compostos que inclui os ácidos gordos e o glicerol; uma molécula de glicerol ligada a três ácidos gordos por uma ligação éster é um triacilglicerol
Existem diversas variações desta estrutura básica, por exemplo a presença de esfingosina em esfingolípidos e grupos hidrofílicos como o fosfato nos fosfolípidos.
Os esteróides, como o colesterol, são outro grupo significativo de lípidos sintetizados em células.
Os glícidos são aldeídos ou cetonas contendo diversos grupos funcionais hidroxilo
Os glícidos simples podem existir numa forma linear ou numa forma cíclica
São as moléculas biológicas mais abundantes e possuem funções muito diversificadas, como o armazenamento e transporte de energia (sob a forma de amido e glicogénio) e construção de elementos estruturais (como a celulose em plantas e a quitina em animais).
Os glícidos mais simples são os monossacarídeos, que incluem a galactose, a frutose e a glicose
Os monossacarídeos podem formar polímeros designados polissacarídeos de formas muito diversas.
Os polímeros ADN e ARN são longas cadeias de nucleótidos
Estas macromoléculas são essenciais no armazenamento e uso da informação genética, através dos processos de transcrição e síntese proteica
Esta informação é protegida por mecanismos de reparação do ADN e propagada através da replicação do ADN
Alguns vírus têm um genoma constituído por ARN (por exemplo, o HIV), e usam transcrição reversa para sintetizar ADN a partir desse ARN.
O ARN de ribozimas (como o spliceossoma) apresenta actividade enzimática tal como as enzimas proteicas, pois pode catalisar reacções químicas.
Os nucleósidos são sintetizados a partir da ligação de uma base azotada a uma ribose
Estas bases são anéis heterocíclicos contendo azoto, classificados como purinas ou pirimidinas
Os nucleótidos também actuam como coenzimas em reacções de transferência de grupos químicos.
O metabolismo envolve um vasto conjunto de reacções químicas, mas a maioria cai dentro de alguns tipos básicos de transferências de grupos funcionais
Esta química comum permite às células usarem um conjunto relativamente pequeno de intermediários metabólicos no transporte de grupos químicos de uma reacção para a seguinte
Estes intermediários de transferência de grupos são as coenzimas
Cada classe de reacção de transferência de grupos corresponde a uma determinada coenzima, servindo de substrato para um conjunto de enzimas que a produz e que a consome
Assim, as coenzimas são continuamente produzidas, consumidas e então recicladas.
A coenzima mais central é o trifosfato de adenosina (ATP), a moeda de troca energética universal das células
O ATP é utilizado para transferir energia química entre diferentes reacções químicas
Existe uma pequena quantidade de ATP permanentemente presente nas células, mas como é constantemente regenerado, o corpo humano é capaz de utilizar o seu peso em ATP por dia
O ATP age como uma ponte entre catabolismo e anabolismo, tendo as reacções catabólicas como produtoras de ATP e as anabólicas como consumidoras
Também serve como um transportador de grupos fosfato em reacções de fosforilação.
As vitaminas são compostos orgânicos necessários em pequenas quantidades e que não podem ser sintetizados pelas células
Na nutrição humana, a maioria das vitaminas funciona como coenzimas após sofrerem uma modificação química; por exemplo, todas as vitaminas hidrossolúveis são fosforiladas ou ligadas a nucleótidos para a sua utilização intracelular
O dinucleótido de nicotinamida-adenina (NADH), um derivado da vitamina B3 (niacina), é uma coenzima importante que age como aceitador de hidrogénio
Centenas de diferentes tipos de desidrogenases retiram electrões dos seus substratos e reduzem NAD a NADH
Esta forma reduzida da coenzima é então substrato para redutases celulares que necessitem de reduzir os seus substratos
O dinucleótido de nicotinamida-adenina existe também sob uma forma fosfatada, NADPH
O par redox NAD/NADH é mais importante no catabolismo, enquanto que o par NADP/NADPH é mais usado no anabolismo.
Cerca de 99% da massa dos mamíferos é constituída pelos elementos carbono, azoto, hidrogénio, oxigénio, cálcio, magnésio, sódio, potássio, cloro e enxofre
Destes, são considerados "inorgânicos" os metais, o enxofre e o cloro
Enquanto que alguns dos elementos inorgânicos são abundantes em sistemas vivos (como o sódio e o potássio), outros encontram-se em quantidades vestigiais
Os compostos orgânicos (proteínas, lípidos, glícidos) contêm a maioria do carbono e azoto; a maioria do oxigénio e hidrogénio encontra-se sob a forma de água.
Os elementos inorgânicos mais abundantes actuam como electrólitos
Os iões mais importantes são o sódio, potássio, cálcio, magnésio, cloreto, fosfato e o ião orgânico bicarbonato
A existência de gradientes iónicos através de membranas celulares mantém a pressão osmótica e o pH
Os iões são também vitais para nervos e músculos, pois os potenciais de acção usados nestes tecidos são produzidos através da troca de electrólitos entre o fluido extracelular e o citoplasma
Os electrólitos entram e saem das células através de proteínas transmembranares denominadas canais iónicos
Por exemplo, a contracção muscular depende do movimento de cálcio, sódio e potássio através de canais iónicos na membrana celular e túbulos-T.
Os metais de transição são normalmente elementos vestigiais em organismos, sendo o zinco e o ferro os mais abundantes
Estes metais são usados por algumas proteínas como cofactores e são essenciais para a actividade de metaloenzimas como a catalase e proteínas de transporte de dioxigénio como a hemoglobina
Tais metais actuam como cofactores quer estando ligados directamente à cadeia polipeptídica, quer estejam integrados em moléculas orgânicas complexas que por sua vez se encontram ligadas à cadeia polipeptídica
Os cofactores sofrem modificações durante a catálise enzimática mas voltam sempre ao seu estado inicial no fim de um ciclo catalítico
Os metais de transição são absorvidos pelos organismos usando transportadores específicos e ligam-se a proteínas de armazenamento como a ferritina e a metalotioneína quando não é necessária a sua disponibilidade para intervir no metabolismo.
O catabolismo é o conjunto das reacções metabólicas que libertam energia
Tais reacções incluem a degradação e oxidação de moléculas encontradas em alimentos, assim como reacções que captam a energia luminosa da luz solar
As reacções catabólicas providenciam energia e componentes necessários às reacções anabólicas
A natureza exacta destas reacções catabólicas difere de organismo para organismo: organismos organotróficos usam moléculas orgânicas como fonte de energia, enquanto litotróficos usam substratos inorgânicos e fototróficos captam energia solar, transformando-a em energia química.
Todas estas diferentes formas de metabolismo dependem de reacções redox que envolvem a transferência de electrões de moléculas doadoras reduzidas, como moléculas orgânicas, água, amoníaco, ácido sulfídrico ous iões ferrosos (Fe), para moléculas aceitadoras, como o dioxigénio (O2), o nitrato (NO3) ou o sulfato (SO4)
Em animais, estas reacções envolvem a degradação de moléculas orgânicas complexas a moléculas mais simples, como dióxido de carbono (CO2) e água (H2O)
Em organismos fotossintéticos, como as plantas e cianobactérias, estas reacções de transferência electrónica não libertam energia, sendo antes utilizadas como forma de armazenar energia absorvida da luz solar.
O conjunto de reacções catabólicas mais comum em animais pode ser separado em três etapas diferentes
Na primeira etapa, moléculas orgânicas complexas como as proteínas, polissacarídeos ou lípidos são degradados nos seus componentes fora das células
Na etapa seguinte, estas moléculas de menor tamanho são importadas pelas células e convertidas a moléculas menores, normalmente o acetil-CoA, num processo que liberta energia
Na última etapa, o grupo acetilo do acetil-CoA é oxidado a água e dióxido de carbono, libertando energia que é armazenada através da redução da coenzima dinucleótido de nicotinamida-adenina, NAD, a NADH.
Macromoléculas como o amido ou as proteínas não podem ser rapidamente assimilados pelas células, tendo de ser degradados nos seus componentes de menor tamanho antes de poderem ser utilizados no metabolismo celular
A digestão destes polímeros é feita por diversas classes de enzimas
Estas enzimas digestivas incluem as proteases, que digerem proteínas a aminoácidos, e glicosídeo hidrolases, que digerem polissacarídeos a monossacarídeos.
Os microorganismos excretam enzimas digestivas para o ambiente ao seu redor, enquanto que os animais segregam estas enzimas em células especializadas do sistema digestivo
Os aminoácidos ou açúcares libertados por estas enzimas extracelulares são então assimiladas pelas células através de proteínas específicas usando transporte activo.
O catabolismo de glícidos consiste na degradação de glícidos complexos em unidades de menor tamanho
Os glícidos são normalmente assimilados pelas células após a sua digestão a monossacarídeos
Após entrada na célula, a principal via de degradação é a glicólise, em que açúcares como a glucose e a frutose são convertidos a piruvato, com formação em simultâneo de ATP
O piruvato é um intermediáro de diversas vias metabólicas, mas a maioria é convertida a acetil-CoA, que entra no ciclo dos ácidos tricarboxílicos (ciclo de Krebs)
Embora haja mais alguma formação de ATP neste ciclo, o produto principal deste é o NADH, resultante da redução do NAD quando o acetil-CoA é oxidado
Esta oxidação liberta dióxido de carbono (CO2)
Uma via alternativa de degradação da glicose é a Via das pentoses-fosfato, que reduz a coenzima NADPH e produz pentoses como a ribose, o açúcar componente dos ácidos nucleicos.
As gorduras são catabolizadas por hidrólise a ácidos gordos livres e glicerol
O glicerol entra na glicólise e os ácidos gordos são degradados por beta-oxidação a acetil-CoA, que entra então no ciclo dos ácidos tricarboxílicos
Devido à sua grande proporção de grupos metileno e pelo facto de os glícidos possuirem mais oxigénio nas suas estruturas químicas, os ácidos gordos libertam mais energia que os glícidos quando oxidados.
Os aminoácidos são utilizados na síntese de proteínas e outras biomoléculas, ou oxidados a ureia e dióxido de carbono para obtenção de energia
A via de oxidação começa com a remoção do grupo amina por uma transaminase, deixando um esqueleto de carbono sob a forma de um cetoácido; o grupo amina é então metabolizado no ciclo da ureia
Vários cetoácidos obtidos através da desaminação de aminoácidos são também intermediários no ciclo dos ácidos tricarboxílicos: por exemplo, a desaminação do glutamato forma α-cetoglutarato
Os aminoácidos glucogénicos também podem ser convertidos a glicose, através da gluconeogénese.
Na fosforilação oxidativa, os electrões obtidos na oxidação de moléculas em diversas vias metabólicas, como por exemplo o ciclo dos ácidos tricarboxílicos, são transferidos para o dioxigénio, e a energia libertada é usada na produção de ATP
Em eucariontes, este processo é feito por uma série de proteínas, a cadeia de transporte electrónico, que se encontram nas membranas mitocondriais
Em procariontes, estas proteínas encontram-se na membrana celular interna
Estas proteínas utilizam a energia obtida da oxidação de NADH para transportar protões através da membrana.
O transporte de protões para o exterior da mitocôndria cria uma diferença de concentração de protões entre os dois compartimentos, criando um gradiente electroquímico
A presença deste gradiente força os protões a regressarem ao interior da mitocôndria através da ATP sintase
O fluxo de protões provoca a rotação da subunidade inferior da ATP sintase, o que causa a fosforilação de difosfato de adenosina (ADP) a trifosfato de adenosina (ATP).
A quimiolitotrofia é um tipo de metabolismo encontrado em procariontes, em que a energia é obtida a partir da oxidação de compostos inorgânicos
Estes organismos podem usar hidrogénio, compostos reduzidos de enxofre (como sulfuretos, ácido sulfídrico e tiossulfato), óxidos de ferro (II), ou amoníaco como fontes de agentes redutores, ganhando energia a partir da oxidação destes compostos com aceitadores de electrões como o oxigénio ou o nitrito
Estes processos microbiológicos são importantes em ciclos biogeoquímicos como a acetogénese, a nitrificação e a desnitrificação e são de importância crítica para a fertilidade do solo.
A energia da luz solar é captada por plantas, cianobactérias, alguns tipos de bactérias e de protistas
Este processo está frequentemente associado à fixação de dióxido de carbono em compostos orgânicos, que é um processo integrante da fotossíntese
Os sistemas de captura de energia e de fixação de carbono podem trabalhar separadamente em procariontes, como acontece com as bactérias púrpura e as bactérias verdes sulfurosas
Estas bactérias usam a luz solar como fonte de energia mas alternam o seu metabolismo entre a fixação de carbono e a fermentação de compostos orgânicos.
A captação de energia solar é um processo semelhante à fosforilação oxidativa, pois ambos os processos envolvem o armazenamento de energia sob a forma de um gradiente de protões, que leva à síntese de ATP
No caso da fotossíntese, os electrões necessários para o funcionamento da cadeia de transporte electrónico provêm de proteínas colectoras de luz denominadas centros reaccionais fotossintéticos
Estas estruturas dividem-se em dois tipos dependendo do pigmento fotossintético presente; a maioria das bactéria fotossintéticas possui apenas um tipo de centro, enquanto as plantas e as cianobactérias possuem dois.
Em plantas, o fotossistema II usa energia luminosa para remover electrões da água, libertando oxigénio no processo
Os electrões movem-se então para o complexo do citocromo b6f, que usa a sua energia para transportar protões através das membranas dos tilacóides nos cloroplastos
Estes protões regressam ao interior dos tilacóides através da ATP sintase, num processo semelhante ao descrito nas mitocôndrias
Estes electrões podem então entrar no fotossistema I e ser utilizados na redução de NADP, no ciclo de Calvin ou reciclados para gerar ainda mais ATP.
O anabolismo é o conjunto de reacções metabólicas de síntese em que a energia libertada pelo catabolismo é utilizada para construir moléculas complexas
Em geral, as moléculas complexas que constituem estruturas celulares são construídas passo a passo a partir de precursores mais simples
O anabolismo divide-se em três etapas fundamentais:
Os organismos diferem entre si na quantidade de diferentes moléculas que conseguem sintetizar
Os seres autotróficos, como as plantas, podem construir moléculas complexas (polissacarídeos e proteínas) a partir de moléculas muito simples como o dióxido de carbono e a água
Os seres heterotróficos necessitam de fontes alimentares para providenciar monossacarídeos e aminoácidos, para poder produzir macromoléculas
Os organismos podem ainda ser classificados segundo a fonte primária da sua energia: fotoautotróficos e foto-heterotróficos obtém energia a partir da luz solar, enquanto que organismos quimioautotróficos e quimio-heterotróficos obtêm energia a partir de reacções de oxidação.
A fotossíntese é o processo em que ocorre síntese de glicose a partir da luz solar, dióxido de carbono e água, havendo produção de oxigénio
Este processo utiliza ATP e NADPH produzido pelos centros reaccionais fotossintéticos para converter CO2 em glicerol-3-fosfato, que pode ser então convertido a glicose
Esta reacção de fixação de carbono é catalisada pela enzima RuBisCO e é parte integrante do ciclo de Calvin
Ocorrem três tipos de fotossíntese em plantas: fixação de carbono em plantas C3, fixação de carbono em plantas C4 e fotossíntese CAM
Estes tipos de fotossíntese diferem na via que o CO2 toma até ao ciclo de Calvin: as plantas C3 fixam o CO2 directamente, enquanto que as C4 e CAM incorporam-no noutros compostos de forma a adaptar a condições de alta luminosidade e dessecação
Algas e plantas aquáticas usam organelas chamadas pirenóides.
Os mecanismos de fixação de carbono em procariontes fotossintéticos são mais diversificados
O CO2 pode ser fixado através do ciclo de Calvin, de um ciclo dos ácidos tricarboxílicos inverso ou através da carboxilação do acetil-CoA
Procariontes quimioautotróficos também utilizam o ciclo de Calvin para a fixação de carbono mas a energia usada nas reacções provém de compostos inorgânicos.
No anabolismo de glícidos, ácidos orgânicos simples podem ser convertidos a monossacarídeos como a glicose, sendo então usados para sintetizar polissacarídeos como o amido
A produção de glicose a partir de compostos como o piruvato, o lactato, o glicerol, o glicerol-3-fosfato e aminoácidos é chamada gluconeogénese
Na gluconeogénese, o piruvato é convertido a glicose-6-fosfato usando diversos intermediários, muitos deles comuns à glicólise
No entanto, esta via não se resume a uma inversão da glicólise, pois diversos passos são catalisados por enzimas não-glicolíticas
Este é um aspecto importante pois permite a regulação separada da formação e da degradação da glicose, evitando que ambas as vias funcionem em simultâneo num ciclo fútil.
Embora a gordura seja um modo comum de armazenamento de energia, em vertebrados, como os humanos, os ácidos gordos não podem ser convertidos a glicose através da gluconeogénese, pois estes organismos são incapazes de transformar acetil-CoA em piruvato
Por essa razão, após um longo jejum os vertebrados necessitam de produzir corpos cetónicos a partir de ácidos gordos para substituir a glicose em falta em tecidos e órgãos que não conseguem metabolizar ácidos gordos, como o cérebro
Noutros organismos, como plantas e bactérias, este problema metabólico é ultrapassado utilizando o ciclo do glioxilato, que evita o passo de descarboxilação no ciclo dos ácidos tricarboxílicos e permite a transformação de acetil-CoA a oxaloacetato, que pode ser então utilizado na produção de glicose.
Os polissacarídeos e os glicanos são sintetizados através da adição sequencial de monossacarídeos, catalisada por glicosiltransferases, de um doador de açúcar fosforilado como o difosfato de uridina-glicose (UDP-glicose) para um grupo hidroxilo aceitador no polissacarídeo nascente
Como qualquer um dos grupos hidroxilo da estrutura do substrato podem ser aceitadores, os polissacarídeos podem ter estruturas lineares ou ramificadas.
Os polissacarídeos podem desempenhar funções estruturais ou metabólicas, podendo também ser transferidos para lípidos e proteínas pelas enzimas oligossacariltransferases.
Os ácidos gordos são sintetizados pelas sintases de ácido gordo, que polimerizam e reduzem unidades de acetil-CoA
As cadeias acilo dos ácidos gordos são aumentadas através de um ciclo de reacções que adicionam o grupo acilo, reduzem-no à forma álcool, desidratam este a um grupo alceno, sendo este finalmente reduzido a um grupo alcano
As enzimas envolvidas na biossíntese de ácidos gordos encontram-se divididas em dois grupos: em animais e fungos todas estas reacções são catalisadas por uma proteína multifuncional (tipo I), enquanto que em plantas e bactérias diferentes enzimas catalisam as diversas reacções (tipo II).
Os terpenos e os isoprenóides são uma classe de lípidos, que inclui os carotenóides, sendo a maior classe de produtos naturais vegetais
Estes compostos são sintetizados através da montagem e modificação de unidades de isopreno doadas pelas moléculas precursoras pirofosfato de isopentenilo e pirofosfato de dimetilalilo
Estes precursores podem ser obtidos de diferentes formas
Em animais e arqueas, a via do mevalonato produz estes compostos a partir do acetil-CoA, enquanto que plantas e bactérias existe uma via alternativa (do não-mevalonato) que utiliza piruvato e 3-fosfato de gliceraldeído como substratos.
Uma reacção importante que utiliza estes doadores de isopreno é a síntese de esteróides
Nesta, as unidades de isopreno são unidas formando esqualeno; este é então convertido a lanosterol
O lanosterol pode ser então convertido a outros esteróides, como o colesterol e o ergosterol.
Diferentes organismos possuem diferentes capacidades de sintetizar os vinte aminoácidos mais comuns
A maioria das bactérias e plantas conseguem sintetizar todos os vinte aminoácidos; os mamíferos conseguem sintetizar apenas dez, denominados não-essenciais por esta razão
Assim, os aminoácidos essenciais têm de ser obtidos através da alimentação
Todos os aminoácidos são sintetizados a partir de intermediários da glicólise, do ciclo dos ácidos tricarboxílicos ou da via das pentoses-fosfato; o azoto não existente nestes intermediários é fornecido pelo glutamato ou pela glutamina
A síntese dos aminoácidos depende da formação do alfa-cetoácido apropriado, que sofre então transaminação para formar um aminoácido.
Os aminoácidos são utilizados na síntese de proteínas, ao serem ligados entre si por ligações peptídicas numa cadeia linear
Os aminoácidos podem ser ligados num número de combinações quase infinito, fazendo com que cada proteína tenha uma sequência única de aminoácidos, denominada estrutura primária
As proteínas são sintetizadas a partir de aminoácidos activados através de uma ligação éster a uma molécula de ARN de transferência (ARNt ou tRNA)
Estes aminoácidos activados, os aminoacil-tRNA, são sintetizados pela aminoacil-tRNA sintetase, numa reacção dependente da presença de ATP
Os ribossomas actuam então no aminoacil-tRNA, agregando-o à cadeia polipeptídica nascente, segundo a informação dada pelo ARN mensageiro.
Os nucleótidos são sintetizados a partir de aminoácidos, dióxido de carbono e ácido fórmico em vias metabólicas que necessitam de grandes quantidades de energia
As purinas são sintetizadas a partir de nucleósidos (bases ligadas à ribose)
Tanto a adenina como a guanina são sintetizadas a partir do monofosfato de inosina, que por sua vez é sintetizado usando átomos provenientes dos aminoácidos glicina, glutamina e aspartato, assim como de formato transferido pela coenzima tetra-hidrofolato
As pirimidinas são sintetizadas a partir da base orotato, formada a partir da glutamina e do aspartato.
Todos os organismos são constantemente expostos a compostos que não podem ser utilizados no metabolismo normal e que são potencialmente tóxicos se se acumularem nas células
Tais compostos são designados xenobióticos
Os xenobióticos, incluindo substâncias como drogas sintéticas, venenos e antibióticos, são desintoxicados usando um conjunto de enzimas específicas
Em humanos, estas enzimas incluem as citocromo P450 oxidases, as UDP-glucuronosiltransferases e as glutationo-S-transferases.
Este sistema de enzimas actua em três fases
Na fase I, o xenobiótico é oxidado; na fase II, existe conjugação de grupos hidrofílicos no xenobiótico oxidado, de modo a torná-lo mais hidrossolúvel; na fase III, o xenobiótico modificado é expulso das células, podendo sofrer mais algum metabolismo em organismos multicelulares antes da sua excreção
Estas reacções são bastante importantes em termos ecológicos, nomeadamente na biodegradação microbiana de agentes poluentes e biorremediação de terras contaminadas e derrames de combustíveis.
Muitas destas reacções microbianas são idênticas às existentes em organismos multicelulares
No entanto, e graças à sua enorme diversidade, os microorganismos conseguem desintoxicar uma variedade superior de xenobióticos que os organismos multicelulares, conseguindo inclusivamente degradar agentes poluentes orgânicos persistentes, como compostos organoclorados.
Um problema relacionado com o dos xenobióticos prende-se com a existência de stress oxidativo em organismos aeróbios
Os processos associados à vida em aerobiose, como a fosforilação oxidativa e a formação de ligações dissulfureto em proteínas, produzem espécies reactivas de oxigénio, como o peróxido de hidrogénio
Estas espécies danosas são removidas por antioxidantes, como a glutationa, e enzimas, como a catalase e outras peroxidases.
Os sistemas vivos têm de obedecer às leis da termodinâmica
A grande complexidade dos organismos aparentemente contradiz a segunda lei da termodinâmica, que enuncia que a entropia de um sistema fechado tende a aumentar; no entanto, os sistemas vivos são sistemas abertos que trocam energia e massa com o seu exterior
Assim, os organismos não se encontram em equilíbrio termodinâmico, sendo antes sistemas dissipativos, pois mantêm a sua ordem ao aumentar a entropia do seu ambiente
O metabolismo celular faz a ponte entre o processo espontâneo de catabolismo e o processo não espontâneo de anabolismo para obter este efeito
Em termos termodinâmicos, o metabolismo mantém a ordem ao criar desordem.
Em fungos, bactérias, plantas ou animais de sangue quente ou frio, vários processos interagem com a temperatura interna e externa aos organismos
As plantas e leveduras parecem ter um termostato biológico simples
Na planta Arabidopsis thaliana, uma única proteína (a histona H2A) desempenha o papel em variações de temperatura inferiores a 1° C
Esta proteína altera o enrolamento do DNA, controlando assim o acesso a determinadas moléculas de DNA, ou inibindo a ativação de genes
Este efeito de "bio-termostato" parece ser comum na natureza
Entender esses mecanismos também pode ajudar a compreender melhor alguns dos efeitos da mudança do clima
O ambiente da maioria dos organismos encontra-se em constante mudança, sendo necessária uma apertada regulação das reacções metabólicas de modo a manter um conjunto de condições mais ou menos constante nas células, chamado homeostase
A regulação metabólica permite aos organismos dar resposta a estímulos do exterior, permitindo a interacção com o seu ambiente
Existem dois conceitos relacionados que são importantes para a compreensão da forma como são reguladas vias metabólicas: em primeiro lugar, a regulação de uma enzima numa via refere-se ao aumento ou diminuição da sua actividade enzimática em resposta a estímulos; o segundo conceito é o controlo exercido por esta enzima na velocidade total da via por sofrer variações na sua actividade enzimática, ou seja, o controlo do fluxo da via metabólica
Por exemplo, uma enzima pode sofrer grandes alterações na sua actividade (ou seja, ser muito regulada) mas se estas mudanças não tiverem um efeito significativo no fluxo da via metabólica, então esta enzima não está envolvida no controlo da via.
Existem diversos níveis de regulação metabólica
Na regulação intrínseca, a via metabólica regula-se a si própria em resposta a mudanças nos níveis de substratos ou produtos; por exemplo, uma diminuição na quantidade de produto pode aumentar o fluxo da via para compensar essa diminuição
Este tipo de regulação envolve frequentemente o uso de regulação alostérica das diversas enzimas que participam na via metabólica
O controlo extrínseco corresponde à mudança do metabolismo de uma célula num organismo multicelular em resposta a sinais de outras células
Estes sinais são normalmente moléculas mensageiras solúveis, como hormonas e factores de crescimento, e são detectados por receptores específicos na superfície das células
Tais sinais são então transmitidos para o interior da célula por sistemas de mensageiros secundários que envolvem frequentemente a fosforilação de proteínas.
A regulação do metabolismo da glicose pela insulina é um exemplo bem conhecido de controlo extrínseco
A insulina é produzida em resposta a um aumento da glicemia
A ligação da hormona a receptores de insulina na superfície de células activa uma cascata de cinases que provoca a absorção de glicose pelas células e a sua conversão a moléculas de armazenamento, como o glicogénio e os ácidos gordos
O metabolismo do glicogénio é controlado pela actividade da glicogénio fosforilase, a enzima que hidrolisa o glicogénio, e pela glicogénio sintase, a enzima que o sintetiza
Estas enzimas são reguladas de forma recíproca, em que a fosforilação activa a fosforilase e inibe a sintase
A insulina provoca a síntese de glicogénio ao activar fosfatases, produzindo um decréscimo na fosforilação destas enzimas.
As vias metabólicas descritas acima são comuns aos três domínios da vida (Eukarya, Archaea e Bacteria), considerando-se por isso que estavam também presentes no mais recente antecessor comum aos três domínios
Este antecessor era procariótico e provavelmente metanogénico, possuindo um extenso metabolismo de lípidos, aminoácidos, nucleótidos e glícidos
A preservação destas vias durante a evolução que se seguiu poderá ter resultado de serem uma solução optimizada para os seus problemas metabólicos específicos: ocorre a produção de metabolitos de forma eficiente e com um número mínimo de passos reaccionais.
Diversos são os modelos propostos para a descrição da evolução de novas vias metabólicas, incluindo a adição sequencial de enzimas a curtas vias ancestrais, a duplicação e posterior divergência evolutiva de vias metabólicas inteiras e a inclusão de enzimas pré-existentes numa nova via reaccional
Não é clara a importância relativa destes mecanismos, mas diversos estudos genómicos sugerem que as enzimas de uma dada via metabólica possuem um antecessor comum
Esta ancestralidade comum implica que diversas vias terão evoluído passo a passo, com a criação de novas funções a partir de passos reaccionais pré-existentes
Existe também a possibilidade de que partes do metabolismo existam como "módulos" que podem ser reutilizados em diferentes vias e que desempenham funções semelhantes em diferentes moléculas.
A evolução de organismos pode levar também à perda de vias metabólicas
Por exemplo, em alguns parasitas, processos metabólicos que não são essenciais à sua sobrevivência são perdidos; o parasita absorve então aminoácidos, nucleótidos e glícidos do seu hospedeiro
Organismos endossimbióticos apresentam também capacidades metabólicas similarmente reduzidas.
O metabolismo é classicamente estudado usando uma aproximação reducionista, focando uma via metabólica isoladamente
A marcação isotópica de precursores é de grande utilidade em estudos com organismos inteiros, tecidos ou células, pois permite seguir o percurso dessas moléculas até serem transformadas no produto final, analisando intermediários e produtos marcados radioactivamente
As enzimas que catalisam estas reacções podem ser purificadas e analisadas do ponto de vista da sua actividade enzimática, medindo parâmetros cinéticos e respostas a inibidores
Outro tipo de investigação consiste na identificação de metabolitos numa célula ou tecido; o conjunto de metabolitos é por vezes designado metaboloma
De uma forma geral, este tipo de estudos é adequado para alcançar uma visão geral de uma via metabólica simples, mas é limitado quando aplicado a sistemas mais complexos, como o funcionamento de uma célula inteira.
É possível ter uma ideia da complexidade da rede metabólica existente nas células, que possuem tipicamente milhares de enzimas, analisando a figura ao lado, que representa apenas 43 proteínas e 40 metabolitos
A sequenciação de genomas mostra que poderão existir até 45000 genes (que corresponderão a tantos outros polipéptidos)
É, no entanto, possível usar esta informação genómica para reconstruir redes completas de reacções bioquímicas e produzir modelos matemáticos holísticos que expliquem e prevejam o seu comportamento
Tais modelos são particularmente úteis quando usados na integração de dados obtidos através de métodos laboratoriais de análise de expressão genética, como o uso de proteómica e microarrays.
Uma relevante aplicação tecnológica desta informação é a engenharia metabólica, em que organismos como leveduras, plantas ou bactérias são geneticamente modificados de modo a serem úteis em aplicações biotecnológicas, como a produção de medicamentos (por exemplo, antibióticos) ou reagentes químicos (como o propan-1,3-diol ou o ácido xiquímico).
Nível introdutório
Nível avançado

Informação geral
Glossários e dicionários
Metabolismo humano
Bases de dados
Vias metabólicas
Transplante de pâncreas é um procedimento cirúrgico no qual umas pâncreas saudável e produtor de insulina é transplantado para outra pessoa.

1966 (MCMLXVI, na numeração romana) foi um ano comum do século XX do actual Calendário Gregoriano, da Era de Cristo, e a sua letra dominical foi B (52 semanas), teve início a um sábado e terminou também a um sábado.
Ano comum com início ao sábado




Coordenadas: 55° N 97° O
Manitoba é uma das dez províncias do Canadá
Manitoba está localizada no centro longitudinal do Canadá
A província é uma das três províncias das pradarias (assim como Alberta e Saskatchewan), é também a quinta província mais populosa do Canadá, com 1,2 milhão de habitantes
Manitoba abrange uma área de 649.950 km² e possui uma paisagem muito diversificada
A província é limitada pelas províncias de Ontário ao leste e de Saskatchewan ao oeste, pelo território de Nunavut ao norte, pelos Territórios do Noroeste ao noroeste, e pelos estados americanos de Dakota Norte e Minnesota ao sul.
As principais fontes de renda da província são a indústria de manufatura, a indústria agropecuária, mineração e o turismo
A capital e maior cidade da província é Winnipeg, que também é o principal pólo comercial, industrial, financeiro e de transportes de Manitoba
Cerca de 60% da população da província vive dentro da região metropolitana de Winnipeg.
O solo fértil desta região faz com que seja propicia a prática da agricultura
A província é uma das líderes nacionais da indústria agrária do Canadá
O valor total dos produtos agrários cultivados na província é o terceiro maior do país, atrás somente de Saskatchewan e de Alberta
A região centro-sul da província é coberta por grandes quantidades de florestas, que fazem da indústria madeireira uma fonte de renda importante na província
A região norte, por fim, é extremamente rica em depósitos minerais, tais como níquel, ferro e zinco
Muito da província é coberta por rios e lagos, que cobrem cerca de um sexto de Manitoba, que são uma das principais atrações turísticas da província.
Manitoba foi colonizada pelos ingleses, tendo feito parte inicialmente de um gigantesco território conhecido como Terra de Rupert, administrada pela companhia inglesa da Baía de Hudson
Algumas regiões de Manitoba também foram colonizadas pelos franceses
Em 15 de maio de 1870, após a Rebelião de Red River, o governo do Canadá elevou a região sul da atual Manitoba à categoria de província
Inicialmente, então, Manitoba possuía apenas 5,6% de seu tamanho atual, ocupando um quadrado localizado no sudeste da atual Manitoba, e que rendeu à província o cognome de The Postage Stamp Province (A Província Selo)
Manitoba cresceu gradualmente em extensão territorial, tendo absorvido terras dos Territórios do Noroeste, e assim adquirindo seus atuais limites territoriais em 1912.


Acredita-se que o nome Manitoba seja derivado das línguas Cree, Ojíbua ou Assiniboine
O nome deriva do Cree "manitou-wapow" ou do Ojíbua "manidoobaa", ambos significando: "estreitos de Manitou, o Grande Espírito", um lugar que se refere ao que agora são chamados de The Narrows, localizados no centro do Lago Manitoba
O nome também pode ser derivado do idioma Assiniboine que significa "Lago da Pradaria".
O lago era conhecido pelos exploradores franceses como "Lac des Prairies"
Thomas Spence escolheu o nome para se referir a uma nova república que ele propôs para a área ao sul do lago
O nome foi aceito em Ottawa sob a Lei de Manitoba de 1870.
Três diferentes tribos nativos americanos viviam na região que atualmente constitui a província de Manitoba, à época da chegada dos primeiros exploradores europeus na região
Os Cree, os Assiniboines e os Objiwa
Os Cree, por sua vez, estavam subdivididos em três subgrupos, cada uma com seu diferentes dialetos e aspectos culturais
Três destas tribos faziam parte do grupo nativo americano dos Cree: os Chippewya, os Wood Cree e os Plain Cree
Os Assiniboines eram aliados dos Cree
Os Chippewya viviam no norte da atual Manitoba, os Wood Cree nas florestas da região centro-sul, os Plains Cree e os Assiniboines nas planícies do sudoeste, e os Objiwa, nas planícies do sudeste, todas sendo tribos nativos americanas nômades.
Os primeiros exploradores europeus a explorarem o atual Manitoba foram os membros de uma expedição inglesa comandada por Thomas Button, em 1612
Eles desembarcaram no litoral da Baía de Hudson, passaram o inverno de 1612 e 1613 no estuário do Rio Nelson, e reivindicaram a região à coroa inglesa
Posteriormente, uma expedição inglesa comandada pelos ingleses Luke Foxe e Thomas James, desembarcariam em Manitoba, no litoral da Baía de Hudson, em 1631.
Em 1670, o Rei Carlos I de Inglaterra cedeu os direitos de comércio e administração da atual Manitoba para a Companhia da Baía de Hudson
Esta região fazia parte de um enorme território administrado pela companhia, conhecido como Terra de Rupert
Muito desta região - incluindo toda a região da atual Manitoba - era reivindicada pelos franceses, instalados na colônia vizinha da Nova França
Durante as décadas de 1680 e 1690, tanto os britânicos quanto os franceses instalaram diversos postos comerciais na região
Rapidamente, tensões e conflitos passaram a ocorrer entre os britânicos e os franceses
Em 1690, a Companhia da Baía de Hudson ordenou Henry Helsey que encontrasse novas fontes de peles animais na região
Kelsey explorou toda a região centro-sul de Manitoba, e persuadiu os nativos americanos da região - que viviam primariamente da caça do bisão - a enviarem suas peles aos postos comerciais da Companhia da Baía de Hudson, localizadas no norte da atual Manitoba.
Em 1731, o francês Pierre Gaultier de Varennes, ao comando de uma expedição composta primariamente por comerciantes de peles, partiu de Montreal em direção à costa do Oceano Pacífico
A expedição construiu diversos fortes entre a região do Lago Superior e do Rio Saskatchewan, passando pela região sul de Manitoba, um destes fortes tendo sido Fort Rouge, em 1738, onde está localizada atualmente Winnipeg
Varennes estabeleceu relações amigáveis com nativos americanos da região, e também passaram a lucrar com o comércio de peles na região.
Em 1763, após a derrota francesa na Guerra Franco-Indígena, os franceses foram forçados a cederem a região para os britânicos
Por um curto período de tempo, a Companhia da Baía de Hudson usufruiu-se de um monopólio no comércio de peles na região
Porém, na década de 1770, a Companhia do North West foi criada em Montreal, e passou a competir com a Companhia da Baía de Hudson
A Companhia North West faliu ainda na década de 1770, mas foi ressuscitada em 1784
A Companhia da Baía de Hudson ainda manteve o controle administrativo da região, mas, sob ordens do governo do Reino Unido, foi forçada a permitir com que a Companhia de North West operasse na região.
Em 1811, a Companhia da Baía de Hudson deu o controle de propriedade de uma grande região - que somavam no total 260 mil quilômetros quadrados em área - da região para Thomas Douglas
Esta região incluía muito das atuais províncias canadenses de Manitoba e Saskatchewan, bem como partes dos atuais estados americanos de Dakota do Norte e Minnesota, uma região que seria conhecido como Colônia de Red River
Douglas, entre 1812 e 1816, enviou colonos escoceses e irlandeses à região, com o objetivo de tentar iniciar a prática da agricultura na região.
Enxames de gafanhotos, geadas e tempestades de neve arruinaram inicialmente as primeiras tentativas de cultivo na região
Além disto, estes colonos haviam-se instalado na região norte da área cedida pela Companhia da Baía de Hudson a Douglas, em uma região onde a Companhia de North West possuía suas principais bases de operações
Alimentos passaram a escassear para estes colonos, que passaram a utilizar-se de fontes de alimentos até então utilizados primariamente pelos nativos americanos e pelos comerciantes da Companhia North West, causando um detrimento entre os colonos da colônia de Red River e a Companhia de North West e os nativos americanos da região
A situação agravou-se em 1815, quando a Companhia da Baía de Hudson proibiu a venda de alimentos por parte dos nativos americanos à Companhia North West ou a exportação de alimentos além dos limites da Terra de Rupert.
Membros da Companhia North West logo atacaram os colonos da colônia de Red River, enquanto os Métis - uma tribo aborígene descendente de nativos americanos e colonos europeus, e que falavam primariamente francês - cuja principal fonte de renda era a venda de alimentos para Companhia do North West, com a qual os Métis eram aliados, atacaram membros da Companhia da Baía de Hudson, na Batalha de Seven Oaks, que resultou em vitória Métis
Conflitos e tensões perduraram até 1821, quando a Companhia da Baía de Hudson e a Companhia North West foram fundidas entre si
Enquanto isto, a prática bem-sucedida da agricultura teria somente início durante a década de 1840.
Em 1867, a Confederação Canadense foi formada, pelas colônias britânicas de "Canadá", Nova Brunswick e Nova Escócia, que juntas passaram a formar o Canadá, um único país independente do Reino Unido
Dois anos depois, em 1869, a Companhia da Baía de Hudson concordou em ceder todas as suas terras para o governo canadense
Assim, a região da atual Manitoba passou a fazer parte do Canadá
Isto não agradou aos Métis, que temiam que grandes números de assentadores canadenses - especialmente colonos anglófonos - instalassem-se na região, e assimilassem culturalmente os Métis
Em 1869, Louis Riel liderou uma rebelião em Fort Gary - atual Winnipeg
Esta rebelião - que estendeu-se até 1870 - ficou conhecida como Rebelião de Red River, e foi marcada pela execução de Thomas Scott - um anglófono que foi condenado por traição.
Em 1870, o governo canadense, em uma tentativa em acabar com a rebelião, cedeu aos Métis uma Carta de Direitos, através do Manitoba Act, que efetivamente criava a província de Manitoba
Esta nova província, então, tinha apenas 5,6% de seu tamanho atual, e ocupava o canto sudeste da atual Manitoba
Manitoba tornou-se a quinta província canadense em 15 de maio de 1870.
A elevação da região de Red River à categoria de província fez com que grandes números de assentadores vindos de outras partes do país passassem a instalar-se na região, e assim, não deu aos Métis a esperada proteção contra assimilação cultural
Estes colonos eram em sua maioria anglófonos, que logo tornaram-se maioria na recém-criada província
Entre 1871 e 1881, a população da província havia mais do que dobrado, de 25 228 habitantes em 1871 para 62 260 habitantes em 1881
O governo de Manitoba rapidamente removeu diversos dos direitos cedidos aos Métis sob o Manitoba Act
Um dos principais direitos era o acesso à educação em francês
Manitoba parou de fornecer verbas à escolas francófonas ainda na década de 1870, e tornou não-oficial o idioma na província
Grandes números de Métis decidiram migrar para o oeste, em direção das atuais províncias canadenses de Saskatchewan e Alberta.
A indústria agrária de Manitoba prosperou após ter sido elevada à categoria de província, especialmente o cultivo de trigo
Manitoba passou a vender trigo para outras regiões em 1876
A venda grandes quantidades de trigo para outras províncias canadenses, e para os Estados Unidos, logo tornou-se a principal fonte de renda de Manitoba
Em 1878, a primeira ferrovia conectando a cidade com outras regiões - especificamente, Saint Paul, em Minnesota - foi inaugurada
Durante o início da década de 1880, a Canadian Pacific Railway passou a conectar Winnipeg com as principais cidades do leste canadense
A inauguração completa da ferrovia, em 1886, logo colocou a província ao centro da primeira malha transcontinental ferroviária da América do Norte, e fez de Winnipeg um grande centro ferroviário, o que estimulou a produção de trigo, que agora poderia ser facilmente transportado até portos localizados nos Grandes Lagos, e daí, para outras regiões do planeta
Durante 1871 e 1912, os limites territoriais de Manitoba foram gradualmente estendidos em direção ao norte e a oeste
Em 1912, a província adquiriu seus atuais limites territoriais.
O crescimento populacional de Manitoba continuou forte até a década de 1920
Grandes números de canadenses de outras regiões do país, bem como muitos imigrantes - primariamente alemães, ucranianos, ingleses, escoceses e irlandeses - instalaram-se na província
A produção de trigo de Manitoba aumentou drasticamente durante este período
O crescimento se deu primariamente a investidores e à infra-estrutura de transporte em rápido crescimento em Winnipeg, onde a maior parte dos migrantes instalou-se
Quando o prédio da Assembleia Legislativa de Manitoba foi construída em Winnipeg, esperava-se que a província alcançaria rapidamente três milhões de habitantes
Porém, os investimentos em Winnipeg diminuíram drasticamente com o início da Primeira Guerra Mundial, e o crescimento populacional da cidade - e consequentemente, o da província - caiu drasticamente.
A década de 1910 foi tempos de grandes agitações no cenário político, social e econômico de Manitoba
A Primeira Guerra Mundial passou a fazer com que a indústria agropecuária da província prosperasse, e estimulou a industrialização da província
Durante a guerra, o Partido Liberal do Canadá tornou-se o partido político no poder da província, substituindo o Partido Conservador do Canadá, que esteve no controle político de Manitoba entre 1900 e 1915
Enquanto os conservadores concentraram-se primariamente no crescimento econômico da província, os liberais concentraram-se na realização de diversas reformas, dando às mulheres o direito de voto, instituindo direitos trabalhistas e educação compulsória para crianças com até 14 anos de idade.
Apesar das reformas, os trabalhadores em geral da província não estavam contentes
Os salários dos trabalhadores industrial continuava baixo, enquanto que os fazendeiros reclamavam da falta de atenção do governo provincial em relação a setor agropecuário de Manitoba
Em maio de 1919, Winnipeg foi o palco de uma grande greve geral, organizada por 52 cooperativas e sindicatos diferentes
Esta greve resultou em diversos conflitos violentos entre os grevistas e policiais
O governo de Manitoba, enquanto isto, ignorou a greve, e esforçou-se em continuar a fornecer os serviços anteriormente fornecidos pelos trabalhadores em greve
O esforço do governo deu certo, e a greve acabou em junho, por decisão dos grevistas
O partido Fazendeiros Unidos de Manitoba subiu ao poder em 1922.
Manitoba foi uma das províncias mais afetadas negativamente pela Grande Depressão
A província era dependente da exportação de trigo para outros países, e a queda súbita dos preços do trigo nos meses que antecederam-se à Depressão iniciou a recessão que perduraria ao longo da década de 1930
Além disso, os fazendeiros de Manitoba sofreram também com períodos prolongados de estiagem e grandes enxames de gafanhotos
Grandes números de fazendeiros abandonaram suas fazendas e foram em direção às cidades
Muitos fazendeiros e trabalhadores desempregados abandonaram a província, em busca de oportunidades de trabalho em outras províncias canadenses
O crescimento populacional da província diminuiu drasticamente
A depressão foi uma das causas da criação de dois novos partidos políticos na província, que posteriormente tornariam-se nacionalmente conhecidos no país: a Federação Cooperativa da Commonwealth, que posteriormente tornaria-se o atual Novo Partido Democrático, e o Partido do Crédito Social.
Os efeitos da depressão na província somente acabaram com a entrada do país na Segunda Guerra Mundial, logo após o início da guerra
Esta aumentou drasticamente a demanda por produtos agrários em geral
A demanda por produtos industrializados no país também estimulou uma maciça industrialização da província
Grandes números de fábricas foram construídas durante a guerra
O crescimento da indústria de manufatura continuou após o fim da Segunda Guerra Mundial, enquanto a indústria agropecuária entrou em recessão, por causa da queda dos preços dos produtos agropecuários no mercado internacional
Ao final da década de 1940, a manufatura havia superado a agropecuária como a principal fonte de renda da província
A modernização da indústria agropecuária e a ascensão da indústria de manufatura fizeram com que grandes números de fazendeiros passassem a migrar das áreas rurais do estado para as cidades, primariamente, Winnipeg.
Em 1945, geólogos descobriram grandes depósitos de cobre, níquel e zinco, no noroeste de Manitoba
A mineração tornou-se uma fonte de renda importante da província, durante a década de 1950, e na década de 1960, a província já era um dos principais centros produtores de níquel do mundo, sendo até os dias atuais a segunda maior produtora do continente americano, atrás somente da província canadense vizinha de Ontário
Durante o início da década de 1950, a província desenvolveu seu sistema de geração e distribuição de eletricidade, e em torno de 1955, todas as áreas rurais de Manitoba possuíam eletricidade.
A industrialização de Manitoba causou um período de acelerado crescimento populacional durante a década de 1950, até o final da década de 1960
Porém, poucas fábricas passaram a serem construídas na província a partir do final da década de 1960
O diminuimento do setor de manufatura de Manitoba - que desde a década de 1950 era a principal fonte de renda da província - diminuiu sensivelmente o crescimento populacional de Manitoba
Desde então, a população da província tem crescido gradualmente, mas muito lentamente, exceto por um curto período de tempo entre 1981 e 1986.
Em 1979, o Manitoba Act, que havia tornado o francês uma língua não-oficial em Manitoba, e que impedia o fornecimento de verbas do governo da província para instituições francófonas, foi julgado inconstitucional pela Suprema Corte do Canadá
Em 1985, a Suprema Corte ordenou que Manitoba traduzisse todas as suas 4,5 mil leis provinciais para a língua francesa, e passasse a fornecer educação pública em francês, em comunidades com uma população francófona significante.
Manitoba limita-se ao norte com o Nunavut e a Baía de Hudson, a leste com o Ontário, ao sul com o Minnesota e a Dakota do Norte, e a oeste com o Saskatchewan.
Uma das características geográficas mais marcantes de Manitoba é a sua abundância de rios e lagos
Somente os lagos de Manitoba cobrem um sexto da província - ou 101 592 quilômetros quadrados
A província possui no total cerca de 100 mil lagos
Os maiores são os lagos Winnipeg (24 387 km²), o Winnipegosis (5 374 km²), e o Manitoba (4 624 km²)
Estes lagos, que interconectam-se entre si através de rios e canais, são chamados comumente de Grandes Lagos de Manitoba
Todos os rios que cortam Manitoba escoam em direção à Baía de Hudson.
O litoral de Manitoba ao longo da Baía de Hudson possui 645 quilômetros de extensão
As águas do litoral congelam entre outubro até abril, impossibilitando o escoamento de produtos para outras regiões via o Oceano Ártico durante este período
A existência de gelo nas águas da Baía de Hudson limitam o movimento de navios de carga e passageiros durante junho até setembro
Florestas cobrem cerca de 251 mil km² (38%) da província.
Manitoba pode ser dividido em três distintas regiões geográficas:
Manitoba possui um clima temperado continental, com invernos muito frios e verões quentes (amenos no extremo norte), e por ser relativamente instável, onde condições climáticas podem mudar drasticamente em um curto período de tempo
O clima de Manitoba é típico de sua localização continental, de suas altas latitudes, e pelo seu terreno pouco acidentado, que permitem o rápido movimento de correntes de ar vindas de quaisquer direções ao longo da província
No geral, as temperaturas da província aumentam à medida que se viaja em direção ao sul.
Os invernos de Manitoba são no geral muito frios - embora ocasionalmente frentes quentes vindas do sul possam elevar a temperatura média da região centro-sul para até os 15°C
A região sul de Manitoba possui uma temperatura média de -18°C, enquanto o norte possui uma temperatura média de -27°C
A média das mínimas no sul é de -22°C, enquanto a média das máximas é de -13°C
No norte, a média das mínimas é de -34°C, e a média das máximas é de -15°C
A menor temperatura já registrada em Manitoba, -53°C, registrada em 9 de janeiro de 1899, em Norway House
Os invernos rigorosos da província renderam à sua capital, Winnipeg, o cognome de Winterpeg (winter, em português, significa "inverno").
Os verões de Manitoba são quentes na região sul e amenos na região norte
A temperatura média da região sul da província é de 21°C, e no norte, de 13°C
No sul, a média das mínimas é de 14°C, e a média das máximas é de 26°C
No norte, a média das mínimas é de 8°C, e a média das máximas é de 20°C
A temperatura mais alta já registrada em Manitoba, de 44°C, foi registrada em St
Albans, em 11 de julho de 1936, e em Emerson, em 12 de julho do mesmo ano.
Encontros de frentes quentes vindas do sul e frentes frias vindas do norte são comuns o ano inteiro em Manitoba
Como consequência, grandes tempestades são comuns no verão, com grandes tempestades de neve ocorrendo com frequência no inverno
A taxa de precipitação média anual de chuva de Manitoba é de 50 centímetros, sendo maior no sudeste, diminuindo à medida que se viaja em direção ao noroeste
O sudeste de Manitoba recebe em média 60 centímetros anuais de chuva, enquanto o noroeste recebe menos do que 40 centímetros anuais
Precipitação de neve é comum em toda Manitoba
A província recebe anualmente cerca de 130 centímetros anuais de neve.
O Tenente-Governador representa a Rainha Isabel II como chefe da província
O chefe do governo, em prática, e também maior oficial do Poder Executivo da província, é o Premier, governador ou primeiro-ministro em português, a pessoa que lidera o partido político com mais cadeiras na Assembleia Legislativa de Manitoba
O governador de Manitoba preside sobre um Conselho Executivo, que é o Gabinete da província
O gabinete é formado por 25 diferentes ministros, que lideram um dado departamento (economia, educação, etc), e são indicados pelo Premier
Tanto o Premier quanto os membros do gabinete renunciam caso percam o suporte da maioria dos membros da Assembleia.
O Poder Legislativo de Manitoba é a Assembleia Legislativa, que é composta por 57 membros
Manitoba está dividido em 57 distritos eleitorais
A população eleitoral de cada um destes distritos elege um membro, que atuará como representante do distrito na Assembleia, para mandatos de até cinco anos de duração
Se o Tenente-Governador dissolver a Assembleia antes destes cinco anos, a pedido do governador, todos precisam concorrer às eleições novamente
Não há limite de termos que uma pessoa pode exercer.
A maior corte do Poder Judiciário de Manitoba é a Court of Appeal of Manitoba
Esta é composta de um chefe de justiça e seis juízes
A segunda corte mais importante da província é a Court of Queen's Bench of Manitoba, que é composta por um chefe de justiça, dois chefes associados de justiça e 31 juízes
A Corte Provincial de Manitoba é a terceira maior corte da província
Todos os juízes da Court of Appeal e do Court's Bench de Manitoba são escolhidos pelo Premier de Manitoba, sem aprovação simbólica do Tenente-Governador
Os juízes continuam a exercer seus ofícios até os 75 anos de idade
Os juízes da Corte provincial também são indicados pelo Premier, mas precisam da aprovação - simbólica - do Tenente-Governador
Tais juízes, uma vez escolhidos, podem servir indefinidamente, até que renunciem, sejam removidos do cargo por justo motivo ou morte.
Manitoba possui cerca de 200 cidades, vilas e municipalidades rurais incorporadas
Impostos são responsáveis por cerca de 95% do orçamento da província
O restante provém de verbas fornecidas pelo governo federal.
Historicamente, Manitoba é uma província conservadora
Até a década de 1920, a maior parte dos Premiers de Manitoba tem sido candidatos do antigo Partido Conservador do Canadá
Entre as décadas de 1920 e 1950, a maioria dos Premiers foram candidatos do Partido Liberal do Canadá
Desde então, os principais partidos políticos a dominarem a Assembleia da província foram o Partido Progressivo do Canadá (que em 2003 viria tornar-se o atual Partido Conservador do Canadá) e o Novo Partido Democrático
Para votar, uma pessoa precisa ter ao menos 18 anos de idade.
O censo nacional de 2006 estima a população de Manitoba em 1 177 765 habitantes, um crescimento de 5,2% em relação aos números de 2001, de 1 119 583
Uma estimativa realizada em 2004 estima a população da província em 1 177 556 habitantes, um crescimento de 5,7% em relação à população da província em 1996.
Lista dos principais grupos étnico-raciais da população de Manitoba
O total das percentagens listadas supera 100% uma vez que estão consideradas aqui respostas múltiplas
Grupos étnico-raciais que componham menos de 3% da população da província não são listadas aqui.
Percentagem da população de Manitoba por afiliação religiosa:
O produto interno bruto de Manitoba, em 2000, foi de 29,9 bilhões de dólares canadenses
A renda per capita da província é de aproximadamente 26 754 dólares canadenses.
O setor primário de Manitoba é responsável por 3,5% do PIB de Manitoba
A agricultura e a pecuária - que já foram anteriormente as principais fontes de renda de Manitoba - empregam juntas aproximadamente 33 mil pessoas, e responde por 2,85% do PIB da província
Manitoba possui cerca de 26 mil fazendas, que ocupam cerca de 14% da província
A pesca e a silvicultura respondem juntas por 0,15% do PIB de Manitoba, empregando cerca de 2,8 mil pessoas.
O setor secundário de Manitoba responde por 19% do PIB da província
A indústria de manufatura responde por 13% do PIB da província, empregando cerca de 71 mil pessoas
O valor total dos produtos fabricados anualmente na província é de 4,5 bilhões de dólares canadenses
Os principais produtos fabricados em Manitoba são alimentos industrializados, equipamentos de transporte, roupas, equipamentos eletrônicos e material impresso
A indústria de construção responde por 4% do PIB da província, empregando cerca de 28,5 mil pessoas
A mineração responde por 1,85% do PIB da província, empregando cerca de 5,9 mil pessoas
Os principais recursos naturais extraídos em Manitoba são níquel, petróleo, ferro e zinco
A província é a segunda maior produtora de níquel do continente americano, perdendo apenas para a província vizinha de Ontário.
O setor terciário de Manitoba responde por 72% do PIB da província
Serviços comunitários e pessoais respondem por 22% do PIB da província, e empregam cerca de 209 mil pessoas
Serviços financeiros e imobiliários respondem por 20% do PIB da província, e empregam aproximadamente 30 mil pessoas
O comércio por atacado e varejo responde por 12% do PIB de Manitoba, e emprega aproximadamente 82 mil pessoas
Transportes e telecomunicações respondem por 11% do PIB de Manitoba, empregando aproximadamente 55 mil pessoas
Serviços governamentais respondem por 4% do PIB da província, e empregam aproximadamente 33 mil pessoas
Utilidades públicas respondem por 4% do PIB da província, e empregam cerca de 6,8 mil pessoas
Cerca de 98% da eletricidade gerada em Manitoba é produzida em usinas hidrelétricas, primariamente operadas em 12 grandes represas
A província também possui duas usinas termoelétricas a carvão, que produzem o restante da eletricidade gerada pela província
Manitoba produz muito mais eletricidade do que consome, como consequência, a província exporta o excedente para Saskatchewan e Ontário, bem como para o Estado americano de Minnesota.
A primeira escola de Manitoba foi fundada em 1812, no assentamento de Red River
A partir de 1818, missionários da Igreja Católica Romana passaram a construir escolas católicas na região
Em 1820, a primeira escola protestante foi fundada na região
Até o início da década de 1870, educação básica na região era fornecida apenas por instituições religiosas
Em 1871, com a criação da província de Manitoba, a província criou um Departamento de Educação, e passou a responsabilizar pelo fornecimento de verbas ao sistema de escolas públicas da província.
Atualmente, todas as escolas de educação básica localizadas na província precisam seguir padrões impostos pelo Departamento de Educação de Manitoba
Escolas públicas localizadas na região sul de Manitoba são administrados por um dado distrito escolar, que operam em uma dada região, em diversas cidades, vilas e municipalidades ao mesmo tempo
As escolas de algumas regiões isoladas do sul de Manitoba, bem como toda a região centro-norte da província, são, por sua vez, administradas diretamente pelas cidades, vilas ou municipalidades nas quais as escolas se localizam
Atendimento escolar é compulsório para todas as crianças e adolescentes com mais de sete anos de idade, até a conclusão do segundo grau ou até os dezesseis anos de idade.
Manitoba possui quatro universidades
A Universidade de Manitoba é a maior universidade da província e está localizada em Winnipeg
Outras universidades são a Universidade de Winnipeg, em Winnipeg, a Universidade de Brandon, em Brandon, e o Colégio Universitário de St
Boniface, em St
Boniface, um subúrbio de Winnipeg
Manitoba possui 38 bibliotecas públicas, dos quais 21 estão localizadas em Winnipeg.
Manitoba é um grande centro de transportes, em parte dado sua localização, na região central do Canadá
Winnipeg é o principal centro rodoviário, ferroviário e aeroportuário da província
O único porto movimentado de Manitoba é o porto de Churchill, localizado às margens da Baía de Hudson, e que somente opera entre agosto e outubro.
Manitoba possui cerca de 1,8 mil quilômetros de ferrovias
Tanto a Canadian National Railway quanto a Canadian Pacific Railway possuem facilidades ferroviárias de porte razoável em Winnipeg
Além da última, Brandon e Portage la Praire também são centros ferroviários importantes
A maioria das linhas ferroviárias importantes cortam a província em um sentido leste-oeste.
A maior parte das principais rodovias de Manitoba estão localizadas no sul da província
Na região norte de Manitoba, onde neva muito, existem poucas estradas pavimentadas, onde estradas de terra ou de pedra dominam
No inverno, veículos compactam neve em tais estradas, para que as últimas permitam o trânsito seguro de veículos em geral.
O Aeroporto Internacional de Winnipeg é o aeroporto mais movimentado da província, e um dos mais movimentados da região central do Canadá, movimentando cerca de três milhões de passageiros por ano.
O primeiro jornal publicado em Manitoba foi o The Nor' Wester, publicado pela primeira vez em 1859 em Fort Garry - atual Winnipeg
Atualmente, são publicados em Manitoba cinco jornais diários e aproximadamente 50 jornais semanais
A primeira estação de rádio de Manitoba foi inaugurada em 1922, e a primeira estação de televisão foi inaugurada em 1954, ambas em Winnipeg
Manitoba possui atualmente 30 estações de rádio - dos quais 19 são AM e 11 são FM - e 15 estações de televisão.
Bandeira · História · Geografia · Política · Demografia · Economia · Educação
Capital Winnipeg · Planícies Centrais · Eastman  · Interlake · Norte · Parkland · Vale Pembina · Westman · Vale do Rio Vermelho
1 · 2 · 3 · 4 · 5 · 6 · 7 · 8 · 9 · 10 · 11 · 12 · 13 · 14 · 15 · 16 · 17 · 18 · 19 · 20 · 21 · 22 · 23
Brandon · Dauphin · Flin Flon · Portage la Prairie · Selkirk · Steinbach · Thompson · Winkler · Winnipeg
História · Geografia · Política · Forças Armadas · Demografia · Economia · Educação · Transportes · Telecomunicações · Cultura · Turismo · Imagens
Área · Crescimento · Despesas anuais · Etimologia · Expectativa de vida · IDH · Nível educacional · PIB · Pobreza · População · Violência
Alberta · Colúmbia Britânica · Saskatchewan · Manitoba · Ontário · Quebec · New Brunswick · Ilha do Príncipe Eduardo · Nova Escócia · Terra Nova e Labrador
Yukon · Territórios do Noroeste · Nunavut
Províncias: Victoria · Edmonton · Regina · Winnipeg · Toronto · Quebec · Fredericton · Charlottetown · Halifax · St
John's
Territórios: Whitehorse · Yellowknife · Iqaluit
Calgary · Vancouver · Saskatoon · Montreal · Moncton
Cadáver é o corpo após a sua morte, enquanto este ainda conserva parte de seus tecidos
Após a decomposição de todos os órgãos, músculos e tecidos, o mesmo passa a ser denominado como ossada
O termo carcaça é aplicado para se referir ao corpo de animais vertebrados e insetos mortos.
A palavra "cadáver", segundo a etimologia popular, teria origem na inscrição latina Caro Data Vermibus ("carne dada aos vermes"), que supostamente seria inscrita nos túmulos
Na verdade não se encontrou até hoje nenhuma inscrição romana deste género
Os etimologistas defendem que a palavra deriva da raiz latina cado, que significa "caído"
A favor desta teoria está o fato de santo Isidoro de Sevilha referir que o corpo deixa de ser cadáver a partir do momento em que é sepultado.

A língua latina ou latim é uma antiga língua indo-europeia do ramo itálico originalmente falada no Lácio, a região do entorno da cidade de Roma
Foi amplamente difundida, especialmente na Europa Ocidental, como a língua oficial da República Romana, do Império Romano e, após a conversão deste último ao cristianismo, da Igreja Católica Romana
Através da Igreja Católica, tornou-se a língua dos acadêmicos e filósofos europeus medievais
Por ser uma língua altamente flexiva e sintética, a sua sintaxe (ordem das palavras) é, em alguma medida, variável, se comparada com a de idiomas analíticos como o português, embora em prosa os romanos tendessem a preferir a ordem SOV
A sintaxe é indicada por uma estrutura de afixos ligados a temas
O alfabeto latino, derivado dos alfabetos etrusco e grego (por sua vez, derivados do alfabeto fenício), continua a ser o mais amplamente usado no mundo.
Embora o latim seja hoje uma língua morta, ou seja, uma língua que não mais possui falantes nativos, ele ainda é empregado pela Igreja Católica para fins rituais e burocráticos
Exerceu enorme influência sobre diversas línguas vivas, ao servir de fonte vocabular para a ciência, o mundo acadêmico e o direito
O latim vulgar, nome dado ao latim no seu uso popular inculto, é o ancestral das línguas neolatinas (italiano, francês, espanhol, português, romeno, catalão, romanche e outros idiomas e dialetos regionais da área); muitas palavras adaptadas do latim foram adotadas por outras línguas modernas, como o inglês
O fato de haver sido a lingua franca do mundo ocidental por mais de mil anos é prova de sua influência.
O latim ainda é a língua oficial da Cidade do Vaticano e do Rito Romano da Igreja Católica
Foi a principal língua litúrgica até o Concílio Vaticano Segundo nos anos 1960
O latim clássico, a língua literária do final da República e do início do Império Romano, ainda hoje é ensinado em muitas escolas primárias e secundárias, embora seu papel se tenha reduzido desde o início do século XX.


O latim inclui-se entre as línguas itálicas, e seu alfabeto baseia-se no alfabeto itálico antigo, derivado do alfabeto grego
No século IX a.C
ou VIII a.C., o latim foi trazido para a península Itálica pelos migrantes latinos, que se fixaram numa região que recebeu o nome de Lácio, situda ao longo do rio Tibre, onde a civilização romana viria a desenvolver-se
Naqueles primeiros anos, o latim sofreu a influência da língua etrusca, proveniente do norte da península e que não era uma língua indo-europeia.
A importância do latim na península Itálica firmou-se gradativamente
A princípio, era apenas a língua de Roma, uma pequena cidade circundada por vários centros menores (Lanúvio, Preneste, Tívoli), nos quais se falavam dialetos latinos ou afins ao latim (o falisco, língua da antiga cidade de Falérios)
Já a poucos quilômetros de Roma, eram faladas línguas muito diversas: o etrusco e sobretudo línguas do grupo indo-europeu - o umbro, no norte, e o osco, na porção mais ao sul, até a atual Calábria
Na Itália setentrional falavam-se outras línguas indo-europeias como o lígure, o gálico e o venético
O grego era difundido nas numerosas colônias gregas da Sicília e da Magna Grécia
Ao longo de toda a era republicana, a situação linguística da Itália permaneceu muito variada: o plurilinguismo era uma condição comum, e os primeiros autores da literatura, como Ênio e Plauto dominavam o latim, o grego e o osco.
Além das variações regionais, mesmo o latim de Roma não foi uma língua sempre igual a si mesma, apresentando fortes diferenças diacrônicas e sociolinguísticas
Do ponto de vista diacrônico, deve-se distinguir:
Embora a literatura romana sobrevivente seja composta quase inteiramente de obras em latim clássico, a língua falada no Império Romano do Ocidente na Antiguidade tardia (200 a 600 d.C) era o latim vulgar, que diferia do primeiro em sua gramática, vocabulário e pronúncia.
O latim manteve-se por muito tempo como a língua jurídica e governamental do Império Romano, mas, com o tempo, o grego passou a predominar entre os membros da elite culta romana, já que grande parte da literatura e da filosofia estudada pela classe alta havia sido produzida por autores gregos, em geral atenienses
Na metade oriental do Império, que viria a tornar-se o Império Bizantino, o grego terminou por suplantar o latim como idioma governamental e era a lingua franca da maioria dos cidadãos orientais, de todas as classes.
A difusão do latim por um território cada vez mais vasto teve duas consequências:
Geralmente, as populações submetidas desejavam elevar-se culturalmente adotando o latim, coisa que ocorre sempre que dois povos entram em contato: prevalece linguisticamente aquele que possui maior prestígio cultural
Dessa forma Roma conseguiu fazer prevalecer o latim sobre o etrusco, o osco e o umbro, mas não sobre o grego, cujo prestígio cultural era maior.
As populações submetidas e as federadas, antes de perder sua língua em favor do latim, atravessaram um período mais ou menos longo de bilinguismo; de fato, algumas das línguas pré-romanas tiveram, no território romanizado, considerável vitalidade durante muito tempo
E essas línguas originárias deram uma cor específica a cada língua neolatina (ou românica) surgente, permanecendo presentes em topônimos dessas regiões até hoje.
Após a sua transformação nas línguas românicas, o latim continuou a fornecer um repertório de termos para muitos campos semânticos, especialmente culturais e técnicos, em uma ampla variedade de línguas.
O latim é uma língua flexiva
No caso dos substantivos e adjetivos a flexão é denominada declinação; no caso dos verbos, conjugação.
No latim clássico cada substantivo ou adjetivo pode tomar seis formas ou casos:
Também existem resquícios de um sétimo caso de origem indo-europeia, o locativo, que indica localização (por exemplo: domī , "em casa"), no entanto, este é limitado a palavras específicas.
Outra característica distintiva do latim é o uso de formas simples para expressar a voz passiva dos verbos, além de uma forma verbo-nominal muito frequente chamada de supino
Ambas formas se perderam nas línguas românicas.
Os romanos usavam o alfabeto latino, derivado do alfabeto itálico antigo, o qual por sua vez advinha do alfabeto grego
O alfabeto latino sobrevive atualmente como sistema de escrita das línguas românicas (como o português), célticas, germânicas (inclusive o inglês) e muitas outras.
Os antigos romanos não usavam pontuação, macros (mas empregavam ápices para distinguir entre vogais longas e breves), nem as letras j e u, letras minúsculas (embora usassem uma forma de escrita cursiva) ou espaço entre palavras (mas por vezes empregavam-se pontos entre palavras para evitar confusões)
Assim, um romano escreveria a frase "Lamentai, ó Vênus e cupidos" da seguinte maneira:
Esta frase seria escrita numa edição moderna como:
Ou, com macros:
A escrita cursiva romana é encontrada nos diversos tabletes de cera escavados em sítios como fortes, como por exemplo os descobertos em Vindolanda, na Muralha de Adriano, na Grã-Bretanha.
A chamada pronúncia reconstituída ou restaurada baseia-se em pesquisas recentes sobre os mais prováveis sons que os romanos antigos atribuíam a cada letra e, embora não haja uniformidade de opiniões em alguns pontos, vem sendo adotada em escolas de todo o mundo.
Há dois outros tipos de pronúncia: a pronúncia tradicional lusófona, também a mais usada em fórmulas jurídicas, e a pronúncia adotada pela Igreja Católica (latim eclesiástico)
Quanto à ortografia, não há diferenças.
A seguir, as principais características da pronúncia restaurada (entre parênteses as pronúncia e a marcação do acento tônico): 

Os romanos antigos faziam distinção entre vogais breves e vogais longas, estas últimas com o dobro de duração das primeiras e, para efeitos de acentuação tônica, usavam a regra da penúltima, segundo a qual o critério de acentação tônica é a duração (longa ou breve) da penúltima vogal: se a penúltima vogal é longa, ela recebe o acento; se é curta, o acento recua para a antepenúltima vogal
Existem ainda alguns aspectos a notar, como, por exemplo:
1) vogal seguida de outra vogal é geralmente breve: filius (pronuncia-se 'fílius': o i antes do u é breve e, portanto, o acento recua).
2) vogal seguida de duas consoantes é geralmente longa: puella (o e vem antes de duas consoantes e, portanto, é longo e acentuado).
3) em latim não existem palavras com acento na última sílaba (oxítonas).
Todas as vogais de uma palavra têm sua duração bem definida e dessa duração depende a compreensão dos ritmos da poesia latina.
O latim não possui artigos.
Os substantivos têm dois números (singular e plural) e seis casos (nominativo, vocativo, acusativo, genitivo, dativo e ablativo)
Organizam-se em cinco declinações, que se distinguem pela terminação da forma de genitivo singular: 1ª: -ae, 2ª: -i, 3ª: -is, 4ª: -us e 5ª: -ei
Nem sempre a forma de nominativo correspondente é determinável a partir da forma de genitivo
Por exemplo, nominativo uerbum, genitivo uerbi ("palavra"); mas nominativo puer, genitivo pueri (menino)
Assim, para se saber declinar um nome em todas as suas formas, é preciso saber a forma de nominativo e a de genitivo; tipicamente os dicionários fornecem ambas: uerbum, uerbi e puer, pueri.
Há três géneros gramaticais: masculino, feminino e neutro
O género de um nome depende em certa medida da declinação que o nome segue, mas a associação não é completamente rígida
Os nomes da primeira declinação são quase todos femininos (p
ex., rosa, rosae "rosa"), mas os que têm referentes humanos geralmente respeitam o género natural e por isso alguns são masculinos (p
ex., nauta, nautae "marinheiro")
Os nomes da segunda declinação cujo nominativo singular termina em -um são todos neutros
Os restantes nomes desta declinação (com nominativo em -us or -r, como dominus, domini "senhor", ager, agri "campo", uir, uiri homem) são quase todos masculinos, mas há muitos nomes de árvores em -us, -i e estes são todos femininos: ficus, fici "figueira"
Nas restantes declinações o género é mais arbitrário.
O adjetivo concorda com o nome que modifica ou de que é predicado em número, género e caso.
A numeração é: unus/una/unum, duo/duae/duo, tres/tria, quattuor, quinque, sex, septem, octo, novem, decem; 11 undecim, 12 duodecim, 13 tredecim, 20 viginti, 30 triginta, 100 centum.
Os verbos flexionam em pessoa, número, tempo, modo, aspeto e voz
Cada verbo pertence a uma de quatro conjugações, que se distinguem por exemplo pela forma de infinitivo presente ativo: 1ª: -are, 2ª: -ēre, 3ª: -ěre, 4ª: -ire
O lema de um verbo latino (isto é a forma de dicionário) não é contudo uma forma de infinitivo mas sim a forma de primeira pessoa singular do presente do indicativo ativo: p.ex., o verbo sum ("sou"), não esse ("ser").
O latim possui muito poucos nomes e verbos com flexão verdadeiramente irregular, mas contém muitíssimos verbos cujas formas se baseiam em radicais diferentes e que não são previsíveis entre si
Por exemplo, o verbo cano ("cantar"), tem formas como cano ("canto", radical can-), cecini ("cantei", radical cecin-) e cantum ("para cantar", radical cant-).
O pronome interrogativo é quis (masculino e feminino) "quem?", quid "quê?"
Quis possui formas plurais qui/quae/qua
Os demonstrativos são is/ea/id, hic/haec/hoc, "este/esta/isto", iste, ista, istud "esse, essa, isso", ille/illa/illud "aquele/aquela/aquilo"
Os pronomes pessoais são: singular ego "eu", tu "tu"; plural nos "nós", uos "vós"
Para a terceira pessoa podem usar-se demonstrativos ou sobretudo sujeitos nulos.
A ordem canónica do latim clássico é SOV, mas é uma língua não configuracional: a ordem das palavras não está diretamente ligada a funções gramaticais, pois a flexão em caso é muitas vezes suficiente para determinar estas funções
Por exemplo, as seguintes frases latinas significam todas "Marco ama Cornélia", uma vez que a forma Marcus é nominativa e a forma Corneliam é acusativa:
A frase "Cornélia ama Marco" seria Cornelia Marcum amat.
-a no singular Ex: "Bona discipula sum" ("Boa discípula sou", ou, "[Eu] sou [uma] boa discípula")
-ae no plural Ex: "Ideo servae sedulae sunt" ("Por isso, escravas aplicadas são", ou, "Por isso, [as] escravas são aplicadas")
-am no singular Ex.: Staphyla Phaedram amat
"Estáfila ama Fedra"
-as no plural Ex.: Staphyla Phaedras amat
"Estáfila ama as Fedras".
Em português, diferenciamos os complementos verbais por posição e por preposições
Em orações afirmativas, por exemplo, o sujeito vem tipicamente antes do verbo e os outros complementos vêm tipicamente depois do verbo
Abaixo temos os sujeitos em negrito e os outros complementos com a primeira letra em negrito.
Em latim, contudo, além da posição relativa dos complementos e das preposições, também se diferenciavam os complementos verbais pela escolha das terminações dos nomes.
Os sujeitos, no latim, ocorrem tipicamente no caso nominativo e "denotativo"
Podem também ocorrer no caso acusativo quando uma oração complementar representa o que alguém imagina, deseja, percebe ou diz.
Aquilo que se faz, imagina, deseja, percebe ou se diz ocorre tipicamente no caso acusativo.
Aquilo com que se atinge ou que se dá a alguém ocorre tipicamente no caso acusativo.
Alguém a quem se dá ou se diz algo ocorre tipicamente no caso dativo.
Alguém a quem algo pertence também ocorre tipicamente no caso dativo.
Aquilo que se usa ocorre no caso ablativo.
(Em latim, não existem pronomes do caso reto para a 3ª pessoa do singular: faz-se o uso de pronomes demonstrativos para indicar essa ausência).
Os numerais latinos podem ser Cardinais, Ordinais, Multiplicativos e Distributivos.
Os três primeiros cardinais declinam nos 3 gêneros (M, F, N), no singular / plural e nos 5 casos (Nom., Acu., Gen., Dat., Abl.)
O cardinal 3 utiliza a mesma forma para os gêneros M e F
Os demais cardinais até 100 não declinam.
Os cardinais são:
Os ordinais indicam em latim, além da sequência, as frações
São declináveis como adjetivos da primeira classe
Apresentam as formas como segue:
Os adjetivos declinam conforme adjetivos de segunda classe e são: simplex, duplex, triplex, etc.
Os advérbios (uma vez, duas vezes, etc) não tem declinação e são: semer, bis, ter, quater, etc.
São também declináveis, indicam "de um em um", "de dois em dois" e assim por diante
Apresentam a forma: singuli, bini, terni, quaterni, etc.
até nuoeni, deni; dezenas: viceni, triceni, etc

A expansão do Império Romano espalhou o latim por toda a Europa e o latim vulgar terminou por dialetar-se, com base no lugar em que se encontrava o falante
O latim vulgar evoluiu gradualmente de modo a tornar-se cada uma das distintas línguas românicas, um processo que continuou pelo menos até o século IX
Tais idiomas mantiveram-se por muitos séculos como línguas orais, apenas, pois o latim ainda era usado para escrever
Por exemplo, o latim foi a língua oficial de Portugal até 1296, quando foi substituído pelo português
Estas línguas derivadas, como o italiano, o francês, o espanhol, o português, o catalão e o romeno, floresceram e afastaram-se umas das outras com o tempo.
Dentre as línguas românicas, o italiano é a que mais conserva o latim em seu léxico, enquanto que o sardo é o que mais preserva a fonologia latina.
Algumas das diferenças entre o latim clássico e as línguas românicas têm sido estudadas na tentativa de se reconstruir o latim vulgar
Por exemplo, as línguas românicas apresentam um acento tônico distinto em certas sílabas, ao qual o latim acrescentava uma quantidade vocálica distinta
O italiano e o sardo logudorês possuem, além do acento tônico, uma ênfase consonantal distinta; o espanhol e o português, apenas o acento tônico; e no francês, a quantidade vocálica e o acento tônico já não são distintos
Outra grande diferença entre as línguas românicas e o latim é que as primeiras, com exceção do romeno, perderam os seus casos gramaticais para a maioria das palavras, afora alguns pronomes
A língua romena possui um caso direto (nominativo/acusativo), um indireto (dativo/genitivo), um vocativo e é o único idioma que preservou do latim o gênero neutro e parte da declinação.
Embora não seja uma língua românica, o inglês sofreu forte influência do latim
Sessenta por cento do seu vocabulário são de origem latina, em geral por intermédio do francês
O mesmo ocorreu com o maltês, uma língua semítica falada na República de Malta, na costa sul da Itália, que fora influenciado por 50% de palavras italianas e sicilianas e, em menor grau, pelo francês em seu léxico, e que mais recentemente fora influenciado pelo inglês em 20% de seu léxico
Também herdou o alfabeto latino, sendo a única língua semítica a ser escrita neste alfabeto.
Ademais do português, outras línguas românicas surgidas a partir do latim incluem o espanhol, o francês, o sardo, o italiano, o romeno, o galego, o occitano, o rético, o catalão e o dalmático - este, já extinto
As áreas onde as línguas românicas extintas eram faladas, são denominadas Romania submersa.
Como o contato com o latim escrito se manteve ao longo dos tempos, mesmo muito depois de o latim deixar de ter falantes nativos, muitas palavras latinas foram sendo introduzidas em muitas línguas
Este fenómeno acentuou-se desde o Renascimento, altura em que a cultura clássica foi revalorizada
Sobretudo o inglês e as línguas românicas receberam (e continuam a receber) muitas palavras de origem latina, mas bastantes outras línguas também o fizeram
Em especial, muitos novos termos dos domínios técnicos e científicos têm na sua base palavras latinas.
O latim vive sob a forma do latim eclesiástico usado para éditos e bulas emitidos pela Igreja Católica, e sob a forma de uma pequena quantidade esparsa de artigos científicos ou sociais escritos utilizando a língua, bem como em inúmeros clubes latinos
O vocabulário latino é usado na ciência, na universidade e no direito
O latim clássico é ensinado em muitas escolas, muitas vezes combinado com o grego, no estudo de clássicos, embora o seu papel tenha diminuído desde o início do século XX
O alfabeto latino, juntamente com suas variantes modernas, como os alfabetos inglês, espanhol, francês, português e alemão, é o alfabeto mais utilizado no mundo
Terminologia decorrente de palavras e conceitos em latim é amplamente utilizada, entre outros domínios, na filosofia, medicina, biologia e direito, em termos e abreviações como subpoena duces tecum, lato sensu, etc., i.e., q.i.d
(quater in die: "quatro vezes por dia") e inter alia (entre outras coisas)
Estes termos em latim são utilizados isoladamente, como termos técnicos
Em nomes científicos para organismos, o latim é geralmente o idioma preferido, seguido pelo grego.
A maior organização que ainda usa o latim em contextos oficiais e semioficiais é a Igreja Católica (principalmente na Igreja Católica de Rito Latino)
A Missa tridentina usa o latim, apesar do rito romano costumar utilizar o vernáculo local; no entanto, pode ser e muitas vezes é rezado em latim, particularmente no Vaticano
Na verdade, o latim ainda é a língua padrão oficial do rito romano da Igreja Católica e o Concílio Vaticano II apenas autorizou que os livros litúrgicos fossem traduzidos e, opcionalmente, usados nas línguas vernáculas
O latim é a língua oficial da Santa Sé e do Vaticano
A Cidade do Vaticano é também onde está instalado o único caixa eletrônico onde as instruções são dadas em latim.
Nos casos em que é importante empregar uma língua neutra, como em nomes científicos de organismos, costuma-se usar o latim.
Alguns filmes, como A Paixão de Cristo, apresentam diálogos em latim
A música 'Nirvana' do Grupo El Bosco é cantada, parte em latim, e em seguida em inglês.
Muitas instituições ainda hoje ostentam lemas em latim, a exemplo do estado brasileiro de Minas Gerais (libertas quæ sera tamen).
 Grécia
 Chipre
 União Europeia
A língua grega (ελληνικά, IPA: [eliniˈka] ou ελληνική γλώσσα, AFI: [eliniˈki ˈɣlosa], lit
"língua helênica") é um ramo independente da família linguística indo-europeia
Natural do sul dos Bálcãs, oeste da Ásia Menor e a região em torno do mar Egeu, é o idioma indo-europeu a ter tido sua história documentada, abrangendo 34 gerações de registros escritos
Seu sistema de escrita foi o alfabeto grego durante a maior parte de sua história; outros sistemas, como o Linear B e o silabário cipriota também foram utilizados
O alfabeto grego surgiu a partir da escrita fenícia, e acabou dando origem, por sua vez, aos alfabetos latino, cirílico, copta, e diversos outros sistemas de escrita.
O idioma grego tem um lugar importante na história da Europa, do mundo ocidental e do cristianismo; o cânone da literatura grega antiga inclui obras de importância monumental, que influenciaram de maneira decisiva o cânone da literatura ocidental posterior; entre as obras de destaque estão poemas épicos como a Ilíada e a Odisseia
O grego também foi a língua na qual diversos dos textos fundamentais da filosofia ocidental, como os diálogos platônicos e as obras de Aristóteles, foram escritos; o Novo Testamento da Bíblia cristã foi escrito no grego koiné
Juntamente com os textos latinos e as tradições do mundo romano, o estudo dos textos gregos e das sociedades da Antiguidade foram a disciplina da História e Arqueologia Clássica.
O grego foi uma língua franca amplamente falada no mundo ao redor do mar Mediterrâneo, e até mesmo em outras partes, durante a Antiguidade Clássica, e viria a se tornar o idioma oficial do Império Bizantino
Em sua forma atual, o grego é a língua oficial da Grécia, uma das línguas oficiais de Chipre e uma das 23 línguas oficiais da União Europeia
É falado por pelo menos 13 milhões de pessoas atualmente, na Grécia, em Chipre e nas comunidades de expatriados em diversos países ao redor do mundo.
As raízes gregas frequentemente são usadas para formar novas palavras em outros idiomas, especialmente nos ramos da ciência e medicina; o grego e o latim são as fontes predominantes do vocabulário científico internacional
Mais de cinquenta mil palavras do inglês, por exemplo, têm origem no grego.


O grego moderno, língua oficial da Grécia, difere em muitas formas do grego antigo e é falado por cerca de 13,1 milhões de pessoas
Na Grécia, é falado por quase toda a população
Também é, juntamente com o turco, a língua oficial de Chipre, embora o uso oficial do turco tenha sido limitado pela República de Chipre desde a invasão turca de 1974
Devido à adesão da Grécia e de Chipre à União Europeia, o grego é, atualmente, uma de suas 24 línguas oficiais
Além disso, o grego é oficialmente reconhecido como uma língua minoritária em partes da Itália e Albânia, bem como na Armênia e Ucrânia, sem falar na diáspora grega em países europeus e americanos, bem como na Austrália
Essa diáspora é formada não apenas por descendentes de gregos da Grécia, como também de indivíduos nascidos das ondas de emigração que quase extinguiram as antigas comunidades gregas de lugares como Egito, Turquia, Bulgária etc.
A língua grega moderna - isto é, o falar inicialmente restrito a um certo estrato das populações da Grécia meridional, acrescido de componentes eruditos e elementos estrangeiros (principalmente franceses e ingleses) - só se tornou a língua oficial do país em 1976
Até esta data, a língua oficial era a chamada "catarévussa", o grego clássico, uma variante livresca decalcada do grego bizantino
O debate em torno da reforma linguística, que começou ainda em meados do século XIX, teve a cidade de Atenas por epicentro e o poeta Kostís Palamás como figura principal.
Os dialetos mais importantes eram os seguintes:
O alfabeto utilizado para escrever a língua grega teve o seu desenvolvimento por volta do século IX a.C., utilizando-se até aos nossos dias, tanto no grego moderno como também na Matemática, Astronomia, etc.
Anteriormente, o alfabeto grego (Ελληνικό αλφάβητο) foi escrito mediante um silabário, utilizado em Creta e zonas da Grécia continental como Micenas ou Pilos entre os séculos XVI a.C
e XII a.C
e conhecido como linear B
O Grego que reproduz parece uma versão primitiva dos dialectos arcado-cipriota e jónico-ático, dos quais provavelmente é antepassado, e é conhecido habitualmente como grego micênico.
Crê-se que o alfabeto grego deriva duma variante do semítico, introduzido na Grécia por mercadores fenícios
Dado que o alfabeto semítico não necessita de notar as vogais, ao contrário da língua grega e outras da família indo-europeia, como o latim e em consequência o português, os gregos adaptaram alguns símbolos fenícios sem valor fonético em grego para representar as vogais
Este facto pode considerar-se fundamental e tornou possível a transcrição fonética satisfatória das línguas Europeias.
As letras obsoletas desapareceram do alfabeto nos seus primeiros tempos, antes do denominado período clássico
Dado que a aparição das letras minúsculas é bastante posterior, não existem minúsculas medievais das ditas letras.
Originariamente existiram variantes do alfabeto grego, sendo as mais importantes a ocidental (Calcídica) e a oriental (Jónica)
A variante ocidental originou o alfabeto etrusco e daí o alfabeto romano
Atenas adoptou no ano 403 a.C
a variante oriental, dando lugar a que pouco depois desaparecessem as demais formas existentes do alfabeto
Já nesta época o grego escrevia-se da esquerda para a direita, enquanto que a princípio a maneira de o escrever era alternadamente da esquerda para a direita e da direita para a esquerda, de maneira que se começava pelo lado em que se tinha concluído a linha anterior, invertendo todos os caracteres em dito processo.
O factor inovador introduzido com o alfabeto grego são as vogais
As primeiras vogais foram Alfa, Épsilon, Iota, Ómicron e Upsilon
Se se contempla o processo de criação do alfabeto grego como resultado de um processo dinâmico baseado na adopção de vários alfabetos semíticos através do tempo, encontrando inclusive influências do linear-B, poder-se-ia dar uma explicação mais satisfatória da sua origem do que as teorias que postulam uma adaptação única de um alfabeto determinado num momento dado.
Alemão · Búlgaro · Checo · Croata · Dinamarquês · Eslovaco · Esloveno · Espanhol · Estoniano · Finlandês · Francês · Grego · Húngaro · Inglês · Irlandês · Italiano · Letão · Lituano · Maltês · Neerlandês · Polaco · Português · Romeno · Sueco
146 °C 
α-D-glucose: 146 °C 
β-D-glucose: 150 °C 
A glicose, glucose ou dextrose, é um monossacarídeo e é um dos carboidratos mais importantes na biologia
As células a usam como fonte de energia e intermediário metabólico
A glicose é um dos principais produtos da fotossíntese e inicia a respiração celular em seres procariontes e eucariontes
É um cristal sólido de sabor adocicado, de formula molecular C6H12O6, encontrado na natureza na forma livre ou combinada
Juntamente com a frutose e a galactose, é o carboidrato fundamental de carboidratos maiores, como sacarose e maltose
Amido e celulose são polímeros de glucose.
No metabolismo, a glicose é uma das principais fontes de energia e fornece 4 calorias de energia por grama
A glicose hidratada (como no soro glicosado) fornece 3,4 calorias por grama
Sua degradação química durante o processo de respiração celular dá origem a energia química (armazenada em moléculas de ATP - 36 ou 38 moleculas (depende da celula) de ATP por moléculas de glicose), gás carbônico e água.
Por ter 6 átomos de carbono é classificada como uma hexose, uma subcategoria dos monossacarídeos
A D-Glicose é um dos 16 estereoisômeros da aldohexose, também conhecida como dextrose acontece abundantemente na natureza, diferente de seu isomero L-Glicose
No Brasil é comumente fabricada a partir da cana-de-açúcar.
No ano de 1747, Andreas Sigismund Marggraf foi o primeiro a isolar a glicose.
A glicose quando em soluçao com a substancia Benedict sob aquecimento muda sua cor de azul para laranja .
Apresenta fórmula mínima: CH2O
Fórmula estrutural:
A glicose (C6H12O6) contém seis átomos de carbono e um grupo aldeído e é consequentemente referida como uma aldo-hexose
A molécula de glicose pode existir em uma forma de cadeia aberta (acíclica) e anel (cíclica) (em equilíbrio), a última sendo o resultado de uma reação intramolecular entre o átomo C do aldeído e a grupo hidroxil C-5 para formar um hemiacetal intramolecular
Em solução aquosa as duas formas estão em equilíbrio, e em pH 7 a forma cíclica é predominante
Como o anel contém cinco átomos de carbono e um átomo de oxigênio, o que lembra a estrutura do pirano, a forma cíclica da glucose também é referida como glucopiranose
Neste anel, cada carbono está ligado a um grupo hidroxila lateral com exceção do quinto átomo, que se liga ao sexto átomo de carbono fora do anel, formando um grupo CH2OH.

O nome Glicose veio do grego (γλυκύς), que significa "doce", mais o sufixo -ose, indicativo de açúcar
Tem função de regulador de energia, participa das vias metabólicas, além de ser precursora de outras importantes moléculas.
Urina é um subproduto líquido do corpo, tipicamente estéril (na ausência de doenças), secretada pelos rins, depositada na bexiga e excretado pela uretra
O metabolismo celular gera vários subprodutos, muitos ricos em nitrogênio, que precisam ser eliminados da corrente sanguínea
Estes subprodutos são eventualmente expelidos do corpo em um processo conhecido como micção, o método primário para excretar do corpo substâncias químicas solúveis em água
Estas substâncias químicas podem ser analisadas por uranálise
É uma forma de limpar o organismo liberando gorduras,sais e outros.
Nos mamíferos, a urina é um fluido excretório resultante da filtragem do sangue nos rins
Nas aves e nos répteis é uma excreção sólida ou semi-sólida.
A urina é constituída pela filtração do plasma com posterior reabsorção dos nutrientes ainda presentes no mesmo, pelo túbulo proximal
A filtração é feita nos néfrons, que obtém uma parede, um tubo, que é chamado de túbulo, o qual é rodeado de vasos sanguíneos, que sugam os nutrientes que o organismo precisa, para depois ir para os ureteres, para a bexiga para ser armazenada, e passada para a uretra para finalmente ser expelida.


A urina humana, tal como a urina de outros animais, é composta por cerca de 3000 componentes, mas principalmente de água (95%, em média), e contém também cerca de 3% de ureia e de ácido úrico, sal e outras substâncias, sendo expelida durante o ato de urinar
O volume, a acidez e a concentração de sais na urina são regulados por hormonas, entre as quais figuram a hormona antidiurética e a aldosterona
Estas hormonas atuam nos rins para garantir que a água, os sais e o equilíbrio ácido-base (acidez ou alcalinidade do sangue e do fluido intersticial) do organismo se mantêm dentro de estreitos limites
Cerca de metade dos sólidos na urina humana são ureia, o principal produto da degradação do metabolismo das proteínas, e o resto inclui nitrogénio, cloretos, cetosteroides, fósforo, amónio, creatinina e ácido úrico
A presença na urina de açúcar, albumina, pigmentos biliares ou quantidades anormais de algumas substâncias, incluindo as constituintes habituais, é indicador de doenças
A urina é normalmente estéril quando é expelida e tem só um vago cheiro
O cheiro desagradável da urina deteriorada é devido à ação de bactérias que provocam a libertação de amoníaco.
A língua portuguesa, também designada português, é uma língua românica flexiva ocidental originada no galego-português falado no Reino da Galiza e no norte de Portugal
Com a criação do Reino de Portugal em 1139 e a expansão para o sul como parte da Reconquista deu-se a difusão da língua pelas terras conquistadas e mais tarde, com as descobertas portuguesas, para o Brasil, África e outras partes do mundo
O português foi usado, naquela época, não somente nas cidades conquistadas pelos portugueses, mas também por muitos governantes locais nos seus contatos com outros estrangeiros poderosos
Especialmente nessa altura a língua portuguesa também influenciou várias línguas.
É uma das línguas oficiais da União Europeia, do Mercosul, da União de Nações Sul-Americanas, da Organização dos Estados Americanos, da União Africana e dos Países Lusófonos
Com aproximadamente 280 milhões de falantes, o português é a 5ª língua mais falada no mundo, a 3ª mais falada no hemisfério ocidental e a mais falada no hemisfério sul do planeta.
Durante a Era dos Descobrimentos, marinheiros portugueses levaram o seu idioma para lugares distantes
A exploração foi seguida por tentativas de colonizar novas terras para o Império Português e, como resultado, o português dispersou-se pelo mundo
Brasil e Portugal são os dois únicos países cuja língua primária é o português
É língua oficial em antigas colônias portuguesas, nomeadamente, Moçambique, Angola, Cabo Verde, Guiné Equatorial, Guiné-Bissau e São Tomé e Príncipe, todas na África
Além disso, por razões históricas, falantes do português, ou de crioulos portugueses, são encontrados também em Macau (China), Timor-Leste, em Damão e Diu e no estado de Goa (Índia), Malaca (Malásia), em enclaves na ilha das Flores (Indonésia), Batticaloa no (Sri Lanka) e nas ilhas ABC no Caribe.
O português é conhecido como "a língua de Camões" (em homenagem a uma das mais conhecidas figuras literárias de Portugal, Luís Vaz de Camões, autor de Os Lusíadas) e "a última flor do Lácio" (expressão usada no soneto Língua Portuguesa, do escritor brasileiro Olavo Bilac.) Miguel de Cervantes, o célebre autor espanhol, considerava o idioma "doce e agradável"
Em março de 2006, o Museu da Língua Portuguesa, um museu interativo sobre o idioma, foi fundado em São Paulo, Brasil, a cidade com o maior número de falantes do português em todo o mundo.
O Dia Internacional da Língua Portuguesa é comemorado em 5 de maio
 A data foi instituída em 2009, no âmbito da Comunidade dos Países de Língua Portuguesa (CPLP), com o propósito de promover o sentido de comunidade e de pluralismo dos falantes do português
A comemoração propicia também a discussão de questões idiomáticas e culturais da lusofonia, promovendo a integração entre os povos desses nove países.

O português teve origem no que é hoje a Galiza e o norte de Portugal, derivada do latim vulgar que foi introduzido no oeste da Península Ibérica há cerca de dois mil anos
Tem um substrato céltico-lusitano, resultante da língua nativa dos povos ibéricos pré-romanos que habitavam a parte ocidental da Península (Galaicos, lusitanos, Célticos e Cónios)
Surgiu no noroeste da Península Ibérica e desenvolveu-se na sua faixa ocidental, incluindo parte da antiga Lusitânia e da Bética romana
O romance galaico-português nasce do latim falado, trazido pelos soldados romanos, colonos e magistrados
O contacto com o latim vulgar fez com que, após um período de bilinguismo, as línguas locais desaparecessem, levando ao aparecimento de novos dialectos
Assume-se que a língua iniciou o seu processo de diferenciação das outras línguas ibéricas através do contacto das diferentes línguas nativas locais com o latim vulgar, o que levou ao possível desenvolvimento de diversos traços individuais ainda no período romano
A língua iniciou a segunda fase do seu processo de diferenciação das outras línguas românicas depois da queda do Império Romano, durante a época das invasões bárbaras no século V quando surgiram as primeiras alterações fonéticas documentadas que se reflectiram no léxico
Começou a ser usada em documentos escritos pelo século IX, e no século XV tornara-se numa língua amadurecida, com uma literatura bastante rica.
Chegando à Península Ibérica em 218 a.C., os romanos trouxeram com eles o latim vulgar, de que todas as línguas românicas (também conhecidas como "línguas novilatinas" ou "neolatinas") descendem
Só no fim do século I a.C
os povos que viviam a sul da Lusitânia pré-romana, os cónios e os celtas, começam o seu processo de romanização
As línguas paleo-ibéricas, como a Língua lusitana ou a sul-lusitana são substituídas pelo latim
A língua difundiu-se com a chegada dos soldados, colonos e mercadores, vindos das várias províncias e colónias romanas, que construíram cidades romanas normalmente perto de cidades nativas.
A partir de 409 d.C., enquanto o Império Romano entrava em colapso, a Península Ibérica era invadida por povos de origem germânica e iraniana ou eslava (suevos, vândalos, búrios, alanos, visigodos), conhecidos pelos romanos como bárbaros que receberam terras como federados
Os bárbaros (principalmente os suevos e os visigodos) absorveram em grande escala a cultura e a língua da Península; contudo, desde que as escolas e a administração romana fecharam, a Europa entrou na Idade Média e as comunidades ficaram isoladas, o latim popular continuou a evoluir de forma diferenciada levando à formação de um proto-ibero-romance "lusitano" (ou proto-galego-português)
Desde 711, com a invasão islâmica da Península, que também introduziu um pequeno contingente de saqalibas, o árabe tornou-se a língua de administração das áreas conquistadas
Contudo, a população continuou a usar as suas falas românicas, o moçárabe nas áreas sob o domínio mouro, de tal forma que, quando os mouros foram expulsos, a influência que exerceram na língua foi relativamente pequena
O seu efeito principal foi no léxico, com a introdução de cerca de mil palavras através do moçárabe-lusitano.
Em 1297, com a conclusão da reconquista, o rei D
Dinis I prossegue políticas em matéria de legislação e centralização do poder, adoptando o português como língua oficial em Portugal
O idioma se espalhou pelo mundo nos séculos XV e XVI quando Portugal estabeleceu um império colonial e comercial (1415-1999) que se estendeu do Brasil, na América, a Goa, na Ásia (Índia, Macau na China e Timor-Leste)
Foi utilizada como língua franca exclusiva na ilha do Sri Lanka por quase 350 anos
Durante esse tempo, muitas línguas crioulas baseadas no português também apareceram em todo o mundo, especialmente na África, na Ásia e no Caribe.
Em março de 1994 foi fundado o Bosque de Portugal, na cidade sul-brasileira de Curitiba; o parque abriga o Memorial da Língua Portuguesa, que homenageia os imigrantes portugueses e os países que adotam a língua portuguesa; originalmente eram sete as nações que estavam representadas em pilares, mas com a independência de Timor-Leste, este também foi homenageado com um pilar construído em 2007
Em março de 2006, fundou-se em São Paulo o Museu da Língua Portuguesa.
O português é a língua da maioria da população de Portugal, Brasil, São Tomé e Príncipe (98,4%) e, de acordo com o censo de 2014, é a língua habitual de 71,15% da população de Angola, entretanto, cerca de 85% dos angolanos são capazes de falar português, segundo o Instituto Nacional de Estatística
Apesar de apenas 10,7% da população de Moçambique ser de falantes nativos do português, o idioma é falado por cerca de 50,4% dos moçambicanos, de acordo com o censo de 2007
A língua também é falada por cerca de 15% da população da Guiné-Bissau, e por cerca de 25% da população de Timor-Leste
Não existem dados disponíveis relativos a Cabo Verde, mas quase toda a população é bilíngue, sendo os cabo-verdianos monolíngues falantes do crioulo cabo-verdiano
Em Macau, apenas 0,7% da população usa o português como língua nativa e cerca de 4% dos macaenses falam esse idioma.
Há também significativas comunidades de imigrantes falantes do português em muitos países como África do Sul, Andorra (18,6%), Austrália, Bermudas, Canadá (0,87% ou 274,670 pessoas segundo o censo de 2006, mas entre 400.000 e 500.000 de acordo com Nancy Gomes), Curaçao, França, Guernsey (2%), Japão, Jersey (4,6%), Luxemburgo (15,7%), Namíbia (5%), Paraguai (10,7% ou 636.000 pessoas), Suíça (3,7%), Venezuela (1 a 2% ou 254.000 a 480.000 pessoas), Uruguai (15%) e nos Estados Unidos (0,24% da população ou 687.126 falantes de acordo com o American Community Survey de 2007), principalmente em Nova Jersey, Nova York e Rhode Island.
Em algumas partes do que era a Índia Portuguesa, como Goa e Damão e Diu, o português ainda é falado, embora esteja em vias de desaparecimento.
A Comunidade dos Países de Língua Portuguesa (sigla CPLP) consiste em nove países independentes que têm o português como língua oficial: Angola, Brasil, Cabo Verde, Timor-Leste, Guiné-Bissau, Guiné Equatorial, Moçambique, Portugal e São Tomé e Príncipe.
A Guiné Equatorial fez um pedido formal de adesão plena à CPLP em junho de 2010, o que somente é concedido a países que têm o português como idioma oficial
Em 2011, o português foi incluído como sua terceira língua oficial (ao lado do espanhol e do francês) e, em julho de 2014, o país foi aceito como membro da CPLP.
O português é também uma das línguas oficiais da região administrativa especial chinesa de Macau (ao lado do chinês) e de várias organizações internacionais como o Mercosul, a Organização dos Estados Ibero-Americanos, a União de Nações Sul-Americanas, a Organização dos Estados Americanos, a União Africana e da União Europeia.
Poderá acrescentar-se a esse número a imensa diáspora de cidadãos de nações lusófonas espalhada pelo mundo, estimando-se que ascenda aos 10 milhões (4,5 milhões de portugueses, 3 milhões de brasileiros, meio milhão de cabo-verdianos, etc.) mas sobre a qual é difícil obter números reais oficiais, incluindo-se nisso a obtenção de dados porcentuais dessa diáspora que fala efetivamente a língua de Camões, uma vez que uma porção significativa será de cidadãos de países lusófonos nascidos fora de território lusófono descendentes de imigrantes, os quais não necessariamente falam o português
É necessário ter-se igualmente em conta que boa parte das diásporas nacionais já se encontra contabilizada nas populações dos países lusófonos, como por exemplo o grande número de cidadãos emigrantes dos Países Africanos de Língua Oficial Portuguesa (PALOPs) e brasileiros em Portugal, ou o grande número de cidadãos emigrantes portugueses no Brasil e nos PALOPs.
A língua portuguesa está no cotidiano de 274 milhões de pessoas, que têm contato direto ou indireto legal, jurídico e socialmente com a língua portuguesa, podendo tal contato consistir do idioma no dia-a-dia, passando pela educação, pelo contato com a administração local ou internacional, pelo comércio e/ou serviços, ou até mesmo consistir do simples vislumbre de sinalética, informação municipal e publicidade em português.
Cabe notar ainda o importante aumento e a consolidação da população das várias jurisdições para números arredondados facilmente identificáveis: Portugal passa dos 10,8 milhões; o Brasil passa dos 206 milhões, Moçambique dos 25,9 milhões, Angola dos 25,8 milhões, Guiné-Bissau 1,7 milhão, Timor-Leste 1,3, Guiné Equatorial com mais de 759 mil, Macau com mais de 597 mil, Cabo Verde com mais de 553 mil e São Tomé e Príncipe passa dos 197 mil
Números recentes e reais que, individualmente e em conjunto, fortalecem as suas nações, as identidades lusófonas e a língua portuguesa no panorama internacional.
Segundo dados estatísticos oficiais e fiáveis dos respectivos governos e seus institutos nacionais de estatística, a população de cada uma das dez jurisdições é a seguinte (por ordem decrescente):



O ensino obrigatório do português nos currículos escolares é observado no Uruguai e na Argentina
Outros países onde o português é ensinado em escolas, ou onde seu ensino está sendo introduzido agora, incluem Venezuela, Zâmbia, República do Congo, Senegal, Namíbia, Suazilândia, Costa do Marfim e África do Sul.
No estado de Goa na Índia, atualmente o português é aprendido, no ensino oficial e particular
A Universidade de Goa tem um mestrado em Estudos Portugueses desde 1988.
Segundo estimativas da UNESCO, o português é um dos idiomas que mais crescem entre as línguas europeias após o inglês e o espanhol
O português é o idioma que tem o maior potencial de crescimento como língua internacional na África Austral e na América do Sul
Espera-se que os países africanos falantes da língua portuguesa tenham uma população combinada de 83 milhões de pessoas até 2050
No total, os países de língua portuguesa terão por volta de 400 milhões de pessoas no mesmo ano.
Desde 1991, quando o Brasil assinou no mercado econômico do Mercosul com outros países sul-americanos, como Argentina, Uruguai e Paraguai, tem havido um aumento no interesse pelo estudo do português nas nações da América do Sul
O peso demográfico do Brasil no continente continuará a reforçar a presença do idioma na região.
Embora no início do século XXI, depois de Macau ter sido cedida à China, o uso de português estivesse em declínio na Ásia, está novamente se tornando uma língua relativamente popular por lá, principalmente por causa do aumento dos laços diplomáticos e financeiros chineses com os países de língua portuguesa.
Existe um número crescente de pessoas que falam português, nos média e na Internet, que estão apresentando tal situação à Comunidade dos Países de Língua Portuguesa (CPLP) e outras organizações para a realização de um debate na comunidade lusófona, com o objetivo de apresentar uma petição para tornar o português uma das línguas oficiais da Organização das Nações Unidas (ONU).
Em outubro de 2005, durante a convenção internacional do Elos Clube Internacional da Comunidade Lusíada, realizada em Tavira (Portugal), uma petição cujo texto pode ser encontrado na Internet com o título "Petição para tornar o idioma português oficial na ONU" foi redigida e aprovada por unanimidade
Rômulo Alexandre Soares, presidente da Câmara Brasil - Portugal, destaca que o posicionamento do Brasil no cenário internacional como uma das potências emergentes do século XXI, pelo tamanho de sua população, e a presença da sua variante do português em todo o mundo, fornece uma justificação legítima para a petição enviada à ONU, e assim tornar o português uma das línguas oficiais da organização
Esta é actualmente uma das causas do Movimento Internacional Lusófono.
Em África, o português é língua oficial em Cabo Verde, São Tomé e Príncipe, Guiné-Bissau, Moçambique e Angola
Finalmente, na Ásia, encontra-se Timor-Leste uma nação lusófona.
Assim como os outros idiomas, o português sofreu uma evolução histórica, sendo influenciado por vários idiomas e dialetos, até chegar ao estágio conhecido atualmente
Deve-se considerar, porém, que o português de hoje compreende vários dialetos e subdialetos, falares e subfalares, muitas vezes bastante distintos, além de dois padrões reconhecidos internacionalmente (o português brasileiro e o português europeu)
No momento atual, o português é a única língua do mundo ocidental falada por mais de cem milhões de pessoas com duas ortografias oficiais (é notado que a língua inglesa tem diferenças de ortografia pontuais mas não ortografias oficiais divergentes)
Esta situação deve ser resolvida pelo Acordo Ortográfico de 1990.
Foi, entretanto, concluído pela Professora Maria Regina Rocha, que através das regras do Acordo Ortográfico de 1990, foram unificados 569 vocábulos, 2.691 palavras que apresentavam diferenças entre as ortografias portuguesa/africana/asiática e brasileira assim se mantiveram após a reforma ortográfica, 1.235 passaram a ter uma grafia diferente e, assim, 3.926 vocábulos ficam com diferenças gráficas entre ambos os lados do Atlântico.
A língua portuguesa tem grande variedade de dialectos, muitos deles com uma acentuada diferença lexical em relação ao português padrão seja no Brasil ou em Portugal
Tais diferenças, entretanto, não prejudicam muito a inteligibilidade entre os locutores de diferentes dialectos.
Os primeiros estudos sobre os dialectos do português europeu começaram a ser registados por Leite de Vasconcelos no começo do século XX
Mesmo assim, todos os aspectos e sons de todos os dialectos de Portugal podem ser encontrados nalgum dialecto no Brasil
O português africano, em especial o português são-tomense, tem muitas semelhanças com o português do Brasil
Ao mesmo tempo, os dialetos do sul de Portugal (chamados "meridionais") apresentam muitas semelhanças com o falar brasileiro, especialmente, o uso intensivo do gerúndio (e
g
falando, escrevendo, etc.)
Na Europa, os dialectos transmontano e alto-minhoto apresentam muitas semelhanças com o galego
Um dialecto já quase desaparecido é o português oliventino ou português alentejano oliventino, falado em Olivença e em Táliga.
Após a independência das antigas colônias africanas, o português padrão de Portugal tem sido o escolhido pelos países africanos de língua portuguesa
Logo, o português tem apenas dois dialetos de aprendizagem, o europeu e o brasileiro
Note-se que na língua portuguesa europeia há uma variedade prestigiada que deu origem à norma-padrão: a variedade de Lisboa
No Brasil, a maior quantidade de falantes se encontra na região sudeste do país, essa região foi alvo de intensas migrações internas, graças ao seu poder econômico
O Distrito Federal apresenta um destaque devido ao seu dialeto próprio, pelas várias ordas de migração interna
Os dialectos europeus e americanos do português apresentam problemas de inteligibilidade mútua (dentro dos dois países), devido, sobretudo, a diferenças culturais, fonéticas, lexicais
Nenhum pode, no entanto, ser considerado como intrinsecamente melhor ou perfeito.
Algumas comunidades cristãs falantes de português na Índia, Sri Lanka, Malásia e Indonésia preservaram a sua língua mesmo depois de terem ficado isoladas de Portugal
A língua foi muito alterada nessas comunidades e, em muitas, nasceram crioulos de base portuguesa, alguns dos quais ainda persistem, após séculos de isolamento
Também é percebível uma variedade de palavras originadas do português no tétum
Palavras de origem portuguesa entraram no léxico de várias outras línguas, como o japonês, o suaíli, o indonésio e o malaio.
O Dicionário Houaiss da Língua Portuguesa, com cerca de 228 500 entradas, 376 500 acepções, 415 500 sinónimos, 26 400 antónimos e 57 000 palavras arcaicas, é um exemplo da riqueza léxica da língua portuguesa
Segundo um levantamento feito pela Academia Brasileira de Letras, a língua portuguesa tem atualmente cerca de 356 mil unidades lexicais
Essas unidades estão dicionarizadas no Vocabulário Ortográfico da Língua Portuguesa.
A maior parte do léxico do português é derivado do latim, já que o português é uma língua românica
No entanto, por causa da origem celtibera,, as migrações dos povos germânicos, a ocupação moura da Península Ibérica durante a Idade Média e a participação de Portugal na Era dos Descobrimentos, adotou palavras de todo o mundo
No século XIII, por exemplo, o léxico do português tinha cerca de 80% das suas palavras com origem latina e 20% com origem pré-romana, celta, germânica e árabe
Atualmente, a língua portuguesa ostenta no seu vocabulário termos provenientes de diferentes idiomas como o provençal, o holandês, o hebraico, o persa, o quíchua, o chinês, o turco, o japonês, o alemão e o russo, além de idiomas bem mais próximos, como o inglês, o francês, o espanhol e o italiano
Também houve influência de algumas línguas africanas.
A maioria das palavras em português que podem ter sua origem rastreada até aos habitantes pré-romanos de Portugal, que incluíam os iberos, galaicos, lusitanos, célticos, túrdulos velhos, cónios e outros, é celta, existindo muito pouco léxico ibérico
No século V, a Península Ibérica (a Hispânia romana) foi conquistada pelos germânicos suevos e visigodos
Esses povos contribuíram com algumas palavras ao léxico português, principalmente nas relacionadas à guerra
Entre os séculos IX e XIII, o português adquiriu cerca de 800 palavras do árabe, devido a influência moura na Iberia
No século XV, as explorações marítimas portuguesas levaram à introdução de estrangeirismos de muitas das línguas asiáticas
Do século XVI ao XIX, por causa do papel de Portugal como intermediário no comércio de escravos no Atlântico e o estabelecimento de grandes colónias portuguesas em Angola, Moçambique e Brasil, o português sofreu várias influências de idiomas africanos e ameríndios.
O português é uma língua indo-europeia, do grupo das línguas românicas (ou latinas), as quais descendem do latim, pertencente ao ramo itálico da família indo-europeia
Comparado com as outras línguas da Península Ibérica, excluindo o galego e o mirandês, considera-se ter maiores parecenças com o sistema vocálico catalão, mas também existem algumas similitudes entre o português e os falares pirenaicos centrais
Como factor decisivo para a evolução do português considera-se frequêntemente a influência de um marcado substrato celta
Os fonemas vocálicos nasais estabelecem uma similitude com o ramo galo-românico (especialmente com o francês antigo).
A língua portuguesa é, em alguns aspectos, parecida com a língua castelhana, tal como com a língua catalã ou a língua italiana, mas é muito diferente na sua sintaxe, na sua fonologia e no seu léxico
Um falante de uma das línguas precisa de alguma prática para entender um falante da outra
Além do mais, as diferenças no vocabulário podem dificultar o entendimento
Entretanto, essa situação usualmente se configura usando o vocabulário corrente da língua
Geralmente, há palavras portuguesas da mesma origem etimológica (às vezes em desuso) que as dos outros romances
Compare-se por exemplo:
Enquanto os falantes de português têm um nível notável de compreensão do castelhano, os falantes castelhanos têm, em geral, maior dificuldade de entendimento
Isto acontece porque o português, apesar de ter sons em comum com o castelhano, também tem sons particulares
No português, por exemplo, há vogais e ditongos nasais (provavelmente herança das línguas célticas)
Além disso, no português europeu há uma profunda redução de intensidade das sílabas finais e as vogais átonas finais tendem a ser ensurdecidas ou mesmo suprimidas
Esta particularidade da variedade europeia chama-se o ‘processo de redução do vocalismo átono’.
Há muitas línguas de contato derivadas do ou influenciadas pelo português, como por exemplo o patuá macaense de Macau
No Brasil, destacam-se o lanc-patuá derivado do francês e vários quilombolas, como o cupópia do Quilombo Cafundó, de Salto de Pirapora, no estado brasileiro de São Paulo.
O português tem duas normas escritas (padrões ou standards) reconhecidas internacionalmente:
Empregado por cerca de 85% dos falantes do português, o padrão brasileiro é hoje o mais falado, escrito, lido e estudado do mundo
É, ademais, amplamente estudado nos países da América do Sul, devido à grande importância econômica do Brasil no Mercosul.
As diferenças entre as variedades do português da Europa e do Brasil estão no vocabulário, na pronúncia e na sintaxe, especialmente nas variedades vernáculas, enquanto nos textos formais essas diferenças diminuem bastante
As diferenças não são maiores que entre o inglês dos Estados Unidos e do Reino Unido ou o francês da França e de Québec
Ambas as variedades são, sem dúvida, dialectos da mesma língua e os falantes de ambas as variedades podem entender-se apenas com pequenas dificuldades pontuais.
Essas diferenças entre as variantes são comuns a todas as línguas naturais, ocorrendo em maior ou menor grau, dependendo do caso
Com um oceano entre Brasil e Portugal, e ao longo de quinhentos anos, a língua evoluiu de maneira diferente em ambos os países, dando origem a dois padrões de linguagem simplesmente diferentes, não existindo um padrão que seja mais correto em relação ao outro.
É importante salientar que dentro daquilo a que se convencionou chamar "português do Brasil" e "português europeu" há um grande número de variações regionais.
Um dos traços mais importantes do português brasileiro é o seu conservadorismo em relação à variante europeia, sobretudo no aspecto fonético
Um português do século XVI mais facilmente reconheceria a fala de um brasileiro do século XX como sua do que a fala de um português
O exemplo mais forte disto é o vocalismo átono usado no Brasil, que corresponde ao do português da época dos descobrimentos
Assim, a linguística não só retira qualquer autoridade de qualquer variante em relação às outras, como mostra que a distância entre as variantes e entre os seus falantes não é tão grande como muitos pensam.
O que mais afasta as duas variantes não é o seu léxico ou pronúncia distintos, considerados naturais até num mesmo país, mas antes a circunstância, pouco comum nas línguas, de seguirem duas ortografias diferentes
Por exemplo, o Brasil eliminou o "c" das sequências interiores cc/cç/ct, e o "p" das sequências pc/pç/pt sempre que não são pronunciados na forma culta da língua, um remanescente do passado latino da língua que persistiu no português europeu.
Nota: no Brasil mantêm-se quando pronunciadas, como em facção, compactar, intelectual, aptidão etc.
Também ocorrem diferenças de acentuação devido a pronúncias diferentes
No Brasil, em palavras como acadêmico, anônimo e bidê usa-se o acento circunflexo por tratar-se de vogais fechadas, enquanto nos restantes países lusófonos estas vogais são abertas: académico, anónimo e bidé respectivamente.
Durante muitos anos, Portugal (até 1975, incluía as suas colónias) e o Brasil tomaram decisões unilateralmente e não chegaram a um acordo comum, legislando sobre a língua.
Existiram pelo menos cinco acordos ortográficos: Acordo Ortográfico de 1911, Acordo Ortográfico de 1943, Acordo Ortográfico de 1945, Acordo Ortográfico de 1971 e o Acordo Ortográfico de 1990
Todos eles estiveram envolvidos em polémicas e divergências entre os países signatários
Os mais significativos foram o Acordo Ortográfico de 1943 que esteve em vigor apenas no Brasil entre 12 de agosto de 1943 e 31 de dezembro de 2008 (com algumas alterações introduzidas pelo Acordo Ortográfico de 1971) e o Acordo Ortográfico de 1945, em vigor em Portugal e todas as colónias portuguesas da época, desde 8 de Dezembro de 1945 até à entrada em vigor do Acordo Ortográfico de 1990 (que ainda não entrou em vigor em todos os países signatários).
O Acordo Ortográfico de 1990 foi proposto para criar uma norma ortográfica única, de que participaram na altura todos os países de língua oficial portuguesa, e em que esteve presente uma delegação não oficial de observadores da Galiza
Os signatários que ratificaram o acordo original foram Portugal (1991), Brasil (1995), Cabo Verde (1998) e São Tomé e Príncipe (2006).
Em julho de 2004 foi aprovado, em São Tomé e Príncipe, o Segundo Protocolo Modificativo, durante a Cúpula dos Chefes de Estado e de governo da CPLP
O Segundo Protocolo vem permitir que o acordo possa vigorar com a ratificação de apenas três países, sem a necessidade de aguardar que todos os demais membros da CPLP adotem o mesmo procedimento, e contemplava também a adesão de Timor-Leste, que ainda não era independente em 1990
Assim, tendo em vista que o Segundo Protocolo Modificativo foi ratificado pelo Brasil (2004), Cabo Verde (2005) e São Tomé e Príncipe (2006), e que o Acordo passaria automaticamente a vigorar um mês após a terceira ratificação necessária, tecnicamente, o novo Acordo Ortográfico da Língua Portuguesa está em vigor, na ordem jurídica internacional e nos ordenamentos jurídicos dos três Estados acima indicados, desde 1º de Janeiro de 2007.
Depois de muita discussão, no dia 16 de maio de 2008, o parlamento português ratificou o Segundo Protocolo Modificativo, estabelecendo um prazo de até seis anos para que a reforma ortográfica seja totalmente implantada
No entanto, não existe nenhuma data oficial para a vigência do tratado no país, pelo que se rege segundo a norma oficial de 1945.
No Brasil, houve a vigência desde janeiro de 2009, tendo o presidente Luiz Inácio Lula da Silva assinado legislação sobre o acordo no segundo semestre de 2008
Porém, até 2012 as duas ortografias estiveram vigentes.
A gramática, a morfologia e a sintaxe do idioma português é semelhante à gramática das demais línguas românicas, especialmente à do espanhol, língua com a qual compartilha 89% de semelhança lexical, e ainda mais à do galego
O português é um idioma relativamente sintético e flexivo.
Substantivos, adjetivos, pronomes e artigos são moderadamente flexionados: existem dois gêneros (masculino e feminino) e dois números (singular e plural)
O caso gramatical da sua língua ancestral, o latim, foi perdido, mas os pronomes pessoais são ainda divididos em três tipos principais de formas: sujeito, objeto do verbo e objeto da preposição
A maioria dos substantivos e adjetivos pode levar muitos sufixos diminutivos ou aumentativos derivacionais e a maioria dos adjetivos podem ter sufixo derivacional "superlativo"
Normalmente os adjetivos seguem o substantivo.
Os verbos são altamente flexionados: existem três tempos (passado, presente e futuro), três modos (indicativo, subjuntivo, imperativo), três aspectos (perfectivo, imperfectivo e progressiva), duas vozes (ativa e passiva) e um infinitivo flexionado
Tempos mais que perfeitos e imperfeitos são sintéticos, totalizando 11 paradigmas de conjugação, enquanto todos os tempos progressivos e construções passivas são perifrásticos
Como em outras línguas românicas, existe também uma construção impessoal passiva, onde o agente substituído por um pronome indefinido
O português é basicamente uma língua SVO, embora a sintaxe SOV possa ocorrer com alguns poucos pronomes e a ordem das palavras geralmente não seja tão rígida quanto no inglês, por exemplo
É uma linguagem de sujeito nulo, com uma tendência de queda dos objetos de pronomes, bem como das variedades coloquiais
O português tem dois verbos de ligação.
A língua portuguesa tem várias características gramaticais que a distinguem da maioria das outras línguas românicas, como um pretérito mais-que-perfeito sintético, verbo no futuro do subjuntivo, infinitivo flexionado e um presente perfeito com um sentido iterativo
Um recurso exclusivo do idioma português é a mesóclise, a infixação de pronomes clíticos em algumas formas verbais.
A língua portuguesa contém alguns sons únicos para falantes de outras línguas, tornando-se, por isso, necessário que estes lhes prestem especial atenção quando os aprendem
O português tem uma das fonologias mais ricas das línguas românicas, com vogais orais e nasais, ditongos nasais e dois ditongos nasais duplos
As vogais semifechadas /e/, /o/ e as vogais semiabertas /ɛ/, /ɔ/ são quatro fonemas separados, ao invés do espanhol, e o contraste entre elas é usado para apofonia
O português europeu também possui duas vogais centrais, uma das quais tende a ser omitida na fala como o e caduc do francês
Há, no português, um máximo de nove vogais orais e 19 consoantes, embora algumas variedades da língua tenham menos fonemas (o português brasileiro é geralmente analisado como tendo sete vogais orais)
Há também cinco vogais nasais, que alguns linguistas consideram como alofones das vogais orais, dez ditongos orais e cinco ditongos nasais
No total, o português do Brasil tem 13 fonemas vogais.
Para as sete vogais do latim vulgar, o português europeu acrescentou duas vogais centrais próximas, uma das quais tende a ser elidida na fala rápida
A carga funcional destas duas vogais adicionais é muito baixa
As vogais altas /e o/ e as vogais baixas /ɛ ɔ/ são quatro fonemas distintos e eles se alternam em várias formas de apofonia
Como o catalão, o português usa qualidade da vogal para contrastar sílabas estressadas ​​com sílabas átonas: vogais isoladas tendem a ser levantadas, e em alguns casos, centralizadas, quando átonas
Ditongos nasais ocorrem principalmente nas extremidades das palavras.
Excerto do épico nacional português Os Lusíadas, de Luís de Camões (I, 33)
Alemão · Búlgaro · Checo · Croata · Dinamarquês · Eslovaco · Esloveno · Espanhol · Estoniano · Finlandês · Francês · Grego · Húngaro · Inglês · Irlandês · Italiano · Letão · Lituano · Maltês · Neerlandês · Polaco · Português · Romeno · Sueco
O Grande Dicionário Houaiss da Língua Portuguesa é um dicionário de língua portuguesa elaborado pelo lexicógrafo brasileiro Antônio Houaiss
A primeira edição foi lançada em 2001, no Rio de Janeiro, pelo Instituto Antônio Houaiss.
O projeto de confecção do dicionário começou em 1985
Antônio Houaiss tinha a ambição de criar o mais completo dicionário de língua portuguesa já compilado
Dezesseis anos depois, o Dicionário Houaiss foi concluído, contando durante esse período com uma equipe de edição com mais de 150 especialistas brasileiros, portugueses, angolanos e timorenses.
Lançado em setembro de 2001, logo foi eleito "o mais completo dicionário brasileiro" pela revista Época, considerado "imbatível" pela revista Veja e consagrado como o grande lançamento editorial de 2001 pelo Caderno B e pela Revista de Domingo, do Jornal do Brasil, assim como pelos jornais O Globo, Estado de Minas e Jornal da Tarde.
O Dicionário Houaiss traz cerca de 228.500 verbetes, 376.500 acepções, 415.500 sinônimos, 26.400 antônimos e 57.000 palavras arcaicas
Além da quantidade de verbetes, a equipe de edição pesquisou também as etimologias de cada palavra e o seu primeiro registro no idioma português
O vocabulário do Dicionário Houaiss abrange a terminologia atual do setor tecnológico e científico, assim como nomenclaturas atualizadas no campo da zoologia, botânica e anatomia, e ainda expressões populares e termos específicos do português europeu, brasileiro, africano e asiático
No Brasil, o Dicionário Houaiss é um dos dicionários mais prestigiados, ao lado do Dicionário Aurélio, e dos mais vendidos, ao lado deste e do Dicionário Michaelis
Em 2002, surgiu uma versão adaptada do dicionário para o mercado de Portugal, onde o Dicionário tem vindo a tornar-se uma obra de referência importante também .
O Instituto Antônio Houaiss de Lexicografia editou também dicionários menores, como o Dicionário de Conjugação Verbal e o Dicionário de Sinônimos e Antônimos.
Em 2012, o Ministério Público Federal (MPF) ajuizou, no dia 22 de fevereiro uma ação civil pública contra a Editora Objetiva e o Instituto Antônio Houaiss, solicitando a imediata retirada de circulação, suspensão de tiragem, venda e distribuição das edições do Dicionário Houaiss, sob a alegação de que a publicação é discriminatória e preconceituosa em relação à etnia cigana
A palavra cigano tem no dicionário como um de seus significados “que ou aquele que trapaceia; velhaco, burlador” e “que ou aquele que faz barganha, que é apegado ao dinheiro; agiota, sovina”
Estes termos são expressos para uso da palavra cigano de forma pejorativa, ou seja, de forma depreciativa.


